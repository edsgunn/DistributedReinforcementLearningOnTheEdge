{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a windy grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.9 -0.9 -0.9 -0.9 -0.9 \n",
      "0 0 0 0 0.0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.9 -0.9 -0.9 \n",
      "-0.9 -0.9 0 0 0.0 \n",
      "0 0 0 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -1.8009, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -1.629, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-1.8009 -1.719 -0.99 -0.99 -0.99 \n",
      "-1.719 -1.719 -1.719 -0.99 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.9 -0.9 \n",
      "-0.9 -0.9 -0.9 -0.9 0.0 \n",
      "-0.99 -0.9 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.537919, 4: -2.597868}, Best action: 1, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -3.13580439, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -3.13580439, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.46519, 2: -3.13580439, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -3.13580439, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -3.13580439, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -3.13580439, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -1.8747, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.8009, 2: -0.99, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.2923900000000006, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-2.546109 -1.8009 -1.719 -0.99 -0.99 \n",
      "-2.46429 -1.719 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -1.719 -0.99 -0.9 \n",
      "-0.99 -1.719 -0.99 -0.9 0.0 \n",
      "-0.99 -1.719 -0.99 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.6723979, 2: -3.13580439, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.6723979, 2: -3.13580439, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.6723979, 2: -3.13580439, 3: -3.27151197, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4798600000000004, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.2923900000000006, 3: -2.96234829, 4: 0}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-3.13580439 -1.8009 -1.719 -1.719 -0.99 \n",
      "-2.4724800000000005 -1.7919 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -1.719 -1.719 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.9 0.0 \n",
      "-0.99 -1.719 -0.99 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.16331469, 2: -3.13580439, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.6782038, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4798600000000004, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4798600000000004, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.4798600000000004, 2: -2.538819, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7919, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.8747, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.7280000000000002, 2: -1.7919, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.88199, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.88199, 2: -1.8009, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.88199, 2: -1.8009, 3: -1.8009, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.88199, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.88199, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8747, 2: -1.7919, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.2923900000000006, 3: -2.96234829, 4: -3.4400015559000003}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.672309439 -1.8009 -1.719 -1.719 -0.99 \n",
      "-2.538819 -1.8738000000000001 -1.719 -1.719 -0.99 \n",
      "-2.46429 -1.7919 -1.719 -1.719 -0.99 \n",
      "-1.8747 -1.719 -0.99 -0.9 0.0 \n",
      "-1.8009 -1.719 -0.999 0 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.16331469, 2: -2.672309439, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.531529, 2: -1.8009, 3: -2.6782038, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.531529, 2: -2.4724800000000005, 3: -2.6782038, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.531529, 2: -2.4724800000000005, 3: -2.6782038, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.531529, 2: -2.4724800000000005, 3: -2.6782038, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5963119, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -3.0818988000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.531529, 2: -2.5396380000000005, 3: -2.6782038, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.46519, 2: -2.46429, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.46429, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -1.7019, 2: -2.2923900000000006, 3: -2.96234829, 4: -3.4400015559000003}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-2.6259599439 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.538819 -2.46519 -2.46519 -1.8738000000000001 -1.719 \n",
      "-2.46429 -1.7919 -1.719 -1.719 -0.99 \n",
      "-1.8747 -1.719 -0.99 -0.9 0 \n",
      "-1.8009 -1.719 -0.999 0 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.540376, 2: -2.538819, 3: -3.2236822800000002, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.46519, 2: -2.538819, 3: -3.0818988000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.4798600000000004, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.5979579999999998, 2: -2.538819, 3: -3.0818988000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.538819, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8009, 2: -1.7280000000000002, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.8747, 2: -2.4715800000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -1.88199, 2: -1.8009, 3: -2.4724800000000005, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.590407, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.590407, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.590407, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.709919, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.709919, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.709919, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -1.378539, 3: -1.709919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -0.99, 2: -1.378539, 3: -1.709919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -1.8009, 2: -1.378539, 3: -1.709919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -3.1266333900000003, 2: -2.2923900000000006, 3: -2.96234829, 4: -3.4400015559000003}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-2.6259599439 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.540376 -2.546109 -2.538819 -1.8738000000000001 -1.719 \n",
      "-2.4724800000000005 -2.46519 -2.46429 -1.719 -0.99 \n",
      "-2.4715800000000003 -1.8738000000000001 -1.719 -0.99 0 \n",
      "-1.88199 -1.7919 -0.99999 -1.709919 -2.2923900000000006 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1492278000000002, 2: -2.5396380000000005, 3: -2.6782038, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.4724800000000005, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.629, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.629, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -0.99, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -1.8009, 3: -1.629, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -3.1266333900000003, 2: -3.1863457800000003, 3: -2.96234829, 4: -3.4400015559000003}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-2.6259599439 -2.597868 -2.5963119 -2.4724800000000005 -1.88199 \n",
      "-2.540376 -2.546109 -2.538819 -2.46519 -1.8738000000000001 \n",
      "-2.4724800000000005 -2.46519 -2.46429 -1.719 -1.719 \n",
      "-2.4715800000000003 -1.8738000000000001 -1.719 -0.99 -1.629 \n",
      "-1.88199 -1.7919 -0.99999 -1.709919 -2.96234829 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.16331469, 2: -2.6259599439, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1492278000000002, 2: -3.1566726000000007, 3: -2.6782038, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1492278000000002, 2: -3.1566726000000007, 3: -2.6782038, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1492278000000002, 2: -3.1566726000000007, 3: -2.6782038, 4: -3.26405988}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.16331469, 2: -3.2668690743899997, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.16331469, 2: -3.2668690743899997, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7738391409000003, 1: -3.16331469, 2: -3.2668690743899997, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.540376, 2: -3.1506858, 3: -3.2236822800000002, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.4798600000000004, 2: -3.1425039000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.4798600000000004, 2: -3.1425039000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.4798600000000004, 2: -3.1425039000000003, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.4715800000000003, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -2.590407, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8009, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8009, 2: -1.7280000000000002, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8009, 2: -1.7280000000000002, 3: -2.46429, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -1.629, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -2.3184899999999997, 3: -2.3823900000000005, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8009, 2: -2.3184899999999997, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8009, 2: -2.3184899999999997, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8009, 2: -2.3184899999999997, 3: -2.3823900000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -1.709919, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.99999, 3: -1.629, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -1.8809838, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -1.8809838, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7919, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -1.8809838, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46512439, 2: -2.3184899999999997, 3: -2.3823900000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -2.45529, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -2.45529, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -2.45529, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.80189, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -1.8747, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80189, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80189, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80189, 2: -1.88928, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.4798600000000004, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.538819, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80189, 2: -1.88928, 3: -2.530629, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4723819000000002, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -2.45529, 4: -2.60436339}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4723819000000002, 1: -2.5373560149000003, 2: -2.1967065900000002, 3: -2.45529, 4: -2.60436339}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4723819000000002, 1: -2.5373560149000003, 2: -2.8990029969000006, 3: -2.45529, 4: -2.60436339}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46512439, 2: -2.524239, 3: -2.3823900000000005, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.8009, 2: -1.8747, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -2.3923890000000005, 3: -1.629, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.88199, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -1.88199, 2: -2.4724800000000005, 3: -2.4724800000000005, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -1.88199, 2: -2.4724800000000005, 3: -2.4724800000000005, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -2.6126109, 2: -2.4724800000000005, 3: -2.4724800000000005, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.88199, 3: -2.6036019, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.88199, 3: -2.6036019, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.6126109, 2: -1.88199, 3: -2.6036019, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.39958, 2: -1.8747, 3: -2.46429, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46512439, 2: -2.524239, 3: -2.596968, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.5469109, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.664297, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -3.1499568000000004, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.8595213379000004, 2: -1.88928, 3: -2.530629, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.8595213379000004, 2: -1.88928, 3: -2.530629, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.8595213379000004, 2: -2.6192448, 3: -2.530629, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -2.46519, 2: -2.5469109, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.46512439, 2: -2.524239, 3: -2.596968, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -1.8809838, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -1.88199, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -2.6708409}, Best action: 1, Actual action: 1\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.6126109, 2: -2.3923890000000005, 3: -2.5143389999999997, 4: -2.6708409}, Best action: 2, Actual action: 2\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -2.1967065900000002, 2: -1.9946898000000004, 3: -2.4804883800000006, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -3.1266333900000003, 2: -3.1863457800000003, 3: -3.3232623835590003, 4: -3.4400015559000003}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-3.2668690743899997 -3.1492278000000002 -2.5963119 -2.5306290000000002 -2.4724800000000005 \n",
      "-2.546109 -2.546109 -2.5389090000000003 -2.546109 -2.546109 \n",
      "-2.546109 -2.46519 -2.46429 -2.546109 -2.589678 \n",
      "-2.4724800000000005 -2.46429 -2.39958 -2.524239 -2.4723819000000002 \n",
      "-2.4724800000000005 -2.46429 -2.5143389999999997 -2.1967065900000002 -3.1266333900000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1567464000000003, 2: -3.1506858, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1567464000000003, 2: -3.1506858, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1567464000000003, 2: -3.1506858, 3: -3.2236822800000002, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.2740360290000003, 2: -3.2668690743899997, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1492278000000002, 2: -3.1566726000000007, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0818988000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -2.5979579999999998, 2: -3.1506858, 3: -3.0818988000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.664936, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.4797700000000003, 3: -2.590407, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1425939, 2: -2.664936, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1425939, 2: -2.664936, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1425939, 2: -2.664936, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.4798600000000004, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.1432697559000005, 2: -2.5469109, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.1432697559000005, 2: -2.5469109, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.1432697559000005, 2: -2.5469109, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.8595213379000004, 2: -3.21173397, 3: -3.1498668, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6783028, 2: -3.2236822800000002, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6783028, 2: -3.2236822800000002, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6783028, 2: -3.2236822800000002, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.664297, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.664297, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.664297, 2: -3.1506858000000006, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.4798600000000004, 2: -3.20877729, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.39958, 2: -3.0835449, 3: -2.46429, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -3.0990961800000005, 2: -2.7549376380000004, 3: -2.5143389999999997, 4: -2.6708409}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.68567299, 2: -2.480589, 3: -2.6036019, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -2.46519, 2: -2.4797700000000003, 3: -2.590407, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -2.480589, 3: -2.6036019, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -3.0990961800000005, 2: -2.7549376380000004, 3: -3.1475088, 4: -2.6708409}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -3.1765725899999997, 2: -3.0835449, 3: -2.46429, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1557960900000004, 2: -2.4797700000000003, 3: -2.590407, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -3.1765725899999997, 2: -3.0835449, 3: -3.1550427, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.0916457999999998, 2: -3.20877729, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.0916457999999998, 2: -3.20877729, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.0916457999999998, 2: -3.20877729, 3: -3.0752649, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1425939, 2: -3.1625685, 3: -3.0752649, 4: -3.380294079}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.2236822800000002, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.2236822800000002, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.1567464000000003, 2: -3.1506858, 3: -3.2236822800000002, 4: -3.7246678470000005}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -3.1565997, 2: -3.1506858, 3: -3.0818988000000003, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.1567464000000003, 2: -3.7114066080000003, 3: -3.2236822800000002, 4: -3.7246678470000005}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.1499658000000004, 2: -3.1425039000000003, 3: -3.2236822800000002, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1425939, 2: -3.1625685, 3: -3.2698747800000003, 4: -3.380294079}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1557960900000004, 2: -3.19188159, 3: -2.590407, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1557960900000004, 2: -3.19188159, 3: -2.590407, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1557960900000004, 2: -3.19188159, 3: -2.590407, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.664936, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.664936, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.664936, 3: -3.1499568000000004, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.664936, 3: -3.27734397, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -2.546199, 2: -2.664936, 3: -3.27734397, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -3.1639698900000006, 2: -2.6716599, 3: -2.4724800000000005, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -3.1639698900000006, 2: -2.6716599, 3: -2.4724800000000005, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530629, 1: -3.1639698900000006, 2: -2.6716599, 3: -3.1499568000000004, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.590407, 1: -3.1573287000000008, 2: -2.664936, 3: -3.27734397, 4: -3.2841171090000003}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.1499658000000004, 2: -3.759751449, 3: -3.2236822800000002, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.1573287000000008, 2: -2.664936, 3: -3.27734397, 4: -3.2841171090000003}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.1557960900000004, 2: -3.19188159, 3: -3.1617495000000004, 4: -3.319925589}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -3.24628857, 3: -2.6036019, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -3.24628857, 3: -2.6036019, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -3.24628857, 3: -2.6036019, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.1639698900000006, 2: -2.6716599, 3: -3.2648051700000003, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.1639698900000006, 2: -2.6716599, 3: -3.2648051700000003, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.1639698900000006, 2: -2.6716599, 3: -3.2648051700000003, 4: -3.26405988}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -3.24628857, 3: -3.26463327, 4: -3.330613458}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.68567299, 2: -3.24628857, 3: -3.26463327, 4: -3.330613458}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -3.3439624209, 2: -3.24628857, 3: -3.26463327, 4: -3.330613458}, Best action: 0, Actual action: 0\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.2779278990000003, 2: -3.19188159, 3: -3.1617495000000004, 4: -3.319925589}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.1573287000000008, 2: -3.7226884329000005, 3: -3.27734397, 4: -3.2841171090000003}, Best action: 1, Actual action: 1\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.1639698900000006, 2: -3.3425611119000003, 3: -3.2648051700000003, 4: -3.3904505069999997}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.1639698900000006, 2: -3.3425611119000003, 3: -3.2648051700000003, 4: -3.3904505069999997}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25129257, 1: -3.779212599900001, 2: -3.3425611119000003, 3: -3.2648051700000003, 4: -3.3904505069999997}, Best action: 0, Actual action: 0\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.27734397, 4: -3.2841171090000003}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.27734397, 4: -3.2841171090000003}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.8823830127, 4: -3.2841171090000003}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.9483731595600005, 4: -3.2841171090000003}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7105129980000005, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.9483731595600005, 4: -3.8885465691900007}, Best action: 0, Actual action: 0\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.37359474, 2: -3.759751449, 3: -3.2236822800000002, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.37359474, 2: -3.759751449, 3: -3.2236822800000002, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.37359474, 2: -3.759751449, 3: -3.8335508748000002, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.37359474, 2: -3.759751449, 3: -3.9720165176700006, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -3.37359474, 2: -3.759751449, 3: -3.9720165176700006, 4: -3.9205949400900004}, Best action: 1, Actual action: 1\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8822339466000004, 1: -3.778548480900001, 2: -3.7226884329000005, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 2, Actual action: 2\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.2779278990000003, 2: -3.19188159, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 2, Actual action: 2\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1765725899999997, 2: -3.0835449, 3: -3.1550427, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1765725899999997, 2: -3.0835449, 3: -3.1550427, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1765725899999997, 2: -3.0835449, 3: -3.1550427, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.670109317, 2: -2.524239, 3: -2.596968, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4723819000000002, 1: -2.5373560149000003, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -2.60436339}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.8595213379000004, 2: -3.21173397, 3: -3.1498668, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.8595213379000004, 2: -3.21173397, 3: -3.1498668, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.8595213379000004, 2: -3.21173397, 3: -3.1498668, 4: -3.26405988}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -2.5373560149000003, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -2.60436339}, Best action: 1, Actual action: 1\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -3.275011629, 2: -3.1863457800000003, 3: -3.3232623835590003, 4: -3.4400015559000003}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-3.27151197 -3.1566726000000007 -2.5963119 -2.5306290000000002 -2.4724800000000005 \n",
      "-3.2236822800000002 -3.13791849 -2.546109 -2.6117919 -2.6117919 \n",
      "-3.711023298 -3.1625685 -3.0916457999999998 -3.0752649 -3.1498668 \n",
      "-3.778548480900001 -3.20877729 -3.1550427 -2.596968 -2.60436339 \n",
      "-3.2648051700000003 -3.24628857 -2.6708409 -2.1967065900000002 -3.1863457800000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2772710700000003, 2: -3.1566726000000007, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -2.5963119, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2772710700000003, 2: -3.318679899, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2772710700000003, 2: -3.318679899, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2772710700000003, 2: -3.318679899, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.13791849, 1: -3.1565997, 2: -3.1506858, 3: -3.765154464, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.318679899, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.7224468009000007, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.2104071900000006, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.1565997, 2: -3.1506858, 3: -3.765154464, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.711023298, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.664297, 2: -3.1506858000000006, 3: -3.2154840900000004, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.282054039, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.1499568000000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6783028, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.386330928}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.282054039, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.282054039, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.282054039, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7731757509, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -2.6783028, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.2412105058590006, 2: -3.21173397, 3: -3.1498668, 4: -3.5426182716990002}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.1432697559000005, 2: -3.2523302700000003, 3: -3.0752649, 4: -3.2846937479999996}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.0916457999999998, 2: -3.20877729, 3: -3.698491059, 4: -3.712660488}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1765725899999997, 2: -3.25298808, 3: -3.1550427, 4: -3.719367288}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20877729, 1: -3.2779278990000003, 2: -3.281536449, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.27660768, 2: -3.1625685, 3: -3.2698747800000003, 4: -3.380294079}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.764749167, 2: -3.20877729, 3: -3.698491059, 4: -3.712660488}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.1625775000000003, 2: -3.1506858, 3: -3.711023298, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -2.664297, 2: -3.1506858000000006, 3: -3.2154840900000004, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.1432697559000005, 2: -3.2523302700000003, 3: -3.7117595879999996, 4: -3.2846937479999996}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.670109317, 2: -3.1550532390000003, 3: -2.596968, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1765725899999997, 2: -3.25298808, 3: -3.8146138749, 4: -3.719367288}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -2.7549376380000004, 3: -3.1475088, 4: -2.6708409}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -2.7549376380000004, 3: -3.1475088, 4: -2.6708409}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -2.7549376380000004, 3: -3.1475088, 4: -3.330465219}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -2.1967065900000002, 2: -2.7320420259000007, 3: -2.4804883800000006, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -2.1967065900000002, 2: -2.7320420259000007, 3: -2.4804883800000006, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -2.8990029969000006, 2: -2.7320420259000007, 3: -2.4804883800000006, 4: -2.597868}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -2.9548261017000006, 3: -3.1475088, 4: -3.46454600868}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -3.199095887490001, 2: -2.7320420259000007, 3: -3.5414579803770003, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -3.199095887490001, 2: -2.7320420259000007, 3: -3.5414579803770003, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -3.199095887490001, 2: -2.7320420259000007, 3: -3.5414579803770003, 4: -3.26405988}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.23476064559, 1: -3.275011629, 2: -3.7755393840000004, 3: -3.3232623835590003, 4: -3.4400015559000003}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.27151197 -3.3420459699000005 -3.2766805800000003 -3.282054039 -3.3251736600000004 \n",
      "-3.2236822800000002 -3.1565997 -3.1625775000000003 -3.1506858000000006 -3.22131609 \n",
      "-3.711023298 -3.20287239 -3.20877729 -3.1550427 -3.21173397 \n",
      "-3.778548480900001 -3.2779278990000003 -3.21468219 -2.6051580000000003 -2.60436339 \n",
      "-3.2648051700000003 -3.24628857 -3.0990961800000005 -2.8933603255179006 -3.23476064559 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.2740360290000003, 2: -3.7775614254390004, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.2740360290000003, 2: -3.7775614254390004, 3: -3.27151197, 4: -3.3863382179999997}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.2740360290000003, 2: -3.7775614254390004, 3: -3.8770758927, 4: -3.3863382179999997}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.7114066080000003, 3: -3.2236822800000002, 4: -3.7246678470000005}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.7114066080000003, 3: -3.2236822800000002, 4: -3.7246678470000005}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.7114066080000003, 3: -3.8335508748000002, 4: -3.7246678470000005}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.1565997, 2: -3.330620019, 3: -3.765154464, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.27660768, 2: -3.8105834859, 3: -3.2698747800000003, 4: -3.380294079}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -3.330620019, 3: -3.765154464, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -3.330620019, 3: -3.765154464, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -3.330620019, 3: -3.765154464, 4: -3.92669812809}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.1625775000000003, 2: -3.37314915, 3: -3.711023298, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.764749167, 2: -3.20877729, 3: -3.698491059, 4: -3.712660488}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.31787105559, 2: -3.2523302700000003, 3: -3.7117595879999996, 4: -3.2846937479999996}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.7124782022790006, 2: -3.1506858000000006, 3: -3.2154840900000004, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.7124782022790006, 2: -3.8243346129000004, 3: -3.2154840900000004, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8153673549000002, 2: -3.37314915, 3: -3.711023298, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8153673549000002, 2: -3.37314915, 3: -3.711023298, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8153673549000002, 2: -3.37314915, 3: -3.711023298, 4: -3.9205949400900004}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.7124782022790006, 2: -3.8243346129000004, 3: -3.9102098391900006, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.7124782022790006, 2: -3.8243346129000004, 3: -3.9102098391900006, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.7124782022790006, 2: -3.8243346129000004, 3: -3.9102098391900006, 4: -3.9205949400900004}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.31787105559, 2: -3.2523302700000003, 3: -3.7117595879999996, 4: -3.2846937479999996}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.2412105058590006, 2: -3.21173397, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.2412105058590006, 2: -3.21173397, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.2412105058590006, 2: -3.8226779127, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.2236822800000002, 3: -3.8266737219, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.2236822800000002, 3: -3.8266737219, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.8335508748000002, 3: -3.8266737219, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.9720165176700006, 3: -3.8266737219, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.719222388, 2: -3.9720165176700006, 3: -3.8266737219, 4: -3.9205949400900004}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3976379619, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3976379619, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3976379619, 2: -3.9259080306000005, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3976379619, 2: -4.03551885474, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3976379619, 2: -4.03551885474, 3: -3.7777293909000007, 4: -3.98156114448}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9645887454000004, 1: -3.719222388, 2: -3.9720165176700006, 3: -3.8266737219, 4: -4.298763948489}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.2412105058590006, 2: -3.89153382417, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -2.8346756832900004, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -2.60436339}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -2.8346756832900004, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -2.60436339}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -2.8346756832900004, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -3.2699706849}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.873400760259, 1: -3.275011629, 2: -3.7755393840000004, 3: -3.3232623835590003, 4: -3.4400015559000003}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-3.3863382179999997 -3.3420459699000005 -3.2766805800000003 -3.282054039 -3.7777293909000007 \n",
      "-3.7246678470000005 -3.765154464 -3.711023298 -3.7126441980000005 -3.8266737219 \n",
      "-3.711023298 -3.2698747800000003 -3.698491059 -3.2846937479999996 -3.3336553964859004 \n",
      "-3.778548480900001 -3.2779278990000003 -3.21468219 -2.6051580000000003 -2.9362269878190004 \n",
      "-3.2648051700000003 -3.24628857 -3.0990961800000005 -2.8933603255179006 -3.275011629 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.8279864178, 3: -4.289594439960001, 4: -3.7246678470000005}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.8279864178, 3: -4.289594439960001, 4: -3.7246678470000005}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -3.7611027990000006, 2: -3.8279864178, 3: -4.289594439960001, 4: -4.289447740770001}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711023298, 1: -4.252737104649, 2: -3.759751449, 3: -3.9720165176700006, 4: -4.024671233409}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -4.28203915128, 2: -3.8279864178, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -3.7947497769000003, 3: -3.765154464, 4: -3.990472028199}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8551728302559, 1: -4.28203915128, 2: -4.3325737576200005, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.8385862497000005, 2: -3.7775614254390004, 3: -3.9396767727600004, 4: -3.3863382179999997}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.8385862497000005, 2: -3.7775614254390004, 3: -3.9396767727600004, 4: -3.3863382179999997}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.8385862497000005, 2: -3.7775614254390004, 3: -3.9396767727600004, 4: -3.9815677783800005}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.3420459699000005, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.2766805800000003, 2: -3.3312186990000003, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8153673549000002, 2: -3.9259763451900005, 3: -3.711023298, 4: -4.024310305509}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -3.7947497769000003, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8153673549000002, 2: -3.9259763451900005, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.3312186990000003, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.282054039, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.9056353389279006, 2: -3.8243346129000004, 3: -3.9102098391900006, 4: -4.29916683785499}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.98102379858}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -3.7224468009000007, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -3.7224468009000007, 4: -3.93749878068}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.88831586679, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.88831586679, 3: -3.7258530219000003, 4: -3.395751066}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.88831586679, 3: -3.7258530219000003, 4: -3.99013347006}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -3.8385862497000005, 2: -3.9848133781629005, 3: -3.9396767727600004, 4: -4.35798153244359}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.02845123960559, 1: -4.28203915128, 2: -4.3325737576200005, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -4.546904129050528, 2: -3.9848133781629005, 3: -3.9396767727600004, 4: -4.35798153244359}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83966881299, 1: -4.546904129050528, 2: -3.9848133781629005, 3: -3.9396767727600004, 4: -4.35798153244359}, Best action: 0, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -3.9848133781629005, 3: -3.9396767727600004, 4: -4.35798153244359}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -3.9848133781629005, 3: -4.4851058632116, 4: -4.35798153244359}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -3.7694410839000003, 2: -3.88831586679, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.8099866059000003, 2: -4.295910766419, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.27660768, 2: -3.8105834859, 3: -3.2698747800000003, 4: -3.380294079}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -3.759751449, 3: -3.9720165176700006, 4: -4.024671233409}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.27660768, 2: -3.8105834859, 3: -4.27238615169, 4: -3.380294079}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.2779278990000003, 2: -3.281536449, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.24628857, 3: -3.26463327, 4: -3.330613458}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -3.29975569017, 3: -3.1475088, 4: -3.46454600868}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.0990961800000005, 2: -3.29975569017, 3: -3.1475088, 4: -3.46454600868}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.7201775238000008, 2: -3.29975569017, 3: -3.1475088, 4: -3.46454600868}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.7348967628000005, 3: -3.26463327, 4: -3.330613458}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.3425611119000003, 3: -3.2648051700000003, 4: -3.3904505069999997}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.3425611119000003, 3: -3.2648051700000003, 4: -3.3904505069999997}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.3425611119000003, 3: -3.8709727047000007, 4: -3.3904505069999997}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.7348967628000005, 3: -3.8709555147000003, 4: -3.330613458}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.7348967628000005, 3: -3.8709555147000003, 4: -3.330613458}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.7348967628000005, 3: -3.8709555147000003, 4: -3.93085824678}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1551156000000002, 1: -3.82149988038, 2: -3.29975569017, 3: -3.8591038287000003, 4: -3.46454600868}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.381038388, 2: -3.25298808, 3: -3.8146138749, 4: -3.719367288}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.764749167, 2: -3.776462316, 3: -3.698491059, 4: -3.712660488}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.8827823661900003, 2: -3.8105834859, 3: -4.27238615169, 4: -3.380294079}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.8827823661900003, 2: -3.8105834859, 3: -4.27238615169, 4: -3.380294079}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.8827823661900003, 2: -3.8105834859, 3: -4.27238615169, 4: -3.97606761189}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.764749167, 2: -3.776462316, 3: -4.00788730989, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.764749167, 2: -3.776462316, 3: -4.00788730989, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.764749167, 2: -3.776462316, 3: -4.00788730989, 4: -4.27852104408}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.381038388, 2: -3.25298808, 3: -3.8146138749, 4: -3.719367288}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.670109317, 2: -3.1550532390000003, 3: -3.7327205979, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.670109317, 2: -3.1550532390000003, 3: -3.7327205979, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -2.670109317, 2: -3.1550532390000003, 3: -3.7327205979, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -3.199095887490001, 2: -2.8933603255179006, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.873400760259, 1: -4.244482118970001, 2: -3.7755393840000004, 3: -3.3232623835590003, 4: -3.4400015559000003}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-4.35172861577529 -3.88831586679 -3.8783510838900006 -3.7792125999 -3.7777293909000007 \n",
      "-4.28203915128 -3.90192256719 -3.8153673549000002 -3.8243346129000004 -3.8266737219 \n",
      "-3.9300273657 -3.8827823661900003 -3.7723427370000002 -3.2846937479999996 -3.3336553964859004 \n",
      "-3.778548480900001 -3.281536449 -3.3354767880000002 -3.1425039000000003 -2.9362269878190004 \n",
      "-3.3904505069999997 -3.7753403850000002 -3.29975569017 -2.9571669 -3.3232623835590003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -4.35172861577529, 3: -4.576209422633109, 4: -4.35798153244359}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -4.363033259169001, 2: -3.88831586679, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -4.02280304355, 4: -4.308931786797}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -4.02280304355, 4: -4.308931786797}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.429299486339901, 1: -4.233596929380001, 2: -3.8915856414900003, 3: -4.02280304355, 4: -4.308931786797}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -3.7792125999, 3: -3.97362315078, 4: -4.294417483548}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -4.252333930470001, 2: -4.03551885474, 3: -3.7777293909000007, 4: -4.050242863587}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -4.3378820666190006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -4.235447204280001, 2: -4.3378820666190006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.434678318798901, 1: -4.235447204280001, 2: -4.3378820666190006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.233596929380001, 2: -4.350320770068, 3: -4.02280304355, 4: -4.308931786797}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -4.363033259169001, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9325108266900006, 1: -4.363033259169001, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4785848522879, 1: -4.363033259169001, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.363033259169001, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.316954294745001}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.363033259169001, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.828428408217951}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.90192256719, 1: -3.9295972323900004, 2: -4.295910766419, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.4968606053408005, 2: -4.430295964629901, 3: -4.381840164447001, 4: -4.916899780748686}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -4.484708713677429, 3: -4.576209422633109, 4: -4.35798153244359}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -4.484708713677429, 3: -4.576209422633109, 4: -4.35798153244359}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -4.484708713677429, 3: -4.576209422633109, 4: -4.865763194523667}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4751050672346, 1: -4.546904129050528, 2: -4.484708713677429, 3: -4.576209422633109, 4: -5.011411423912393}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.972345611183487, 1: -4.546904129050528, 2: -4.484708713677429, 3: -4.576209422633109, 4: -5.011411423912393}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.4968606053408005, 2: -4.430295964629901, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.233596929380001, 2: -4.350320770068, 3: -4.4876140739739006, 4: -4.308931786797}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -3.8153673549000002, 2: -3.9259763451900005, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7723427370000002, 1: -3.9113952615, 2: -3.776462316, 3: -4.00788730989, 4: -4.377298929678}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.33713435246, 2: -3.9259763451900005, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9056353389279006, 2: -3.8243346129000004, 3: -3.9102098391900006, 4: -4.29916683785499}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9645887454000004, 1: -3.8973027485457905, 2: -3.9720165176700006, 3: -3.8266737219, 4: -4.298763948489}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9056353389279006, 2: -4.382039176029, 3: -3.9102098391900006, 4: -4.29916683785499}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.31787105559, 2: -3.8267375427, 3: -3.7117595879999996, 4: -3.2846937479999996}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.31787105559, 2: -3.8267375427, 3: -3.7117595879999996, 4: -3.2846937479999996}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.31787105559, 2: -3.8267375427, 3: -3.7117595879999996, 4: -3.8890713106799994}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1425039000000003, 1: -3.5106327953694993, 2: -3.1550532390000003, 3: -3.7327205979, 4: -3.3898579247700003}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.7772152645590005, 2: -3.8267375427, 3: -3.7117595879999996, 4: -3.9763826860958997}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -3.9113952615, 2: -3.776462316, 3: -4.00788730989, 4: -4.377298929678}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.7772152645590005, 2: -3.8267375427, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9511654697727896, 2: -4.382039176029, 3: -3.9102098391900006, 4: -4.29916683785499}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.33713435246, 2: -4.390308670968, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.413807250407, 2: -4.350320770068, 3: -4.4876140739739006, 4: -4.308931786797}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.413807250407, 2: -4.350320770068, 3: -4.4876140739739006, 4: -4.308931786797}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.413807250407, 2: -4.350320770068, 3: -4.4876140739739006, 4: -4.82112792598527}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.235447204280001, 2: -4.3378820666190006, 3: -4.5558327803535, 4: -4.294417483548}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9511654697727896, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.29916683785499}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -3.7772152645590005, 2: -3.8267375427, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.5106327953694993, 2: -3.1550532390000003, 3: -3.7327205979, 4: -3.3898579247700003}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -2.9362269878190004, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -3.5230843719549005}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.873400760259, 1: -4.244482118970001, 2: -3.7755393840000004, 3: -4.757226417133885, 4: -3.4400015559000003}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-4.546904129050528 -4.4968606053408005 -4.413807250407 -4.294417483548 -3.9358403956800005 \n",
      "-4.28203915128 -3.9295972323900004 -4.024310305509 -4.01371417458 -3.8973027485457905 \n",
      "-3.9300273657 -3.8827823661900003 -3.9113952615 -3.8267375427 -3.3336553964859004 \n",
      "-3.778548480900001 -3.281536449 -3.3354767880000002 -3.3898579247700003 -3.0752649000000005 \n",
      "-3.3904505069999997 -3.7753403850000002 -3.29975569017 -2.9571669 -3.4400015559000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -4.546904129050528, 2: -4.9370106027179625, 3: -4.576209422633109, 4: -5.011411423912393}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.28203915128, 2: -4.3325737576200005, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -3.9300273657, 3: -3.9720165176700006, 4: -4.024671233409}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.8827823661900003, 2: -4.2883133438700005, 3: -4.27238615169, 4: -4.384179384768}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.8572865316, 2: -3.281536449, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.381038388, 2: -3.3354767880000002, 3: -3.8146138749, 4: -3.719367288}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.5106327953694993, 2: -3.5938491840333904, 3: -3.7327205979, 4: -3.3898579247700003}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.5106327953694993, 2: -3.5938491840333904, 3: -3.7327205979, 4: -3.3898579247700003}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.5106327953694993, 2: -3.5938491840333904, 3: -3.7327205979, 4: -3.9847707115407}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9571669, 1: -3.199095887490001, 2: -2.98117856323458, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.64636846853695, 2: -3.5938491840333904, 3: -3.7327205979, 4: -4.142089635403364}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -3.0800239590609007, 2: -3.1786851996900003, 3: -3.0752649000000005, 4: -3.5230843719549005}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.64636846853695, 2: -3.75034948740334, 3: -3.7327205979, 4: -4.142089635403364}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.199095887490001, 2: -2.98117856323458, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.873400760259, 1: -4.244482118970001, 2: -3.7755393840000004, 3: -4.757226417133885, 4: -4.926992500120928}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-4.576209422633109 -4.4968606053408005 -4.413807250407 -4.294417483548 -3.9358403956800005 \n",
      "-4.289594439960001 -3.9295972323900004 -4.024310305509 -4.01371417458 -3.8973027485457905 \n",
      "-3.9720165176700006 -3.9143811771899997 -3.9113952615 -3.8267375427 -3.3336553964859004 \n",
      "-3.778548480900001 -3.319925589 -3.381038388 -3.679391483073705 -3.0800239590609007 \n",
      "-3.3904505069999997 -3.7753403850000002 -3.29975569017 -3.199095887490001 -3.7755393840000004 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.4968606053408005, 2: -4.772243109260791, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -3.9295972323900004, 2: -4.295910766419, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.946322760309, 2: -4.2883133438700005, 3: -4.27238615169, 4: -4.384179384768}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.4636084767629, 2: -4.295910766419, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.4636084767629, 2: -4.295910766419, 3: -4.39920543890728, 4: -3.990472028199}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.4636084767629, 2: -4.295910766419, 3: -4.39920543890728, 4: -4.53132954566109}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.33713435246, 2: -4.390308670968, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.33713435246, 2: -4.390308670968, 3: -4.344849649088999, 4: -4.024310305509}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.33713435246, 2: -4.390308670968, 3: -4.344849649088999, 4: -4.562122378013191}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -3.9113952615, 2: -4.32936964368, 3: -4.00788730989, 4: -4.377298929678}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.381038388, 2: -3.9793325978636997, 3: -3.8146138749, 4: -3.719367288}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8194041339, 1: -3.82149988038, 2: -3.29975569017, 3: -3.8591038287000003, 4: -3.46454600868}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.199095887490001, 2: -3.3563047573634583, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.199095887490001, 2: -3.3563047573634583, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.811177257615901, 2: -3.3563047573634583, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.873400760259, 1: -4.244482118970001, 2: -4.920011028726049, 3: -4.757226417133885, 4: -4.926992500120928}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.576209422633109 -4.5326598187699805 -4.413807250407 -4.294417483548 -3.9358403956800005 \n",
      "-4.289594439960001 -4.39920543890728 -4.344849649088999 -4.01371417458 -3.8973027485457905 \n",
      "-3.9720165176700006 -3.946322760309 -4.00788730989 -3.8267375427 -3.3336553964859004 \n",
      "-3.778548480900001 -3.319925589 -3.719367288 -3.679391483073705 -3.0800239590609007 \n",
      "-3.3904505069999997 -3.7753403850000002 -3.46454600868 -3.4393600289790003 -3.873400760259 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -4.823142125441853, 2: -4.9370106027179625, 3: -4.576209422633109, 4: -5.011411423912393}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -4.823142125441853, 2: -4.9370106027179625, 3: -4.576209422633109, 4: -5.011411423912393}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -4.823142125441853, 2: -4.9370106027179625, 3: -5.06435057459613, 4: -5.011411423912393}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.3325737576200005, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.3325737576200005, 3: -4.289594439960001, 4: -4.375438041267}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.3325737576200005, 3: -4.8035309403636015, 4: -4.375438041267}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.4636084767629, 2: -4.589282424104191, 3: -4.39920543890728, 4: -4.832820675365499}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.375438041267}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.375438041267}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.412976862482458, 1: -4.511526081345, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.881648617552971}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -4.856885708911786, 2: -4.9370106027179625, 3: -5.313180179067514, 4: -5.011411423912393}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.511526081345, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.962676120366089}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -4.438056453183901, 3: -3.9720165176700006, 4: -4.024671233409}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -4.438056453183901, 3: -3.9720165176700006, 4: -4.024671233409}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -4.438056453183901, 3: -4.514535031079701, 4: -4.024671233409}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -4.438056453183901, 3: -4.6114372021692605, 4: -4.024671233409}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.252737104649, 2: -4.438056453183901, 3: -4.6114372021692605, 4: -4.56245082240219}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8822339466000004, 1: -3.778548480900001, 2: -3.85769293119, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -3.3904505069999997}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -3.3904505069999997}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8797778727, 1: -3.91146824169, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -3.9853099613699996}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8822339466000004, 1: -4.0241197587599995, 2: -3.85769293119, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.8572865316, 2: -3.9298898431800007, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.8572865316, 2: -3.9298898431800007, 3: -3.7736111970000006, 4: -3.319925589}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.8572865316, 2: -3.9298898431800007, 3: -3.7736111970000006, 4: -3.9211322859899997}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8822339466000004, 1: -4.0241197587599995, 2: -3.9749090202089996, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.371771328218, 1: -4.3858979799939, 2: -4.438056453183901, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.5684859874472, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.962676120366089}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.3858979799939, 2: -4.438056453183901, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.0241197587599995, 2: -3.9749090202089996, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.0241197587599995, 2: -3.9749090202089996, 3: -3.9483731595600005, 4: -4.294370185299001}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.0241197587599995, 2: -3.9749090202089996, 3: -4.493019575199601, 4: -4.294370185299001}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7825582140000003, 1: -3.8572865316, 2: -3.9298898431800007, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -3.946322760309, 2: -4.2883133438700005, 3: -4.27238615169, 4: -4.384179384768}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -3.8572865316, 2: -3.9298898431800007, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7753403850000002, 1: -3.7804148910900004, 2: -3.82913331228, 3: -3.8709555147000003, 4: -4.3183522025459995}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.343754365010001, 2: -3.9298898431800007, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.9109059478377004, 2: -3.9793325978636997, 3: -3.8146138749, 4: -3.719367288}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.9109059478377004, 2: -3.9793325978636997, 3: -3.8146138749, 4: -3.719367288}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.9109059478377004, 2: -3.9793325978636997, 3: -3.8146138749, 4: -4.2846242320800005}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.343754365010001, 2: -4.305676487598, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -3.9109059478377004, 2: -3.9793325978636997, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8194041339, 1: -3.82149988038, 2: -3.8212432378839005, 3: -3.8591038287000003, 4: -3.46454600868}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8194041339, 1: -3.82149988038, 2: -3.8212432378839005, 3: -3.8591038287000003, 4: -3.46454600868}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8194041339, 1: -3.82149988038, 2: -3.8212432378839005, 3: -3.8591038287000003, 4: -4.052736867898801}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -4.097372861814571, 2: -3.9793325978636997, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -3.679391483073705, 2: -3.75034948740334, 3: -3.7327205979, 4: -4.142089635403364}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -3.4730850915461358, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -3.4730850915461358, 3: -3.5414579803770003, 4: -3.4393600289790003}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -3.4730850915461358, 3: -3.5414579803770003, 4: -4.029817626370891}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.994069708358719, 1: -4.244482118970001, 2: -4.920011028726049, 3: -4.757226417133885, 4: -4.926992500120928}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-4.9370106027179625 -4.5326598187699805 -4.413807250407 -4.294417483548 -3.9358403956800005 \n",
      "-4.8897378377085605 -4.4636084767629 -4.344849649088999 -4.01371417458 -3.8973027485457905 \n",
      "-4.438056453183901 -4.27238615169 -4.00788730989 -3.8267375427 -3.3336553964859004 \n",
      "-4.0241197587599995 -4.343754365010001 -4.097372861814571 -3.7327205979 -3.0800239590609007 \n",
      "-3.91146824169 -3.7804148910900004 -3.8212432378839005 -3.5414579803770003 -4.244482118970001 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.909425962539779, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.962676120366089}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.909425962539779, 2: -4.896613781276897, 3: -4.8897378377085605, 4: -4.962676120366089}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.909425962539779, 2: -4.896613781276897, 3: -5.34966143231479, 4: -4.962676120366089}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.4636084767629, 2: -4.589282424104191, 3: -4.8840253573169985, 4: -4.832820675365499}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.4190343666269, 2: -4.2883133438700005, 3: -4.27238615169, 4: -4.384179384768}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.536772057242991, 2: -4.438056453183901, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.4190343666269, 2: -4.2883133438700005, 3: -4.9220643422479595, 4: -4.384179384768}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.0297806204299995, 2: -4.32936964368, 3: -4.00788730989, 4: -4.377298929678}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.4190343666269, 2: -4.5752200553979, 3: -4.9220643422479595, 4: -4.384179384768}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.4190343666269, 2: -4.5752200553979, 3: -4.9220643422479595, 4: -4.384179384768}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.4190343666269, 2: -4.5752200553979, 3: -4.9220643422479595, 4: -4.8896032401388805}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.343754365010001, 2: -4.498401466508337, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -3.7804148910900004, 2: -3.82913331228, 3: -3.8709555147000003, 4: -4.3183522025459995}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -3.7804148910900004, 2: -3.82913331228, 3: -3.8709555147000003, 4: -4.3183522025459995}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.340177550891901, 2: -3.82913331228, 3: -3.8709555147000003, 4: -4.3183522025459995}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -3.82149988038, 2: -3.8212432378839005, 3: -3.8591038287000003, 4: -4.39899103524888}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -3.7853390255203143, 3: -3.5414579803770003, 4: -4.116180686789459}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -3.82149988038, 2: -4.150705287893761, 3: -3.8591038287000003, 4: -4.39899103524888}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -3.82149988038, 2: -4.150705287893761, 3: -3.8591038287000003, 4: -4.39899103524888}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.3775648911458, 2: -4.150705287893761, 3: -3.8591038287000003, 4: -4.39899103524888}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.37812035391396, 3: -3.8709555147000003, 4: -4.3183522025459995}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -3.91146824169, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -4.441151073024001}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -3.91146824169, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -4.441151073024001}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -4.4594360999379, 2: -3.9320530121700004, 3: -3.9945717711090007, 4: -4.441151073024001}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.37812035391396, 3: -4.4553848272389, 4: -4.3183522025459995}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.37812035391396, 3: -4.4553848272389, 4: -4.3183522025459995}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.37812035391396, 3: -4.4553848272389, 4: -4.829700504316859}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.150705287893761, 3: -4.421384349777, 4: -4.39899103524888}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -3.7853390255203143, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.994069708358719, 1: -5.285135860440934, 2: -4.920011028726049, 3: -4.757226417133885, 4: -4.926992500120928}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-4.9370106027179625 -4.5326598187699805 -4.413807250407 -4.294417483548 -3.9358403956800005 \n",
      "-4.909425962539779 -4.589282424104191 -4.344849649088999 -4.01371417458 -3.8973027485457905 \n",
      "-4.536772057242991 -4.52372046056019 -4.0297806204299995 -3.8267375427 -3.3336553964859004 \n",
      "-4.0241197587599995 -4.348738298169001 -4.097372861814571 -3.7327205979 -3.0800239590609007 \n",
      "-3.9945717711090007 -4.43561573803599 -4.38119513946083 -3.9997245792259912 -4.757226417133885 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -5.040024696780629, 2: -4.9370106027179625, 3: -5.313180179067514, 4: -5.011411423912393}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -4.5326598187699805, 2: -4.772243109260791, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.806993630545191, 2: -4.589282424104191, 3: -4.8840253573169985, 4: -4.832820675365499}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.5019435970610004, 2: -4.390308670968, 3: -4.344849649088999, 4: -4.869291063293919}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -4.806993630545191, 2: -4.878256458172508, 3: -4.8840253573169985, 4: -4.832820675365499}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.52372046056019, 1: -4.860344472320791, 2: -4.5752200553979, 3: -4.9220643422479595, 4: -4.968378160981677}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -5.044912936108273, 2: -4.878256458172508, 3: -4.8840253573169985, 4: -4.832820675365499}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -5.044912936108273, 2: -4.878256458172508, 3: -4.8840253573169985, 4: -4.832820675365499}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.839482789921071, 1: -5.044912936108273, 2: -4.878256458172508, 3: -4.8840253573169985, 4: -5.297866814582605}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -5.070584745401392, 2: -4.772243109260791, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.413807250407, 2: -4.7657443124736005, 3: -4.4876140739739006, 4: -4.905872616353607}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.5019435970610004, 2: -4.390308670968, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -4.354660911270069, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.29916683785499}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.52398875094396, 2: -4.3378820666190006, 3: -4.5558327803535, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.52398875094396, 2: -4.3378820666190006, 3: -4.5558327803535, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.52398875094396, 2: -4.3378820666190006, 3: -4.5558327803535, 4: -4.80791991002868}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -4.252333930470001, 2: -4.03551885474, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -4.252333930470001, 2: -4.03551885474, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4816147600688, 1: -4.252333930470001, 2: -4.03551885474, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.252333930470001, 2: -4.03551885474, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.252333930470001, 2: -4.5723221578134, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.252333930470001, 2: -4.63792893528681, 3: -4.4240250690099, 4: -4.050242863587}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.252333930470001, 2: -4.63792893528681, 3: -4.4240250690099, 4: -4.585721005864171}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9645887454000004, 1: -3.8973027485457905, 2: -3.9720165176700006, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.3336553964859004, 2: -3.89153382417, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -3.0800239590609007, 2: -3.1786851996900003, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.994069708358719, 1: -5.285135860440934, 2: -4.920011028726049, 3: -5.374701229914939, 4: -4.926992500120928}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.011411423912393 -4.8445914639722405 -4.4876140739739006 -4.5218189271627 -4.4240250690099 \n",
      "-4.909425962539779 -4.878256458172508 -4.5019435970610004 -4.29916683785499 -3.9645887454000004 \n",
      "-4.536772057242991 -4.5752200553979 -4.0297806204299995 -3.8267375427 -3.5426182716990002 \n",
      "-4.0241197587599995 -4.348738298169001 -4.097372861814571 -3.7327205979 -3.1786851996900003 \n",
      "-3.9945717711090007 -4.43561573803599 -4.38119513946083 -3.9997245792259912 -4.920011028726049 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -5.070584745401392, 2: -4.952408183755749, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8445914639722405, 1: -5.070584745401392, 2: -4.952408183755749, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.308578232214739, 1: -5.070584745401392, 2: -4.952408183755749, 3: -4.868149057724008, 4: -4.916899780748686}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -5.040024696780629, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.011411423912393}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -5.040024696780629, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.011411423912393}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -5.040024696780629, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.460384395760278}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029848619197066, 1: -5.040024696780629, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.520215821125651}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.47716224346933, 1: -5.040024696780629, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.520215821125651}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -4.909425962539779, 2: -5.00518424430564, 3: -5.4012233060657655, 4: -4.962676120366089}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.536772057242991, 2: -4.817339453853091, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.0241197587599995, 2: -4.3613630553609, 3: -4.5689782638892495, 4: -4.294370185299001}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -4.53090654985149, 2: -4.79107058527926, 3: -3.9945717711090007, 4: -4.441151073024001}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -4.53090654985149, 2: -4.79107058527926, 3: -3.9945717711090007, 4: -4.441151073024001}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4127090615339, 1: -4.53090654985149, 2: -4.79107058527926, 3: -4.535060311709191, 4: -4.441151073024001}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.538015110474291, 2: -4.3613630553609, 3: -4.5689782638892495, 4: -4.294370185299001}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8293581705165805, 1: -4.538015110474291, 2: -4.3613630553609, 3: -4.5689782638892495, 4: -4.294370185299001}, Best action: 4, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.613214210319899, 2: -4.817339453853091, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.613214210319899, 2: -4.817339453853091, 3: -4.6114372021692605, 4: -4.800962137005909}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.613214210319899, 2: -4.817339453853091, 3: -5.096407853974027, 4: -4.800962137005909}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -4.538015110474291, 2: -4.3613630553609, 3: -4.5689782638892495, 4: -5.241217136648331}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.396511498283901, 2: -4.498401466508337, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.396511498283901, 2: -4.498401466508337, 3: -4.421970616446001, 4: -4.348738298169001}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.396511498283901, 2: -4.498401466508337, 3: -4.421970616446001, 4: -4.8573518513337905}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.699883318585343, 3: -4.4553848272389, 4: -4.929247537101994}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.43561573803599, 2: -4.699883318585343, 3: -4.4553848272389, 4: -4.929247537101994}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -4.936410321612751, 2: -4.699883318585343, 3: -4.4553848272389, 4: -4.929247537101994}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -4.53090654985149, 2: -4.79107058527926, 3: -4.927800371013379, 4: -4.441151073024001}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -4.53090654985149, 2: -4.79107058527926, 3: -4.927800371013379, 4: -4.441151073024001}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -4.53090654985149, 2: -4.79107058527926, 3: -4.927800371013379, 4: -4.941447476451841}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -4.53090654985149, 2: -4.79107058527926, 3: -4.927800371013379, 4: -5.064179053024891}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -5.023124960364856, 2: -4.79107058527926, 3: -4.927800371013379, 4: -5.064179053024891}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.460744811475801, 1: -5.002502742224784, 2: -4.699883318585343, 3: -4.942870851873331, 4: -4.929247537101994}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.932499897637542, 2: -4.498401466508337, 3: -4.421970616446001, 4: -4.946909498743339}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -4.538015110474291, 2: -4.8586143270529805, 3: -4.5689782638892495, 4: -5.241217136648331}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8197107562455805, 1: -5.283079670112687, 2: -4.992310355823325, 3: -4.927800371013379, 4: -5.064179053024891}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -5.25776722360635, 2: -4.8586143270529805, 3: -4.5689782638892495, 4: -5.241217136648331}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -5.25776722360635, 2: -4.8586143270529805, 3: -4.5689782638892495, 4: -5.241217136648331}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -5.25776722360635, 2: -4.8586143270529805, 3: -5.057770220139217, 4: -5.241217136648331}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.47477725725029, 1: -4.932499897637542, 2: -4.498401466508337, 3: -5.017989301128776, 4: -4.946909498743339}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -4.860344472320791, 2: -4.5752200553979, 3: -4.9220643422479595, 4: -4.968378160981677}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.0297806204299995, 2: -4.32936964368, 3: -4.85197403265108, 4: -4.377298929678}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -4.097372861814571, 2: -4.2782403610760715, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.38119513946083, 3: -4.421384349777, 4: -4.39899103524888}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -3.9997245792259912, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1067345290670465, 1: -4.539749367095652, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.0538207717803605, 2: -3.75034948740334, 3: -3.7327205979, 4: -4.142089635403364}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.21724597679, 1: -4.85850534914473, 2: -4.2782403610760715, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.621850080112802, 2: -4.32936964368, 3: -4.85197403265108, 4: -4.377298929678}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -3.8333146500459003, 2: -3.8267375427, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.7281849464879198, 2: -3.89153382417, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.7281849464879198, 2: -3.89153382417, 3: -3.705951249, 4: -3.5426182716990002}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.7281849464879198, 2: -3.89153382417, 3: -3.705951249, 4: -4.12378262724609}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -3.8333146500459003, 2: -4.15219455434619, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.0538207717803605, 2: -3.75034948740334, 3: -4.6892413009899006, 4: -4.142089635403364}, Best action: 2, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.334177137205704, 1: -4.680429905253873, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.334177137205704, 1: -4.680429905253873, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.116180686789459}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.334177137205704, 1: -4.680429905253873, 2: -4.231887300430478, 3: -4.3495607011455, 4: -4.6457244249784075}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.994069708358719, 1: -5.285135860440934, 2: -5.316120188690119, 3: -5.374701229914939, 4: -4.926992500120928}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.065155513475481 -4.916899780748686 -4.4876140739739006 -4.5218189271627 -4.4240250690099 \n",
      "-4.962676120366089 -4.878256458172508 -4.5019435970610004 -4.29916683785499 -3.9645887454000004 \n",
      "-4.800962137005909 -4.62164430808809 -4.377298929678 -3.9763826860958997 -3.7281849464879198 \n",
      "-5.010431011078033 -4.498401466508337 -4.2782403610760715 -3.75034948740334 -3.1786851996900003 \n",
      "-4.927800371013379 -4.699883318585343 -4.39899103524888 -4.334177137205704 -4.926992500120928 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.3806374993352835, 2: -5.065155513475481, 3: -5.313180179067514, 4: -5.520215821125651}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -4.952408183755749, 3: -5.446058159141439, 4: -4.916899780748686}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -4.952408183755749, 3: -5.446058159141439, 4: -4.916899780748686}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -4.952408183755749, 3: -5.446058159141439, 4: -5.3743788004813045}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.89753074852478, 2: -4.7657443124736005, 3: -4.4876140739739006, 4: -4.905872616353607}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -5.030208218294435, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.89753074852478, 2: -4.7657443124736005, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495114318240891, 1: -4.89753074852478, 2: -4.7657443124736005, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.990554029599211, 1: -4.89753074852478, 2: -4.7657443124736005, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.52398875094396, 2: -4.5218189271627, 3: -4.5558327803535, 4: -4.894476464964258}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.482048619369091, 2: -4.63792893528681, 3: -4.4240250690099, 4: -4.802962584267118}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.52398875094396, 2: -4.935642198614289, 3: -4.5558327803535, 4: -4.894476464964258}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.354660911270069, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.29916683785499}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.354660911270069, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.29916683785499}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.354660911270069, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.812241822448041}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.15219455434619, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.15219455434619, 3: -4.33011043476, 4: -3.9763826860958997}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.15219455434619, 3: -4.33011043476, 4: -4.518508244347269}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.7281849464879198, 2: -3.89153382417, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -4.29321132917419, 2: -3.1786851996900003, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -4.29321132917419, 2: -3.1786851996900003, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.25151127, 1: -4.29321132917419, 2: -3.7926035317179, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.8475535063976922, 2: -3.89153382417, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9645887454000004, 1: -3.9899911460081587, 2: -3.9720165176700006, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.482048619369091, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -3.9899911460081587, 2: -3.9720165176700006, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -3.9899911460081587, 2: -3.9720165176700006, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -3.9899911460081587, 2: -4.514535031079701, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -3.8475535063976922, 2: -3.89153382417, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -3.9129844818717903, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -3.9129844818717903, 3: -4.16108494951493, 4: -3.5230843719549005}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -3.9129844818717903, 3: -4.16108494951493, 4: -4.106006778478959}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -3.9129844818717903, 3: -4.16108494951493, 4: -4.480118108164046}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -4.460815878503329, 3: -4.16108494951493, 4: -4.480118108164046}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.6394884334774975, 2: -3.75034948740334, 3: -4.6892413009899006, 4: -4.142089635403364}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.29321132917419, 2: -4.716560396957426, 3: -4.353891579748199, 4: -4.480118108164046}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.994069708358719, 1: -5.285135860440934, 2: -5.316120188690119, 3: -5.374701229914939, 4: -5.4954752159272315}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.313180179067514 -5.044063419604565 -4.89753074852478 -4.5558327803535 -4.56553824124961 \n",
      "-4.962676120366089 -4.878256458172508 -4.5019435970610004 -4.382039176029 -4.298763948489 \n",
      "-4.800962137005909 -4.62164430808809 -4.377298929678 -4.33011043476 -3.89153382417 \n",
      "-5.010431011078033 -4.498401466508337 -4.2782403610760715 -4.142089635403364 -4.330135674198001 \n",
      "-4.927800371013379 -4.699883318585343 -4.39899103524888 -4.334177137205704 -4.994069708358719 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.3806374993352835, 2: -5.389204373753984, 3: -5.313180179067514, 4: -5.520215821125651}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.3806374993352835, 2: -5.389204373753984, 3: -5.313180179067514, 4: -5.520215821125651}, Best action: 3, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.3806374993352835, 2: -5.389204373753984, 3: -5.902692833018529, 4: -5.520215821125651}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -5.065727962620801, 2: -5.00518424430564, 3: -5.4012233060657655, 4: -4.962676120366089}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -5.065727962620801, 2: -5.00518424430564, 3: -5.4012233060657655, 4: -4.962676120366089}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -5.065727962620801, 2: -5.00518424430564, 3: -5.4012233060657655, 4: -5.4160352695331415}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249465197493348, 1: -5.044912936108273, 2: -4.878256458172508, 3: -4.8840253573169985, 4: -5.349767741294329}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.5019435970610004, 2: -4.5901393485066, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.621850080112802, 2: -4.432594373955, 3: -4.85197403265108, 4: -4.377298929678}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.621850080112802, 2: -4.432594373955, 3: -4.85197403265108, 4: -4.377298929678}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.621850080112802, 2: -4.432594373955, 3: -4.85197403265108, 4: -4.8833420260069795}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.335049262089834, 3: -4.33011043476, 4: -4.715128413455141}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.457275113303901, 1: -4.621850080112802, 2: -4.8506488895511, 3: -4.85197403265108, 4: -4.978735645504248}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.89580649274528, 2: -4.5901393485066, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.556336066864686, 2: -4.382039176029, 3: -4.5072771512058, 4: -4.90849952037356}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -4.415517454782947, 2: -4.583346331374578, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -4.415517454782947, 2: -4.583346331374578, 3: -4.4462319967215995, 4: -4.298763948489}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -4.415517454782947, 2: -4.583346331374578, 3: -4.4462319967215995, 4: -4.81187519312499}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.138453691923239, 2: -3.89153382417, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.138453691923239, 2: -3.89153382417, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.138453691923239, 2: -4.4412957799947, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.330135674198001, 1: -4.474517596687981, 2: -4.716560396957426, 3: -4.353891579748199, 4: -4.480118108164046}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.821255265292705, 2: -4.696277068457294, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.821255265292705, 2: -4.696277068457294, 3: -4.375579991437179, 4: -4.314198774414609}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.821255265292705, 2: -4.696277068457294, 3: -4.375579991437179, 4: -4.825920884717294}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.335049262089834, 3: -4.94340388525216, 4: -4.715128413455141}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.494648309354, 1: -4.821255265292705, 2: -4.696277068457294, 3: -4.848947901436484, 4: -4.926811881535844}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -4.493694143055995, 2: -4.583346331374578, 3: -4.4462319967215995, 4: -4.957756657686686}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.556336066864686, 2: -4.82020271587899, 3: -4.5072771512058, 4: -4.90849952037356}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.78730340993357, 1: -4.89580649274528, 2: -4.90846566743415, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -4.89753074852478, 2: -5.039247762249147, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -4.89580649274528, 2: -4.90846566743415, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -4.89580649274528, 2: -4.90846566743415, 3: -5.228149805650504, 4: -4.869291063293919}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -4.89580649274528, 2: -4.90846566743415, 3: -5.228149805650504, 4: -5.331054867597467}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -4.621850080112802, 2: -4.8506488895511, 3: -4.85197403265108, 4: -4.978735645504248}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -4.2782403610760715, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.6394884334774975, 2: -4.752536125371427, 3: -4.6892413009899006, 4: -4.142089635403364}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.6394884334774975, 2: -4.752536125371427, 3: -4.6892413009899006, 4: -4.142089635403364}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.220775656279999, 1: -4.6394884334774975, 2: -4.752536125371427, 3: -4.6892413009899006, 4: -4.669301568217062}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.444025946543901, 1: -4.566926290146682, 2: -4.974170056785724, 3: -4.94340388525216, 4: -4.715128413455141}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -4.556336066864686, 2: -4.82020271587899, 3: -5.228443477166772, 4: -4.90849952037356}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -4.566926290146682, 2: -4.974170056785724, 3: -4.94340388525216, 4: -4.715128413455141}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.6394884334774975, 2: -4.752536125371427, 3: -4.6892413009899006, 4: -4.7857584384085055}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.334177137205704, 1: -4.680429905253873, 2: -4.414052655140999, 3: -4.3495607011455, 4: -4.7924011558465285}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.87463232448437, 2: -4.752536125371427, 3: -4.6892413009899006, 4: -4.7857584384085055}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -4.682916640784333, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -4.682916640784333, 3: -4.76905934244438, 4: -4.4182996618770005}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -4.682916640784333, 3: -4.76905934244438, 4: -4.920652692308071}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.87463232448437, 2: -4.752536125371427, 3: -4.947746856219361, 4: -4.7857584384085055}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.474517596687981, 2: -4.716560396957426, 3: -4.353891579748199, 4: -4.480118108164046}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.87463232448437, 2: -4.901905792133184, 3: -4.947746856219361, 4: -4.7857584384085055}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.87463232448437, 2: -4.901905792133184, 3: -4.947746856219361, 4: -4.7857584384085055}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.87463232448437, 2: -4.901905792133184, 3: -4.947746856219361, 4: -5.25504017895174}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -4.680429905253873, 2: -4.414052655140999, 3: -4.3495607011455, 4: -4.7924011558465285}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.577896423119136, 3: -4.421384349777, 4: -4.39899103524888}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.577896423119136, 3: -4.421384349777, 4: -4.39899103524888}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.577896423119136, 3: -4.421384349777, 4: -4.903081842076481}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.927870680468841, 1: -5.002502742224784, 2: -4.699883318585343, 3: -4.942870851873331, 4: -4.929247537101994}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.577896423119136, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.46363059036158, 2: -4.577896423119136, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.505199817659597, 1: -4.961903837229038, 2: -4.577896423119136, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 0, Actual action: 0\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -5.217845925629289, 3: -4.76905934244438, 4: -5.185227748266117}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -4.932499897637542, 2: -4.498401466508337, 3: -5.017989301128776, 4: -4.946909498743339}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.828514009059799, 1: -4.85850534914473, 2: -5.217845925629289, 3: -5.0206111221161915, 4: -5.185227748266117}, Best action: 0, Actual action: 0\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -4.827559700482898, 2: -4.8506488895511, 3: -4.85197403265108, 4: -4.978735645504248}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -4.85850534914473, 2: -5.217845925629289, 3: -5.0206111221161915, 4: -5.185227748266117}, Best action: 1, Actual action: 1\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -4.577896423119136, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -4.680429905253873, 2: -4.414052655140999, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -5.285135860440934, 2: -5.316120188690119, 3: -5.374701229914939, 4: -5.4954752159272315}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.389204373753984 -5.044063419604565 -4.905872616353607 -4.5558327803535 -4.56553824124961 \n",
      "-5.065727962620801 -4.8840253573169985 -4.90846566743415 -4.77984957913188 -4.493694143055995 \n",
      "-4.800962137005909 -4.62164430808809 -4.8506488895511 -4.715128413455141 -4.696277068457294 \n",
      "-5.010431011078033 -4.932499897637542 -5.0206111221161915 -4.901905792133184 -4.474517596687981 \n",
      "-4.927800371013379 -4.927870680468841 -4.933172292976123 -4.680429905253873 -5.285135860440934 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -5.065727962620801, 2: -5.351906155550296, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.894025495874319, 2: -4.817339453853091, 3: -5.1463442957565215, 4: -4.800962137005909}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.894025495874319, 2: -4.817339453853091, 3: -5.1463442957565215, 4: -4.800962137005909}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.894025495874319, 2: -4.817339453853091, 3: -5.1463442957565215, 4: -5.268875544675377}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -4.860344472320791, 2: -4.62164430808809, 3: -4.9220643422479595, 4: -4.968378160981677}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -5.3181453028555215, 2: -4.8506488895511, 3: -4.85197403265108, 4: -4.978735645504248}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -5.114678260131441, 2: -4.974170056785724, 3: -4.94340388525216, 4: -4.715128413455141}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -5.114678260131441, 2: -4.974170056785724, 3: -4.94340388525216, 4: -4.715128413455141}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -5.114678260131441, 2: -4.974170056785724, 3: -4.94340388525216, 4: -5.190766856244179}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -5.3181453028555215, 2: -5.204318903853775, 3: -4.85197403265108, 4: -4.978735645504248}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -4.860344472320791, 2: -5.2911900313452005, 3: -4.9220643422479595, 4: -4.968378160981677}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -4.932499897637542, 2: -5.260936493989272, 3: -5.017989301128776, 4: -4.946909498743339}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.927870680468841, 1: -5.002502742224784, 2: -4.985529110051415, 3: -4.942870851873331, 4: -4.929247537101994}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -5.384825240943516, 2: -5.260936493989272, 3: -5.017989301128776, 4: -4.946909498743339}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -5.384825240943516, 2: -5.260936493989272, 3: -5.017989301128776, 4: -4.946909498743339}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -5.384825240943516, 2: -5.260936493989272, 3: -5.017989301128776, 4: -5.401687643856438}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -5.25776722360635, 2: -5.010431011078033, 3: -5.341254626926836, 4: -5.241217136648331}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.053405970597328, 1: -5.384825240943516, 2: -5.260936493989272, 3: -5.4602480490860845, 4: -5.504740098299953}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -5.381359364318488, 2: -5.2911900313452005, 3: -4.9220643422479595, 4: -4.968378160981677}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -4.894025495874319, 2: -5.125265834936663, 3: -5.1463442957565215, 4: -5.328932512088541}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1181999508087594, 1: -5.25776722360635, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.241217136648331}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.037650782654032, 1: -5.535144509742527, 2: -5.125265834936663, 3: -5.1463442957565215, 4: -5.328932512088541}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2753751104667925, 1: -5.295352127236866, 2: -5.351906155550296, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.457831407430061, 2: -5.389204373753984, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -5.044063419604565, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.039247762249147, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.039247762249147, 3: -5.423230064215883, 4: -4.905872616353607}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.039247762249147, 3: -5.423230064215883, 4: -5.364344080881783}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.834724013756938, 2: -4.935642198614289, 3: -4.5558327803535, 4: -4.894476464964258}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.094149328311249, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.834724013756938, 2: -4.935642198614289, 3: -5.481844233967462, 4: -4.894476464964258}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.56210258401169, 1: -4.834724013756938, 2: -4.935642198614289, 3: -5.481844233967462, 4: -4.894476464964258}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051513351450638, 1: -4.834724013756938, 2: -4.935642198614289, 3: -5.481844233967462, 4: -4.894476464964258}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77984957913188, 1: -5.054843901705281, 2: -4.82020271587899, 3: -5.228443477166772, 4: -4.90849952037356}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.255150560472517, 2: -4.935642198614289, 3: -5.481844233967462, 4: -4.894476464964258}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.255150560472517, 2: -4.935642198614289, 3: -5.481844233967462, 4: -4.894476464964258}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.255150560472517, 2: -4.935642198614289, 3: -5.481844233967462, 4: -5.353973583117475}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.56553824124961, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -4.493694143055995, 2: -4.583346331374578, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -4.821255265292705, 2: -4.696277068457294, 3: -4.848947901436484, 4: -4.926811881535844}, Best action: 2, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.474517596687981, 2: -4.716560396957426, 3: -5.211853493085709, 4: -4.480118108164046}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -5.531753235766942, 2: -5.316120188690119, 3: -5.374701229914939, 4: -5.4954752159272315}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.457831407430061 -5.070584745401392 -5.104718025880595 -5.091650195273613 -4.61693174834628 \n",
      "-5.295352127236866 -4.8840253573169985 -4.90846566743415 -4.82020271587899 -4.583346331374578 \n",
      "-5.125265834936663 -4.968378160981677 -4.978735645504248 -4.974170056785724 -4.696277068457294 \n",
      "-5.241217136648331 -5.260936493989272 -5.0206111221161915 -4.901905792133184 -4.480118108164046 \n",
      "-4.927800371013379 -4.929247537101994 -4.933172292976123 -4.680429905253873 -5.316120188690119 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.070584745401392, 2: -5.378163161206879, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249465197493348, 1: -5.044912936108273, 2: -5.034399959436661, 3: -4.8840253573169985, 4: -5.349767741294329}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.295352127236866, 2: -5.351906155550296, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.125265834936663, 3: -5.1463442957565215, 4: -5.328932512088541}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -5.381359364318488, 2: -5.2911900313452005, 3: -5.356367085882994, 4: -4.968378160981677}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -5.381359364318488, 2: -5.2911900313452005, 3: -5.356367085882994, 4: -4.968378160981677}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.266956793102073, 1: -5.381359364318488, 2: -5.2911900313452005, 3: -5.356367085882994, 4: -5.4212241264933265}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249465197493348, 1: -5.044912936108273, 2: -5.034399959436661, 3: -5.677637758793561, 4: -5.349767741294329}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -5.133279214165897, 2: -4.90846566743415, 3: -5.228149805650504, 4: -5.3987087458834235}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.054843901705281, 2: -4.82020271587899, 3: -5.228443477166772, 4: -4.90849952037356}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -5.254586179192691, 2: -4.583346331374578, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -5.254586179192691, 2: -4.583346331374578, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.926918256228964, 1: -5.254586179192691, 2: -5.070845161550866, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.996446080000317, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.61693174834628, 1: -4.996446080000317, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.101407890995115, 1: -4.996446080000317, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -4.996446080000317, 2: -4.63792893528681, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -4.996446080000317, 2: -5.120515331110997, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -4.996446080000317, 2: -5.302451226367465, 3: -5.0068333951655974, 4: -4.802962584267118}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -4.996446080000317, 2: -5.302451226367465, 3: -5.0068333951655974, 4: -5.270695951683077}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.132406541783383, 1: -5.254586179192691, 2: -5.397888303700547, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.132406541783383, 1: -5.254586179192691, 2: -5.397888303700547, 3: -4.995517692148858, 4: -4.957756657686686}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.132406541783383, 1: -5.254586179192691, 2: -5.397888303700547, 3: -4.995517692148858, 4: -5.411558558494884}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.054843901705281, 2: -5.094530800001308, 3: -5.228443477166772, 4: -4.90849952037356}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.054843901705281, 2: -5.094530800001308, 3: -5.228443477166772, 4: -4.90849952037356}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.054843901705281, 2: -5.094530800001308, 3: -5.228443477166772, 4: -5.36673456353994}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -5.114678260131441, 2: -4.974170056785724, 3: -5.324439354972591, 4: -5.423233832678667}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -4.696277068457294, 3: -4.848947901436484, 4: -4.926811881535844}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -4.696277068457294, 3: -4.848947901436484, 4: -4.926811881535844}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -5.173612132296138, 3: -4.848947901436484, 4: -4.926811881535844}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.035034808814785, 1: -5.114678260131441, 2: -5.20140143112898, 3: -5.324439354972591, 4: -5.423233832678667}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.4345621361669645, 2: -5.094530800001308, 3: -5.228443477166772, 4: -5.531097016735272}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.132406541783383, 1: -5.254586179192691, 2: -5.397888303700547, 3: -5.37543638071747, 4: -5.487525186490063}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -5.415427500726247, 2: -5.302451226367465, 3: -5.0068333951655974, 4: -5.4741909199685646}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.255150560472517, 2: -5.091650195273613, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -5.415427500726247, 2: -5.302451226367465, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.166863226681828, 1: -5.415427500726247, 2: -5.302451226367465, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6018455362804636, 1: -5.415427500726247, 2: -5.302451226367465, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.415427500726247, 2: -5.302451226367465, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.415427500726247, 2: -5.725230615994393, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.254586179192691, 2: -5.397888303700547, 3: -5.37543638071747, 4: -5.487525186490063}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -5.345009013393166, 3: -5.463272985283625, 4: -4.926811881535844}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -5.345009013393166, 3: -5.463272985283625, 4: -4.926811881535844}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.950912748279896, 1: -5.006484779846535, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.383398812197618}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.416176241963303, 2: -5.397888303700547, 3: -5.37543638071747, 4: -5.487525186490063}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.4345621361669645, 2: -5.5667023788446715, 3: -5.228443477166772, 4: -5.531097016735272}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -5.133279214165897, 2: -5.295210766605397, 3: -5.228149805650504, 4: -5.3987087458834235}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -5.3181453028555215, 2: -5.204318903853775, 3: -5.322076425844949, 4: -4.978735645504248}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -5.3181453028555215, 2: -5.204318903853775, 3: -5.322076425844949, 4: -4.978735645504248}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.063740383620736, 1: -5.3181453028555215, 2: -5.204318903853775, 3: -5.322076425844949, 4: -5.430649437408865}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -5.4461037942750306, 2: -5.295210766605397, 3: -5.228149805650504, 4: -5.3987087458834235}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249465197493348, 1: -5.044912936108273, 2: -5.379297186565328, 3: -5.677637758793561, 4: -5.349767741294329}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.504559646453902, 1: -5.381359364318488, 2: -5.2911900313452005, 3: -5.356367085882994, 4: -5.708357415062012}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.3181453028555215, 2: -5.204318903853775, 3: -5.322076425844949, 4: -5.544694654473683}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.114678260131441, 2: -5.20140143112898, 3: -5.324439354972591, 4: -5.423233832678667}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.910607400376293, 2: -4.901905792133184, 3: -4.947746856219361, 4: -5.373956200727514}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.753509112507794, 2: -4.716560396957426, 3: -5.211853493085709, 4: -4.480118108164046}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.753509112507794, 2: -4.716560396957426, 3: -5.211853493085709, 4: -4.480118108164046}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.753509112507794, 2: -4.716560396957426, 3: -5.211853493085709, 4: -4.976907478429282}, Best action: 2, Actual action: 2\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.753509112507794, 2: -4.716560396957426, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.753509112507794, 2: -5.192069961231258, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -5.531753235766942, 2: -5.538785662644139, 3: -5.374701229914939, 4: -5.4954752159272315}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-5.457831407430061 -5.363119013966908 -5.104718025880595 -5.255150560472517 -5.4741909199685646 \n",
      "-5.351906155550296 -5.249465197493348 -5.295210766605397 -5.342510894534238 -5.397888303700547 \n",
      "-5.1463442957565215 -5.356367085882994 -5.3181453028555215 -5.20140143112898 -5.006484779846535 \n",
      "-5.241217136648331 -5.260936493989272 -5.0206111221161915 -4.910607400376293 -4.827514574695633 \n",
      "-4.927800371013379 -4.929247537101994 -4.933172292976123 -4.680429905253873 -5.374701229914939 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.457831407430061, 2: -5.524611807255096, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.351906155550296, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249465197493348, 1: -5.690355219000439, 2: -5.379297186565328, 3: -5.677637758793561, 4: -5.349767741294329}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.363119013966908, 2: -5.378163161206879, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -5.690355219000439, 2: -5.379297186565328, 3: -5.677637758793561, 4: -5.349767741294329}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -5.690355219000439, 2: -5.379297186565328, 3: -5.677637758793561, 4: -5.349767741294329}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -5.690355219000439, 2: -5.379297186565328, 3: -5.677637758793561, 4: -5.768288644577839}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -5.4461037942750306, 2: -5.295210766605397, 3: -5.509194458812751, 4: -5.3987087458834235}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.342510894534238, 1: -5.4345621361669645, 2: -5.5667023788446715, 3: -5.580800511191054, 4: -5.531097016735272}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.255150560472517, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.4345621361669645, 2: -5.5667023788446715, 3: -5.580800511191054, 4: -5.531097016735272}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.382011517641024, 2: -5.20140143112898, 3: -5.324439354972591, 4: -5.423233832678667}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.006484779846535, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.827514574695633, 1: -4.82885890748188, 2: -5.269549377254439, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.310935283488116, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -4.82885890748188, 2: -5.269549377254439, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -5.531753235766942, 2: -5.538785662644139, 3: -5.858313563009843, 4: -5.4954752159272315}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.524611807255096 -5.37405855997792 -5.104718025880595 -5.321277786288184 -5.4741909199685646 \n",
      "-5.4012233060657655 -5.677637758793561 -5.345730247298429 -5.531097016735272 -5.397888303700547 \n",
      "-5.1463442957565215 -5.356367085882994 -5.3181453028555215 -5.324439354972591 -5.342469243409135 \n",
      "-5.241217136648331 -5.260936493989272 -5.0206111221161915 -4.910607400376293 -4.934220815649246 \n",
      "-4.927800371013379 -4.929247537101994 -4.933172292976123 -4.680429905253873 -5.4954752159272315 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.780827126738746, 2: -5.524611807255096, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.769623771845097, 2: -5.378163161206879, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.37405855997792, 1: -5.769623771845097, 2: -5.378163161206879, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7903932895799075, 1: -5.769623771845097, 2: -5.378163161206879, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.104718025880595, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321277786288184, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.742362785522248, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.4332675391893215}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.481844233967462, 4: -5.844273460662283}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.720706809481489, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.259308296063538, 1: -5.333878836120553, 2: -5.720706809481489, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685970549417819, 1: -5.333878836120553, 2: -5.720706809481489, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.345730247298429, 1: -5.4461037942750306, 2: -5.756954901233272, 3: -5.509194458812751, 4: -5.3987087458834235}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.763429383923783, 2: -5.720706809481489, 3: -5.423230064215883, 4: -5.518225095509988}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.57263791708397, 3: -5.446058159141439, 4: -5.448888508890287}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.780827126738746, 2: -5.805448614307625, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530136228739242, 1: -5.780827126738746, 2: -5.805448614307625, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.932423968152711, 1: -5.780827126738746, 2: -5.805448614307625, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.687257425524641, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.687257425524641, 3: -5.4012233060657655, 4: -5.4958027648408825}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.687257425524641, 3: -5.815113208519847, 4: -5.4958027648408825}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.687257425524641, 3: -5.9331115603731, 4: -5.4958027648408825}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.581000539022384, 2: -5.687257425524641, 3: -5.9331115603731, 4: -5.901180516005203}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.436912893888825, 3: -5.1463442957565215, 4: -5.328932512088541}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.436912893888825, 3: -5.1463442957565215, 4: -5.328932512088541}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.436912893888825, 3: -5.583173309138434, 4: -5.328932512088541}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.436912893888825, 3: -5.774752665705562, 4: -5.328932512088541}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.436912893888825, 3: -5.774752665705562, 4: -5.749328586000573}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.504559646453902, 1: -5.381359364318488, 2: -5.6446173152560775, 3: -5.356367085882994, 4: -5.708357415062012}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.535144509742527, 2: -5.782348628954107, 3: -5.774752665705562, 4: -5.878832302650006}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.25776722360635, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.241217136648331}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.25776722360635, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.241217136648331}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.25776722360635, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.669507594349981}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -4.992310355823325, 3: -4.927800371013379, 4: -5.064179053024891}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -4.992310355823325, 3: -4.927800371013379, 4: -5.064179053024891}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -4.992310355823325, 3: -5.384298337622175, 4: -5.064179053024891}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -4.985529110051415, 3: -4.942870851873331, 4: -4.929247537101994}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -4.985529110051415, 3: -4.942870851873331, 4: -4.929247537101994}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -4.985529110051415, 3: -4.942870851873331, 4: -5.385615258762814}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.064179053024891}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.064179053024891}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0828434693748505, 1: -5.283079670112687, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.508402938252651}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.417295022881472, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.725742210556142}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.417295022881472, 2: -5.49430193729164, 3: -5.341254626926836, 4: -5.725742210556142}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.417295022881472, 2: -5.49430193729164, 3: -5.7605417105034205, 4: -5.725742210556142}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.283079670112687, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.283079670112687, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.707602499802546, 2: -5.391921540634947, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -4.985529110051415, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -4.933172292976123, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -4.680429905253873, 2: -4.722365312471256, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -4.680429905253873, 2: -4.722365312471256, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.159191213781024, 2: -4.722365312471256, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -5.531753235766942, 2: -5.538785662644139, 3: -5.858313563009843, 4: -5.924483085469351}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.805448614307625 -5.448888508890287 -5.518225095509988 -5.594324233139642 -5.4741909199685646 \n",
      "-5.626638933465021 -5.677637758793561 -5.3987087458834235 -5.531097016735272 -5.397888303700547 \n",
      "-5.676818917743505 -5.381359364318488 -5.3181453028555215 -5.324439354972591 -5.342469243409135 \n",
      "-5.492317129030642 -5.260936493989272 -5.0206111221161915 -4.910607400376293 -4.934220815649246 \n",
      "-5.47747073320514 -5.002502742224784 -4.971629507527018 -4.7924011558465285 -5.531753235766942 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -5.626638933465021, 2: -5.687257425524641, 3: -5.9331115603731, 4: -6.010728488208652}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676818917743505, 1: -5.6989003316594005, 2: -5.782348628954107, 3: -5.774752665705562, 4: -5.878832302650006}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -6.060887216718741, 2: -5.687257425524641, 3: -5.9331115603731, 4: -6.010728488208652}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -5.690355219000439, 2: -5.727050439606905, 3: -5.677637758793561, 4: -5.8340595855757}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.792793053787406, 1: -6.060887216718741, 2: -6.067612327175249, 3: -5.9331115603731, 4: -6.010728488208652}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -5.853073590587145, 2: -5.805448614307625, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.57263791708397, 3: -5.924016161192931, 4: -5.448888508890287}, Best action: 4, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -5.853073590587145, 2: -6.278997951997036, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 4, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.060887216718741, 2: -6.067612327175249, 3: -5.9331115603731, 4: -6.010728488208652}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.060887216718741, 2: -6.067612327175249, 3: -5.9331115603731, 4: -6.010728488208652}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.060887216718741, 2: -6.067612327175249, 3: -6.299131519939521, 4: -6.010728488208652}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.060887216718741, 2: -6.067612327175249, 3: -6.39860322744296, 4: -6.010728488208652}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.060887216718741, 2: -6.067612327175249, 3: -6.39860322744296, 4: -6.369762924269873}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.6989003316594005, 2: -5.782348628954107, 3: -5.774752665705562, 4: -5.878832302650006}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.492317129030642, 1: -5.721024035079424, 2: -5.49430193729164, 3: -5.864063139584334, 4: -5.725742210556142}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -5.782348628954107, 3: -5.774752665705562, 4: -5.878832302650006}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -5.782348628954107, 3: -5.774752665705562, 4: -5.878832302650006}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -5.782348628954107, 3: -6.155024925792061, 4: -5.878832302650006}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.504559646453902, 1: -5.381359364318488, 2: -5.6446173152560775, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.39221271428058, 1: -5.384825240943516, 2: -5.260936493989272, 3: -5.4602480490860845, 4: -5.504740098299953}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.093946637640973, 2: -5.217845925629289, 3: -5.0206111221161915, 4: -5.185227748266117}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.39221271428058, 1: -5.384825240943516, 2: -5.492788658313042, 3: -5.4602480490860845, 4: -5.504740098299953}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -5.394422468315802, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.002502742224784, 2: -5.394422468315802, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.452277495424553, 2: -5.394422468315802, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -5.184465452553249, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -5.184465452553249, 3: -5.149043923031828, 4: -4.971629507527018}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -5.184465452553249, 3: -5.149043923031828, 4: -5.4241828518495865}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.0454022360271775, 2: -5.184465452553249, 3: -5.149043923031828, 4: -5.529194096366973}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.491316034784732, 2: -5.184465452553249, 3: -5.149043923031828, 4: -5.529194096366973}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.399783762028989, 1: -5.814709948878255, 2: -5.466462147928465, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.39221271428058, 1: -5.490509745296427, 2: -5.492788658313042, 3: -5.4602480490860845, 4: -5.504740098299953}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.504559646453902, 1: -5.699494496563159, 2: -5.6446173152560775, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -5.690355219000439, 2: -5.727050439606905, 3: -6.1599261494471556, 4: -5.8340595855757}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.699494496563159, 2: -5.6446173152560775, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.3181453028555215, 2: -5.563321281091845, 3: -5.322076425844949, 4: -5.544694654473683}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.093946637640973, 2: -5.217845925629289, 3: -5.763769557375867, 4: -5.185227748266117}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.619857181134254, 2: -5.184465452553249, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -4.952956652218349, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -4.952956652218349, 3: -4.898138808666143, 4: -4.7924011558465285}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -4.952956652218349, 3: -4.898138808666143, 4: -5.261085051820341}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.213458049145908, 1: -5.619857181134254, 2: -5.300291481491013, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.60881168033223, 2: -5.217845925629289, 3: -5.763769557375867, 4: -5.185227748266117}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.60881168033223, 2: -5.217845925629289, 3: -5.763769557375867, 4: -5.185227748266117}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.60881168033223, 2: -5.217845925629289, 3: -5.763769557375867, 4: -5.618557250922167}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -4.910607400376293, 2: -5.019086246826196, 3: -4.947746856219361, 4: -5.373956200727514}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -4.952956652218349, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -6.010752859683361, 2: -5.538785662644139, 3: -5.858313563009843, 4: -5.924483085469351}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.810337956574145 -5.448888508890287 -5.518225095509988 -5.594324233139642 -5.4741909199685646 \n",
      "-6.067612327175249 -5.727050439606905 -5.3987087458834235 -5.531097016735272 -5.397888303700547 \n",
      "-5.837135947993386 -5.699494496563159 -5.322076425844949 -5.324439354972591 -5.342469243409135 \n",
      "-5.49430193729164 -5.4602480490860845 -5.293174758297128 -4.92173858232856 -4.934220815649246 \n",
      "-5.47747073320514 -5.44228691589368 -5.300291481491013 -4.981712051963588 -5.538785662644139 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.57263791708397, 3: -6.233391224494881, 4: -5.448888508890287}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.57263791708397, 3: -6.233391224494881, 4: -5.448888508890287}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.57263791708397, 3: -6.233391224494881, 4: -5.858488543090162}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.763429383923783, 2: -5.720706809481489, 3: -5.853630115326154, 4: -5.518225095509988}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.763429383923783, 2: -5.720706809481489, 3: -5.853630115326154, 4: -5.518225095509988}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.763429383923783, 2: -5.720706809481489, 3: -5.853630115326154, 4: -5.921584836914089}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -5.827510386342492, 2: -5.594324233139642, 3: -5.708224143208212, 4: -5.924721175579872}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.697757555218704, 2: -5.8590193371877, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.697757555218704, 2: -5.8590193371877, 3: -5.524919997688186, 4: -5.4741909199685646}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.697757555218704, 2: -5.8590193371877, 3: -5.524919997688186, 4: -5.881513737171394}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -5.827510386342492, 2: -5.893527068488502, 3: -5.708224143208212, 4: -5.924721175579872}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.763429383923783, 2: -6.003473309791259, 3: -5.853630115326154, 4: -6.125930999371415}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.4461037942750306, 2: -5.756954901233272, 3: -5.509194458812751, 4: -5.3987087458834235}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.4461037942750306, 2: -5.756954901233272, 3: -5.509194458812751, 4: -5.3987087458834235}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.4461037942750306, 2: -5.756954901233272, 3: -5.509194458812751, 4: -5.812824958753916}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.55791130677474, 2: -5.563321281091845, 3: -5.322076425844949, 4: -5.544694654473683}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.699494496563159, 2: -5.77215942683858, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.490509745296427, 2: -5.492788658313042, 3: -5.4602480490860845, 4: -5.504740098299953}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.721024035079424, 2: -5.49430193729164, 3: -5.864063139584334, 4: -5.725742210556142}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.490509745296427, 2: -5.492788658313042, 3: -5.896409374114837, 4: -5.504740098299953}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.466462147928465, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.466462147928465, 3: -5.496272118137496, 4: -5.44228691589368}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.466462147928465, 3: -5.496272118137496, 4: -5.85248109346325}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.300291481491013, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -4.981712051963588, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.703082915880558, 1: -6.010752859683361, 2: -5.867478258465547, 3: -5.858313563009843, 4: -5.924483085469351}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.810337956574145 -5.769623771845097 -5.78903891219943 -5.827510386342492 -5.697757555218704 \n",
      "-6.067612327175249 -5.727050439606905 -5.509194458812751 -5.531097016735272 -5.397888303700547 \n",
      "-5.837135947993386 -5.708357415062012 -5.544694654473683 -5.324439354972591 -5.342469243409135 \n",
      "-5.721024035079424 -5.492788658313042 -5.293174758297128 -4.92173858232856 -4.934220815649246 \n",
      "-5.47747073320514 -5.496272118137496 -5.465215910239608 -5.117668367059611 -5.703082915880558 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -5.902692833018529, 4: -5.810337956574145}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -5.902692833018529, 4: -6.1874075404824715}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -5.902692833018529, 4: -6.299921948793256}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -6.271450478046861, 4: -6.299921948793256}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.175712369473655, 1: -6.291127722960925, 2: -6.278997951997036, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.519898256221026, 1: -6.291127722960925, 2: -6.278997951997036, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -5.769623771845097, 2: -5.9270261190714875, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -6.041175547257467, 2: -5.727050439606905, 3: -6.1599261494471556, 4: -5.8340595855757}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.755492284361912, 2: -5.756954901233272, 3: -5.509194458812751, 4: -5.892626569238166}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.76907292106253, 1: -6.041175547257467, 2: -5.935152555599019, 3: -6.1599261494471556, 4: -5.8340595855757}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -6.115873233266103, 2: -5.9270261190714875, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8353514895355625, 1: -6.115873233266103, 2: -5.9270261190714875, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2101698554773614, 1: -6.115873233266103, 2: -5.9270261190714875, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.849297022557952, 2: -6.003473309791259, 3: -5.853630115326154, 4: -6.125930999371415}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.78903891219943, 1: -5.849297022557952, 2: -6.003473309791259, 3: -5.853630115326154, 4: -6.125930999371415}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.168025410101482, 1: -5.849297022557952, 2: -6.003473309791259, 3: -5.853630115326154, 4: -6.125930999371415}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.755492284361912, 2: -5.756954901233272, 3: -6.123868511941924, 4: -5.892626569238166}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.55791130677474, 2: -5.563321281091845, 3: -6.048798184800654, 4: -5.544694654473683}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.55791130677474, 2: -5.563321281091845, 3: -6.048798184800654, 4: -5.544694654473683}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.55791130677474, 2: -5.563321281091845, 3: -6.048798184800654, 4: -5.945672135571052}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.293174758297128, 1: -5.60881168033223, 2: -5.399376586867726, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.743262684898148, 2: -5.563321281091845, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.382011517641024, 2: -5.4753928147885915, 3: -5.324439354972591, 4: -5.423233832678667}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.641175380938982, 1: -5.743262684898148, 2: -5.769128005636983, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.966751898559875, 2: -5.756954901233272, 3: -6.123868511941924, 4: -5.892626569238166}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.65659137283117, 2: -5.5667023788446715, 3: -5.580800511191054, 4: -5.531097016735272}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.65659137283117, 2: -5.5667023788446715, 3: -5.580800511191054, 4: -5.531097016735272}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.65659137283117, 2: -5.5667023788446715, 3: -5.580800511191054, 4: -5.933298285229097}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.416176241963303, 2: -5.397888303700547, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.416176241963303, 2: -5.397888303700547, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.416176241963303, 2: -5.812078356367499, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.342469243409135, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -4.934220815649246, 2: -5.269549377254439, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.176682036413113, 1: -6.010752859683361, 2: -5.867478258465547, 3: -5.858313563009843, 4: -5.924483085469351}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.201295050394233 -5.999685567147032 -5.853630115326154 -5.827510386342492 -5.697757555218704 \n",
      "-6.067612327175249 -5.8340595855757 -5.827389376744708 -5.580800511191054 -5.468775704262472 \n",
      "-5.837135947993386 -5.708357415062012 -5.743262684898148 -5.382011517641024 -5.345009013393166 \n",
      "-5.721024035079424 -5.492788658313042 -5.399376586867726 -4.92173858232856 -5.211853493085709 \n",
      "-5.47747073320514 -5.496272118137496 -5.465215910239608 -5.117668367059611 -5.858313563009843 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.291127722960925, 2: -6.201295050394233, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.115873233266103, 2: -6.181824130788687, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.115873233266103, 2: -6.181824130788687, 3: -6.233391224494881, 4: -5.999685567147032}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.115873233266103, 2: -6.181824130788687, 3: -6.233391224494881, 4: -6.359713866103799}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.041175547257467, 2: -5.935152555599019, 3: -6.1599261494471556, 4: -5.8340595855757}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.041175547257467, 2: -5.935152555599019, 3: -6.1599261494471556, 4: -5.8340595855757}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.041175547257467, 2: -5.935152555599019, 3: -6.1599261494471556, 4: -6.208994222873887}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827389376744708, 1: -5.966751898559875, 2: -5.955884073678897, 3: -6.123868511941924, 4: -5.892626569238166}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.003473309791259, 3: -5.853630115326154, 4: -6.125930999371415}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.237175587642927, 2: -6.181824130788687, 3: -6.233391224494881, 4: -6.489828705555923}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.003473309791259, 3: -6.492640557471452, 4: -6.125930999371415}, Best action: 2, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.237175587642927, 2: -6.777221264630745, 3: -6.233391224494881, 4: -6.489828705555923}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.291127722960925, 2: -6.379874814428519, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.122197990315988, 2: -6.067612327175249, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.041175547257467, 2: -6.213700650723116, 3: -6.1599261494471556, 4: -6.328372992322594}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.892750369416045, 2: -5.77215942683858, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.892750369416045, 2: -5.77215942683858, 3: -5.919103761479747, 4: -5.708357415062012}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.892750369416045, 2: -5.77215942683858, 3: -5.919103761479747, 4: -6.094605247706431}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -5.743262684898148, 2: -5.769128005636983, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.60881168033223, 2: -5.399376586867726, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.92173858232856, 1: -5.402955628334492, 2: -5.019086246826196, 3: -4.947746856219361, 4: -5.373956200727514}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.382011517641024, 2: -5.4753928147885915, 3: -6.001795994057835, 4: -5.423233832678667}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.402955628334492, 2: -5.019086246826196, 3: -4.947746856219361, 4: -5.373956200727514}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.60881168033223, 2: -5.426545910372907, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.402955628334492, 2: -5.019086246826196, 3: -5.79027687302399, 4: -5.373956200727514}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.238656067602898, 2: -5.269549377254439, 3: -5.211853493085709, 4: -5.218104669378444}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.402955628334492, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.373956200727514}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.402955628334492, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.373956200727514}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.402955628334492, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.790300142662038}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -5.117668367059611, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.176682036413113, 1: -6.010752859683361, 2: -5.867478258465547, 3: -6.508880347120313, 4: -5.924483085469351}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.299921948793256 -6.237175587642927 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.122197990315988 -6.127887060925977 -5.892626569238166 -5.580800511191054 -5.468775704262472 \n",
      "-5.837135947993386 -5.892750369416045 -5.769128005636983 -5.423233832678667 -5.345009013393166 \n",
      "-5.721024035079424 -5.492788658313042 -5.508114450966509 -5.5856069401517345 -5.218104669378444 \n",
      "-5.47747073320514 -5.496272118137496 -5.465215910239608 -5.1317031675223905 -5.867478258465547 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.237175587642927, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.127887060925977, 2: -6.213700650723116, 3: -6.1599261494471556, 4: -6.328372992322594}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.892750369416045, 2: -6.129258717451358, 3: -5.919103761479747, 4: -6.184909660509893}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.857303376403524, 2: -5.492788658313042, 3: -5.896409374114837, 4: -5.504740098299953}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.60881168033223, 2: -5.508114450966509, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.5856069401517345, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1317031675223905, 1: -5.24103502447982, 2: -5.2644242260630545, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.61524025970831, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.24103502447982, 2: -5.2644242260630545, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.24103502447982, 2: -5.2644242260630545, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.669341872276636, 2: -5.2644242260630545, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.176682036413113, 1: -6.010752859683361, 2: -6.538860051837325, 3: -6.508880347120313, 4: -5.924483085469351}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.299921948793256 -6.321908141995641 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.122197990315988 -6.1599261494471556 -5.892626569238166 -5.580800511191054 -5.468775704262472 \n",
      "-5.837135947993386 -5.919103761479747 -5.769128005636983 -5.423233832678667 -5.345009013393166 \n",
      "-5.721024035079424 -5.504740098299953 -5.60881168033223 -5.623509954082044 -5.218104669378444 \n",
      "-5.47747073320514 -5.496272118137496 -5.465215910239608 -5.3252737218364805 -5.924483085469351 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.4438787573080445, 2: -6.379874814428519, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.4438787573080445, 2: -6.379874814428519, 3: -6.529472067078347, 4: -6.299921948793256}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.4438787573080445, 2: -6.379874814428519, 3: -6.529472067078347, 4: -6.632928973401863}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.487306078114334, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.321908141995641, 1: -6.487306078114334, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652936409216033, 1: -6.487306078114334, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.2859165053195944, 2: -6.213700650723116, 3: -6.1599261494471556, 4: -6.328372992322594}, Best action: 3, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.2859165053195944, 2: -6.213700650723116, 3: -6.1599261494471556, 4: -6.328372992322594}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.122197990315988, 2: -6.400113425996073, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -5.837135947993386, 3: -6.199204882032033, 4: -5.878832302650006}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.938433850175169, 2: -6.129258717451358, 3: -5.919103761479747, 4: -6.184909660509893}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -6.278187641597934, 3: -6.199204882032033, 4: -5.878832302650006}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -6.278187641597934, 3: -6.199204882032033, 4: -5.878832302650006}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -5.91866690768076, 2: -6.278187641597934, 3: -6.199204882032033, 4: -6.249737395411505}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.721024035079424, 2: -5.89674308741927, 3: -5.864063139584334, 4: -5.725742210556142}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.47747073320514, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.7398823148005675, 3: -5.496272118137496, 4: -5.913082449168382}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.4822012219791105, 4: -5.567943504018895}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.888803112000991, 4: -5.567943504018895}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.998914549455404, 4: -5.567943504018895}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734700594748222, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.998914549455404, 4: -5.966828588657194}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.89674308741927, 3: -5.864063139584334, 4: -5.725742210556142}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.89674308741927, 3: -5.864063139584334, 4: -5.725742210556142}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.89674308741927, 3: -5.864063139584334, 4: -6.110425411606089}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.89674308741927, 3: -5.864063139584334, 4: -6.260933684223919}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.89674308741927, 3: -6.2362974570217435, 4: -6.260933684223919}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.857303376403524, 2: -5.910851571114177, 3: -5.896409374114837, 4: -5.504740098299953}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.857303376403524, 2: -5.910851571114177, 3: -5.896409374114837, 4: -5.504740098299953}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -5.857303376403524, 2: -5.910851571114177, 3: -5.896409374114837, 4: -5.909313489452957}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.7398823148005675, 3: -5.890210201616829, 4: -5.913082449168382}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.465215910239608, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.3252737218364805, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.176682036413113, 1: -6.010752859683361, 2: -6.538860051837325, 3: -6.508880347120313, 4: -6.595385087069472}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.4438787573080445 -6.489828705555923 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.181692682967918 -6.203541998630058 -5.892626569238166 -5.580800511191054 -5.468775704262472 \n",
      "-6.07436040644931 -5.938433850175169 -5.769128005636983 -5.423233832678667 -5.345009013393166 \n",
      "-5.908853697404106 -5.896409374114837 -5.60881168033223 -5.623509954082044 -5.218104669378444 \n",
      "-5.838216697894563 -5.8076706747701685 -5.529194096366973 -5.39360094020161 -6.010752859683361 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181692682967918, 1: -6.240299916906242, 2: -6.400113425996073, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.4438787573080445, 2: -6.65873307645932, 3: -6.529472067078347, 4: -6.730991497027287}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.240299916906242, 2: -6.400113425996073, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.07436040644931, 1: -6.1258961591824095, 2: -6.278187641597934, 3: -6.199204882032033, 4: -6.319093934762566}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.444261920914566, 2: -6.400113425996073, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.444261920914566, 2: -6.400113425996073, 3: -6.39860322744296, 4: -6.446294937969167}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.444261920914566, 2: -6.400113425996073, 3: -6.722728936973094, 4: -6.446294937969167}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203541998630058, 1: -6.2859165053195944, 2: -6.213700650723116, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.674712731592734, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.674712731592734, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.489828705555923}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.674712731592734, 2: -6.777221264630745, 3: -6.619152578047838, 4: -6.8057441220558905}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.59903080842486, 2: -6.65873307645932, 3: -6.529472067078347, 4: -6.730991497027287}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.59903080842486, 2: -6.65873307645932, 3: -6.529472067078347, 4: -6.730991497027287}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.59903080842486, 2: -6.65873307645932, 3: -6.841819581041296, 4: -6.730991497027287}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.444261920914566, 2: -6.564880361489954, 3: -6.756364768754129, 4: -6.446294937969167}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.1258961591824095, 2: -6.278187641597934, 3: -6.199204882032033, 4: -6.319093934762566}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -5.908853697404106, 2: -5.948513788364889, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.998914549455404, 4: -6.14179034061178}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -5.838216697894563, 2: -5.899727489011886, 3: -5.998914549455404, 4: -6.14179034061178}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -6.212777195084052, 2: -5.899727489011886, 3: -5.998914549455404, 4: -6.14179034061178}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8076706747701685, 1: -5.814709948878255, 2: -5.900813118774139, 3: -5.890210201616829, 4: -5.913082449168382}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -6.135035012628812, 2: -5.910851571114177, 3: -5.896409374114837, 4: -6.235347083832151}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -6.219840895035007, 2: -5.948513788364889, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8979145850557195, 1: -6.135035012628812, 2: -5.910851571114177, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -5.938433850175169, 2: -6.129258717451358, 3: -6.253764541294479, 4: -6.184909660509893}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.135035012628812, 2: -5.910851571114177, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.60881168033223, 2: -5.975153066619556, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.75999330571151, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.75999330571151, 3: -5.788729239546663, 4: -5.529194096366973}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.75999330571151, 3: -5.788729239546663, 4: -5.931566627693945}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -5.619857181134254, 2: -5.75999330571151, 3: -5.788729239546663, 4: -6.04524097948814}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.621380281010145, 1: -6.014070034832171, 2: -5.75999330571151, 3: -5.788729239546663, 4: -6.04524097948814}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.939528386090471, 2: -5.975153066619556, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.939528386090471, 2: -5.975153066619556, 3: -5.763769557375867, 4: -5.688310924851941}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.939528386090471, 2: -5.975153066619556, 3: -5.763769557375867, 4: -6.076362941615266}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.135035012628812, 2: -6.034222618180523, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935607713514107, 1: -5.939528386090471, 2: -5.975153066619556, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -5.8478213038526725, 2: -5.769128005636983, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.445876105301785, 2: -5.4753928147885915, 3: -6.001795994057835, 4: -5.423233832678667}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.445876105301785, 2: -5.4753928147885915, 3: -6.001795994057835, 4: -5.423233832678667}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.445876105301785, 2: -5.4753928147885915, 3: -6.001795994057835, 4: -5.8351427877375865}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.706762395799485, 2: -5.623509954082044, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.238656067602898, 2: -5.269549377254439, 3: -5.774089871897857, 4: -5.218104669378444}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.238656067602898, 2: -5.269549377254439, 3: -5.774089871897857, 4: -5.218104669378444}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.238656067602898, 2: -5.269549377254439, 3: -5.774089871897857, 4: -5.648475249134384}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.176682036413113, 1: -6.508246359172349, 2: -6.538860051837325, 3: -6.508880347120313, 4: -6.595385087069472}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.6379781667397015 -6.674712731592734 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.446294937969167 -6.213700650723116 -5.892626569238166 -5.580800511191054 -5.468775704262472 \n",
      "-6.199204882032033 -6.059643692035746 -5.8478213038526725 -5.4753928147885915 -5.345009013393166 \n",
      "-6.12678137212457 -6.135035012628812 -5.939528386090471 -5.689015777604744 -5.269549377254439 \n",
      "-5.998914549455404 -5.814709948878255 -5.75999330571151 -5.39360094020161 -6.176682036413113 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.779755236783284, 2: -6.65873307645932, 3: -6.929396912928267, 4: -6.730991497027287}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6379781667397015, 1: -6.779755236783284, 2: -6.65873307645932, 3: -6.929396912928267, 4: -6.730991497027287}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.940560131733129, 1: -6.779755236783284, 2: -6.65873307645932, 3: -6.929396912928267, 4: -6.730991497027287}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.674712731592734, 2: -6.777221264630745, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.2859165053195944, 2: -6.213700650723116, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -5.966751898559875, 2: -5.955884073678897, 3: -6.123868511941924, 4: -5.892626569238166}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -5.966751898559875, 2: -5.955884073678897, 3: -6.123868511941924, 4: -5.892626569238166}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -5.966751898559875, 2: -5.955884073678897, 3: -6.123868511941924, 4: -6.262290178006731}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.65659137283117, 2: -5.828959763881911, 3: -5.580800511191054, 4: -6.002358755387093}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -5.966751898559875, 2: -6.016036821432644, 3: -6.123868511941924, 4: -6.3504951174805795}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -5.8478213038526725, 2: -5.869732205033419, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.166554455917367, 1: -5.939528386090471, 2: -5.975153066619556, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -5.75999330571151, 3: -5.788729239546663, 4: -6.04524097948814}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.401237188527171, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.401237188527171, 3: -5.6127149006748, 4: -5.39360094020161}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.401237188527171, 3: -5.6127149006748, 4: -5.808176855583465}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.508246359172349, 2: -6.538860051837325, 3: -6.508880347120313, 4: -6.595385087069472}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.730991497027287 -6.6005688002449965 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.446294937969167 -6.2859165053195944 -6.016036821432644 -5.65659137283117 -5.468775704262472 \n",
      "-6.199204882032033 -6.059643692035746 -5.869732205033419 -5.4753928147885915 -5.345009013393166 \n",
      "-6.12678137212457 -6.135035012628812 -5.975153066619556 -5.689015777604744 -5.269549377254439 \n",
      "-5.998914549455404 -5.814709948878255 -5.788729239546663 -5.6127149006748 -6.508246359172349 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.506402081029209, 2: -6.564880361489954, 3: -6.756364768754129, 4: -6.446294937969167}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.506402081029209, 2: -6.564880361489954, 3: -6.756364768754129, 4: -6.446294937969167}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.506402081029209, 2: -6.564880361489954, 3: -6.756364768754129, 4: -6.766128393551942}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.298761110815566, 2: -6.278187641597934, 3: -6.199204882032033, 4: -6.319093934762566}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.298761110815566, 2: -6.278187641597934, 3: -6.199204882032033, 4: -6.319093934762566}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.298761110815566, 2: -6.278187641597934, 3: -6.541276442649151, 4: -6.319093934762566}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.059643692035746, 1: -6.281633157620001, 2: -6.129258717451358, 3: -6.253764541294479, 4: -6.184909660509893}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.2859165053195944, 2: -6.294397586155226, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.129258717451358, 3: -6.253764541294479, 4: -6.184909660509893}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -5.869732205033419, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.999630673336634, 2: -5.4753928147885915, 3: -6.001795994057835, 4: -5.894673924068205}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.430965785016802, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.430965785016802, 2: -5.345009013393166, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.430965785016802, 2: -5.763958202187781, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.526978056254912, 2: -5.269549377254439, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.526978056254912, 2: -5.269549377254439, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.526978056254912, 2: -5.695289933301539, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.77232353567226, 2: -6.538860051837325, 3: -6.508880347120313, 4: -6.595385087069472}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.730991497027287 -6.6005688002449965 -6.003473309791259 -5.827510386342492 -5.697757555218704 \n",
      "-6.564880361489954 -6.294397586155226 -6.016036821432644 -5.65659137283117 -5.468775704262472 \n",
      "-6.298761110815566 -6.184909660509893 -5.922041400482101 -5.530073428882538 -5.448579207326477 \n",
      "-6.12678137212457 -6.135035012628812 -5.975153066619556 -5.689015777604744 -5.684609037094938 \n",
      "-5.998914549455404 -5.814709948878255 -5.788729239546663 -5.6127149006748 -6.508880347120313 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -6.779755236783284, 2: -6.972390620236047, 3: -6.929396912928267, 4: -6.730991497027287}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -6.779755236783284, 2: -6.972390620236047, 3: -6.929396912928267, 4: -6.730991497027287}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -6.779755236783284, 2: -6.972390620236047, 3: -6.929396912928267, 4: -7.025202262294831}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.571996162548868, 2: -6.564880361489954, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.49329121166756, 2: -6.294397586155226, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -6.233410445976653, 2: -6.016036821432644, 3: -6.123868511941924, 4: -6.3504951174805795}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.65659137283117, 2: -5.828959763881911, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.530073428882538, 1: -5.999630673336634, 2: -5.776996582327324, 3: -6.001795994057835, 4: -5.894673924068205}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.690923043436163, 1: -5.945018614677973, 2: -5.828959763881911, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -5.827510386342492, 2: -5.893527068488502, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -5.945018614677973, 2: -5.828959763881911, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.468775704262472, 1: -5.76901771135773, 2: -5.868310591627026, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.697757555218704, 2: -5.8590193371877, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.76901771135773, 2: -5.868310591627026, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.76901771135773, 2: -5.868310591627026, 3: -5.672582854576833, 4: -5.487525186490063}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.76901771135773, 2: -5.868310591627026, 3: -5.672582854576833, 4: -5.893647919705958}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -5.945018614677973, 2: -5.912604296840794, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.76901771135773, 2: -5.868310591627026, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.711431574077776, 2: -5.875478106082388, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.711431574077776, 2: -5.875478106082388, 3: -5.463272985283625, 4: -5.448579207326477}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.711431574077776, 2: -5.875478106082388, 3: -5.463272985283625, 4: -5.858207078667094}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -5.999630673336634, 2: -5.776996582327324, 3: -6.001795994057835, 4: -5.894673924068205}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -5.711431574077776, 2: -5.875478106082388, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.684609037094938, 1: -5.824890886792945, 2: -5.946381218896632, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.74919474320914, 1: -6.075676477454677, 2: -5.875478106082388, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.89025092907022, 2: -5.868310591627026, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.89025092907022, 2: -5.868310591627026, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -5.89025092907022, 2: -6.2401626383805935, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.075676477454677, 2: -5.875478106082388, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.075676477454677, 2: -5.875478106082388, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.075676477454677, 2: -6.246685076534973, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.075676477454677, 2: -6.312636686670119, 3: -6.125694530213495, 4: -5.911071825946446}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.075676477454677, 2: -6.312636686670119, 3: -6.125694530213495, 4: -6.279075361611266}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -5.824890886792945, 2: -5.946381218896632, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -5.824890886792945, 2: -5.946381218896632, 3: -5.774089871897857, 4: -5.708158939671786}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -5.824890886792945, 2: -5.946381218896632, 3: -5.774089871897857, 4: -6.094424635101325}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.706762395799485, 2: -5.689015777604744, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -5.824890886792945, 2: -5.946381218896632, 3: -6.085511767049628, 4: -6.186455259747397}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.77232353567226, 2: -6.538860051837325, 3: -7.002991147304134, 4: -6.595385087069472}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.895528616485191 -6.6005688002449965 -6.003473309791259 -5.8751829852955755 -5.755170046985693 \n",
      "-6.571996162548868 -6.402429583975964 -6.0834426941365125 -5.945018614677973 -6.062061190153398 \n",
      "-6.298761110815566 -6.184909660509893 -5.922041400482101 -5.894673924068205 -6.125694530213495 \n",
      "-6.12678137212457 -6.135035012628812 -5.975153066619556 -5.706762395799485 -5.878965730667528 \n",
      "-5.998914549455404 -5.814709948878255 -5.788729239546663 -5.6127149006748 -6.538860051837325 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.6005688002449965, 2: -6.777221264630745, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.49329121166756, 2: -6.402429583975964, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -6.233410445976653, 2: -6.0834426941365125, 3: -6.123868511941924, 4: -6.3504951174805795}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -5.945018614677973, 2: -6.164164775883841, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -5.999630673336634, 2: -6.103959233235731, 3: -6.001795994057835, 4: -5.894673924068205}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -5.999630673336634, 2: -6.103959233235731, 3: -6.001795994057835, 4: -5.894673924068205}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -5.999630673336634, 2: -6.103959233235731, 3: -6.001795994057835, 4: -6.264153270902066}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -5.706762395799485, 2: -6.18706319606276, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.81180326978232, 3: -5.6127149006748, 4: -5.8558198082653545}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -5.844816092134455, 3: -5.788729239546663, 4: -6.04524097948814}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -5.814709948878255, 2: -5.900813118774139, 3: -5.890210201616829, 4: -5.913082449168382}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -5.814709948878255, 2: -5.900813118774139, 3: -5.890210201616829, 4: -5.913082449168382}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.191386053479213, 2: -5.900813118774139, 3: -5.890210201616829, 4: -5.913082449168382}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -6.300056985608032, 2: -6.194185995465025, 3: -5.998914549455404, 4: -6.14179034061178}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -6.300056985608032, 2: -6.194185995465025, 3: -5.998914549455404, 4: -6.14179034061178}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.111321250025297, 1: -6.300056985608032, 2: -6.194185995465025, 3: -6.359012240004418, 4: -6.14179034061178}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.12678137212457, 1: -6.219840895035007, 2: -6.272162192731622, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.298761110815566, 2: -6.436130154708748, 3: -6.639459633959241, 4: -6.319093934762566}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.219840895035007, 2: -6.272162192731622, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.194185995465025, 3: -6.486071436520932, 4: -6.14179034061178}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.194185995465025, 3: -6.486071436520932, 4: -6.14179034061178}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.194185995465025, 3: -6.486071436520932, 4: -6.48902920995672}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.290208868657553, 2: -5.900813118774139, 3: -6.3481418052205605, 4: -5.913082449168382}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -5.844816092134455, 3: -6.188787982546053, 4: -6.04524097948814}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.81180326978232, 3: -6.150142174100278, 4: -5.8558198082653545}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -5.731117810338739, 2: -5.81180326978232, 3: -6.150142174100278, 4: -5.8558198082653545}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -6.115317207408252, 2: -5.81180326978232, 3: -6.150142174100278, 4: -5.8558198082653545}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.77232353567226, 2: -6.90034673338218, 3: -7.002991147304134, 4: -6.595385087069472}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.895528616485191 -6.7460248430450305 -6.003473309791259 -5.8751829852955755 -5.755170046985693 \n",
      "-6.571996162548868 -6.467831540648172 -6.123868511941924 -6.002358755387093 -6.062061190153398 \n",
      "-6.319093934762566 -6.184909660509893 -5.922041400482101 -6.001795994057835 -6.125694530213495 \n",
      "-6.260933684223919 -6.135035012628812 -5.975153066619556 -5.751603187522085 -5.878965730667528 \n",
      "-6.299077225753555 -5.913082449168382 -6.04524097948814 -5.8558198082653545 -6.595385087069472 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -6.895528616485191, 2: -6.972390620236047, 3: -6.929396912928267, 4: -7.094121968023943}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.571996162548868, 2: -6.654950080934729, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.567947236059911, 2: -6.436130154708748, 3: -6.639459633959241, 4: -6.319093934762566}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.567947236059911, 2: -6.436130154708748, 3: -6.639459633959241, 4: -6.319093934762566}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.567947236059911, 2: -6.436130154708748, 3: -6.639459633959241, 4: -6.650375480633935}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.267408957822205, 3: -6.253764541294479, 4: -6.184909660509893}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.267408957822205, 3: -6.253764541294479, 4: -6.184909660509893}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.267408957822205, 3: -6.253764541294479, 4: -6.528267791064003}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.567947236059911, 2: -6.553389840483889, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.267408957822205, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -5.922041400482101, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -6.122440607931246, 2: -6.103959233235731, 3: -6.001795994057835, 4: -6.386116172492881}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -6.353658895235056, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -6.353658895235056, 3: -6.048798184800654, 4: -5.996475372044645}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -6.353658895235056, 3: -6.048798184800654, 4: -6.356792588560627}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.281633157620001, 2: -6.323594430172722, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.135035012628812, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.290208868657553, 2: -6.224382346506323, 3: -6.3481418052205605, 4: -5.913082449168382}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.290208868657553, 2: -6.224382346506323, 3: -6.3481418052205605, 4: -5.913082449168382}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.290208868657553, 2: -6.224382346506323, 3: -6.3481418052205605, 4: -6.280905028743228}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.04524097948814}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.04524097948814}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.401169291334208}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.054725031101436, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.444444204325584}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.069669877231087, 1: -6.409799778302307, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.444444204325584}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.166554455917367, 1: -6.15954741623537, 2: -5.975153066619556, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751603187522085, 1: -6.016975309126537, 2: -6.18706319606276, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062655008071546, 1: -6.122440607931246, 2: -6.103959233235731, 3: -6.357324650761947, 4: -6.386116172492881}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -6.269187739963043, 2: -6.164164775883841, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -6.269187739963043, 2: -6.164164775883841, 3: -6.291149088952604, 4: -6.002358755387093}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -6.269187739963043, 2: -6.164164775883841, 3: -6.291149088952604, 4: -6.362146467402255}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.062061190153398, 1: -6.248162358833756, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.914671156578822, 2: -5.8590193371877, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755170046985693, 1: -5.914671156578822, 2: -5.8590193371877, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.137204742756981, 1: -5.914671156578822, 2: -5.8590193371877, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -5.914671156578822, 2: -5.8590193371877, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -5.914671156578822, 2: -6.231707596840807, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.167893857073752, 1: -6.248162358833756, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.167893857073752, 1: -6.248162358833756, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.0841569041778305}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.167893857073752, 1: -6.248162358833756, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.436582782801826}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.076153555767471, 4: -5.96333657184457}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.076153555767471, 4: -6.326636280378559}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -6.204208447378597, 2: -5.893527068488502, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8751829852955755, 1: -6.204208447378597, 2: -5.893527068488502, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.246416516618973, 1: -6.204208447378597, 2: -5.893527068488502, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.266513573666163, 4: -6.454348008209507}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.259526137397735, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.266513573666163, 4: -6.454348008209507}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.596168785031939, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.266513573666163, 4: -6.454348008209507}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.204208447378597, 2: -6.5595688781410155, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.204208447378597, 2: -6.5595688781410155, 3: -6.139200215299085, 4: -5.924721175579872}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.204208447378597, 2: -6.5595688781410155, 3: -6.139200215299085, 4: -6.291496269777684}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.003473309791259, 3: -6.598310947587999, 4: -6.125930999371415}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.204208447378597, 2: -6.5595688781410155, 3: -6.376733402460828, 4: -6.501901801370027}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1893757172810355, 1: -6.269187739963043, 2: -6.426686041612636, 3: -6.291149088952604, 4: -6.529188115206137}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.376733402460828, 4: -6.501901801370027}, Best action: 0, Actual action: 0\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298398577137584, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.376733402460828, 4: -6.501901801370027}, Best action: 0, Actual action: 0\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631542705195201, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.376733402460828, 4: -6.501901801370027}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.125930999371415}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.125930999371415}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.146878452588944, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.474597209427988}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -6.233410445976653, 2: -6.323809347302809, 3: -6.123868511941924, 4: -6.3504951174805795}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.49329121166756, 2: -6.467831540648172, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2241793310886555, 1: -6.233410445976653, 2: -6.323809347302809, 3: -6.751330399119212, 4: -6.3504951174805795}, Best action: 0, Actual action: 0\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.475021339931853, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 0, Actual action: 0\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25473312928209, 1: -6.475021339931853, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.591807147646701, 1: -6.475021339931853, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.233410445976653, 2: -6.323809347302809, 3: -6.751330399119212, 4: -6.3504951174805795}, Best action: 1, Actual action: 1\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.127251008092848, 1: -6.295800123118549, 2: -6.353658895235056, 3: -6.593002676152266, 4: -6.435205788544592}, Best action: 0, Actual action: 0\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.486414361152873, 2: -6.323809347302809, 3: -6.751330399119212, 4: -6.3504951174805795}, Best action: 2, Actual action: 2\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.269187739963043, 2: -6.426686041612636, 3: -6.291149088952604, 4: -6.529188115206137}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3681760926707, 1: -6.122440607931246, 2: -6.103959233235731, 3: -6.357324650761947, 4: -6.386116172492881}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.131176388879615, 2: -6.312636686670119, 3: -6.125694530213495, 4: -6.449205482899416}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3681760926707, 1: -6.122440607931246, 2: -6.472208492796504, 3: -6.357324650761947, 4: -6.386116172492881}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.016975309126537, 2: -6.18706319606276, 3: -5.79027687302399, 4: -5.855424073217143}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.166554455917367, 1: -6.15954741623537, 2: -6.156313888554845, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.016975309126537, 2: -6.18706319606276, 3: -6.465641937031823, 4: -5.855424073217143}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.016975309126537, 2: -6.18706319606276, 3: -6.465641937031823, 4: -5.855424073217143}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.016975309126537, 2: -6.18706319606276, 3: -6.465641937031823, 4: -6.2284359066276}, Best action: 1, Actual action: 1\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -6.219092369264505, 2: -5.9234422475045045, 3: -6.150142174100278, 4: -5.8558198082653545}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -6.219092369264505, 2: -5.9234422475045045, 3: -6.150142174100278, 4: -5.8558198082653545}, Best action: 4, Actual action: 4\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -6.219092369264505, 2: -5.9234422475045045, 3: -6.150142174100278, 4: -6.228796025521473}, Best action: 2, Actual action: 2\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.77232353567226, 2: -6.90034673338218, 3: -7.002991147304134, 4: -7.144916688059952}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.912869753313102 -6.7460248430450305 -6.52575617335579 -6.499677449736929 -6.314054396512927 \n",
      "-6.654950080934729 -6.474972987100666 -6.3504951174805795 -6.291149088952604 -6.248162358833756 \n",
      "-6.567947236059911 -6.323594430172722 -6.295800123118549 -6.2023683279425565 -6.131176388879615 \n",
      "-6.260933684223919 -6.235347083832151 -6.15954741623537 -6.18706319606276 -5.878965730667528 \n",
      "-6.299077225753555 -6.256858660510035 -6.126687035587824 -5.96151492711597 -6.77232353567226 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.675665703412565, 2: -6.654950080934729, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.49329121166756, 2: -6.588368412246629, 3: -6.474972987100666, 4: -6.522377480284456}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.675665703412565, 2: -6.8102231276450125, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.567947236059911, 2: -6.631940239884375, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.272162192731622, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.272162192731622, 3: -6.299991646511783, 4: -6.260933684223919}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.272162192731622, 3: -6.299991646511783, 4: -6.597449652643766}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.303100285089271, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.303100285089271, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.235347083832151}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.299922877147459, 1: -6.303100285089271, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.574165846287258}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.4975416759913385, 2: -6.323594430172722, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.295800123118549, 2: -6.353658895235056, 3: -6.593002676152266, 4: -6.435205788544592}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.166554455917367, 1: -6.15954741623537, 2: -6.25852488816137, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346840971684949, 1: -6.4574125783874115, 2: -6.126687035587824, 3: -6.188787982546053, 4: -6.444444204325584}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.96151492711597, 1: -6.219092369264505, 2: -6.077926288644981, 3: -6.150142174100278, 4: -6.320867823030796}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.244911575607591, 2: -6.18706319606276, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -5.878965730667528, 2: -5.946381218896632, 3: -6.085511767049628, 4: -6.186455259747397}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.89443051870047, 1: -6.967741919124356, 2: -6.90034673338218, 3: -7.002991147304134, 4: -7.144916688059952}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.912869753313102 -6.7460248430450305 -6.52575617335579 -6.499677449736929 -6.314054396512927 \n",
      "-6.737711061716308 -6.49329121166756 -6.3504951174805795 -6.291149088952604 -6.248162358833756 \n",
      "-6.628151007827365 -6.4975416759913385 -6.353658895235056 -6.2023683279425565 -6.131176388879615 \n",
      "-6.299991646511783 -6.303100285089271 -6.166554455917367 -6.244911575607591 -5.946381218896632 \n",
      "-6.299077225753555 -6.256858660510035 -6.188787982546053 -6.077926288644981 -6.89443051870047 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -6.912869753313102, 2: -6.972390620236047, 3: -6.929396912928267, 4: -7.094121968023943}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.737711061716308, 1: -6.887603831549785, 2: -6.8102231276450125, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -7.048832935321519, 2: -6.972390620236047, 3: -6.929396912928267, 4: -7.094121968023943}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -7.048832935321519, 2: -6.972390620236047, 3: -6.929396912928267, 4: -7.094121968023943}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -7.048832935321519, 2: -6.972390620236047, 3: -7.205751190764723, 4: -7.094121968023943}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.7460248430450305, 2: -6.777221264630745, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.49329121166756, 2: -6.588368412246629, 3: -6.954786518474244, 4: -6.522377480284456}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.4975416759913385, 2: -6.631957542743297, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.303100285089271, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.660354115118167}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256858660510035, 1: -6.290208868657553, 2: -6.419083428036026, 3: -6.3481418052205605, 4: -6.5698402035444445}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.598365543522056, 2: -6.31126450976448, 3: -6.307937105987044, 4: -6.660354115118167}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.577847357177205, 3: -6.299991646511783, 4: -6.64019634137699}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.577847357177205, 3: -6.299991646511783, 4: -6.64019634137699}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.496834265399043, 2: -6.577847357177205, 3: -6.632992398325723, 4: -6.64019634137699}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.299077225753555, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.290208868657553, 2: -6.419083428036026, 3: -6.3481418052205605, 4: -6.5698402035444445}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.290208868657553, 2: -6.419083428036026, 3: -6.3481418052205605, 4: -6.5698402035444445}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.624090070478373, 2: -6.419083428036026, 3: -6.3481418052205605, 4: -6.5698402035444445}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.624976906187974, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.300056985608032, 2: -6.624976906187974, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.473825036423431, 1: -6.63305185690331, 2: -6.624976906187974, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.651935979400284, 2: -6.577847357177205, 3: -6.8257349948057975, 4: -6.64019634137699}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.598365543522056, 2: -6.31126450976448, 3: -6.6337869442732496, 4: -6.660354115118167}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.166554455917367, 1: -6.478571240449675, 2: -6.25852488816137, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.5188134194625045, 2: -6.353658895235056, 3: -6.593002676152266, 4: -6.435205788544592}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3681760926707, 1: -6.2023683279425565, 2: -6.472208492796504, 3: -6.357324650761947, 4: -6.386116172492881}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.244911575607591, 2: -6.280668561446974, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.219092369264505, 2: -6.077926288644981, 3: -6.150142174100278, 4: -6.320867823030796}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -6.967741919124356, 2: -6.90034673338218, 3: -7.002991147304134, 4: -7.144916688059952}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.987629805105362 -6.777221264630745 -6.52575617335579 -6.499677449736929 -6.314054396512927 \n",
      "-6.756364768754129 -6.522377480284456 -6.3504951174805795 -6.291149088952604 -6.248162358833756 \n",
      "-6.628151007827365 -6.597556738512447 -6.435205788544592 -6.357324650761947 -6.131176388879615 \n",
      "-6.614674636973065 -6.526035560269515 -6.176289635635979 -6.280668561446974 -5.946381218896632 \n",
      "-6.486071436520932 -6.419083428036026 -6.188787982546053 -6.150142174100278 -6.90034673338218 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.834168365755227, 2: -6.777221264630745, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.596564595234274, 2: -6.52575617335579, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.499677449736929, 4: -6.501901801370027}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.596564595234274, 2: -6.817314351622492, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.596564595234274, 2: -6.817314351622492, 3: -6.598310947587999, 4: -6.526431267539844}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.596564595234274, 2: -6.817314351622492, 3: -6.598310947587999, 4: -6.8390524534612585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.486414361152873, 2: -6.610423004100346, 3: -6.751330399119212, 4: -6.3504951174805795}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.486414361152873, 2: -6.610423004100346, 3: -6.751330399119212, 4: -6.3504951174805795}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.486414361152873, 2: -6.610423004100346, 3: -6.751330399119212, 4: -6.678950556907328}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.5188134194625045, 2: -6.5592842351569765, 3: -6.593002676152266, 4: -6.435205788544592}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.5188134194625045, 2: -6.5592842351569765, 3: -6.593002676152266, 4: -6.435205788544592}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.5188134194625045, 2: -6.5592842351569765, 3: -6.593002676152266, 4: -6.756037267575579}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.478571240449675, 2: -6.25852488816137, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.478571240449675, 2: -6.25852488816137, 3: -6.364097276463811, 4: -6.176289635635979}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.478571240449675, 2: -6.25852488816137, 3: -6.364097276463811, 4: -6.5204235684287415}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.447611451363194, 2: -6.280668561446974, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -6.172385293214134, 2: -5.946381218896632, 3: -6.085511767049628, 4: -6.186455259747397}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -6.172385293214134, 2: -5.946381218896632, 3: -6.085511767049628, 4: -6.186455259747397}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -6.172385293214134, 2: -6.311206909195935, 3: -6.085511767049628, 4: -6.186455259747397}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.447611451363194, 2: -6.344635643450969, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.125308645708897, 1: -6.172385293214134, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.186455259747397}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.131176388879615, 2: -6.312636686670119, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.172385293214134, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.186455259747397}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -6.967741919124356, 2: -7.079583897689122, 3: -7.002991147304134, 4: -7.144916688059952}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.987629805105362 -6.820011564194213 -6.598310947587999 -6.501901801370027 -6.314054396512927 \n",
      "-6.756364768754129 -6.522377480284456 -6.588751767827358 -6.291149088952604 -6.248162358833756 \n",
      "-6.628151007827365 -6.597556738512447 -6.554675946811393 -6.357324650761947 -6.228251053538805 \n",
      "-6.614674636973065 -6.526035560269515 -6.364097276463811 -6.38591087529016 -6.186455259747397 \n",
      "-6.486071436520932 -6.419083428036026 -6.188787982546053 -6.150142174100278 -6.967741919124356 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.8102231276450125, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.8102231276450125, 3: -6.756364768754129, 4: -6.846798524988853}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.8102231276450125, 3: -7.0482919395662575, 4: -6.846798524988853}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.812337878719741, 2: -6.588368412246629, 3: -6.954786518474244, 4: -6.522377480284456}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.812337878719741, 2: -6.588368412246629, 3: -6.954786518474244, 4: -6.522377480284456}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.812337878719741, 2: -6.588368412246629, 3: -6.954786518474244, 4: -6.835363507058855}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588751767827358, 1: -6.761158124836407, 2: -6.610423004100346, 3: -6.751330399119212, 4: -6.82189068822456}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.703557504682697, 2: -6.817314351622492, 3: -6.598310947587999, 4: -6.927122567485888}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.834168365755227, 2: -6.863584626881265, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820011564194213, 1: -6.834168365755227, 2: -6.863584626881265, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 0, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -6.834168365755227, 2: -6.863584626881265, 3: -6.850787632138245, 4: -6.942088000424338}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.777115451363303, 1: -6.812337878719741, 2: -6.895725773164823, 3: -6.954786518474244, 4: -6.920114764625655}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.072880352179799, 2: -6.863584626881265, 3: -6.850787632138245, 4: -7.1298851763041675}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -7.048832935321519, 2: -7.061519184890079, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987629805105362, 1: -7.048832935321519, 2: -7.061519184890079, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258743122645879, 1: -7.048832935321519, 2: -7.061519184890079, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.864148071794911, 3: -7.121109927349086, 4: -6.846798524988853}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.864148071794911, 3: -7.121109927349086, 4: -6.846798524988853}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -6.864148071794911, 3: -7.121109927349086, 4: -7.1305866577398564}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.812337878719741, 2: -6.895725773164823, 3: -6.954786518474244, 4: -6.920114764625655}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597556738512447, 1: -6.655265398521443, 2: -6.631957542743297, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.925254746067056, 2: -6.895725773164823, 3: -6.954786518474244, 4: -6.920114764625655}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.761158124836407, 2: -6.610423004100346, 3: -6.751330399119212, 4: -6.82189068822456}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.471125752917247, 2: -6.426686041612636, 3: -6.291149088952604, 4: -6.529188115206137}, Best action: 3, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.471125752917247, 2: -6.426686041612636, 3: -6.291149088952604, 4: -6.529188115206137}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.761158124836407, 2: -6.849684673727005, 3: -6.751330399119212, 4: -6.82189068822456}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.925254746067056, 2: -6.944015210637763, 3: -6.954786518474244, 4: -6.920114764625655}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.925254746067056, 2: -6.944015210637763, 3: -6.954786518474244, 4: -6.920114764625655}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.925254746067056, 2: -6.944015210637763, 3: -6.954786518474244, 4: -7.197304435809347}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.655265398521443, 2: -6.631957542743297, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.655265398521443, 2: -6.631957542743297, 3: -6.833622224921398, 4: -6.618376057554928}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.655265398521443, 2: -6.631957542743297, 3: -6.833622224921398, 4: -6.9227222123749845}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.554675946811393, 2: -6.5592842351569765, 3: -6.593002676152266, 4: -6.855842596522186}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.478571240449675, 2: -6.613194023588186, 3: -6.364097276463811, 4: -6.621447516253584}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.598365543522056, 2: -6.526035560269515, 3: -6.6337869442732496, 4: -6.660354115118167}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.478571240449675, 2: -6.613194023588186, 3: -6.822498531464688, 4: -6.621447516253584}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346840971684949, 1: -6.4574125783874115, 2: -6.341495794522718, 3: -6.188787982546053, 4: -6.444444204325584}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.704403869276492, 2: -6.419083428036026, 3: -6.637860338864563, 4: -6.5698402035444445}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346840971684949, 1: -6.4574125783874115, 2: -6.341495794522718, 3: -6.718336374963786, 4: -6.444444204325584}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.219092369264505, 2: -6.197073482904064, 3: -6.150142174100278, 4: -6.320867823030796}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346840971684949, 1: -6.4574125783874115, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.444444204325584}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.5607753899072705, 2: -6.613194023588186, 3: -6.822498531464688, 4: -6.621447516253584}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.4574125783874115, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.444444204325584}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.4574125783874115, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.444444204325584}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.4574125783874115, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.764444225936281}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.4574125783874115, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.8069486110874315}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.7762454463325446, 2: -6.5157647404734975, 3: -6.718336374963786, 4: -6.8069486110874315}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.219092369264505, 2: -6.197073482904064, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -7.06942965460328, 2: -7.079583897689122, 3: -7.002991147304134, 4: -7.144916688059952}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.061519184890079 -6.863584626881265 -6.703557504682697 -6.501901801370027 -6.314054396512927 \n",
      "-6.887603831549785 -6.944015210637763 -6.761158124836407 -6.426686041612636 -6.248162358833756 \n",
      "-6.628151007827365 -6.655265398521443 -6.5592842351569765 -6.357324650761947 -6.228251053538805 \n",
      "-6.614674636973065 -6.598365543522056 -6.613194023588186 -6.38591087529016 -6.186455259747397 \n",
      "-6.486071436520932 -6.5698402035444445 -6.571205995199642 -6.219092369264505 -7.002991147304134 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.150790098773124, 2: -7.061519184890079, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.072880352179799, 2: -6.863584626881265, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -6.703557504682697, 2: -6.817314351622492, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.761158124836407, 2: -6.849684673727005, 3: -7.180425999258702, 4: -6.82189068822456}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.7103863886168265, 2: -6.5592842351569765, 3: -6.593002676152266, 4: -6.855842596522186}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3681760926707, 1: -6.578615209036404, 2: -6.472208492796504, 3: -6.357324650761947, 4: -6.386116172492881}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.7103863886168265, 2: -6.705361390632874, 3: -6.593002676152266, 4: -6.855842596522186}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.655265398521443, 2: -6.872483271191559, 3: -6.833622224921398, 4: -6.96415783085957}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.598365543522056, 2: -6.800246260791188, 3: -6.6337869442732496, 4: -6.660354115118167}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.704403869276492, 2: -6.678519936367004, 3: -6.637860338864563, 4: -6.5698402035444445}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.704403869276492, 2: -6.678519936367004, 3: -6.637860338864563, 4: -6.5698402035444445}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635114921900509, 1: -6.704403869276492, 2: -6.678519936367004, 3: -6.637860338864563, 4: -6.878554585225445}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.881407119223206, 2: -6.800246260791188, 3: -6.6337869442732496, 4: -6.660354115118167}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614674636973065, 1: -6.651935979400284, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -6.64019634137699}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.628151007827365, 2: -6.631940239884375, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.930269780037473, 1: -6.651935979400284, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -6.64019634137699}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.930269780037473, 1: -6.651935979400284, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -6.64019634137699}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.930269780037473, 1: -6.651935979400284, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -6.942578670653061}, Best action: 1, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.941374137298099, 2: -6.631940239884375, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.91020263010501, 2: -6.872483271191559, 3: -6.833622224921398, 4: -6.96415783085957}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.941374137298099, 2: -7.098428026174769, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.941374137298099, 2: -7.098428026174769, 3: -6.639459633959241, 4: -6.77830297337748}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.690304654873729, 1: -6.941374137298099, 2: -7.098428026174769, 3: -6.941908266902909, 4: -6.77830297337748}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -6.887603831549785, 2: -7.1044084889424814, 3: -7.121109927349086, 4: -7.173018603927863}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -6.941374137298099, 2: -7.098428026174769, 3: -7.013337597138012, 4: -6.77830297337748}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -6.941374137298099, 2: -7.098428026174769, 3: -7.013337597138012, 4: -6.77830297337748}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -6.941374137298099, 2: -7.098428026174769, 3: -7.013337597138012, 4: -7.068255705773507}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -6.651935979400284, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -7.20777638889566}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.624976906187974, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.624976906187974, 3: -6.486071436520932, 4: -6.566193577322342}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.624976906187974, 3: -6.802325007234049, 4: -6.566193577322342}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.624976906187974, 3: -6.898849298354502, 4: -6.566193577322342}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.624976906187974, 3: -6.898849298354502, 4: -6.875236155363331}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -6.704403869276492, 2: -6.678519936367004, 3: -6.637860338864563, 4: -6.962298545261957}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.939164565099094, 3: -6.898849298354502, 4: -6.953754909548592}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -6.80710346519331, 2: -6.939164565099094, 3: -6.898849298354502, 4: -6.953754909548592}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87543886295588, 1: -7.094464153325912, 2: -6.939164565099094, 3: -6.898849298354502, 4: -6.953754909548592}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -6.818911461521983, 2: -6.669908988626949, 3: -6.8257349948057975, 4: -7.20777638889566}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.652103776154651, 1: -6.881407119223206, 2: -6.800246260791188, 3: -6.921265150375508, 4: -6.660354115118167}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.91020263010501, 2: -6.872483271191559, 3: -6.961324525999125, 4: -6.96415783085957}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.63501067212456, 1: -6.7103863886168265, 2: -6.705361390632874, 3: -6.9500652404175955, 4: -6.855842596522186}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.889136042960792, 2: -6.849684673727005, 3: -7.180425999258702, 4: -6.82189068822456}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.889136042960792, 2: -6.849684673727005, 3: -7.180425999258702, 4: -6.82189068822456}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.889136042960792, 2: -6.849684673727005, 3: -7.180425999258702, 4: -7.1079205262843494}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.471125752917247, 2: -6.426686041612636, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.347092008901477, 1: -6.248162358833756, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.539652302509921}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.228251053538805, 1: -6.5127497263914105, 2: -6.312636686670119, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.347092008901477, 1: -6.569699589249808, 2: -6.295119516384937, 3: -6.256467765898726, 4: -6.539652302509921}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.471125752917247, 2: -6.603680114816607, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3681760926707, 1: -6.578615209036404, 2: -6.472208492796504, 3: -6.87606463275953, 4: -6.386116172492881}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.705335210354992, 2: -6.603680114816607, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.347092008901477, 1: -6.569699589249808, 2: -6.295119516384937, 3: -6.767258636452842, 4: -6.539652302509921}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.347092008901477, 1: -6.569699589249808, 2: -6.295119516384937, 3: -6.767258636452842, 4: -6.539652302509921}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.347092008901477, 1: -6.569699589249808, 2: -6.628558759910293, 3: -6.767258636452842, 4: -6.539652302509921}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.325675509586313, 4: -6.454348008209507}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.419634208041924, 2: -6.314054396512927, 3: -6.325675509586313, 4: -6.454348008209507}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.419634208041924, 2: -6.645789500826764, 3: -6.325675509586313, 4: -6.454348008209507}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.836377071680967, 4: -6.501901801370027}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.836377071680967, 4: -6.501901801370027}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.533815175735498, 2: -6.5595688781410155, 3: -6.836377071680967, 4: -6.8167306392467255}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.620640419209546, 1: -6.705335210354992, 2: -6.65941481975346, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 0, Actual action: 0\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.916100257133282, 2: -6.5595688781410155, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 2, Actual action: 2\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.419634208041924, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.454348008209507}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.649093262065619, 1: -6.569699589249808, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.539652302509921}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.649093262065619, 1: -6.569699589249808, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.539652302509921}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.649093262065619, 1: -6.569699589249808, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.851083595284028}, Best action: 1, Actual action: 1\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.312636686670119, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.312636686670119, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.644499384869809, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.788306379635507, 3: -6.471746345445658, 4: -6.449205482899416}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.788306379635507, 3: -6.471746345445658, 4: -6.768776989438468}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.578615209036404, 2: -6.472208492796504, 3: -6.87606463275953, 4: -6.386116172492881}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.578615209036404, 2: -6.472208492796504, 3: -6.87606463275953, 4: -6.386116172492881}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.578615209036404, 2: -6.472208492796504, 3: -6.87606463275953, 4: -6.711365716968522}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5127497263914105, 2: -6.788306379635507, 3: -6.719928734263799, 4: -6.81899223875483}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.261109483812142, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.186455259747397}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.261109483812142, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.186455259747397}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.261109483812142, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.529674286370132}, Best action: 1, Actual action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -7.06942965460328, 2: -7.079583897689122, 3: -7.320129654491377, 4: -7.144916688059952}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.094121968023943 -7.016240041481112 -6.803948000109472 -6.728308326512791 -6.454348008209507 \n",
      "-7.079185791590738 -6.944015210637763 -6.790584161078936 -6.648749573572224 -6.649093262065619 \n",
      "-6.98220555704404 -6.91020263010501 -6.705361390632874 -6.578615209036404 -6.5623037330345335 \n",
      "-6.818911461521983 -6.660354115118167 -6.613194023588186 -6.38591087529016 -6.352348968609871 \n",
      "-6.898849298354502 -6.678519936367004 -6.571205995199642 -6.219092369264505 -7.06942965460328 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.079185791590738, 2: -7.1044084889424814, 3: -7.121109927349086, 4: -7.173018603927863}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -6.98220555704404, 2: -7.098428026174769, 3: -7.013337597138012, 4: -7.229338621788811}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -6.818911461521983, 2: -6.955194957547962, 3: -6.8257349948057975, 4: -7.20777638889566}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -6.939164565099094, 3: -6.898849298354502, 4: -6.953754909548592}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -6.939164565099094, 3: -6.898849298354502, 4: -6.953754909548592}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -6.939164565099094, 3: -7.177952861502598, 4: -6.953754909548592}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -6.704403869276492, 2: -6.678519936367004, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.571205995199642, 3: -6.718336374963786, 4: -6.8069486110874315}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.219092369264505, 2: -6.292130177606755, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.219092369264505, 2: -6.292130177606755, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.559374056030699, 2: -6.292130177606755, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -7.341083456648826, 2: -7.079583897689122, 3: -7.320129654491377, 4: -7.144916688059952}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.094121968023943 -7.016240041481112 -6.803948000109472 -6.728308326512791 -6.454348008209507 \n",
      "-7.1044084889424814 -6.944015210637763 -6.790584161078936 -6.648749573572224 -6.649093262065619 \n",
      "-7.013337597138012 -6.91020263010501 -6.705361390632874 -6.578615209036404 -6.5623037330345335 \n",
      "-6.8257349948057975 -6.660354115118167 -6.613194023588186 -6.38591087529016 -6.352348968609871 \n",
      "-6.953754909548592 -6.704403869276492 -6.594585418624213 -6.320867823030796 -7.079583897689122 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.072880352179799, 2: -7.016240041481112, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -7.046893831585759, 2: -6.817314351622492, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.803948000109472, 1: -7.046893831585759, 2: -6.817314351622492, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.09159268009962, 1: -7.046893831585759, 2: -6.817314351622492, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.916100257133282, 2: -6.755860596328061, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.728308326512791, 1: -6.916100257133282, 2: -6.755860596328061, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022760577126641, 1: -6.916100257133282, 2: -6.755860596328061, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.454348008209507}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.454348008209507}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.773456687470651}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.635492873172787, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.952094896017023}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9382985145872365, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.952094896017023}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.839081785837229, 2: -6.68837611284759, 3: -6.799108010068354, 4: -6.952094896017023}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.839081785837229, 2: -6.986422262691307, 3: -6.799108010068354, 4: -6.952094896017023}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.916100257133282, 2: -6.803607946282507, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.839081785837229, 2: -7.1059197144244965, 3: -7.090833237495666, 4: -6.952094896017023}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.649093262065619, 1: -6.670205675127777, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.906565026820748}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.969673720856874, 2: -7.1059197144244965, 3: -7.090833237495666, 4: -6.952094896017023}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.969673720856874, 2: -7.1059197144244965, 3: -7.090833237495666, 4: -6.952094896017023}, Best action: 4, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.916100257133282, 2: -7.120017041156407, 3: -6.836377071680967, 4: -6.874063356270426}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.046893831585759, 2: -7.03166117963761, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.046893831585759, 2: -7.03166117963761, 3: -7.084040461756112, 4: -6.927122567485888}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.046893831585759, 2: -7.03166117963761, 3: -7.084040461756112, 4: -7.203681536412159}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.916100257133282, 2: -7.120017041156407, 3: -7.194606986831666, 4: -6.874063356270426}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.916100257133282, 2: -7.120017041156407, 3: -7.194606986831666, 4: -6.874063356270426}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.916100257133282, 2: -7.120017041156407, 3: -7.194606986831666, 4: -7.155397654206087}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.875314833215177, 1: -6.705335210354992, 2: -6.65941481975346, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.875314833215177, 1: -6.705335210354992, 2: -6.65941481975346, 3: -6.997692532181823, 4: -6.648749573572224}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.875314833215177, 1: -6.705335210354992, 2: -6.65941481975346, 3: -6.997692532181823, 4: -6.950362111950724}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -6.670205675127777, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.906565026820748}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.5623037330345335, 2: -6.788306379635507, 3: -6.719928734263799, 4: -6.81899223875483}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.352348968609871, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -7.341083456648826, 2: -7.291112823368612, 3: -7.320129654491377, 4: -7.144916688059952}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.094121968023943 -7.072880352179799 -7.046893831585759 -6.97709718030683 -6.969673720856874 \n",
      "-7.1044084889424814 -6.944015210637763 -6.790584161078936 -6.705335210354992 -6.704000403201226 \n",
      "-7.013337597138012 -6.91020263010501 -6.705361390632874 -6.578615209036404 -6.590563995731849 \n",
      "-6.8257349948057975 -6.660354115118167 -6.613194023588186 -6.38591087529016 -6.422617414189548 \n",
      "-6.953754909548592 -6.704403869276492 -6.594585418624213 -6.320867823030796 -7.144916688059952 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.150790098773124, 2: -7.165655466262832, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.150790098773124, 2: -7.165655466262832, 3: -7.268211521467671, 4: -7.094121968023943}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.150790098773124, 2: -7.165655466262832, 3: -7.268211521467671, 4: -7.355650990901788}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.1044084889424814, 3: -7.121109927349086, 4: -7.173018603927863}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.953410081226197, 2: -6.944015210637763, 3: -6.954786518474244, 4: -7.22918678789525}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.889136042960792, 2: -6.790584161078936, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.875314833215177, 1: -6.705335210354992, 2: -6.968808078828846, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.578615209036404, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -6.813625450862021}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38591087529016, 1: -6.447611451363194, 2: -6.495963567369303, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.73044932988867, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -6.813625450862021}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.447611451363194, 2: -6.495963567369303, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.447611451363194, 2: -6.495963567369303, 3: -6.465641937031823, 4: -6.396593591055255}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.447611451363194, 2: -6.495963567369303, 3: -6.465641937031823, 4: -6.7209001678602815}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.652562849464542, 2: -6.3636759748888645, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.652562849464542, 2: -6.3636759748888645, 3: -6.655955404474836, 4: -6.320867823030796}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.652562849464542, 2: -6.3636759748888645, 3: -6.655955404474836, 4: -6.651989718958025}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.18886755205366, 1: -7.341083456648826, 2: -7.291112823368612, 3: -7.320129654491377, 4: -7.360730462905389}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.165655466262832 -7.072880352179799 -7.046893831585759 -6.97709718030683 -6.969673720856874 \n",
      "-7.121109927349086 -6.953410081226197 -6.889136042960792 -6.875314833215177 -6.704000403201226 \n",
      "-7.013337597138012 -6.91020263010501 -6.705361390632874 -6.754285741743623 -6.590563995731849 \n",
      "-6.8257349948057975 -6.660354115118167 -6.613194023588186 -6.465641937031823 -6.422617414189548 \n",
      "-6.953754909548592 -6.704403869276492 -6.594585418624213 -6.459350314652351 -7.18886755205366 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.3696498859207225, 2: -7.165655466262832, 3: -7.268211521467671, 4: -7.427705079096409}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.072880352179799, 2: -7.112821884236784, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -6.953410081226197, 2: -7.094774691537714, 3: -6.954786518474244, 4: -7.22918678789525}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.91020263010501, 2: -6.961606971540049, 3: -6.961324525999125, 4: -6.96415783085957}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -6.881407119223206, 2: -6.800246260791188, 3: -6.921265150375508, 4: -6.660354115118167}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -6.881407119223206, 2: -6.800246260791188, 3: -6.921265150375508, 4: -6.660354115118167}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -6.881407119223206, 2: -6.800246260791188, 3: -6.921265150375508, 4: -6.9609222447575325}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.77607734449445, 2: -6.613194023588186, 3: -6.822498531464688, 4: -6.621447516253584}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.664664081791265, 2: -6.495963567369303, 3: -6.465641937031823, 4: -6.794655292390216}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.77607734449445, 2: -6.798489371354596, 3: -6.822498531464688, 4: -6.621447516253584}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.77607734449445, 2: -6.798489371354596, 3: -6.822498531464688, 4: -6.621447516253584}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.663119150732132, 1: -6.77607734449445, 2: -6.798489371354596, 3: -6.822498531464688, 4: -6.925517239790762}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -6.7103863886168265, 2: -6.705361390632874, 3: -6.9500652404175955, 4: -6.855842596522186}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.754285741743623, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -6.813625450862021}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.664664081791265, 2: -6.495963567369303, 3: -6.909936681868586, 4: -6.794655292390216}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.422617414189548, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.341083456648826, 2: -7.291112823368612, 3: -7.320129654491377, 4: -7.360730462905389}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.268211521467671 -7.112821884236784 -7.046893831585759 -6.97709718030683 -6.969673720856874 \n",
      "-7.121109927349086 -6.954786518474244 -6.889136042960792 -6.875314833215177 -6.704000403201226 \n",
      "-7.013337597138012 -6.961324525999125 -6.7103863886168265 -6.813625450862021 -6.590563995731849 \n",
      "-6.8257349948057975 -6.881407119223206 -6.77607734449445 -6.664664081791265 -6.4603852222297915 \n",
      "-6.953754909548592 -6.704403869276492 -6.594585418624213 -6.459350314652351 -7.291112823368612 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.239550201011199, 2: -7.112821884236784, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.046893831585759, 2: -7.171157436542806, 3: -7.084040461756112, 4: -7.31601370914768}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -6.889136042960792, 2: -7.010379936495437, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -6.7103863886168265, 2: -7.041507589875622, 3: -6.9500652404175955, 4: -6.855842596522186}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -6.77607734449445, 2: -6.798489371354596, 3: -6.822498531464688, 4: -6.989678236072103}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.594585418624213, 3: -6.718336374963786, 4: -6.8069486110874315}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.652562849464542, 2: -6.459350314652351, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.341083456648826, 2: -7.390497008568656, 3: -7.320129654491377, 4: -7.360730462905389}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.268211521467671 -7.1298851763041675 -7.084040461756112 -6.97709718030683 -6.969673720856874 \n",
      "-7.121109927349086 -6.954786518474244 -6.903507044329015 -6.875314833215177 -6.704000403201226 \n",
      "-7.013337597138012 -6.961324525999125 -6.855842596522186 -6.813625450862021 -6.590563995731849 \n",
      "-6.8257349948057975 -6.881407119223206 -6.798489371354596 -6.664664081791265 -6.4603852222297915 \n",
      "-6.953754909548592 -6.704403869276492 -6.718336374963786 -6.507672681522433 -7.320129654491377 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.3696498859207225, 2: -7.34559863189192, 3: -7.268211521467671, 4: -7.427705079096409}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.3696498859207225, 2: -7.34559863189192, 3: -7.268211521467671, 4: -7.427705079096409}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.3696498859207225, 2: -7.34559863189192, 3: -7.51407248453558, 4: -7.427705079096409}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.335428989875018, 1: -7.3696498859207225, 2: -7.34559863189192, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5752403807862665, 1: -7.3696498859207225, 2: -7.34559863189192, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.239550201011199, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.239550201011199, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.1298851763041675}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.239550201011199, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.388195510436792}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.205092436763135, 1: -7.239550201011199, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.474944424821818}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.456634117454453, 1: -7.239550201011199, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.474944424821818}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -7.192605138507679, 2: -7.094774691537714, 3: -6.954786518474244, 4: -7.22918678789525}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.121109927349086, 4: -7.173018603927863}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.121109927349086, 4: -7.173018603927863}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.380210033887669, 4: -7.173018603927863}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.448166072570336, 4: -7.173018603927863}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.186582605643527, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.448166072570336, 4: -7.427446929574355}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.3696498859207225, 2: -7.409766855995567, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.263505080364746, 2: -7.235093169510836, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -7.192605138507679, 2: -7.094774691537714, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.903507044329015, 1: -7.024326579075709, 2: -7.010379936495437, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.184889577956818, 2: -7.171157436542806, 3: -7.084040461756112, 4: -7.31601370914768}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.257332100065257, 2: -7.319266192008143, 3: -7.245058905349167, 4: -7.474944424821818}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.497390455895849, 2: -7.409766855995567, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.257332100065257, 2: -7.319266192008143, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.126849527168309, 1: -7.192605138507679, 2: -7.2013181750602735, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.398481327012856, 2: -7.319266192008143, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.184889577956818, 2: -7.171157436542806, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.13118389282418, 1: -7.184889577956818, 2: -7.171157436542806, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.389377342470004, 1: -7.184889577956818, 2: -7.171157436542806, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -6.97709718030683, 2: -7.120017041156407, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.875314833215177, 1: -6.899211840354987, 2: -6.968808078828846, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -7.1667147329349765, 2: -7.120017041156407, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0745231407383935, 1: -7.1667147329349765, 2: -7.120017041156407, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3378160580719385, 1: -7.1667147329349765, 2: -7.120017041156407, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -6.969673720856874, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -6.88248659127075, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.906565026820748}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -6.88248659127075, 2: -6.704000403201226, 3: -6.767258636452842, 4: -6.906565026820748}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -6.88248659127075, 2: -7.000640366913116, 3: -6.767258636452842, 4: -6.906565026820748}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -6.899211840354987, 2: -6.968808078828846, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.837159063743497, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -6.813625450862021}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.837159063743497, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -6.813625450862021}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.837159063743497, 2: -6.8225481276566935, 3: -6.87606463275953, 4: -7.1003991602844385}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.590563995731849, 1: -6.701633037877449, 2: -6.788306379635507, 3: -6.719928734263799, 4: -6.81899223875483}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -6.88248659127075, 2: -7.081543532218114, 3: -7.165087454332824, 4: -6.906565026820748}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.701633037877449, 2: -6.788306379635507, 3: -6.719928734263799, 4: -6.81899223875483}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.548063128347531, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.548063128347531, 2: -6.4603852222297915, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478783739563378, 1: -6.548063128347531, 2: -6.7789505522291105, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.803075333793876, 2: -6.788306379635507, 3: -6.719928734263799, 4: -6.81899223875483}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.837159063743497, 2: -6.9206116493084675, 3: -6.87606463275953, 4: -7.136303899430366}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.664664081791265, 2: -6.751916462230464, 3: -6.909936681868586, 4: -6.794655292390216}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.507672681522433, 1: -6.652562849464542, 2: -6.5752400516032505, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.837681280212298, 2: -6.751916462230464, 3: -6.909936681868586, 4: -6.794655292390216}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.548063128347531, 2: -6.825709884269247, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.341083456648826, 2: -7.390497008568656, 3: -7.5192642978379505, 4: -7.360730462905389}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.427705079096409 -7.398481327012856 -7.184889577956818 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.263505080364746 -7.192605138507679 -7.010379936495437 -6.968808078828846 -6.906565026820748 \n",
      "-7.013337597138012 -6.961324525999125 -6.855842596522186 -6.87606463275953 -6.788306379635507 \n",
      "-6.8257349948057975 -6.881407119223206 -6.798489371354596 -6.794655292390216 -6.601083912720302 \n",
      "-6.953754909548592 -6.704403869276492 -6.718336374963786 -6.5752400516032505 -7.341083456648826 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.263505080364746, 2: -7.370276817096632, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.121538839537211, 2: -7.098428026174769, 3: -7.013337597138012, 4: -7.229338621788811}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.121538839537211, 2: -7.098428026174769, 3: -7.013337597138012, 4: -7.229338621788811}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.121538839537211, 2: -7.098428026174769, 3: -7.282137213395591, 4: -7.229338621788811}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.985907096256216, 2: -6.961606971540049, 3: -6.961324525999125, 4: -6.96415783085957}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.121538839537211, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.229338621788811}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -7.169959077819346, 2: -6.955194957547962, 3: -6.8257349948057975, 4: -7.20777638889566}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -7.169959077819346, 2: -6.955194957547962, 3: -6.8257349948057975, 4: -7.20777638889566}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -7.169959077819346, 2: -6.955194957547962, 3: -7.111418845273276, 4: -7.20777638889566}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -6.881407119223206, 2: -6.936711785185549, 3: -6.921265150375508, 4: -7.104291695716616}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -6.704403869276492, 2: -6.89052884974841, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -6.704403869276492, 2: -6.89052884974841, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -7.001007521041608, 2: -6.89052884974841, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.791532296730826, 3: -6.718336374963786, 4: -6.8069486110874315}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9368789170513825, 1: -7.181429120400373, 2: -7.030905348695508, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.018707846036279, 2: -6.936711785185549, 3: -6.921265150375508, 4: -7.104291695716616}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.964898572310091, 1: -7.169959077819346, 2: -7.169459262325593, 3: -7.244849800141177, 4: -7.20777638889566}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.140999229746417, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.229338621788811}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.169959077819346, 2: -7.169459262325593, 3: -7.244849800141177, 4: -7.20777638889566}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.018707846036279, 2: -6.936711785185549, 3: -7.233694358608725, 4: -7.104291695716616}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -6.919221923535058, 2: -6.798489371354596, 3: -6.822498531464688, 4: -6.989678236072103}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.837681280212298, 2: -6.879122780184547, 3: -6.909936681868586, 4: -6.794655292390216}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.837681280212298, 2: -6.879122780184547, 3: -6.909936681868586, 4: -6.794655292390216}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.837681280212298, 2: -6.879122780184547, 3: -6.909936681868586, 4: -7.083136316075096}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.652562849464542, 2: -6.5752400516032505, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.517547460760327, 2: -7.390497008568656, 3: -7.5192642978379505, 4: -7.360730462905389}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.427705079096409 -7.398481327012856 -7.184889577956818 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.307153961718265 -7.192605138507679 -7.010379936495437 -6.968808078828846 -6.906565026820748 \n",
      "-7.147989569042699 -6.961606971540049 -6.855842596522186 -6.87606463275953 -6.788306379635507 \n",
      "-7.169959077819346 -7.018707846036279 -6.822498531464688 -6.879122780184547 -6.601083912720302 \n",
      "-6.953754909548592 -6.962298545261957 -6.791532296730826 -6.61971568011369 -7.360730462905389 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.497390455895849, 2: -7.519415686652415, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.497390455895849, 2: -7.519415686652415, 3: -7.593104730252323, 4: -7.427705079096409}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.497390455895849, 2: -7.519415686652415, 3: -7.593104730252323, 4: -7.659211621977732}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.307153961718265, 2: -7.370276817096632, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.147989569042699, 1: -7.421361925458372, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.229338621788811}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.420586947096413, 2: -7.370276817096632, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.192605138507679, 2: -7.2013181750602735, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.985907096256216, 2: -6.961606971540049, 3: -7.364578912625054, 4: -6.96415783085957}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.059661287902188, 2: -7.041507589875622, 3: -6.9500652404175955, 4: -6.855842596522186}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.059661287902188, 2: -7.041507589875622, 3: -6.9500652404175955, 4: -6.855842596522186}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.059661287902188, 2: -7.041507589875622, 3: -6.9500652404175955, 4: -7.13881676283519}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.985907096256216, 2: -7.149393200336976, 3: -7.364578912625054, 4: -6.96415783085957}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.985907096256216, 2: -7.149393200336976, 3: -7.364578912625054, 4: -6.96415783085957}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -6.985907096256216, 2: -7.149393200336976, 3: -7.364578912625054, 4: -7.237383626082209}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.018707846036279, 2: -7.100447569315778, 3: -7.233694358608725, 4: -7.104291695716616}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.030905348695508, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.030905348695508, 3: -7.077539840693038, 4: -6.962298545261957}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.030905348695508, 3: -7.077539840693038, 4: -7.235691676188381}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.791532296730826, 3: -7.190705560307999, 4: -6.8069486110874315}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.652562849464542, 2: -6.61971568011369, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.517547460760327, 2: -7.390497008568656, 3: -7.5192642978379505, 4: -7.65251416035863}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.519415686652415 -7.398481327012856 -7.184889577956818 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.420586947096413 -7.2013181750602735 -7.010379936495437 -6.968808078828846 -6.906565026820748 \n",
      "-7.229338621788811 -7.1452935501147525 -7.041507589875622 -6.87606463275953 -6.788306379635507 \n",
      "-7.169959077819346 -7.100447569315778 -6.822498531464688 -6.879122780184547 -6.601083912720302 \n",
      "-6.953754909548592 -7.077539840693038 -6.8069486110874315 -6.64827414495198 -7.390497008568656 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.398481327012856, 2: -7.4081855723884, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.258162160798208, 2: -7.2013181750602735, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.024326579075709, 2: -7.010379936495437, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.108957799233735, 2: -6.968808078828846, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.016571419807809, 2: -7.081543532218114, 3: -7.165087454332824, 4: -6.906565026820748}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.016571419807809, 2: -7.081543532218114, 3: -7.165087454332824, 4: -6.906565026820748}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.016571419807809, 2: -7.081543532218114, 3: -7.165087454332824, 4: -7.184974174406881}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.803075333793876, 2: -6.788306379635507, 3: -7.110091715058613, 4: -6.81899223875483}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.803075333793876, 2: -6.788306379635507, 3: -7.110091715058613, 4: -6.81899223875483}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.803075333793876, 2: -7.077358805468312, 3: -7.110091715058613, 4: -6.81899223875483}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.601083912720302, 2: -6.825709884269247, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.42306768287826, 1: -7.517547460760327, 2: -7.631819575737279, 3: -7.5192642978379505, 4: -7.65251416035863}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.519415686652415 -7.4081855723884 -7.184889577956818 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.420586947096413 -7.22918678789525 -7.024326579075709 -6.989162215195375 -7.081543532218114 \n",
      "-7.229338621788811 -7.1452935501147525 -7.041507589875622 -6.87606463275953 -6.81899223875483 \n",
      "-7.169959077819346 -7.100447569315778 -6.822498531464688 -6.879122780184547 -6.624466110524848 \n",
      "-6.953754909548592 -7.077539840693038 -6.8069486110874315 -6.64827414495198 -7.42306768287826 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.56853375458138, 2: -7.519415686652415, 3: -7.593104730252323, 4: -7.738807431473411}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.472915854500107, 2: -7.4081855723884, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.184889577956818, 2: -7.268564459702813, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.024326579075709, 2: -7.245772537500909, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.059661287902188, 2: -7.041507589875622, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.982093812625274, 2: -6.9206116493084675, 3: -6.87606463275953, 4: -7.136303899430366}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.059661287902188, 2: -7.173763111522781, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -6.919221923535058, 2: -7.083519723971535, 3: -6.822498531464688, 4: -6.989678236072103}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.241332606265813, 2: -7.100447569315778, 3: -7.233694358608725, 4: -7.104291695716616}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -6.919221923535058, 2: -7.083519723971535, 3: -7.333612384292248, 4: -6.989678236072103}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.941122930565172, 3: -7.190705560307999, 4: -6.8069486110874315}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.941122930565172, 3: -7.190705560307999, 4: -6.8069486110874315}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8489121629933845, 1: -6.8553939844167875, 2: -6.941122930565172, 3: -7.190705560307999, 4: -7.094323236089562}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -7.105550567334325, 2: -7.083519723971535, 3: -7.333612384292248, 4: -6.989678236072103}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -7.105550567334325, 2: -7.083519723971535, 3: -7.333612384292248, 4: -6.989678236072103}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.997654641485841, 1: -7.105550567334325, 2: -7.083519723971535, 3: -7.333612384292248, 4: -7.260607194825614}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.08923252467435, 1: -7.132189939276616, 2: -7.173763111522781, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.306053805706825, 2: -7.245772537500909, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.306053805706825, 2: -7.245772537500909, 3: -7.180425999258702, 4: -7.159036638347309}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.306053805706825, 2: -7.245772537500909, 3: -7.180425999258702, 4: -7.4147233408960505}, Best action: 3, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.132189939276616, 2: -7.173763111522781, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.105550567334325, 2: -7.083519723971535, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.909712569819863, 2: -6.879122780184547, 3: -6.909936681868586, 4: -7.146835468579471}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.672793214403422, 2: -6.825709884269247, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.672793214403422, 2: -6.825709884269247, 3: -6.647706047900248, 4: -6.624466110524848}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.672793214403422, 2: -6.825709884269247, 3: -6.647706047900248, 4: -6.928264160577612}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.909712569819863, 2: -6.953729827543582, 3: -6.909936681868586, 4: -7.146835468579471}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.652562849464542, 2: -6.64827414495198, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.517547460760327, 2: -7.631819575737279, 3: -7.5192642978379505, 4: -7.65251416035863}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.56853375458138 -7.4605791153838625 -7.268564459702813 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.420586947096413 -7.22918678789525 -7.180425999258702 -6.989162215195375 -7.081543532218114 \n",
      "-7.229338621788811 -7.1452935501147525 -7.173763111522781 -6.885798502268522 -6.81899223875483 \n",
      "-7.169959077819346 -7.104291695716616 -7.105550567334325 -6.909936681868586 -6.672793214403422 \n",
      "-6.953754909548592 -7.077539840693038 -6.8553939844167875 -6.652562849464542 -7.517547460760327 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.420586947096413, 2: -7.463037843900883, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.229338621788811}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.229338621788811}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.248515668676768, 3: -7.377940422541123, 4: -7.478698145827819}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1452935501147525, 1: -7.283744064915008, 2: -7.149393200336976, 3: -7.364578912625054, 4: -7.282323110575756}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.258162160798208, 2: -7.298539566067332, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.258162160798208, 2: -7.298539566067332, 3: -7.363577693000185, 4: -7.22918678789525}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.258162160798208, 2: -7.298539566067332, 3: -7.363577693000185, 4: -7.478559976984677}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.283744064915008, 2: -7.149393200336976, 3: -7.364578912625054, 4: -7.282323110575756}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.173763111522781, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885798502268522, 1: -6.982093812625274, 2: -6.9206116493084675, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.108957799233735, 2: -7.19119847960769, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.108957799233735, 2: -7.19119847960769, 3: -6.997692532181823, 4: -6.989162215195375}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.108957799233735, 2: -7.19119847960769, 3: -6.997692532181823, 4: -7.260137615827791}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.4076792313847415, 2: -7.245772537500909, 3: -7.180425999258702, 4: -7.559375916712134}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.416824708352772, 2: -7.298539566067332, 3: -7.363577693000185, 4: -7.526967347945016}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.4076792313847415, 2: -7.245772537500909, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.108957799233735, 2: -7.19119847960769, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -6.982093812625274, 2: -6.9206116493084675, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.927185502682832, 2: -7.11822690091987, 3: -7.110091715058613, 4: -6.81899223875483}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.927185502682832, 2: -7.11822690091987, 3: -7.110091715058613, 4: -6.81899223875483}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.927185502682832, 2: -7.11822690091987, 3: -7.110091715058613, 4: -7.105282937266895}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.672793214403422, 2: -6.825709884269247, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.662430173224127, 2: -7.631819575737279, 3: -7.5192642978379505, 4: -7.65251416035863}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.56853375458138 -7.4605791153838625 -7.268564459702813 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.448166072570336 -7.363577693000185 -7.328423478455353 -7.19119847960769 -7.081543532218114 \n",
      "-7.377940422541123 -7.282323110575756 -7.194873097989781 -6.982093812625274 -6.997681053935056 \n",
      "-7.169959077819346 -7.104291695716616 -7.105550567334325 -6.909936681868586 -6.757883402689082 \n",
      "-6.953754909548592 -7.077539840693038 -6.8553939844167875 -6.652562849464542 -7.5192642978379505 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.56853375458138, 2: -7.652571882299846, 3: -7.593104730252323, 4: -7.738807431473411}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.463037843900883, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.463037843900883, 3: -7.448166072570336, 4: -7.463876603528692}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.463037843900883, 3: -7.677831126039006, 4: -7.463876603528692}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.416824708352772, 2: -7.49892971198247, 3: -7.363577693000185, 4: -7.526967347945016}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.610801715720238, 3: -7.712843766163616, 4: -7.463876603528692}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.610801715720238, 3: -7.712843766163616, 4: -7.463876603528692}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.497822978358578, 2: -7.610801715720238, 3: -7.712843766163616, 4: -7.69212770921111}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.412539342460627, 3: -7.377940422541123, 4: -7.519167506210964}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.412539342460627, 3: -7.377940422541123, 4: -7.519167506210964}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.412539342460627, 3: -7.613925784512421, 4: -7.519167506210964}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.283744064915008, 2: -7.425687440367151, 3: -7.364578912625054, 4: -7.282323110575756}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.283744064915008, 2: -7.425687440367151, 3: -7.364578912625054, 4: -7.282323110575756}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.283744064915008, 2: -7.425687440367151, 3: -7.364578912625054, 4: -7.526914030623939}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.241332606265813, 2: -7.214614514994975, 3: -7.233694358608725, 4: -7.104291695716616}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.241332606265813, 2: -7.214614514994975, 3: -7.233694358608725, 4: -7.104291695716616}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131921827280627, 1: -7.241332606265813, 2: -7.214614514994975, 3: -7.233694358608725, 4: -7.364905443102121}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.38285068002196, 2: -7.425687440367151, 3: -7.364578912625054, 4: -7.552524095643551}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.421361925458372, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.519167506210964}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.169959077819346, 2: -7.235682472232854, 3: -7.244849800141177, 4: -7.20777638889566}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -7.003517604967183, 3: -7.238518583880525, 4: -6.953754909548592}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -7.003517604967183, 3: -7.238518583880525, 4: -6.953754909548592}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.990170167083416, 1: -7.178551894326854, 2: -7.003517604967183, 3: -7.238518583880525, 4: -7.227916967689219}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.2495373845162945, 2: -7.235682472232854, 3: -7.244849800141177, 4: -7.20777638889566}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.2495373845162945, 2: -7.235682472232854, 3: -7.244849800141177, 4: -7.20777638889566}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.2495373845162945, 2: -7.235682472232854, 3: -7.244849800141177, 4: -7.4590765138950506}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.241332606265813, 2: -7.214614514994975, 3: -7.233694358608725, 4: -7.413347224407521}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.105550567334325, 2: -7.180441424346637, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -6.8553939844167875, 2: -6.941122930565172, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -6.8553939844167875, 2: -6.941122930565172, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.138408525819277, 2: -6.941122930565172, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.652562849464542, 2: -6.754040857711063, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.652562849464542, 2: -6.754040857711063, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.953832193012733, 2: -6.754040857711063, 3: -6.655955404474836, 4: -6.719776511555782}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -6.982688201122796, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.754040857711063, 3: -7.221572983356949, 4: -6.719776511555782}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.754040857711063, 3: -7.221572983356949, 4: -6.719776511555782}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.754040857711063, 3: -7.221572983356949, 4: -7.014996625515762}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.662430173224127, 2: -7.631819575737279, 3: -7.7824387709947125, 4: -7.65251416035863}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.593104730252323 -7.4605791153838625 -7.268564459702813 -7.1667147329349765 -7.0114145028652715 \n",
      "-7.5880746681601385 -7.416824708352772 -7.328423478455353 -7.19119847960769 -7.081543532218114 \n",
      "-7.4498030455795075 -7.38285068002196 -7.194873097989781 -6.982093812625274 -6.997681053935056 \n",
      "-7.244849800141177 -7.233694358608725 -7.163424184111031 -6.909936681868586 -6.757883402689082 \n",
      "-7.003517604967183 -7.077539840693038 -7.0412877944724634 -6.857177942118303 -7.631819575737279 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.472915854500107, 2: -7.4605791153838625, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.3081934868470055, 2: -7.268564459702813, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.1667147329349765, 2: -7.257437418009708, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.216591215863232, 2: -7.19119847960769, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.100185309485542, 2: -7.081543532218114, 3: -7.165087454332824, 4: -7.301920267485014}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.100185309485542, 2: -7.081543532218114, 3: -7.165087454332824, 4: -7.301920267485014}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.100185309485542, 2: -7.344204614318484, 3: -7.165087454332824, 4: -7.301920267485014}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -6.997681053935056, 2: -7.11822690091987, 3: -7.110091715058613, 4: -7.221548550899784}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.757883402689082, 2: -6.825709884269247, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.662430173224127, 2: -7.7062510410346565, 3: -7.7824387709947125, 4: -7.65251416035863}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.593104730252323 -7.472915854500107 -7.3081934868470055 -7.194606986831666 -7.0114145028652715 \n",
      "-7.5880746681601385 -7.416824708352772 -7.328423478455353 -7.216591215863232 -7.165087454332824 \n",
      "-7.4498030455795075 -7.38285068002196 -7.194873097989781 -6.982093812625274 -7.073653661571662 \n",
      "-7.244849800141177 -7.233694358608725 -7.163424184111031 -6.909936681868586 -6.825709884269247 \n",
      "-7.003517604967183 -7.077539840693038 -7.0412877944724634 -6.857177942118303 -7.65251416035863 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.689867894240111, 2: -7.652571882299846, 3: -7.593104730252323, 4: -7.738807431473411}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.689867894240111, 2: -7.652571882299846, 3: -7.593104730252323, 4: -7.738807431473411}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.689867894240111, 2: -7.652571882299846, 3: -7.809725304529613, 4: -7.738807431473411}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607458929911082, 1: -7.689867894240111, 2: -7.652571882299846, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8227876262190845, 1: -7.689867894240111, 2: -7.652571882299846, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.472915854500107, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.416824708352772, 2: -7.49892971198247, 3: -7.682097818158259, 4: -7.526967347945016}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.38285068002196, 2: -7.425687440367151, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.241332606265813, 2: -7.376957411040301, 3: -7.233694358608725, 4: -7.413347224407521}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.380699233325608, 1: -7.2495373845162945, 2: -7.467406004369216, 3: -7.244849800141177, 4: -7.506810453898117}, Best action: 3, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.4498030455795075, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.519167506210964}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.2495373845162945, 2: -7.467406004369216, 3: -7.244849800141177, 4: -7.506810453898117}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.2495373845162945, 2: -7.467406004369216, 3: -7.244849800141177, 4: -7.506810453898117}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.2495373845162945, 2: -7.467406004369216, 3: -7.492813318128471, 4: -7.506810453898117}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.178551894326854, 2: -7.003517604967183, 3: -7.238518583880525, 4: -7.284829532106489}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.10423169522152, 3: -7.077539840693038, 4: -7.318602500062199}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.178551894326854, 2: -7.333159031458079, 3: -7.238518583880525, 4: -7.284829532106489}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.178551894326854, 2: -7.333159031458079, 3: -7.238518583880525, 4: -7.284829532106489}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.432482223837437, 2: -7.333159031458079, 3: -7.238518583880525, 4: -7.284829532106489}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.333159031458079, 3: -7.238518583880525, 4: -7.284829532106489}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.333159031458079, 3: -7.487051911331278, 4: -7.284829532106489}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.333159031458079, 3: -7.549417112139384, 4: -7.284829532106489}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.333159031458079, 3: -7.549417112139384, 4: -7.5291948742169055}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.10423169522152, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.0412877944724634, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.857177942118303, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.662430173224127, 2: -7.7062510410346565, 3: -7.7824387709947125, 4: -7.8156662475402445}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.689867894240111 -7.474944424821818 -7.3081934868470055 -7.194606986831666 -7.0114145028652715 \n",
      "-7.5880746681601385 -7.49892971198247 -7.328423478455353 -7.216591215863232 -7.165087454332824 \n",
      "-7.513308642672304 -7.425687440367151 -7.194873097989781 -6.982093812625274 -7.073653661571662 \n",
      "-7.297802998475047 -7.241332606265813 -7.163424184111031 -6.909936681868586 -6.825709884269247 \n",
      "-7.3877435762752395 -7.181429120400373 -7.157051175633598 -6.8922862345233735 -7.662430173224127 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5880746681601385, 1: -7.625914040094167, 2: -7.610801715720238, 3: -7.712843766163616, 4: -7.742449383391559}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.689867894240111, 2: -7.718319030375071, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.625914040094167, 2: -7.610801715720238, 3: -7.712843766163616, 4: -7.742449383391559}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.621791521653065, 2: -7.49892971198247, 3: -7.682097818158259, 4: -7.526967347945016}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.328423478455353, 1: -7.4076792313847415, 2: -7.382833071129417, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.3081934868470055, 2: -7.431895379647612, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.4076792313847415, 2: -7.382833071129417, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.216591215863232, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -6.982093812625274, 2: -7.115444878322259, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.97607331439309, 2: -6.953729827543582, 3: -6.909936681868586, 4: -7.146835468579471}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.163424184111031, 2: -7.180441424346637, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.158442912563071, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.158442912563071, 3: -7.190705560307999, 4: -7.157051175633598}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.158442912563071, 3: -7.190705560307999, 4: -7.412916569826574}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.8922862345233735, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.812583498532125, 2: -7.7062510410346565, 3: -7.7824387709947125, 4: -7.8156662475402445}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.718319030375071 -7.474944424821818 -7.31601370914768 -7.194606986831666 -7.0114145028652715 \n",
      "-7.625914040094167 -7.526967347945016 -7.4076792313847415 -7.277155109812795 -7.165087454332824 \n",
      "-7.513308642672304 -7.425687440367151 -7.194873097989781 -7.115444878322259 -7.073653661571662 \n",
      "-7.297802998475047 -7.241332606265813 -7.180441424346637 -6.953729827543582 -6.825709884269247 \n",
      "-7.3877435762752395 -7.181429120400373 -7.190705560307999 -6.931291966690409 -7.7062510410346565 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.654919599215756, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.654919599215756, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.474944424821818}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.654919599215756, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.702199426587854}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.509699074564517, 1: -7.654919599215756, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.753076193056044}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.73382615785371, 1: -7.654919599215756, 2: -7.5335951238976655, 3: -7.626417043891326, 4: -7.753076193056044}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.610914136299528, 2: -7.431895379647612, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.610914136299528, 2: -7.431895379647612, 3: -7.476901759508437, 4: -7.31601370914768}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.610914136299528, 2: -7.431895379647612, 3: -7.476901759508437, 4: -7.557572475324389}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.257437418009708, 3: -7.194606986831666, 4: -7.217580973698567}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.610914136299528, 2: -7.470821197298411, 3: -7.476901759508437, 4: -7.675592505047005}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.447575257846674, 1: -7.610914136299528, 2: -7.470821197298411, 3: -7.476901759508437, 4: -7.675592505047005}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677293484640474, 1: -7.610914136299528, 2: -7.470821197298411, 3: -7.476901759508437, 4: -7.675592505047005}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.257437418009708, 3: -7.651996657538973, 4: -7.217580973698567}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.257437418009708, 3: -7.651996657538973, 4: -7.217580973698567}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.257437418009708, 3: -7.651996657538973, 4: -7.467998686065696}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -7.027207698678681, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0114145028652715, 1: -7.027207698678681, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.280387197607397, 1: -7.027207698678681, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.27814018463595, 2: -7.385570562115137, 3: -7.165087454332824, 4: -7.301920267485014}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.277155109812795, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -7.195258093576082, 2: -7.115444878322259, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -7.073653661571662, 2: -7.11822690091987, 3: -7.110091715058613, 4: -7.221548550899784}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.874324810159399, 2: -6.825709884269247, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.874324810159399, 2: -6.825709884269247, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.874324810159399, 2: -7.111395994685015, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.812583498532125, 2: -7.725330088209138, 3: -7.7824387709947125, 4: -7.8156662475402445}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.718319030375071 -7.579330616799387 -7.476901759508437 -7.304989489121841 -7.1059197144244965 \n",
      "-7.625914040094167 -7.526967347945016 -7.4076792313847415 -7.294144712650056 -7.19610619198035 \n",
      "-7.513308642672304 -7.425687440367151 -7.194873097989781 -7.136303899430366 -7.110091715058613 \n",
      "-7.297802998475047 -7.241332606265813 -7.180441424346637 -6.953729827543582 -6.944949852465342 \n",
      "-7.3877435762752395 -7.181429120400373 -7.190705560307999 -6.931291966690409 -7.725330088209138 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.654919599215756, 2: -7.579330616799387, 3: -7.626417043891326, 4: -7.753076193056044}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.610914136299528, 2: -7.493322708425681, 3: -7.476901759508437, 4: -7.675592505047005}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.654919599215756, 2: -7.714223486881773, 3: -7.626417043891326, 4: -7.753076193056044}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.833736179157404, 2: -7.718319030375071, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.654919599215756, 2: -7.714223486881773, 3: -7.91448011899294, 4: -7.753076193056044}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.621791521653065, 2: -7.585915988747082, 3: -7.682097818158259, 4: -7.526967347945016}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.621791521653065, 2: -7.585915988747082, 3: -7.682097818158259, 4: -7.526967347945016}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5412905682434275, 1: -7.621791521653065, 2: -7.585915988747082, 3: -7.682097818158259, 4: -7.749540286629965}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.762335511757039, 2: -7.714223486881773, 3: -7.91448011899294, 4: -7.753076193056044}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.610914136299528, 2: -7.493322708425681, 3: -7.8250879815028185, 4: -7.675592505047005}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.304989489121841, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.320076955690471, 1: -7.406441607877455, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.320076955690471, 1: -7.406441607877455, 2: -7.1059197144244965, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.320076955690471, 1: -7.406441607877455, 2: -7.366386940126293, 3: -7.1465487518111495, 4: -7.338784411973192}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.386293917596027, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.320076955690471, 1: -7.406441607877455, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.338784411973192}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.320076955690471, 1: -7.406441607877455, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.338784411973192}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.561270029678329, 1: -7.406441607877455, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.338784411973192}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.406441607877455, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.338784411973192}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.406441607877455, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.578293814895605}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.19610619198035, 1: -7.27814018463595, 2: -7.385570562115137, 3: -7.511004384381646, 4: -7.301920267485014}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.4694901762918295, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.6570470838702995}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.4694901762918295, 2: -7.425343182979661, 3: -7.597552948433896, 4: -7.6570470838702995}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.4694901762918295, 2: -7.657062296511492, 3: -7.597552948433896, 4: -7.6570470838702995}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.27814018463595, 2: -7.385570562115137, 3: -7.511004384381646, 4: -7.301920267485014}, Best action: 1, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.27814018463595, 2: -7.385570562115137, 3: -7.511004384381646, 4: -7.301920267485014}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -7.136190372415257, 2: -7.11822690091987, 3: -7.110091715058613, 4: -7.221548550899784}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -7.195258093576082, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -7.195258093576082, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.136303899430366}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -7.195258093576082, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.394036548481633}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.97607331439309, 2: -6.953729827543582, 3: -7.393367257316794, 4: -7.146835468579471}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.944949852465342, 2: -7.179342695697615, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.733033474476282, 1: -7.812583498532125, 2: -7.811790808428418, 3: -7.7824387709947125, 4: -7.8156662475402445}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.738807431473411 -7.741013742512979 -7.566373757031259 -7.400995409143884 -7.597552948433896 \n",
      "-7.625914040094167 -7.585915988747082 -7.4076792313847415 -7.294144712650056 -7.301920267485014 \n",
      "-7.513308642672304 -7.425687440367151 -7.194873097989781 -7.249801244535106 -7.11822690091987 \n",
      "-7.297802998475047 -7.241332606265813 -7.180441424346637 -6.97607331439309 -6.958252099572323 \n",
      "-7.3877435762752395 -7.181429120400373 -7.190705560307999 -6.931291966690409 -7.733033474476282 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.833736179157404, 2: -7.872316778402269, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.833736179157404, 2: -7.872316778402269, 3: -7.843014263680938, 4: -7.738807431473411}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.833736179157404, 2: -7.872316778402269, 3: -7.843014263680938, 4: -7.942314762640804}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.625914040094167, 2: -7.735213238277824, 3: -7.712843766163616, 4: -7.742449383391559}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.513308642672304, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.519167506210964}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.297802998475047, 2: -7.467406004369216, 3: -7.521406613271046, 4: -7.506810453898117}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.3877435762752395, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.313866283044847, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.181429120400373, 2: -7.313866283044847, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.199912663509299, 1: -7.435100499564339, 2: -7.313866283044847, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.241332606265813, 2: -7.376957411040301, 3: -7.601735814854615, 4: -7.413347224407521}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.313866283044847, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.19859614122024, 3: -7.190705560307999, 4: -7.439630416158746}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.455858132153963, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.455858132153963, 3: -7.422381018474056, 4: -7.318602500062199}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.455858132153963, 3: -7.422381018474056, 4: -7.559928275056602}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.437315891713826, 1: -7.50644827532697, 2: -7.455731945151825, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.467406004369216, 3: -7.521406613271046, 4: -7.506810453898117}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.376957411040301, 3: -7.601735814854615, 4: -7.413347224407521}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.180441424346637, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -6.97607331439309, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.146835468579471}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.931291966690409, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.941737366941092, 1: -7.812583498532125, 2: -7.811790808428418, 3: -7.7824387709947125, 4: -7.8156662475402445}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.843014263680938 -7.741013742512979 -7.566373757031259 -7.400995409143884 -7.597552948433896 \n",
      "-7.712843766163616 -7.585915988747082 -7.4076792313847415 -7.294144712650056 -7.301920267485014 \n",
      "-7.519167506210964 -7.425687440367151 -7.194873097989781 -7.249801244535106 -7.11822690091987 \n",
      "-7.506810453898117 -7.413347224407521 -7.268663527093067 -6.99025504473884 -6.958252099572323 \n",
      "-7.455731945151825 -7.455858132153963 -7.19859614122024 -6.98670709692589 -7.7824387709947125 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.860363990392016, 2: -7.872316778402269, 3: -7.843014263680938, 4: -8.039557781381577}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.860363990392016, 2: -7.872316778402269, 3: -7.843014263680938, 4: -8.039557781381577}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.860363990392016, 2: -7.872316778402269, 3: -8.037142979949653, 4: -8.039557781381577}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.735213238277824, 3: -7.712843766163616, 4: -7.742449383391559}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.735213238277824, 3: -7.712843766163616, 4: -7.742449383391559}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.735213238277824, 3: -7.918687827208891, 4: -7.742449383391559}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.621791521653065, 2: -7.585915988747082, 3: -7.682097818158259, 4: -7.783399388940173}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.4076792313847415, 2: -7.48372219196216, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.194873097989781, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.249801244535106, 1: -7.25204696966791, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.467562710644789}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.391225862422309, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.391225862422309, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.294144712650056}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3178952273196165, 1: -7.391225862422309, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.537671688511551}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.400995409143884, 1: -7.441542241775727, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.634905822320935, 1: -7.441542241775727, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.391225862422309, 2: -7.3551701090574415, 3: -7.415914312617731, 4: -7.581262302980044}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.386988307661072, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.301920267485014}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.386988307661072, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.301920267485014}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.386988307661072, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.544747443411363}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -7.136190372415257, 2: -7.11822690091987, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -7.136190372415257, 2: -7.11822690091987, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.133870538502492, 1: -7.136190372415257, 2: -7.377586479837082, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.404462620511202, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.6379352735466055}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.136190372415257, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -6.958252099572323, 2: -7.179342695697615, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.941737366941092, 1: -7.812583498532125, 2: -7.811790808428418, 3: -8.03108543068103, 4: -7.8156662475402445}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.872316778402269 -7.741013742512979 -7.566373757031259 -7.525324177194434 -7.597552948433896 \n",
      "-7.742449383391559 -7.621791521653065 -7.468615132510197 -7.391225862422309 -7.420760463707478 \n",
      "-7.519167506210964 -7.425687440367151 -7.235974367038011 -7.25204696966791 -7.221548550899784 \n",
      "-7.506810453898117 -7.413347224407521 -7.268663527093067 -6.99025504473884 -6.977468314856962 \n",
      "-7.455731945151825 -7.455858132153963 -7.19859614122024 -6.98670709692589 -7.811790808428418 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.762335511757039, 2: -7.741013742512979, 3: -7.91448011899294, 4: -7.753076193056044}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.610914136299528, 2: -7.566373757031259, 3: -7.8250879815028185, 4: -7.675592505047005}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.6018420125141, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.6018420125141, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.525324177194434}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.6018420125141, 2: -7.5678917258688845, 3: -7.651996657538973, 4: -7.748045001246934}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.629261172942444, 2: -7.715993272447531, 3: -7.597552948433896, 4: -7.6570470838702995}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.6018420125141, 2: -7.810807060818344, 3: -7.651996657538973, 4: -7.80479679807849}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.391225862422309, 2: -7.5500724275686055, 3: -7.415914312617731, 4: -7.581262302980044}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.25204696966791, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.467562710644789}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.99025504473884, 1: -7.211953824458541, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.146835468579471}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.287311283205251, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.467562710644789}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.211953824458541, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.146835468579471}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.211953824458541, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.146835468579471}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.211953824458541, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.4036202764073185}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.996904601174759, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -6.98670709692589, 2: -6.996904601174759, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -7.25790345820256, 2: -6.996904601174759, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.941737366941092, 1: -7.812583498532125, 2: -7.951400212278355, 3: -8.03108543068103, 4: -7.8156662475402445}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.872316778402269 -7.753076193056044 -7.610914136299528 -7.64707714981348 -7.600542376666118 \n",
      "-7.742449383391559 -7.621791521653065 -7.468615132510197 -7.415914312617731 -7.420760463707478 \n",
      "-7.519167506210964 -7.425687440367151 -7.235974367038011 -7.305932106476725 -7.221548550899784 \n",
      "-7.506810453898117 -7.413347224407521 -7.268663527093067 -7.220782363251286 -6.977468314856962 \n",
      "-7.455731945151825 -7.455858132153963 -7.19859614122024 -7.019819602558919 -7.812583498532125 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.742449383391559}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.742449383391559}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.748371404573983, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.945628938886319}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.562551293032019, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.519167506210964}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.562551293032019, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.519167506210964}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.562551293032019, 2: -7.539935653812425, 3: -7.66554944584435, 4: -7.742442430651978}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.497577498475263, 2: -7.425687440367151, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.491826317872414, 3: -7.235974367038011, 4: -7.243434521021771}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.470170653206628, 1: -7.497577498475263, 2: -7.503707981337504, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.621791521653065, 2: -7.658811776296349, 3: -7.682097818158259, 4: -7.783399388940173}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.497577498475263, 2: -7.503707981337504, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.453853294824806, 3: -7.601735814854615, 4: -7.413347224407521}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.453853294824806, 3: -7.601735814854615, 4: -7.413347224407521}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.453853294824806, 3: -7.601735814854615, 4: -7.646145974210844}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.268663527093067, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.280428130955825, 2: -7.220782363251286, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -7.023375764784251, 2: -7.179342695697615, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -7.023375764784251, 2: -7.179342695697615, 3: -7.161637786344114, 4: -6.977468314856962}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.991020648710015, 1: -7.023375764784251, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.249496166519836}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.249803237895107, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.249803237895107, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.221548550899784}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.249803237895107, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.4716091813188035}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.023375764784251, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.941737366941092, 1: -7.952642350400375, 2: -7.951400212278355, 3: -8.03108543068103, 4: -7.8156662475402445}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.872316778402269 -7.753076193056044 -7.610914136299528 -7.64707714981348 -7.600542376666118 \n",
      "-7.76536282048828 -7.658811776296349 -7.468615132510197 -7.415914312617731 -7.420760463707478 \n",
      "-7.562551293032019 -7.503707981337504 -7.243434521021771 -7.305932106476725 -7.313914693264754 \n",
      "-7.506810453898117 -7.533002786427865 -7.294160979086093 -7.273827571359268 -7.033027236986023 \n",
      "-7.455731945151825 -7.455858132153963 -7.19859614122024 -7.019819602558919 -7.8156662475402445 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.933439849631731, 2: -7.872316778402269, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.762335511757039, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.753076193056044}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.762335511757039, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.753076193056044}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.762335511757039, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.9552993356810004}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.73521692593027, 2: -7.658811776296349, 3: -7.682097818158259, 4: -7.783399388940173}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.468615132510197, 2: -7.48372219196216, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.491826317872414, 3: -7.6744356658011705, 4: -7.243434521021771}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.491826317872414, 3: -7.6744356658011705, 4: -7.243434521021771}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.350869970344605, 2: -7.491826317872414, 3: -7.6744356658011705, 4: -7.4915254141298115}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.475700066942848, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.475700066942848, 3: -7.333612384292248, 4: -7.294160979086093}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.475700066942848, 3: -7.333612384292248, 4: -7.537686490968345}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.533002786427865, 3: -7.601735814854615, 4: -7.702235766229178}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3420438091348075, 1: -7.413553870674318, 2: -7.475700066942848, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.407742929528755, 1: -7.543357390094196, 2: -7.491826317872414, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.514043475278655, 2: -7.48372219196216, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.513280631673239, 2: -7.5500724275686055, 3: -7.415914312617731, 4: -7.581262302980044}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.514043475278655, 2: -7.655262812416578, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.543357390094196, 2: -7.491826317872414, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.417667857869896, 2: -7.341203953705271, 3: -7.305932106476725, 4: -7.467562710644789}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.543357390094196, 2: -7.566987638033388, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.413553870674318, 2: -7.475700066942848, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.19859614122024, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.019819602558919, 1: -7.2932830727718105, 2: -7.027883093928497, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.280428130955825, 2: -7.273827571359268, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.033027236986023, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.941737366941092, 1: -7.952642350400375, 2: -7.951400212278355, 3: -8.03108543068103, 4: -8.058143215259864}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.880861987284783 -7.77559466614248 -7.610914136299528 -7.64707714981348 -7.600542376666118 \n",
      "-7.76536282048828 -7.682097818158259 -7.529859648440409 -7.513280631673239 -7.420760463707478 \n",
      "-7.562551293032019 -7.503707981337504 -7.566987638033388 -7.341203953705271 -7.313914693264754 \n",
      "-7.506810453898117 -7.548364949892908 -7.472218261455827 -7.280428130955825 -7.136109990920887 \n",
      "-7.455731945151825 -7.455858132153963 -7.236150426339717 -7.027883093928497 -7.941737366941092 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.933439849631731, 2: -7.967223394215623, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.880861987284783, 1: -7.933439849631731, 2: -7.967223394215623, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.071584408429153, 1: -7.933439849631731, 2: -7.967223394215623, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.76536282048828, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.562551293032019, 2: -7.6688003920786345, 3: -7.66554944584435, 4: -7.7815921226532625}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.622076103379566, 3: -7.521406613271046, 4: -7.506810453898117}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.622076103379566, 3: -7.521406613271046, 4: -7.506810453898117}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.622076103379566, 3: -7.521406613271046, 4: -7.731197513047287}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.622076103379566, 3: -7.521406613271046, 4: -7.765459108054276}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.6138525966304496, 2: -7.622076103379566, 3: -7.7444800180766515, 4: -7.765459108054276}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.50644827532697, 2: -7.455731945151825, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.455858132153963, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.305913492194749, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.236150426339717, 2: -7.305913492194749, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.246530587517741, 1: -7.484896887969143, 2: -7.305913492194749, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.472218261455827, 2: -7.475700066942848, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.305913492194749, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.027883093928497, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -7.952642350400375, 2: -7.951400212278355, 3: -8.03108543068103, 4: -8.058143215259864}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.967223394215623 -7.77559466614248 -7.610914136299528 -7.64707714981348 -7.600542376666118 \n",
      "-7.802202829404764 -7.682097818158259 -7.529859648440409 -7.513280631673239 -7.420760463707478 \n",
      "-7.584723178752542 -7.503707981337504 -7.566987638033388 -7.341203953705271 -7.313914693264754 \n",
      "-7.622076103379566 -7.548364949892908 -7.475700066942848 -7.280428130955825 -7.136109990920887 \n",
      "-7.50644827532697 -7.4754393073989664 -7.323176655301557 -7.0722727572975375 -7.951400212278355 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.8798710899757465, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.77559466614248, 1: -7.8798710899757465, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.975791146189657, 1: -7.8798710899757465, 2: -7.802864117446617, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.610914136299528, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.675592505047005}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.719783665004521, 2: -7.655262812416578, 3: -7.529859648440409, 4: -7.559375916712134}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.73521692593027, 2: -7.715459434962895, 3: -7.682097818158259, 4: -7.783399388940173}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.802202829404764, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.584723178752542, 1: -7.736771596960677, 2: -7.6688003920786345, 3: -7.66554944584435, 4: -7.7815921226532625}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.8238460577300355, 2: -7.818113274712919, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.73521692593027, 2: -7.715459434962895, 3: -7.987994073633684, 4: -7.783399388940173}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.55247907219161, 1: -7.719783665004521, 2: -7.655262812416578, 3: -7.875485197552231, 4: -7.559375916712134}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.760277728866684, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.675592505047005}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.760277728866684, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.675592505047005}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.760277728866684, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.884789179592775}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.719094518275761, 1: -7.760277728866684, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.940945477762644}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.924376011630942, 1: -7.760277728866684, 2: -7.752149959230617, 3: -7.8250879815028185, 4: -7.940945477762644}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.64707714981348, 2: -7.810807060818344, 3: -7.651996657538973, 4: -7.80479679807849}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.513280631673239, 2: -7.5500724275686055, 3: -7.727966646237483, 4: -7.581262302980044}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.417667857869896, 2: -7.341203953705271, 3: -7.740712696623972, 4: -7.467562710644789}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.313914693264754, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.5195015408269175}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.136109990920887, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -7.952642350400375, 2: -7.9933717008032446, 3: -8.03108543068103, 4: -8.058143215259864}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.967223394215623 -7.845126862147279 -7.760277728866684 -7.651996657538973 -7.600542376666118 \n",
      "-7.8238460577300355 -7.73521692593027 -7.559375916712134 -7.5500724275686055 -7.420760463707478 \n",
      "-7.66554944584435 -7.503707981337504 -7.566987638033388 -7.417667857869896 -7.391415330044458 \n",
      "-7.622076103379566 -7.548364949892908 -7.475700066942848 -7.280428130955825 -7.155251302916392 \n",
      "-7.50644827532697 -7.4754393073989664 -7.323176655301557 -7.0722727572975375 -7.952642350400375 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.8238460577300355, 2: -7.9313334697912365, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.736771596960677, 2: -7.6688003920786345, 3: -7.66554944584435, 4: -7.7815921226532625}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.736771596960677, 2: -7.6688003920786345, 3: -7.66554944584435, 4: -7.7815921226532625}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.736771596960677, 2: -7.6688003920786345, 3: -7.8756499957183586, 4: -7.7815921226532625}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.654569001617618, 2: -7.503707981337504, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.659314374255617, 2: -7.566987638033388, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.417667857869896, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.467562710644789}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.280428130955825, 2: -7.324134819094606, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.143422481338318, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.143422481338318, 3: -7.221572983356949, 4: -7.0722727572975375}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.143422481338318, 3: -7.221572983356949, 4: -7.33576820914076}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.032579541801367, 2: -7.9933717008032446, 3: -8.03108543068103, 4: -8.058143215259864}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.967223394215623 -7.845126862147279 -7.760277728866684 -7.651996657538973 -7.600542376666118 \n",
      "-7.887600461150504 -7.73521692593027 -7.559375916712134 -7.5500724275686055 -7.420760463707478 \n",
      "-7.736771596960677 -7.552524095643551 -7.603357217392111 -7.467562710644789 -7.391415330044458 \n",
      "-7.622076103379566 -7.548364949892908 -7.475700066942848 -7.324134819094606 -7.155251302916392 \n",
      "-7.50644827532697 -7.4754393073989664 -7.323176655301557 -7.18897332578446 -7.9933717008032446 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.8798710899757465, 2: -7.845126862147279, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.760277728866684, 2: -7.869347487271981, 3: -7.8250879815028185, 4: -7.940945477762644}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.719783665004521, 2: -7.655262812416578, 3: -7.875485197552231, 4: -7.559375916712134}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.719783665004521, 2: -7.655262812416578, 3: -7.875485197552231, 4: -7.559375916712134}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.719783665004521, 2: -7.655262812416578, 3: -7.875485197552231, 4: -7.779032084208041}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.597703265668594, 2: -7.5500724275686055, 3: -7.727966646237483, 4: -7.581262302980044}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.420760463707478, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.6379352735466055}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.411640561972394, 2: -7.416193784170727, 3: -7.391415330044458, 4: -7.5195015408269175}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.538913571861208, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.467562710644789}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.538913571861208, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.467562710644789}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.533237341700056, 1: -7.538913571861208, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.6954820666867585}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.597703265668594, 2: -7.665823218359917, 3: -7.727966646237483, 4: -7.581262302980044}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.597703265668594, 2: -7.665823218359917, 3: -7.727966646237483, 4: -7.581262302980044}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.597703265668594, 2: -7.665823218359917, 3: -7.727966646237483, 4: -7.79894869571184}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.538913571861208, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.356583746506589, 2: -7.324134819094606, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.155251302916392, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.032579541801367, 2: -8.05388992841962, 3: -8.03108543068103, 4: -8.058143215259864}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.967223394215623 -7.8798710899757465 -7.799122265423497 -7.651996657538973 -7.600542376666118 \n",
      "-7.887600461150504 -7.73521692593027 -7.719783665004521 -7.626595804138508 -7.511004384381646 \n",
      "-7.736771596960677 -7.552524095643551 -7.603357217392111 -7.558391296914978 -7.411640561972394 \n",
      "-7.622076103379566 -7.548364949892908 -7.475700066942848 -7.356583746506589 -7.161637786344114 \n",
      "-7.50644827532697 -7.4754393073989664 -7.323176655301557 -7.18897332578446 -8.03108543068103 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -7.98328786955868, 2: -7.967223394215623, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.8798710899757465, 2: -7.970337646596741, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.73521692593027, 2: -7.789053991971493, 3: -7.987994073633684, 4: -7.783399388940173}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.654569001617618, 2: -7.779630784940794, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.654569001617618, 2: -7.779630784940794, 3: -7.647761050883787, 4: -7.552524095643551}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.654569001617618, 2: -7.779630784940794, 3: -7.647761050883787, 4: -7.772796927035631}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.736771596960677, 2: -7.744883504091241, 3: -7.89929331715553, 4: -7.7815921226532625}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.7005281352360235, 2: -7.622076103379566, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.548364949892908, 2: -7.600355764041981, 3: -7.601735814854615, 4: -7.702235766229178}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.506867658550567, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.4754393073989664, 2: -7.506867658550567, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485470677426239, 1: -7.70264976973306, 2: -7.506867658550567, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.578501101954356, 1: -7.709942333982454, 2: -7.600355764041981, 3: -7.601735814854615, 4: -7.702235766229178}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.654569001617618, 2: -7.779630784940794, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.709942333982454, 2: -7.600355764041981, 3: -7.601735814854615, 4: -7.702235766229178}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.565011754823329, 2: -7.475700066942848, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.356583746506589, 2: -7.428167037271738, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.18897332578446, 3: -7.221572983356949, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.032579541801367, 2: -8.05388992841962, 3: -8.156559492382758, 4: -8.058143215259864}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.98328786955868 -7.91448011899294 -7.799122265423497 -7.651996657538973 -7.600542376666118 \n",
      "-7.887600461150504 -7.783399388940173 -7.719783665004521 -7.626595804138508 -7.511004384381646 \n",
      "-7.744883504091241 -7.779630784940794 -7.603357217392111 -7.558391296914978 -7.411640561972394 \n",
      "-7.6724103902519625 -7.601735814854615 -7.565011754823329 -7.393367257316794 -7.161637786344114 \n",
      "-7.50644827532697 -7.506867658550567 -7.323176655301557 -7.221572983356949 -8.032579541801367 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.887600461150504, 1: -7.891479656906927, 2: -7.9313334697912365, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -7.98328786955868, 2: -8.079417922301916, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.891479656906927, 2: -7.9313334697912365, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.847558803433516, 2: -7.744883504091241, 3: -7.89929331715553, 4: -7.7815921226532625}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.821745069035766, 2: -7.779630784940794, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.659314374255617, 2: -7.665009728677955, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.659314374255617, 2: -7.665009728677955, 3: -7.6744356658011705, 4: -7.603357217392111}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.659314374255617, 2: -7.665009728677955, 3: -7.6744356658011705, 4: -7.819055067826821}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.565011754823329, 2: -7.606402841364622, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.323176655301557, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.2252867614375536, 3: -7.221572983356949, 4: -7.419749030798113}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.481791782049284, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.481791782049284, 3: -7.547138581081182, 4: -7.439630416158746}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.481791782049284, 3: -7.547138581081182, 4: -7.670063678704459}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.2252867614375536, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.092214327712046, 2: -8.05388992841962, 3: -8.156559492382758, 4: -8.058143215259864}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.039557781381577 -7.91448011899294 -7.799122265423497 -7.651996657538973 -7.600542376666118 \n",
      "-7.9313334697912365 -7.783399388940173 -7.719783665004521 -7.626595804138508 -7.511004384381646 \n",
      "-7.7815921226532625 -7.820668197859645 -7.665009728677955 -7.558391296914978 -7.411640561972394 \n",
      "-7.6724103902519625 -7.601735814854615 -7.588274266276595 -7.393367257316794 -7.161637786344114 \n",
      "-7.50644827532697 -7.506867658550567 -7.5006614549693476 -7.246179518163648 -8.05388992841962 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.953512819001093, 2: -7.970337646596741, 3: -7.91448011899294, 4: -7.983021698091301}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.079417922301916, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.079417922301916, 3: -8.070609130212498, 4: -8.039557781381577}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.079417922301916, 3: -8.070609130212498, 4: -8.215997581057234}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.079417922301916, 3: -8.070609130212498, 4: -8.258793153577846}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.079417922301916, 3: -8.244254308493373, 4: -8.258793153577846}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.953512819001093, 2: -7.970337646596741, 3: -8.20348981481837, 4: -7.983021698091301}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.791066210064303, 2: -7.789053991971493, 3: -7.987994073633684, 4: -7.783399388940173}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.791066210064303, 2: -7.789053991971493, 3: -7.987994073633684, 4: -7.783399388940173}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.791066210064303, 2: -7.789053991971493, 3: -7.987994073633684, 4: -7.982893443935556}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.719783665004521, 2: -7.781084947572228, 3: -7.875485197552231, 4: -7.8786660864782325}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.793590958832459, 2: -7.665009728677955, 3: -7.6744356658011705, 4: -7.885950149929732}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.586440560652752, 2: -7.558391296914978, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.411640561972394, 2: -7.416193784170727, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.220704329143274, 2: -7.179342695697615, 3: -7.161637786344114, 4: -7.287676342107096}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.458726768536072, 2: -7.428167037271738, 3: -7.393367257316794, 4: -7.48204462545215}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.588274266276595, 2: -7.606402841364622, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.5006614549693476, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.246179518163648, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.092214327712046, 2: -8.116117889226244, 3: -8.156559492382758, 4: -8.058143215259864}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.09042730905048 -7.970337646596741 -7.799122265423497 -7.651996657538973 -7.600542376666118 \n",
      "-7.9313334697912365 -7.791066210064303 -7.781084947572228 -7.626595804138508 -7.511004384381646 \n",
      "-7.7815921226532625 -7.820668197859645 -7.6744356658011705 -7.586440560652752 -7.416193784170727 \n",
      "-7.6724103902519625 -7.601735814854615 -7.593994680373556 -7.428167037271738 -7.179342695697615 \n",
      "-7.50644827532697 -7.506867658550567 -7.518179464686284 -7.2517139561768555 -8.058143215259864 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.09042730905048, 2: -8.150287175621077, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.962503604004598, 2: -7.9313334697912365, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -7.791066210064303, 2: -7.931930167850812, 3: -7.987994073633684, 4: -8.007423077890465}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.820668197859645, 1: -7.821745069035766, 2: -7.8366824245816895, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.902650081198579, 1: -8.013847861272742, 2: -7.931930167850812, 3: -7.987994073633684, 4: -8.007423077890465}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.999904786941648, 2: -7.970337646596741, 3: -8.20348981481837, 4: -7.983021698091301}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.799122265423497, 2: -7.869347487271981, 3: -7.8250879815028185, 4: -7.940945477762644}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.880636246729596, 2: -7.781084947572228, 3: -7.875485197552231, 4: -7.8786660864782325}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.626595804138508, 1: -7.766290319774438, 2: -7.665823218359917, 3: -7.727966646237483, 4: -7.834034514762745}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.750465026636672, 2: -7.810807060818344, 3: -7.651996657538973, 4: -7.80479679807849}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -7.869347487271981, 3: -7.8250879815028185, 4: -7.940945477762644}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.999904786941648, 2: -8.014322799652707, 3: -8.20348981481837, 4: -7.983021698091301}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.999904786941648, 2: -8.014322799652707, 3: -8.20348981481837, 4: -7.983021698091301}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -7.999904786941648, 2: -8.014322799652707, 3: -8.20348981481837, 4: -8.164549745263084}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.013847861272742, 2: -7.931930167850812, 3: -7.987994073633684, 4: -8.007423077890465}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.880636246729596, 2: -7.855651096109415, 3: -7.875485197552231, 4: -7.8786660864782325}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.766290319774438, 2: -7.665823218359917, 3: -7.727966646237483, 4: -7.834034514762745}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.629122463706759, 2: -7.5338506057666335, 3: -7.511004384381646, 4: -7.6379352735466055}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.766290319774438, 2: -7.750495873185126, 3: -7.727966646237483, 4: -7.834034514762745}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.872477836307236, 1: -7.880636246729596, 2: -7.894881916482475, 3: -7.875485197552231, 4: -7.8786660864782325}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -7.869347487271981, 3: -8.148756373604236, 4: -7.940945477762644}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.750465026636672, 2: -7.810807060818344, 3: -8.003520930771181, 4: -7.80479679807849}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691139798070433, 1: -7.750465026636672, 2: -7.810807060818344, 3: -8.003520930771181, 4: -7.80479679807849}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.898937216244094, 1: -7.750465026636672, 2: -7.810807060818344, 3: -8.003520930771181, 4: -7.80479679807849}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.766290319774438, 2: -7.750495873185126, 3: -8.049503712032609, 4: -7.834034514762745}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.629122463706759, 2: -7.5338506057666335, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.629122463706759, 2: -7.5338506057666335, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.629122463706759, 2: -7.755804051247637, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.442090663135972, 2: -7.416193784170727, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.442090663135972, 2: -7.416193784170727, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.442090663135972, 2: -7.6487363435953615, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.220704329143274, 2: -7.179342695697615, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.220704329143274, 2: -7.179342695697615, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.220704329143274, 2: -7.43320185308483, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.077671946394785, 1: -8.092214327712046, 2: -8.116117889226244, 3: -8.156559492382758, 4: -8.259060441856874}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.133244719044617 -8.014322799652707 -7.9167579851642484 -7.80479679807849 -7.600542376666118 \n",
      "-7.957391505725927 -7.987994073633684 -7.875485197552231 -7.766290319774438 -7.63413859741156 \n",
      "-7.7815921226532625 -7.821745069035766 -7.6744356658011705 -7.586440560652752 -7.459476649828665 \n",
      "-7.6724103902519625 -7.601735814854615 -7.593994680373556 -7.428167037271738 -7.264984709494104 \n",
      "-7.50644827532697 -7.506867658550567 -7.518179464686284 -7.2517139561768555 -8.077671946394785 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.133422841435948, 2: -8.150287175621077, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.133244719044617, 1: -8.133422841435948, 2: -8.150287175621077, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.301252694330602, 1: -8.133422841435948, 2: -8.150287175621077, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.962503604004598, 2: -8.00389697713121, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.962503604004598, 2: -8.00389697713121, 3: -7.957391505725927, 4: -7.970743731593558}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.962503604004598, 2: -8.00389697713121, 3: -8.141226270210593, 4: -7.970743731593558}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.847558803433516, 2: -7.975989286211167, 3: -7.89929331715553, 4: -7.7815921226532625}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.847558803433516, 2: -7.975989286211167, 3: -7.89929331715553, 4: -7.7815921226532625}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.847558803433516, 2: -7.975989286211167, 3: -7.89929331715553, 4: -7.981248831614469}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6724103902519625, 1: -7.7005281352360235, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.899408296447442, 2: -7.975989286211167, 3: -7.89929331715553, 4: -8.054647513942594}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.899408296447442, 2: -7.975989286211167, 3: -7.89929331715553, 4: -8.054647513942594}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.899408296447442, 2: -7.975989286211167, 3: -8.088356918611533, 4: -8.054647513942594}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.7005281352360235, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.50644827532697, 2: -7.684818281559893, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.50644827532697, 2: -7.684818281559893, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.730867930547543, 2: -7.684818281559893, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.788114653887655, 2: -7.684818281559893, 3: -7.549417112139384, 4: -7.592778302902734}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.788114653887655, 2: -7.684818281559893, 3: -7.76996957204684, 4: -7.592778302902734}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.788114653887655, 2: -7.684818281559893, 3: -7.827147382555899, 4: -7.592778302902734}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.788114653887655, 2: -7.684818281559893, 3: -7.827147382555899, 4: -7.809428255641488}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.506867658550567, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.519471555209489, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.518179464686284, 2: -7.519471555209489, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.741543312864519, 2: -7.519471555209489, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.2517139561768555, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.092214327712046, 2: -8.116117889226244, 3: -8.156559492382758, 4: -8.259060441856874}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.150287175621077 -8.014322799652707 -7.9167579851642484 -7.80479679807849 -7.600542376666118 \n",
      "-7.970743731593558 -7.987994073633684 -7.875485197552231 -7.766290319774438 -7.63413859741156 \n",
      "-7.927368619185923 -7.821745069035766 -7.6744356658011705 -7.586440560652752 -7.459476649828665 \n",
      "-7.750275916538448 -7.601735814854615 -7.593994680373556 -7.428167037271738 -7.264984709494104 \n",
      "-7.692330452710447 -7.666463974135605 -7.525835460024202 -7.279865001064443 -8.092214327712046 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.999339979749602, 2: -8.00389697713121, 3: -8.163750546264785, 4: -7.970743731593558}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.999339979749602, 2: -8.00389697713121, 3: -8.163750546264785, 4: -7.970743731593558}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -7.999339979749602, 2: -8.00389697713121, 3: -8.163750546264785, 4: -8.15337679575014}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.927368619185923, 2: -7.975989286211167, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.750275916538448, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.692330452710447, 1: -7.788114653887655, 2: -7.749044631581948, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.765459108054276}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.776383219751212, 3: -7.84166860507833, 4: -7.9665677883293915}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.709942333982454, 2: -7.715352630627906, 3: -7.601735814854615, 4: -7.702235766229178}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.835044332007359, 3: -7.84166860507833, 4: -7.9955271868314215}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.709942333982454, 2: -7.715352630627906, 3: -8.006559490411423, 4: -7.702235766229178}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.709942333982454, 2: -7.715352630627906, 3: -8.006559490411423, 4: -7.702235766229178}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.709942333982454, 2: -7.715352630627906, 3: -8.006559490411423, 4: -7.9090345472685515}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.740412132250947, 3: -7.666463974135605, 4: -7.668121452469645}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -7.788114653887655, 2: -7.749044631581948, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.740412132250947, 3: -7.9433725489949385, 4: -7.668121452469645}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.740412132250947, 3: -7.9433725489949385, 4: -7.668121452469645}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.740412132250947, 3: -7.9433725489949385, 4: -7.877990521747377}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.73349622568856, 2: -7.740412132250947, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.93748156537659, 2: -7.740412132250947, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.764926291006138, 2: -7.525835460024202, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.279865001064443, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.165523855361988, 2: -8.116117889226244, 3: -8.156559492382758, 4: -8.259060441856874}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.150287175621077 -8.014322799652707 -7.9167579851642484 -7.80479679807849 -7.600542376666118 \n",
      "-8.00389697713121 -7.987994073633684 -7.875485197552231 -7.766290319774438 -7.63413859741156 \n",
      "-7.970460354314735 -7.821745069035766 -7.6744356658011705 -7.586440560652752 -7.459476649828665 \n",
      "-7.84166860507833 -7.715352630627906 -7.593994680373556 -7.428167037271738 -7.264984709494104 \n",
      "-7.788114653887655 -7.769967935844699 -7.547138581081182 -7.2932830727718105 -8.116117889226244 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -8.124853914653322, 2: -8.014322799652707, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -7.9167579851642484, 3: -8.148756373604236, 4: -7.940945477762644}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.952948159943619, 2: -7.810807060818344, 3: -8.003520930771181, 4: -7.80479679807849}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.952948159943619, 2: -7.810807060818344, 3: -8.003520930771181, 4: -7.80479679807849}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.952948159943619, 2: -7.810807060818344, 3: -8.003520930771181, 4: -8.002365086251427}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.629261172942444, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.6570470838702995}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.600542376666118, 1: -7.629261172942444, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.6570470838702995}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.816493562766167, 1: -7.629261172942444, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.6570470838702995}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.63413859741156, 1: -7.6700292115489646, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.6570470838702995}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.6570470838702995}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.867912846321973}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -7.715993272447531, 3: -7.817247324979811, 4: -7.936745835314698}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -7.921553877927254, 3: -7.817247324979811, 4: -7.936745835314698}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.952948159943619, 2: -7.8375200311813895, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.846578381197609, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.6700292115489646, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.6700292115489646, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.6379352735466055}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.6700292115489646, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.850521098927412}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.459476649828665, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.264984709494104, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.165523855361988, 2: -8.203213256641316, 3: -8.156559492382758, 4: -8.259060441856874}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.150287175621077 -8.017899049750726 -7.940945477762644 -7.952948159943619 -7.861350906359997 \n",
      "-8.00389697713121 -7.987994073633684 -7.875485197552231 -7.766290319774438 -7.7091790075161155 \n",
      "-7.970460354314735 -7.821745069035766 -7.6744356658011705 -7.586440560652752 -7.5195015408269175 \n",
      "-7.84166860507833 -7.715352630627906 -7.593994680373556 -7.428167037271738 -7.287676342107096 \n",
      "-7.788114653887655 -7.769967935844699 -7.547138581081182 -7.2932830727718105 -8.156559492382758 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.158829403781596, 2: -8.150287175621077, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -8.124853914653322, 2: -8.114006247948312, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.017899049750726, 1: -8.124853914653322, 2: -8.114006247948312, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.19628813527316, 1: -8.124853914653322, 2: -8.114006247948312, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -8.013561204960002, 3: -8.148756373604236, 4: -7.940945477762644}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -8.013561204960002, 3: -8.148756373604236, 4: -7.940945477762644}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -8.013561204960002, 3: -8.148756373604236, 4: -8.126260384764004}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.971679068139894, 1: -7.982591034075854, 2: -8.013561204960002, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.154227952007304, 1: -7.982591034075854, 2: -8.013561204960002, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.880636246729596, 2: -7.894881916482475, 3: -7.875485197552231, 4: -7.8786660864782325}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.013847861272742, 2: -8.056270404633707, 3: -7.987994073633684, 4: -8.007423077890465}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -8.12110257951556, 2: -8.00389697713121, 3: -8.163750546264785, 4: -8.194803063172191}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.013847861272742, 2: -8.056270404633707, 3: -8.18195595883965, 4: -8.007423077890465}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.013847861272742, 2: -8.056270404633707, 3: -8.18195595883965, 4: -8.007423077890465}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.013847861272742, 2: -8.056270404633707, 3: -8.18195595883965, 4: -8.186755000880323}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.821745069035766, 2: -7.8366824245816895, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.880830052448085, 2: -7.715352630627906, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.734363205152831, 2: -7.606402841364622, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.734363205152831, 2: -7.606402841364622, 3: -7.7350934954357955, 4: -7.593994680373556}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.734363205152831, 2: -7.606402841364622, 3: -7.7350934954357955, 4: -7.810535159139936}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.458726768536072, 2: -7.428167037271738, 3: -7.785838881415721, 4: -7.48204462545215}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.3333116597794445, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.3333116597794445, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.287676342107096}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.3333116597794445, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.531785471317457}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.165523855361988, 2: -8.203213256641316, 3: -8.317388561491349, 4: -8.259060441856874}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.158829403781596 -8.124853914653322 -8.013561204960002 -7.952948159943619 -7.861350906359997 \n",
      "-8.12110257951556 -8.036998292046245 -7.8786660864782325 -7.766290319774438 -7.7091790075161155 \n",
      "-7.970460354314735 -7.8366824245816895 -7.6744356658011705 -7.586440560652752 -7.5195015408269175 \n",
      "-7.84166860507833 -7.822670954165371 -7.6344761538317725 -7.458726768536072 -7.347405488821155 \n",
      "-7.788114653887655 -7.769967935844699 -7.547138581081182 -7.2932830727718105 -8.165523855361988 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -8.12110257951556, 2: -8.186402390804396, 3: -8.163750546264785, 4: -8.194803063172191}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -7.970460354314735, 2: -7.975989286211167, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.92231540384637, 3: -7.84166860507833, 4: -7.9955271868314215}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.92231540384637, 3: -7.84166860507833, 4: -7.9955271868314215}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.905815258349307, 2: -7.92231540384637, 3: -8.035918430621281, 4: -7.9955271868314215}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -7.788114653887655, 2: -7.886082839658608, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -7.788114653887655, 2: -7.886082839658608, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -7.9871843350377665, 2: -7.886082839658608, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -8.038707813374055, 2: -7.886082839658608, 3: -7.827147382555899, 4: -7.905645633627661}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -8.038707813374055, 2: -7.886082839658608, 3: -8.02270411812587, 4: -7.905645633627661}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.963481983660926, 2: -7.769967935844699, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.764926291006138, 2: -7.549274196864619, 3: -7.547138581081182, 4: -7.727257711330366}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7871329603256525, 1: -7.963481983660926, 2: -7.790179044260228, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.880830052448085, 2: -7.822670954165371, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6344761538317725, 1: -7.734363205152831, 2: -7.6774555843265695, 3: -7.7350934954357955, 4: -7.842239817419337}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.793590958832459, 2: -7.788797923368929, 3: -7.6744356658011705, 4: -7.885950149929732}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -7.8366824245816895, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7025892684422255, 1: -7.793590958832459, 2: -7.788797923368929, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.880636246729596, 2: -7.894881916482475, 3: -8.157823719398506, 4: -7.8786660864782325}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.880636246729596, 2: -7.894881916482475, 3: -8.157823719398506, 4: -7.8786660864782325}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.880636246729596, 2: -7.894881916482475, 3: -8.157823719398506, 4: -8.069586138695191}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.793590958832459, 2: -7.788797923368929, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.586440560652752, 2: -7.659267984889137, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.458726768536072, 2: -7.545834540833922, 3: -7.785838881415721, 4: -7.48204462545215}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.302041990379702, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.2932830727718105, 2: -7.302041990379702, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.536887596222347, 2: -7.302041990379702, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.294645474943803, 2: -8.203213256641316, 3: -8.317388561491349, 4: -8.259060441856874}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.158829403781596 -8.124853914653322 -8.013561204960002 -7.952948159943619 -7.861350906359997 \n",
      "-8.155223220457582 -8.036998292046245 -7.894881916482475 -7.766290319774438 -7.7091790075161155 \n",
      "-7.975989286211167 -7.871966143919431 -7.793590958832459 -7.659267984889137 -7.5195015408269175 \n",
      "-7.92231540384637 -7.858051001505707 -7.6774555843265695 -7.48204462545215 -7.347405488821155 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.3748069369174365 -8.203213256641316 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.124853914653322, 2: -8.143566461782571, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.036998292046245, 2: -8.056270404633707, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -7.922765549896371, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -7.922765549896371, 3: -7.931561098626528, 4: -7.871966143919431}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -7.922765549896371, 3: -7.931561098626528, 4: -8.063489190966683}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.793590958832459, 2: -7.823896646465622, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.734363205152831, 2: -7.6774555843265695, 3: -7.7350934954357955, 4: -7.842239817419337}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.553431965798773, 2: -7.545834540833922, 3: -7.785838881415721, 4: -7.48204462545215}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.553431965798773, 2: -7.545834540833922, 3: -7.785838881415721, 4: -7.48204462545215}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.501747643870138, 1: -7.553431965798773, 2: -7.545834540833922, 3: -7.785838881415721, 4: -7.7086606091614565}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.700212738579493, 2: -7.659267984889137, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.53058527967309, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.53058527967309, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.5195015408269175}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.53058527967309, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.742746402152495}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.347405488821155, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.294645474943803, 2: -8.301452996533323, 3: -8.317388561491349, 4: -8.259060441856874}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.158829403781596 -8.143566461782571 -8.013561204960002 -7.952948159943619 -7.861350906359997 \n",
      "-8.155223220457582 -8.056270404633707 -7.894881916482475 -7.766290319774438 -7.7091790075161155 \n",
      "-7.975989286211167 -7.931561098626528 -7.823896646465622 -7.700212738579493 -7.604456973912445 \n",
      "-7.92231540384637 -7.858051001505707 -7.728201705048899 -7.545834540833922 -7.424579506786184 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.3748069369174365 -8.259060441856874 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.158829403781596, 2: -8.209526947860196, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.155223220457582, 1: -8.16818314494649, 2: -8.186402390804396, 3: -8.163750546264785, 4: -8.194803063172191}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.209526947860196, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.143566461782571, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.077402113424892, 2: -8.013561204960002, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.952948159943619, 2: -8.039480491888202, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.766290319774438, 2: -7.777468577989485, 3: -8.049503712032609, 4: -7.834034514762745}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.700212738579493, 2: -7.756723046558717, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.553431965798773, 2: -7.545834540833922, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.424579506786184, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.294645474943803, 2: -8.301452996533323, 3: -8.317388561491349, 4: -8.33455786124878}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.258793153577846 -8.196377851949043 -8.077402113424892 -7.967770393200114 -7.861350906359997 \n",
      "-8.163750546264785 -8.056270404633707 -7.894881916482475 -7.777468577989485 -7.7091790075161155 \n",
      "-7.975989286211167 -7.931561098626528 -7.823896646465622 -7.740712696623972 -7.604456973912445 \n",
      "-7.92231540384637 -7.858051001505707 -7.728201705048899 -7.553431965798773 -7.448556391099826 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.3748069369174365 -8.294645474943803 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365239149812517, 1: -8.16818314494649, 2: -8.186402390804396, 3: -8.163750546264785, 4: -8.194803063172191}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.365239149812517, 1: -8.16818314494649, 2: -8.186402390804396, 3: -8.163750546264785, 4: -8.194803063172191}, Best action: 3, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.317241528829904, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.317241528829904, 3: -8.26875394791389, 4: -8.258793153577846}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.317241528829904, 3: -8.26875394791389, 4: -8.41550176975584}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.317241528829904, 3: -8.26875394791389, 4: -8.439240874785835}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.317241528829904, 3: -8.424566092601639, 4: -8.439240874785835}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.205341222195859, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.205341222195859, 3: -8.20348981481837, 4: -8.196377851949043}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.205341222195859, 3: -8.20348981481837, 4: -8.358703845273629}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.318197770996179, 1: -8.321613748948801, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.469559971606522, 1: -8.321613748948801, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.16818314494649, 2: -8.186402390804396, 3: -8.492218765974618, 4: -8.194803063172191}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -8.048797605544921, 2: -7.975989286211167, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -8.005085231643928, 3: -7.931561098626528, 4: -8.12378901451273}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.991144070392719, 1: -8.048797605544921, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.177369636325695, 2: -8.186402390804396, 3: -8.492218765974618, 4: -8.194803063172191}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.048797605544921, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.998954395483932, 2: -7.92231540384637, 3: -8.107302202325066, 4: -7.9955271868314215}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.858051001505707, 1: -7.880830052448085, 2: -7.866192780020272, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -7.93161013771218, 2: -8.005085231643928, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.880830052448085, 2: -7.866192780020272, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.734363205152831, 2: -7.728201705048899, 3: -7.7350934954357955, 4: -7.842239817419337}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.553431965798773, 2: -7.668492854580201, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.3748069369174365, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.295695417065618, 1: -8.342102489968855, 2: -8.301452996533323, 3: -8.317388561491349, 4: -8.33455786124878}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.348389722301537 -8.205341222195859 -8.077402113424892 -7.967770393200114 -7.861350906359997 \n",
      "-8.186402390804396 -8.056270404633707 -7.894881916482475 -7.777468577989485 -7.7091790075161155 \n",
      "-8.054647513942594 -8.005085231643928 -7.823896646465622 -7.740712696623972 -7.604456973912445 \n",
      "-7.9955271868314215 -7.880830052448085 -7.734363205152831 -7.628936815483001 -7.448556391099826 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.419749030798113 -8.295695417065618 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.348389722301537, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.237263024123957, 2: -8.186402390804396, 3: -8.492218765974618, 4: -8.194803063172191}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.079992405779365, 2: -8.056270404633707, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.996989942601791, 2: -7.894881916482475, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.913801350226833, 2: -7.777468577989485, 3: -8.049503712032609, 4: -7.834034514762745}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.7091790075161155, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.604456973912445, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.774048716750452}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448556391099826, 1: -7.461120785383098, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.611001776464323, 1: -7.693776374182105, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.774048716750452}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.830528049620693, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.693776374182105, 2: -7.692967071499674, 3: -7.687867328626725, 4: -7.774048716750452}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.782147251933425, 2: -7.756723046558717, 3: -7.740712696623972, 4: -7.771470453445722}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.898098119187767, 2: -7.823896646465622, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.782147251933425, 2: -7.756723046558717, 3: -8.011427553299551, 4: -7.771470453445722}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.693776374182105, 2: -7.692967071499674, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.693776374182105, 2: -7.692967071499674, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.693776374182105, 2: -7.900600035064703, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.461120785383098, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.342102489968855, 2: -8.301452996533323, 3: -8.317388561491349, 4: -8.33455786124878}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.365824908781715 -8.205341222195859 -8.077402113424892 -7.967770393200114 -7.861350906359997 \n",
      "-8.194803063172191 -8.079992405779365 -7.98923773981973 -7.834034514762745 -7.855169600727239 \n",
      "-8.054647513942594 -8.005085231643928 -7.885950149929732 -7.771470453445722 -7.71288547357852 \n",
      "-7.9955271868314215 -7.880830052448085 -7.734363205152831 -7.628936815483001 -7.470289005730301 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.419749030798113 -8.301452996533323 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.205341222195859, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.077402113424892, 2: -8.14324413005033, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.996989942601791, 2: -7.98923773981973, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.913801350226833, 2: -7.922181853887002, 3: -8.049503712032609, 4: -7.834034514762745}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.913801350226833, 2: -7.922181853887002, 3: -8.049503712032609, 4: -7.834034514762745}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.860776873020419, 1: -7.913801350226833, 2: -7.922181853887002, 3: -8.049503712032609, 4: -8.028971408434098}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.985989975011656, 2: -8.039480491888202, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.967770393200114, 1: -7.985989975011656, 2: -8.039480491888202, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.150671057812104, 1: -7.985989975011656, 2: -8.039480491888202, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -7.913801350226833, 2: -7.922181853887002, 3: -8.049503712032609, 4: -8.07012640798995}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.782147251933425, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -7.771470453445722}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.782147251933425, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -7.771470453445722}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.782147251933425, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -7.972038112635607}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.628936815483001, 2: -7.668492854580201, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.456993981514894, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.456993981514894, 3: -7.6482579354242795, 4: -7.419749030798113}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.456993981514894, 3: -7.6482579354242795, 4: -7.651971618026283}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.342102489968855, 2: -8.376471689631979, 3: -8.317388561491349, 4: -8.33455786124878}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.365824908781715 -8.22245400802279 -8.14324413005033 -8.003520930771181 -7.861350906359997 \n",
      "-8.194803063172191 -8.079992405779365 -7.996989942601791 -7.922181853887002 -7.855169600727239 \n",
      "-8.054647513942594 -8.005085231643928 -7.885950149929732 -7.7941461995838415 -7.71288547357852 \n",
      "-7.9955271868314215 -7.880830052448085 -7.734363205152831 -7.668492854580201 -7.470289005730301 \n",
      "-7.905645633627661 -7.790179044260228 -7.549274196864619 -7.482784132959482 -8.317388561491349 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.365824908781715, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.237263024123957, 2: -8.244219266833742, 3: -8.492218765974618, 4: -8.194803063172191}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.237263024123957, 2: -8.244219266833742, 3: -8.492218765974618, 4: -8.194803063172191}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.237263024123957, 2: -8.244219266833742, 3: -8.492218765974618, 4: -8.357270787486694}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.121955237670052, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.121955237670052, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.054647513942594}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.121955237670052, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.22972923768776}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.121955237670052, 2: -8.122163418508602, 3: -8.10735641198358, 4: -8.289931617475476}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.121955237670052, 2: -8.122163418508602, 3: -8.277694334905059, 4: -8.289931617475476}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.998954395483932, 2: -8.057252851604261, 3: -8.107302202325066, 4: -7.9955271868314215}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.998954395483932, 2: -8.057252851604261, 3: -8.107302202325066, 4: -7.9955271868314215}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -7.998954395483932, 2: -8.057252851604261, 3: -8.107302202325066, 4: -8.175929740016594}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -8.038707813374055, 2: -7.982282312000067, 3: -8.089997511936058, 4: -7.905645633627661}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -8.038707813374055, 2: -7.982282312000067, 3: -8.089997511936058, 4: -7.905645633627661}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.959254922795008, 1: -8.038707813374055, 2: -7.982282312000067, 3: -8.089997511936058, 4: -8.094137526601173}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -8.103468402786799, 2: -8.057252851604261, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.880830052448085, 2: -7.946462659091635, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.790179044260228, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.764926291006138, 2: -7.549274196864619, 3: -7.962291555971896, 4: -7.727257711330366}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.482784132959482, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.342102489968855, 2: -8.376471689631979, 3: -8.508057032262323, 4: -8.33455786124878}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.370790212961715 -8.22245400802279 -8.14324413005033 -8.003520930771181 -7.861350906359997 \n",
      "-8.244219266833742 -8.079992405779365 -7.996989942601791 -7.922181853887002 -7.855169600727239 \n",
      "-8.122163418508602 -8.005085231643928 -7.885950149929732 -7.7941461995838415 -7.71288547357852 \n",
      "-8.065668625921175 -7.935956745252643 -7.734363205152831 -7.668492854580201 -7.470289005730301 \n",
      "-7.982282312000067 -7.793930003886365 -7.677149850530993 -7.493782293056899 -8.33455786124878 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.374372972047647, 2: -8.370790212961715, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.22245400802279, 2: -8.263229834093748, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.079992405779365, 2: -8.100481392814176, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -8.064777165587639, 2: -8.005085231643928, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.898098119187767, 2: -7.965335332359123, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.898098119187767, 2: -7.965335332359123, 3: -8.015156330491285, 4: -7.885950149929732}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.898098119187767, 2: -7.965335332359123, 3: -8.015156330491285, 4: -8.076214636436056}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.734363205152831, 2: -7.791100062801896, 3: -7.7350934954357955, 4: -7.842239817419337}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.677149850530993, 1: -7.764926291006138, 2: -7.715982567383643, 3: -7.962291555971896, 4: -7.727257711330366}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.891927699445388, 2: -7.791100062801896, 3: -7.7350934954357955, 4: -7.842239817419337}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.998128031095592, 2: -7.946462659091635, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.998128031095592, 2: -7.946462659091635, 3: -8.006559490411423, 4: -7.935956745252643}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.998128031095592, 2: -7.946462659091635, 3: -8.006559490411423, 4: -8.121720638179905}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.891927699445388, 2: -7.791100062801896, 3: -8.10163431319822, 4: -7.842239817419337}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.672890396494772, 2: -7.668492854580201, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.470289005730301, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.342102489968855, 2: -8.376471689631979, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.374372972047647 -8.263229834093748 -8.14324413005033 -8.003520930771181 -7.861350906359997 \n",
      "-8.244219266833742 -8.100481392814176 -7.996989942601791 -7.922181853887002 -7.855169600727239 \n",
      "-8.122163418508602 -8.064777165587639 -7.95464400809257 -7.7941461995838415 -7.71288547357852 \n",
      "-8.065668625921175 -7.998128031095592 -7.842239817419337 -7.672890396494772 -7.492090691914536 \n",
      "-7.982282312000067 -7.793930003886365 -7.715982567383643 -7.493782293056899 -8.342102489968855 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.247990788705897, 2: -8.244219266833742, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.192118278209518, 2: -8.100481392814176, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -7.996989942601791, 2: -8.044491730939797, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -7.95464400809257, 2: -7.965335332359123, 3: -8.015156330491285, 4: -8.105080940185697}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.891927699445388, 2: -7.8905892184901525, 3: -8.10163431319822, 4: -7.842239817419337}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.891927699445388, 2: -7.8905892184901525, 3: -8.10163431319822, 4: -7.842239817419337}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.879740504682125, 1: -7.891927699445388, 2: -7.8905892184901525, 3: -8.10163431319822, 4: -8.036438233851596}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -8.047678652918918, 2: -7.965335332359123, 3: -8.015156330491285, 4: -8.105080940185697}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7941461995838415, 1: -7.857653545734573, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -8.000743085329635}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -7.986271202313718, 2: -7.922181853887002, 3: -8.049503712032609, 4: -8.07012640798995}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.910225341149716, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.910225341149716, 2: -7.855169600727239, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.865621997676099, 1: -7.910225341149716, 2: -8.048204336661787, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.871385409692512, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861350906359997, 1: -7.871385409692512, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.053829324787596, 1: -7.871385409692512, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.910225341149716, 2: -8.07597425178382, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.910225341149716, 2: -8.07597425178382, 3: -7.910753421890526, 4: -7.897775771247403}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.910225341149716, 2: -8.07597425178382, 3: -7.910753421890526, 4: -8.086975951835138}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.71288547357852, 2: -7.922018866593975, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.504131917447803, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.504131917447803, 2: -7.492090691914536, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.504131917447803, 2: -7.717802529642228, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.412027855132216, 2: -8.376471689631979, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.374372972047647 -8.263229834093748 -8.14324413005033 -8.003520930771181 -7.936745835314698 \n",
      "-8.247990788705897 -8.146238501863218 -8.044491730939797 -7.986271202313718 -7.910753421890526 \n",
      "-8.122163418508602 -8.064777165587639 -8.009791954898825 -7.857653545734573 -7.739882007808626 \n",
      "-8.065668625921175 -7.998128031095592 -7.8905892184901525 -7.672890396494772 -7.535355260346683 \n",
      "-7.982282312000067 -7.793930003886365 -7.715982567383643 -7.493782293056899 -8.376471689631979 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.267039249483565, 2: -8.263229834093748, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.179022780596469, 2: -8.14324413005033, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.108778091184899, 2: -8.039480491888202, 3: -8.003520930771181, 4: -8.026990227888001}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.179022780596469, 2: -8.197176366929689, 3: -8.148756373604236, 4: -8.169686083669715}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.267039249483565, 2: -8.322350728750143, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.146238501863218, 1: -8.192118278209518, 2: -8.187609992788868, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.325157111457564, 2: -8.322350728750143, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29197387436545, 1: -8.325157111457564, 2: -8.322350728750143, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.44569622567256, 1: -8.325157111457564, 2: -8.322350728750143, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.179022780596469, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.169686083669715}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.179022780596469, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.169686083669715}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.179022780596469, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.33441433613944}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -8.142960640815161, 2: -8.044491730939797, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -7.986271202313718, 2: -8.054905561977762, 3: -8.049503712032609, 4: -8.07012640798995}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096381921606856, 1: -7.857653545734573, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -8.000743085329635}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.672890396494772, 2: -7.717783380099564, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.493782293056899, 1: -7.568342771829793, 2: -7.499270280907459, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.737252697025565, 2: -7.717783380099564, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.535355260346683, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.412027855132216, 2: -8.430863334579133, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.374372972047647 -8.325157111457564 -8.181321532802171 -8.026990227888001 -7.936745835314698 \n",
      "-8.247990788705897 -8.18195595883965 -8.061419248321029 -8.049503712032609 -7.910753421890526 \n",
      "-8.122163418508602 -8.064777165587639 -8.009791954898825 -7.900806575734222 -7.739882007808626 \n",
      "-8.065668625921175 -7.998128031095592 -7.8905892184901525 -7.737252697025565 -7.567278088691763 \n",
      "-7.982282312000067 -7.793930003886365 -7.715982567383643 -7.499270280907459 -8.412027855132216 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.247990788705897, 2: -8.285811854862857, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.188572545100456, 2: -8.122163418508602, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -8.064777165587639, 2: -8.088128144607476, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -7.998128031095592, 2: -8.0054373167787, 3: -8.006559490411423, 4: -8.148806817682216}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.793930003886365, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.715982567383643, 3: -7.962291555971896, 4: -7.727257711330366}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.568342771829793, 2: -7.499270280907459, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.422075324364998, 2: -8.430863334579133, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.374372972047647 -8.325157111457564 -8.181321532802171 -8.026990227888001 -7.936745835314698 \n",
      "-8.285811854862857 -8.18195595883965 -8.061419248321029 -8.049503712032609 -7.910753421890526 \n",
      "-8.188572545100456 -8.083213385556814 -8.009791954898825 -7.900806575734222 -7.739882007808626 \n",
      "-8.065668625921175 -8.0054373167787 -7.8905892184901525 -7.737252697025565 -7.567278088691763 \n",
      "-7.982282312000067 -7.929338879969388 -7.727257711330366 -7.568342771829793 -8.422075324364998 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.303751447862558, 2: -8.285811854862857, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.192118278209518, 2: -8.187609992788868, 3: -8.18195595883965, 4: -8.209892267718953}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.303751447862558, 2: -8.355965512146401, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.188572545100456, 2: -8.244685845976848, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.065668625921175, 1: -8.103468402786799, 2: -8.089197627643376, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.252048841506198, 2: -8.244685845976848, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.083213385556814, 1: -8.184961421746193, 2: -8.088128144607476, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.192118278209518, 2: -8.187609992788868, 3: -8.444234268652636, 4: -8.209892267718953}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061419248321029, 1: -8.142960640815161, 2: -8.173328846968092, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.233940580120883, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.181321532802171, 1: -8.233940580120883, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.345002594849975, 1: -8.233940580120883, 2: -8.197176366929689, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.108778091184899, 2: -8.039480491888202, 3: -8.30084475569655, 4: -8.026990227888001}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.108778091184899, 2: -8.039480491888202, 3: -8.30084475569655, 4: -8.026990227888001}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.108778091184899, 2: -8.039480491888202, 3: -8.30084475569655, 4: -8.204561107378083}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.024125721026373, 3: -8.030115957754907, 4: -7.936745835314698}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.024125721026373, 3: -8.030115957754907, 4: -8.122438710136375}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.024125721026373, 3: -8.030115957754907, 4: -8.211785705045001}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.201954406134, 3: -8.030115957754907, 4: -8.211785705045001}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.108778091184899, 2: -8.132712175793726, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.063326492276374, 2: -8.054905561977762, 3: -8.049503712032609, 4: -8.07012640798995}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.142960640815161, 2: -8.173328846968092, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.142960640815161, 2: -8.173328846968092, 3: -8.157823719398506, 4: -8.090273973720493}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.142960640815161, 2: -8.173328846968092, 3: -8.157823719398506, 4: -8.26214931608565}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -8.047678652918918, 2: -8.009791954898825, 3: -8.015156330491285, 4: -8.105080940185697}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096381921606856, 1: -7.900806575734222, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -8.000743085329635}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.737252697025565, 2: -7.775416098890769, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.568342771829793, 2: -7.571808040826395, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.568342771829793, 2: -7.571808040826395, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.787191922365112, 2: -7.571808040826395, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.453715134875413, 2: -8.430863334579133, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.374372972047647 -8.325157111457564 -8.221579721282252 -8.132712175793726 -8.081205114329695 \n",
      "-8.355965512146401 -8.192118278209518 -8.157823719398506 -8.054905561977762 -7.910753421890526 \n",
      "-8.252048841506198 -8.088128144607476 -8.015156330491285 -7.9069756325706075 -7.739882007808626 \n",
      "-8.089197627643376 -8.0054373167787 -7.8905892184901525 -7.747281652450957 -7.567278088691763 \n",
      "-7.982282312000067 -7.929338879969388 -7.727257711330366 -7.586180105091737 -8.430863334579133 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.325157111457564, 2: -8.349680800647484, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.192118278209518, 2: -8.24851059041892, 3: -8.444234268652636, 4: -8.209892267718953}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.184961421746193, 2: -8.088128144607476, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -8.047678652918918, 2: -8.100632521834601, 3: -8.015156330491285, 4: -8.105080940185697}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.184961421746193, 2: -8.20108944215869, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.184961421746193, 2: -8.20108944215869, 3: -8.165982806880756, 4: -8.12378901451273}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.184961421746193, 2: -8.20108944215869, 3: -8.165982806880756, 4: -8.292648003206583}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.252048841506198, 2: -8.271871426898702, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.384762397833367, 1: -8.103468402786799, 2: -8.089197627643376, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -8.012896106257516, 2: -8.0054373167787, 3: -8.006559490411423, 4: -8.148806817682216}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139895669679102, 1: -7.891927699445388, 2: -7.8905892184901525, 3: -8.10163431319822, 4: -8.086233632177683}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.804082914884689, 2: -7.775416098890769, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.804082914884689, 2: -7.775416098890769, 3: -7.785838881415721, 4: -7.747281652450957}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.804082914884689, 2: -7.775416098890769, 3: -7.785838881415721, 4: -7.950026303730372}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.567278088691763, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.453715134875413, 2: -8.48646359373854, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.374372972047647 -8.349680800647484 -8.221579721282252 -8.132712175793726 -8.081205114329695 \n",
      "-8.355965512146401 -8.209892267718953 -8.157823719398506 -8.054905561977762 -7.910753421890526 \n",
      "-8.271871426898702 -8.184961421746193 -8.047678652918918 -7.9069756325706075 -7.739882007808626 \n",
      "-8.103468402786799 -8.006559490411423 -7.891927699445388 -7.785838881415721 -7.593160991553097 \n",
      "-7.982282312000067 -7.929338879969388 -7.727257711330366 -7.586180105091737 -8.453715134875413 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.363118906317624, 2: -8.355965512146401, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.270595624953007, 2: -8.24851059041892, 3: -8.444234268652636, 4: -8.209892267718953}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.270595624953007, 2: -8.24851059041892, 3: -8.444234268652636, 4: -8.209892267718953}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.270595624953007, 2: -8.24851059041892, 3: -8.444234268652636, 4: -8.371001963624247}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.202227547549565, 2: -8.173328846968092, 3: -8.157823719398506, 4: -8.322013050668845}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.270595624953007, 2: -8.332688271754682, 3: -8.444234268652636, 4: -8.41839377460175}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.184961421746193, 2: -8.20108944215869, 3: -8.400757842308098, 4: -8.34371087389407}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.110409311697437, 1: -8.012896106257516, 2: -8.091920998654894, 3: -8.006559490411423, 4: -8.148806817682216}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.384762397833367, 1: -8.103468402786799, 2: -8.193323989355084, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.038707813374055, 2: -7.982282312000067, 3: -8.089997511936058, 4: -8.156410240124073}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.929338879969388, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.746007184273406, 3: -7.962291555971896, 4: -7.727257711330366}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.746007184273406, 3: -7.962291555971896, 4: -7.727257711330366}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.746007184273406, 3: -7.962291555971896, 4: -7.931804517310633}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.586180105091737, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.513703578326128, 2: -8.48646359373854, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.374372972047647 -8.349680800647484 -8.221579721282252 -8.132712175793726 -8.081205114329695 \n",
      "-8.363118906317624 -8.332688271754682 -8.173328846968092 -8.054905561977762 -7.910753421890526 \n",
      "-8.271871426898702 -8.20108944215869 -8.047678652918918 -7.9069756325706075 -7.739882007808626 \n",
      "-8.107302202325066 -8.012896106257516 -7.891927699445388 -7.785838881415721 -7.593160991553097 \n",
      "-8.038707813374055 -7.9433725489949385 -7.764926291006138 -7.632653521437391 -8.48646359373854 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.368131516495465, 2: -8.349680800647484, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.233940580120883, 2: -8.221579721282252, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.230975815864904, 2: -8.132712175793726, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.224589366394873, 3: -8.271121849635257, 4: -8.211785705045001}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.081205114329695, 1: -8.084336915679648, 2: -8.224589366394873, 3: -8.271121849635257, 4: -8.211785705045001}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.253896654040023, 1: -8.084336915679648, 2: -8.224589366394873, 3: -8.271121849635257, 4: -8.211785705045001}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.9384597677135735, 2: -8.07597425178382, 3: -7.910753421890526, 4: -8.115980121514784}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.063326492276374, 2: -8.054905561977762, 3: -8.25807228991686, 4: -8.07012640798995}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.9384597677135735, 2: -8.07597425178382, 3: -8.215548847391041, 4: -8.115980121514784}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.739882007808626, 2: -7.922018866593975, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.604237068118261, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.604237068118261, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.593160991553097}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.604237068118261, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.809776502313317}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.491765216770807, 1: -8.513703578326128, 2: -8.511887807898317, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.374372972047647 -8.368131516495465 -8.233940580120883 -8.183718985540652 -8.11614396329929 \n",
      "-8.363118906317624 -8.332688271754682 -8.173328846968092 -8.063326492276374 -7.963150403096345 \n",
      "-8.271871426898702 -8.20108944215869 -8.047678652918918 -7.9069756325706075 -7.774048716750452 \n",
      "-8.107302202325066 -8.012896106257516 -7.891927699445388 -7.785838881415721 -7.604791257061015 \n",
      "-8.038707813374055 -7.9433725489949385 -7.764926291006138 -7.632653521437391 -8.491765216770807 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.374372972047647, 2: -8.397266767794632, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.363118906317624, 2: -8.385609288066991, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.277454962541755, 2: -8.271871426898702, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.340285432714666, 1: -8.203809329407871, 2: -8.20108944215869, 3: -8.400757842308098, 4: -8.34371087389407}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -8.047678652918918, 2: -8.100632521834601, 3: -8.28178473480444, 4: -8.105080940185697}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139895669679102, 1: -7.891927699445388, 2: -7.964357060334291, 3: -8.10163431319822, 4: -8.086233632177683}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.819406603551648, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.764926291006138, 2: -7.819406603551648, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -7.966082924815586, 2: -7.819406603551648, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.632653521437391, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.532418629035675, 1: -8.513703578326128, 2: -8.511887807898317, 3: -8.508057032262323, 4: -8.513795858623867}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.397266767794632 -8.368131516495465 -8.233940580120883 -8.183718985540652 -8.11614396329929 \n",
      "-8.385609288066991 -8.332688271754682 -8.173328846968092 -8.063326492276374 -7.963150403096345 \n",
      "-8.277454962541755 -8.203809329407871 -8.05197845689159 -7.9069756325706075 -7.774048716750452 \n",
      "-8.107302202325066 -8.012896106257516 -7.964357060334291 -7.785838881415721 -7.604791257061015 \n",
      "-8.038707813374055 -7.9433725489949385 -7.864390012719452 -7.6482579354242795 -8.508057032262323 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.397266767794632, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.368131516495465, 2: -8.394447654303372, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.356878314109718, 2: -8.332688271754682, 3: -8.444234268652636, 4: -8.41839377460175}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.202227547549565, 2: -8.173328846968092, 3: -8.414964828151787, 4: -8.322013050668845}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.063326492276374, 2: -8.13564296804577, 3: -8.25807228991686, 4: -8.07012640798995}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096381921606856, 1: -7.95725534216413, 2: -7.9069756325706075, 3: -8.011427553299551, 4: -8.000743085329635}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.824448603938871, 2: -7.922018866593975, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.824448603938871, 2: -7.922018866593975, 3: -7.93876401712809, 4: -7.774048716750452}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.824448603938871, 2: -7.922018866593975, 3: -7.93876401712809, 4: -7.974384332242912}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.63875353239618, 2: -7.750127106096944, 3: -7.604791257061015, 4: -7.840409675407122}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.804082914884689, 2: -7.807036861729405, 3: -7.785838881415721, 4: -7.993089670474561}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139895669679102, 1: -7.978783065659511, 2: -7.964357060334291, 3: -8.10163431319822, 4: -8.086233632177683}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.804082914884689, 2: -7.807036861729405, 3: -8.129713107012348, 4: -7.993089670474561}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.654791548276221, 3: -7.6482579354242795, 4: -7.7053622868296925}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -8.030327641358394, 2: -7.864390012719452, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.654791548276221, 3: -8.034981703845183, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.532418629035675, 1: -8.513703578326128, 2: -8.511887807898317, 3: -8.552591785139883, 4: -8.513795858623867}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.439240874785835 -8.380697134530243 -8.233940580120883 -8.183718985540652 -8.11614396329929 \n",
      "-8.385609288066991 -8.353665193219623 -8.202227547549565 -8.07012640798995 -7.963150403096345 \n",
      "-8.277454962541755 -8.203809329407871 -8.05197845689159 -7.95725534216413 -7.842325778613309 \n",
      "-8.107302202325066 -8.012896106257516 -7.978783065659511 -7.807036861729405 -7.63875353239618 \n",
      "-8.038707813374055 -7.9433725489949385 -7.886820155375685 -7.660108279225259 -8.511887807898317 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.394447654303372, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.394447654303372, 3: -8.458089175988741, 4: -8.380697134530243}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.394447654303372, 3: -8.458089175988741, 4: -8.526434392422521}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.233940580120883, 2: -8.309654834521144, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.202227547549565, 2: -8.248627343440672, 3: -8.414964828151787, 4: -8.322013050668845}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05197845689159, 1: -8.097229301842656, 2: -8.100632521834601, 3: -8.28178473480444, 4: -8.105080940185697}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.242325304837145, 2: -8.248627343440672, 3: -8.414964828151787, 4: -8.322013050668845}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.381481342607247, 1: -8.097229301842656, 2: -8.100632521834601, 3: -8.28178473480444, 4: -8.105080940185697}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139895669679102, 1: -7.978783065659511, 2: -8.017742867090028, 3: -8.10163431319822, 4: -8.086233632177683}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -8.030327641358394, 2: -7.886820155375685, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.660108279225259, 3: -8.034981703845183, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.532418629035675, 1: -8.513703578326128, 2: -8.539553459759329, 3: -8.552591785139883, 4: -8.513795858623867}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.439240874785835 -8.408936635328253 -8.309654834521144 -8.183718985540652 -8.11614396329929 \n",
      "-8.385609288066991 -8.353665193219623 -8.248627343440672 -8.07012640798995 -7.963150403096345 \n",
      "-8.277454962541755 -8.203809329407871 -8.100632521834601 -7.95725534216413 -7.842325778613309 \n",
      "-8.107302202325066 -8.012896106257516 -8.017742867090028 -7.807036861729405 -7.63875353239618 \n",
      "-8.038707813374055 -7.9433725489949385 -7.8933697217100285 -7.66211072636669 -8.513703578326128 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.436527746419712, 2: -8.385609288066991, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.431122688422338, 1: -8.356878314109718, 2: -8.353665193219623, 3: -8.444234268652636, 4: -8.41839377460175}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.333012366401862, 1: -8.282988264976266, 2: -8.248627343440672, 3: -8.414964828151787, 4: -8.322013050668845}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.110982911609831, 2: -8.13564296804577, 3: -8.25807228991686, 4: -8.07012640798995}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.110982911609831, 2: -8.13564296804577, 3: -8.25807228991686, 4: -8.07012640798995}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.110982911609831, 2: -8.13564296804577, 3: -8.25807228991686, 4: -8.243815031270854}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096381921606856, 1: -7.95725534216413, 2: -7.9876770238249275, 3: -8.011427553299551, 4: -8.000743085329635}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.854181832147215, 1: -7.875497219182136, 2: -7.807036861729405, 3: -8.129713107012348, 4: -7.993089670474561}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.63875353239618, 2: -7.750127106096944, 3: -7.967008619652836, 4: -7.840409675407122}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.532418629035675, 1: -8.543713881166875, 2: -8.539553459759329, 3: -8.552591785139883, 4: -8.513795858623867}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.439240874785835 -8.408936635328253 -8.309654834521144 -8.183718985540652 -8.11614396329929 \n",
      "-8.407910128289075 -8.356878314109718 -8.261665124815927 -8.13564296804577 -7.963150403096345 \n",
      "-8.277454962541755 -8.203809329407871 -8.100632521834601 -7.9876770238249275 -7.842325778613309 \n",
      "-8.107302202325066 -8.012896106257516 -8.017742867090028 -7.854181832147215 -7.660049998724951 \n",
      "-8.038707813374055 -7.9433725489949385 -7.8933697217100285 -7.66211072636669 -8.513795858623867 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.479422247612385, 4: -8.439240874785835}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.479422247612385, 4: -8.57970919605511}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.479422247612385, 4: -8.626302940171543}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.61627424532727, 4: -8.626302940171543}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.487463133809182, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.636472562918165, 4: -8.626302940171543}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.623591451766357, 1: -8.511563611322039, 2: -8.51791320514079, 3: -8.636472562918165, 4: -8.626302940171543}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.436527746419712, 2: -8.505029735314594, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.436527746419712, 2: -8.505029735314594, 3: -8.492218765974618, 4: -8.407910128289075}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.426146369379307, 1: -8.436527746419712, 2: -8.505029735314594, 3: -8.492218765974618, 4: -8.551198216743058}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.656725670347488, 1: -8.561563565046354, 2: -8.51791320514079, 3: -8.636472562918165, 4: -8.626302940171543}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.408936635328253, 3: -8.458089175988741, 4: -8.552146039227983}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.367198371527236, 2: -8.309654834521144, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.230975815864904, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.183718985540652, 1: -8.230975815864904, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.347184276841995, 1: -8.230975815864904, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.139971705794135, 1: -8.156475118313928, 2: -8.13564296804577, 3: -8.25807228991686, 4: -8.29427766153105}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -7.963150403096345, 2: -8.07597425178382, 3: -8.215548847391041, 4: -8.115980121514784}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.842325778613309, 2: -7.922018866593975, 3: -7.93876401712809, 4: -8.035241802414777}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.660049998724951, 2: -7.750127106096944, 3: -7.967008619652836, 4: -7.840409675407122}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.532418629035675, 1: -8.543713881166875, 2: -8.539553459759329, 3: -8.552591785139883, 4: -8.587164694438913}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.561563565046354 -8.458089175988741 -8.358449885897084 -8.232435309167252 -8.11614396329929 \n",
      "-8.436527746419712 -8.356878314109718 -8.261665124815927 -8.139971705794135 -8.048598920986414 \n",
      "-8.277454962541755 -8.203809329407871 -8.100632521834601 -7.9876770238249275 -7.888873076828541 \n",
      "-8.107302202325066 -8.012896106257516 -8.017742867090028 -7.854181832147215 -7.677264089391392 \n",
      "-8.038707813374055 -7.9433725489949385 -7.8933697217100285 -7.66211072636669 -8.532418629035675 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.656725670347488, 1: -8.561563565046354, 2: -8.563029995129964, 3: -8.636472562918165, 4: -8.626302940171543}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.642124333101972, 1: -8.436527746419712, 2: -8.505029735314594, 3: -8.492218765974618, 4: -8.580298380871543}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.322783812463085, 1: -8.277454962541755, 2: -8.37006959083841, 3: -8.306553176003248, 4: -8.289931617475476}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.384762397833367, 1: -8.175995512998734, 2: -8.193323989355084, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.384762397833367, 1: -8.175995512998734, 2: -8.193323989355084, 3: -8.107302202325066, 4: -8.196746034343644}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.384762397833367, 1: -8.175995512998734, 2: -8.193323989355084, 3: -8.27764500411581, 4: -8.196746034343644}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.038707813374055, 2: -8.12099272397521, 3: -8.089997511936058, 4: -8.156410240124073}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.038707813374055, 2: -8.12099272397521, 3: -8.089997511936058, 4: -8.156410240124073}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.21522411017039, 2: -8.12099272397521, 3: -8.089997511936058, 4: -8.156410240124073}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.274420395685246, 2: -8.12099272397521, 3: -8.089997511936058, 4: -8.156410240124073}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.274420395685246, 2: -8.12099272397521, 3: -8.261897735861812, 4: -8.156410240124073}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.952012634174535, 3: -7.9433725489949385, 4: -7.9519309949824715}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.222300302078953, 1: -8.274420395685246, 2: -8.146231037083421, 3: -8.304193880006101, 4: -8.156410240124073}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.952012634174535, 3: -8.292784394937065, 4: -7.9519309949824715}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.952012634174535, 3: -8.292784394937065, 4: -7.9519309949824715}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.015076768906518, 1: -7.963481983660926, 2: -7.952012634174535, 3: -8.292784394937065, 4: -8.136257205434049}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933140716356093, 1: -8.030327641358394, 2: -7.8933697217100285, 3: -7.962291555971896, 4: -7.9674462709925225}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.900782767186337, 1: -7.811883705305891, 2: -7.66211072636669, 3: -8.034981703845183, 4: -7.7053622868296925}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.688108350591113, 1: -8.543713881166875, 2: -8.539553459759329, 3: -8.552591785139883, 4: -8.587164694438913}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.563029995129964 -8.458089175988741 -8.358449885897084 -8.232435309167252 -8.11614396329929 \n",
      "-8.448391294300793 -8.356878314109718 -8.261665124815927 -8.139971705794135 -8.048598920986414 \n",
      "-8.289931617475476 -8.203809329407871 -8.100632521834601 -7.9876770238249275 -7.888873076828541 \n",
      "-8.193323989355084 -8.012896106257516 -8.017742867090028 -7.854181832147215 -7.677264089391392 \n",
      "-8.155687209644142 -7.963481983660926 -7.895646660528022 -7.683249375041726 -8.539553459759329 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.471714079494951, 3: -8.458089175988741, 4: -8.552146039227983}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.656725670347488, 1: -8.589743831104602, 2: -8.563029995129964, 3: -8.636472562918165, 4: -8.626302940171543}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.485673712854872, 1: -8.486290651770839, 2: -8.471714079494951, 3: -8.681863213654145, 4: -8.552146039227983}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.367198371527236, 2: -8.359777861740044, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.367198371527236, 2: -8.359777861740044, 3: -8.41117742944211, 4: -8.358449885897084}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.374213116698048, 1: -8.367198371527236, 2: -8.359777861740044, 3: -8.41117742944211, 4: -8.506189396166345}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.401808838534771, 1: -8.312968385703565, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.401808838534771, 1: -8.312968385703565, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.232435309167252}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.401808838534771, 1: -8.312968385703565, 2: -8.259047360186425, 3: -8.30084475569655, 4: -8.3915161313422}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.273702567104518, 1: -8.11614396329929, 2: -8.224589366394873, 3: -8.271121849635257, 4: -8.211785705045001}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.054256433919207, 1: -8.048598920986414, 2: -8.07597425178382, 3: -8.215548847391041, 4: -8.115980121514784}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.003827897839194, 1: -7.888873076828541, 2: -7.922018866593975, 3: -7.93876401712809, 4: -8.035241802414777}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809767078046084, 1: -7.677264089391392, 2: -7.750127106096944, 3: -7.967008619652836, 4: -7.840409675407122}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.688108350591113, 1: -8.543713881166875, 2: -8.605007578526813, 3: -8.552591785139883, 4: -8.587164694438913}, Best action: 1, Actual action: 1\n",
      "[159, 34, 49, 43, 20, 32, 42, 41, 25, 84, 97, 61, 42, 64, 48, 14, 15, 50, 29, 26, 58, 36, 68, 41, 61, 16, 54, 47, 25, 34, 30, 11, 33, 45, 16, 17, 38, 27, 82, 17, 28, 23, 48, 78, 11, 32, 16, 16, 7, 54, 25, 20, 11, 28, 23, 38, 9, 26, 15, 25, 32, 22, 26, 17, 23, 26, 18, 21, 11, 17, 18, 15, 19, 34, 26, 23, 21, 24, 27, 15, 10, 26, 18, 17, 20, 16, 23, 19, 7, 31, 15, 15, 13, 10, 16, 11, 9, 20, 18, 13]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.WindyGrid import WindyGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = WindyGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(0.9, 0.01, 0.9, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, WindyGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 159)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 49)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 43)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 84)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 97)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 64)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 48)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 50)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 58)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 36)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 68)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 47)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 45)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 82)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 48)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 78)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
