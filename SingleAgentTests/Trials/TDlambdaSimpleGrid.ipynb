{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{TD} (\\lambda)$ in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.61, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.61, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.61, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.61, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.61, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9951, 1: -1.71, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.24169, 1: -2.439, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.993594431719002, 1: -4.6330961589, 2: -3.60876069, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.494881411867603, 1: -6.095837082963511, 2: -5.414613682671001, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.806898996308588, 1: -6.863098828250636, 2: -6.3618504052477, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.493961838605456, 1: -7.264889964096759, 2: -6.857888844563901, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.583454283853134, 1: -7.317224727399495, 2: -6.9224996634561675, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.663997484576045, 1: -7.364326014371957, 2: -6.980649400459208, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.671246372641107, 1: -7.368565130199479, 2: -6.985882876789481, 3: -1.071, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.736486365226664, 1: -7.406717172647173, 2: -7.0329841637619435, 3: -2.61, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.789917919154236, 1: -7.4379636954118356, 2: -7.07156011779239, 3: -3.8704409999999996, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.829783201539598, 1: -7.46127672604655, 2: -7.100341637094506, 3: -4.810856030099999, 4: -4.29605721}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.856911127550013, 1: -7.477141010263167, 2: -7.119927173164403, 3: -5.450799053932749, 4: -6.0614845429329005}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.85024375197369, 1: -7.473241960218533, 2: -7.115113531133992, 3: -5.293516831705259, 4: -5.487397163010433}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.868374802162325, 1: -7.48384491354522, 2: -7.128203596969408, 3: -6.144808615618321, 4: -7.048552220031621}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.881741215974895, 1: -7.49166152980988, 2: -7.137853740506026, 3: -7.119357703405244, 4: -8.199453259995046}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.89072999703112, 1: -7.496918126918783, 2: -7.1443433665664, 3: -8.033990130509062, 4: -8.973422823610044}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.618495111118643, 1: -7.337716439250667, 2: -6.947798073148974, 3: -3.8195738719292196, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.356017155158874, 1: -7.18422055857244, 2: -6.758296985891903, 3: -2.260877526029188, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.39454071838072, 1: -7.2067489581173785, 2: -6.786109824836272, 3: -2.489645450578798, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.426091516659412, 1: -7.225199717344684, 2: -6.8088885399317105, 3: -2.677006380784929, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.449631567255144, 1: -7.238965828804177, 2: -6.825883739264417, 3: -2.816796370811723, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.761434168715198, 1: -7.421306531412396, 2: -3.0511274991683734, 3: 9.265759354581506, 4: 2.1594588422109764}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.611752032267564, 1: -7.333773118285125, 2: 2.386800814967798, 3: 29.293191768024393, 4: 15.047682184476361}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.664531967431623, 1: -7.364638577445393, 2: 0.469314128456507, 3: 18.694862386945097, 4: 10.503121233326043}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.699221480229138, 1: -7.384924842239261, 2: -0.7909503781981675, 3: 9.146592784112835, 4: 7.516217123194258}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.720053340992614, 1: -7.397107216954745, 2: -1.5477685808932016, 3: 1.6894410450412884, 4: 5.7225116047766384}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.6959565719744, 1: -7.3830155391663155, 2: -0.6723367783200769, 3: 12.530064834471581, 4: 7.79733862357979}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.674102912104784, 1: -7.370235621113909, 2: 0.12160322409336566, 3: 22.36156153386706, 4: 11.91077283686444}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.699771002562958, 1: -7.385246200329216, 2: -0.8109144375659342, 3: 7.901493116052169, 4: 7.079362349546467}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.712549972753951, 1: -7.392719282312253, 2: -1.2751724009830847, 3: -0.9086490586064055, 4: 4.674023678230229}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.686110823053241, 1: -7.377257791259206, 2: -0.31464227914401544, 3: 21.022906402256737, 4: 9.650567817652224}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.63829191580674, 1: -7.349293518015638, 2: 1.4226110487290309, 3: 60.689197800664644, 4: 26.094388424696675}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.67507830681831, 1: -7.37080602737913, 2: 0.08616728861012768, 3: 23.8124679825415, 4: 13.444395996876642}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.690914599155388, 1: -7.380067017049935, 2: -0.48916270423011654, 3: 4.894163282284701, 4: 7.998659879795794}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.685415308017694, 1: -7.376851057320289, 2: -0.2893743280412986, 3: 12.637877740194991, 4: 9.889739415929924}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.6835778329484, 1: -7.375776510496141, 2: -0.22261914974832236, 3: 15.225280717028594, 4: 10.957520257919285}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.692190549909078, 1: -7.380813187081333, 2: -0.5355177930577344, 3: 0.8271840332676152, 4: 5.952557566576941}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.681342894721292, 1: -7.374469529076779, 2: -0.14142419787249866, 3: 22.13858945239256, 4: 12.256272149476658}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66290061394557, 1: -7.363684569558814, 2: 0.5285809422708039, 3: 58.370467739529154, 4: 28.974935707330346}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.679918289781117, 1: -7.373636426772584, 2: -0.08966852599013087, 3: 18.784039621682112, 4: 13.547733383978388}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.686366303441735, 1: -7.377407194995168, 2: -0.3239238412012636, 3: 1.1941405562374037, 4: 7.70235165927067}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.67681396799094, 1: -7.371821033912831, 2: 0.023110993060211193, 3: 31.51667194639695, 4: 16.36192498080097}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.656848776245916, 1: -7.3601454831847475, 2: 0.7484432475567604, 3: 94.89333585413425, 4: 44.36393990583171}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.673978471258831, 1: -7.370162848689377, 2: 0.12612414032086472, 3: 31.07715313841088, 4: 20.338827523304587}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.68001579660059, 1: -7.373693448304441, 2: -0.09321093330090197, 3: 4.88832862874434, 4: 11.87122668649574}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.673672053504957, 1: -7.369983657020445, 2: 0.13725624879615797, 3: 36.72253573989664, 4: 20.768591215377796}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660241204697188, 1: -7.362129359472042, 2: 0.6251968591321189, 3: 104.12129640524518, 4: 49.75943923200741}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.672468727114156, 1: -7.369279957376701, 2: 0.18097290602050659, 3: 32.49015829327928, 4: 23.36600356134661}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.676566073021164, 1: -7.371676066094249, 2: 0.03211697805665248, 3: 4.663017059988082, 4: 14.52177233205183}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.670138094852035, 1: -7.367917014533355, 2: 0.2656444070346806, 3: 54.984576925227586, 4: 28.396735919433574}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.654446542690927, 1: -7.358740668240309, 2: 0.8357160122024029, 3: 177.82621712338937, 4: 80.34781784761245}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.667650314820365, 1: -7.366462172409571, 2: 0.3560250616313143, 3: 57.5558547464983, 4: 36.633197355345146}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.671924440728713, 1: -7.368961661244862, 2: 0.2007467442128709, 3: 12.543720630390197, 4: 22.482559932346433}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.668114740442606, 1: -7.366733766340706, 2: 0.3391525523196887, 3: 58.68637069851212, 4: 35.09559206920863}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.65954512698898, 1: -7.3617222964847855, 2: 0.6504852520434959, 3: 162.48053956050273, 4: 78.5175177333798}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.667500342487822, 1: -7.366374469291125, 2: 0.3614735327236522, 3: 50.604639239448986, 4: 38.20872458857503}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.670016050462454, 1: -7.367845643545296, 2: 0.2700782603817126, 3: 9.771281357640142, 4: 25.46172202440811}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66547905625464, 1: -7.365192430558269, 2: 0.4349065414931523, 3: 94.34270223015776, 4: 48.45050982640701}, Best action: 3, Actual action: 3\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.653556959075633, 1: -7.35822044390388, 2: 0.8680344440754499, 3: 316.57545193742885, 4: 140.7714808959981}, Best action: 3, Actual action: 3\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.663439427171161, 1: -7.3639996650123765, 2: 0.5090059431092007, 3: 102.97042882683112, 4: 64.24475598806912}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.666516155647832, 1: -7.365798921431482, 2: 0.3972288847689907, 3: 26.30101291616539, 4: 40.419538291987394}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.664291367108545, 1: -7.3644978755020745, 2: 0.47805510009353874, 3: 89.90973589873732, 4: 57.64760104701692}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.659378304762294, 1: -7.361624739627073, 2: 0.6565458771218643, 3: 230.37864620648668, 4: 115.73685584009613}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.664150825312396, 1: -7.364415687317192, 2: 0.4831609612920661, 3: 72.29387521155786, 4: 59.309287309115966}, Best action: 3, Actual action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.665621314871737, 1: -7.365275622732011, 2: 0.4297383084614714, 3: 16.178991811696513, 4: 41.92305512577937}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.662316204901405, 1: -7.363342809883863, 2: 0.549812430300937, 3: 160.8008220068666, 4: 81.00079557665461}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.653238310761525, 1: -7.358034099860541, 2: 0.8796108868673209, 3: 558.0226018000224, 4: 244.78060248421758}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660637558640952, 1: -7.362361145404065, 2: 0.610797383120208, 3: 183.13137992695158, 4: 111.2862732620136}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.662901771814797, 1: -7.3636852466753195, 2: 0.5285388770652665, 3: 51.03064684492577, 4: 70.43622690810916}, Best action: 4, Actual action: 4\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.661702934825405, 1: -7.362984172412517, 2: 0.5720924350473154, 3: 131.2000193440411, 4: 92.06517384346726}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.659327477244345, 1: -7.361595015932365, 2: 0.6583924328001856, 3: 290.05309558121655, 4: 157.4356073863657}, Best action: 3, Actual action: 3\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66189190287771, 1: -7.363094680045444, 2: 0.5652272556312239, 3: 91.55845166220905, 4: 86.86494479983713}, Best action: 3, Actual action: 3\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66267308191071, 1: -7.363551509889303, 2: 0.5368471450664299, 3: 21.952466456272532, 4: 65.36760783664731}, Best action: 4, Actual action: 4\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66018932064995, 1: -7.362099017923947, 2: 0.6270817983522438, 3: 275.5554639724934, 4: 133.71846020605653}, Best action: 3, Actual action: 3\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.65313137428708, 1: -7.3579715639105725, 2: 0.883495872049926, 3: 996.2029683088412, 4: 429.90004067464434}, Best action: 3, Actual action: 3\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.658773563283296, 1: -7.361271089639353, 2: 0.6785160392897129, 3: 329.55227851152847, 4: 193.12968733324922}, Best action: 3, Actual action: 3\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660487170150715, 1: -7.362273198918546, 2: 0.6162609731556293, 3: 96.5220073278283, 4: 121.21942276052886}, Best action: 4, Actual action: 4\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.659961412251413, 1: -7.36196573815872, 2: 0.6353616743805911, 3: 178.43679057580698, 4: 143.28247021843677}, Best action: 3, Actual action: 3\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.65929466597236, 1: -7.361575828054011, 2: 0.6595844611155157, 3: 282.31801994451234, 4: 185.94156955348632}, Best action: 3, Actual action: 3\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.66037010962699, 1: -7.362204742471923, 2: 0.6205137634453729, 3: 88.45179420067703, 4: 117.13359996519694}, Best action: 4, Actual action: 4\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.659841375636836, 1: -7.36189554130809, 2: 0.6397225855796989, 3: 198.13630430397444, 4: 150.96253387378172}, Best action: 3, Actual action: 3\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.65905584196718, 1: -7.361436164893088, 2: 0.6682608994045808, 3: 361.09324925182136, 4: 224.94589625432207}, Best action: 3, Actual action: 3\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660051115959215, 1: -7.362018196467377, 2: 0.6321027528811811, 3: 121.22781995825795, 4: 131.20870933906053}, Best action: 4, Actual action: 4\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660151047024467, 1: -7.362076635686823, 2: 0.6284722731052007, 3: 93.41800832984524, 4: 121.79697245335159}, Best action: 4, Actual action: 4\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.660437365949246, 1: -7.36224407365453, 2: 0.61807035190819, 3: 13.738327705720366, 4: 82.96907201516842}, Best action: 4, Actual action: 0\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.662319491639936, 1: -7.363344731953179, 2: 0.5496930236106153, 3: -510.0383456118418, 4: -258.9043678447766}, Best action: 2, Actual action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.260017903682735, 1: -7.128080645428497, 2: -6.688988451146295, 3: 4.300002030771204, 4: 16.60125042604016}, Best action: 4, Actual action: 4\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.25965897036752, 1: -7.127870742904979, 2: -6.6887293122283715, 3: 4.3149143681975, 4: 16.6408084397801}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259723276073533, 1: -7.127908348581011, 2: -6.688775738988904, 3: 4.312242706510306, 4: 14.236048553164785}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259775927050512, 1: -7.1279391386260285, 2: -6.68881375139016, 3: 4.3100552552449525, 4: 10.085881590350958}, Best action: 4, Actual action: 4\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259815198599181, 1: -7.127962104443964, 2: -6.688842104251809, 3: 4.308423669208815, 4: 5.18260695603197}, Best action: 4, Actual action: 4\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.25984191487931, 1: -7.127977727999594, 2: -6.688861392592094, 3: 4.307313707644461, 4: 0.4804938778419867}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 4.640506885025525, 1: -7.363135464982178, 2: 7.74172646274627, 3: -410.4532536350062, 4: -193.90434075833122}, Best action: 2, Actual action: 2\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259780326705952, 1: -7.127941711523946, 2: -6.688816927807343, 3: 5.80266967157037, 4: 14.820119622398206}, Best action: 4, Actual action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259731547918127, 1: -7.1279131859170315, 2: -6.688781711008683, 3: 8.884753966178442, 4: 26.177325455031497}, Best action: 4, Actual action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259773315192373, 1: -7.127937611223607, 2: -6.688811865708159, 3: 6.245691666402769, 4: 13.196656883372153}, Best action: 4, Actual action: 4\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259797417997255, 1: -7.1279517064311415, 2: -6.688829267198941, 3: 4.722757626846709, 4: 3.6181524025644}, Best action: 3, Actual action: 3\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 4.734489023966178, 1: -7.363134390429148, 2: 6.405873840277206, 3: -409.94189982778676, 4: -193.57057582765512}, Best action: 2, Actual action: 2\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.25979866990017, 1: -7.1279524385381094, 2: -6.688830171034705, 3: 4.877455937351278, 4: 3.0001598491675248}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 4.0586190438064955, 1: -7.363142118047858, 2: 1.1657101115944952, 3: -413.61928673806165, 4: -195.9708371923864}, Best action: 0, Actual action: 0\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 4.460986915996642, 1: -7.363137517539493, 2: 4.130699661112522, 3: -411.430016035496, 4: -194.54188179211997}, Best action: 0, Actual action: 0\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 2.891527847293449, 1: -7.3631405814008115, 2: 2.1560664096347146, 3: -412.88803356087817, 4: -195.49354209348715}, Best action: 0, Actual action: 0\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.47207802958035394, 1: -7.36314303960566, 2: 0.5717737380665919, 3: -414.05783381555943, 4: -196.25708055823748}, Best action: 2, Actual action: 2\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259830661947337, 1: -7.127971147337623, 2: -6.688853268318055, 3: -1.5455159071350368, 4: -12.792476032550582}, Best action: 3, Actual action: 3\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.442956964239572, 1: -7.363147623157572, 2: -4.095634127280187, 3: -416.23903535264867, 4: -197.6807691463323}, Best action: 2, Actual action: 2\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259841462921871, 1: -7.127977463696999, 2: -6.688861066292594, 3: -5.319957276240568, 4: -18.124296690440108}, Best action: 3, Actual action: 3\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.999640277659097, 1: -7.363149317825886, 2: -6.826560634341881, 3: -417.0454870304876, 4: -198.2071469390609}, Best action: 2, Actual action: 2\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.25984553796276, 1: -7.127979846761846, 2: -6.688864008347961, 3: -7.863404756581399, 4: -20.135910284134177}, Best action: 2, Actual action: 2\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578812915637755, 1: -6.72971515534371, 2: -6.197179204128041, 3: -2.420783411825441, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578787470331203, 1: -6.729700275047481, 2: -6.197160833391956, 3: -2.4207031088890867, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578791495876997, 1: -6.729702629167829, 2: -6.197163739713372, 3: -2.4207158131238344, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578794792799002, 1: -6.729704557192393, 2: -6.197166119990612, 3: -2.4207262178920925, 4: -2.4561}, Best action: 3, Actual action: 3\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259833928408968, 1: -7.127973057549101, 2: -3.51633692758592, 3: 1.4442429821266756, 4: -14.404940494532317}, Best action: 3, Actual action: 3\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.252635431420115, 1: -7.363144182812267, 2: 8.175377015637695, 3: -414.60185819946133, 4: -196.61216984908765}, Best action: 2, Actual action: 2\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259827445507812, 1: -7.127969266378835, 2: -1.3072234745724356, 3: 7.6623275180005646, 4: -11.204704608355824}, Best action: 3, Actual action: 3\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.263877343092995, 1: -7.363145515940981, 2: 0.7869549953988209, 3: -415.2362619231041, 4: -197.02625049511556}, Best action: 2, Actual action: 2\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259833317936925, 1: -7.127972700547908, 2: -3.308312469736813, 3: -0.6079065201555632, 4: -14.103585516904078}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.53965370047209, 1: -7.363146361574758, 2: -4.9263315378246135, 3: -415.6386785926053, 4: -197.28891123979508}, Best action: 0, Actual action: 0\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467866775438616, 1: -7.363146313991615, 2: -4.594013405351615, 3: -415.61603492538364, 4: -197.27413152775662}, Best action: 0, Actual action: 0\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.231171159057435, 1: -7.363146489917187, 2: -5.8226682177914295, 3: -415.69975365146126, 4: -197.32877544437773}, Best action: 0, Actual action: 0\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.252553438974529, 1: -7.363146626403966, 2: -6.775884606579928, 3: -415.76470440975214, 4: -197.3711693505778}, Best action: 0, Actual action: 0\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312185046919169, 1: -7.363146722932744, 2: -7.4500364450081005, 3: -415.81064012133254, 4: -197.40115197586528}, Best action: 0, Actual action: 0\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.238096628915345, 1: -7.363146785243531, 2: -7.885211657307992, 3: -415.84029231821114, 4: -197.42050621415558}, Best action: 1, Actual action: 0\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.942922079086697, 1: -7.363146822004628, 2: -8.141949199978603, 3: -415.8577860355604, 4: -197.43192451059912}, Best action: 1, Actual action: 1\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181273972077234, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181272946208626, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919970022033003, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919970462504155, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477452031844679, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4774525756362245, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728044179347915, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728044850695501, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458915708820755, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458916537644936, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458916890985771, 1: -1.71, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458917208992522, 1: -2.439, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728046039638188, 1: -4.264860690000001, 2: -3.1541490000000003, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.47745399576045, 1: -5.861894039100001, 2: -5.12579511, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919971857687692, 1: -6.918211886598551, 2: -6.4298912180229015, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274207612274, 1: -7.617461637097644, 2: -7.2931625149353625, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274230441915, 1: -7.739038291688213, 2: -7.443257150232362, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274250988591, 1: -7.8484572808197255, 2: -7.578342321999661, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274252837792, 1: -7.858304989841562, 2: -7.590499987458718, 3: -1.071, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1812742694806, 1: -7.946934371038087, 2: -7.69991897659023, 3: -2.61, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274283111059, 1: -8.019521834238041, 2: -7.789533128688939, 3: -3.8704409999999996, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274293280746, 1: -8.073679340531527, 2: -7.856394247569786, 3: -4.810856030099999, 4: -4.29605721}, Best action: 4, Actual action: 4\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274300201116, 1: -8.11053298198918, 2: -7.901892570357013, 3: -5.450799053932749, 4: -6.0614845429329005}, Best action: 3, Actual action: 3\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274298500259, 1: -8.101475265271029, 2: -7.890710204038307, 3: -5.293516831705259, 4: -5.487397163010433}, Best action: 3, Actual action: 3\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274303125514, 1: -8.12610653353113, 2: -7.921119177198926, 3: -6.144808615618321, 4: -7.048552220031621}, Best action: 3, Actual action: 3\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274306535304, 1: -8.144264981104083, 2: -7.9435370137087435, 3: -7.119357703405244, 4: -8.199453259995046}, Best action: 3, Actual action: 3\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181274308828354, 1: -8.156476357457006, 2: -7.958612786983958, 3: -8.033990130509062, 4: -8.973422823610044}, Best action: 0, Actual action: 0\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.1953898141551, 1: -8.957542726191093, 2: -8.506931863420432, 3: -415.88265541572673, 4: -197.44815696419576}, Best action: 2, Actual action: 2\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259837033021961, 1: -7.12797487311226, 2: -4.574264878975356, 3: -9.704741772470003, 4: -15.937509584819315}, Best action: 2, Actual action: 2\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802318150666, 1: -6.729708957982844, 2: -6.197171553065242, 3: -4.006096489085249, 4: -8.085068387829056}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836981511798, 1: -7.127974842989357, 2: -4.600813945172756, 3: -9.551715156648847, 4: -15.912081975741252}, Best action: 2, Actual action: 2\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802342813088, 1: -6.729708972405312, 2: -6.197171570870758, 3: -5.034520789849316, 4: -8.103515896331428}, Best action: 3, Actual action: 3\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.25983699548207, 1: -7.127974851159106, 2: -5.53533665501898, 3: -9.593218095799946, 4: -15.918978295748474}, Best action: 2, Actual action: 2\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802358765527, 1: -6.729708981734225, 2: -6.197171582387933, 3: -6.579036462973987, 4: -8.11544833245143}, Best action: 2, Actual action: 2\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.42546419684643, 1: -6.055242220378028, 2: -5.3644965683679375, 3: -3.078675071134763, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464077041473, 1: -6.055242150316649, 2: -5.364496481872409, 3: -3.078674870200692, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464097788232, 1: -6.055242162449256, 2: -5.364496496850935, 3: -3.078674904996669, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464114779828, 1: -6.055242172385861, 2: -5.364496509118349, 3: -3.0786749334945744, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464127457257, 1: -6.055242179799562, 2: -5.364496518271067, 3: -3.0786749547568615, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802307931335, 1: -6.729708952006628, 2: -3.1779076785952114, 3: -1.6357750104116797, 4: -8.077424322249604}, Best action: 3, Actual action: 3\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836971931918, 1: -7.127974837387088, 2: 1.2671727458194924, 3: -9.523255204431816, 4: -15.907352938668375}, Best action: 2, Actual action: 2\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802293636585, 1: -6.7297089436471245, 2: -2.2327618860782605, 3: 0.9262683307338757, 4: -8.066731838908117}, Best action: 3, Actual action: 3\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836977202308, 1: -7.127974840469188, 2: -2.5804554003322115, 3: -9.538912503667401, 4: -15.909954627806204}, Best action: 2, Actual action: 2\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802313050172, 1: -6.7297089550001, 2: -3.516356878930565, 3: -3.5409280467143023, 4: -8.081253215596192}, Best action: 2, Actual action: 2\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464139610384, 1: -6.0552421869066535, 2: -5.364496527045256, 3: -4.407469950212293, 4: -6.7831100338970245}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324564544, 1: -6.729708961733651, 2: -5.181426240301591, 3: -7.861731660616959, 4: -8.089865974891397}, Best action: 2, Actual action: 2\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464152905683, 1: -6.055242194681683, 2: -5.364496536644058, 3: -5.936472176793192, 4: -9.5039002944802}, Best action: 2, Actual action: 2\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275825127179, 1: -4.913026798319982, 2: -7.348080818666629, 3: -3.6708074962962756, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.4722757818178, 1: -4.913026772992859, 2: -7.348080752656296, 3: -3.6708074576937415, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275790748599, 1: -4.913026778215549, 2: -7.348080766268244, 3: -3.670807465653945, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275798062924, 1: -4.913026782492932, 2: -7.348080777416429, 3: -3.670807472173352, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.47227580352014, 1: -4.913026785684288, 2: -7.348080785734091, 3: -3.670807477037481, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464139250094, 1: -6.055242186695959, 2: -3.4093236978787695, 3: -3.334648805437802, 4: -6.709379930889952}, Best action: 3, Actual action: 3\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802320260772, 1: -6.729708959216828, 2: -2.3510721017044003, 3: -6.246729363052497, 4: -8.086646752891726}, Best action: 2, Actual action: 2\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464139034, 1: -6.055242186569588, 2: -3.3761324106974997, 3: -2.9006443918010842, 4: -6.665157882679068}, Best action: 3, Actual action: 3\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802322193155, 1: -6.729708960346877, 2: -4.785039234241715, 3: -6.971862208083577, 4: -8.088092177217703}, Best action: 2, Actual action: 2\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464144131707, 1: -6.055242189550704, 2: -4.159124044601428, 3: -5.511536332843433, 4: -7.708368216587344}, Best action: 2, Actual action: 2\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275810582799, 1: -4.913026789814498, 2: -7.348080796498697, 3: -4.747939530302157, 4: -7.653626537865401}, Best action: 3, Actual action: 3\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464145899502, 1: -6.055242190584503, 2: -5.535659272814512, 3: -6.990059063166685, 4: -8.070135138115406}, Best action: 2, Actual action: 2\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275816642178, 1: -4.913026793357994, 2: -7.348080805734146, 3: -6.202132727333564, 4: -10.53423945741999}, Best action: 1, Actual action: 1\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458918657922057, 1: -5.760532092533964, 2: -9.55694235365505, 3: -4.962539388102366, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458918651508859, 1: -5.7458304512536245, 2: -9.518625318768018, 3: -4.9401317653614125, 4: 0.0}, Best action: 4, Actual action: 3\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728046879273031, 1: -6.641135270292668, 2: -6.087821321348968, 3: -4.520222040356252, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728046876162368, 1: -6.632331695011202, 2: -6.076952709890368, 3: -4.499770830422131, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.728046876867876, 1: -6.6343283731222185, 2: -6.079417744595326, 3: -4.504409228108719, 4: -0.9}, Best action: 4, Actual action: 0\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464148635063, 1: -6.055242192184248, 2: -8.066933936523416, 3: -9.277989920893036, 4: -8.629949124125453}, Best action: 1, Actual action: 1\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.377550864102121, 1: -6.64493926281288, 2: -6.092517608410957, 3: -4.529058932997185, 4: -10.997115955258986}, Best action: 3, Actual action: 3\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454402238264, 1: -7.282121794825861, 2: -6.8791627096615615, 3: -4.028609165392323, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401274577, 1: -7.278754687792944, 2: -6.8750057873987, 3: -4.0166872287745345, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401520572, 1: -7.279614192248661, 2: -6.876066904010696, 3: -4.019730481496705, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401722042, 1: -7.280318126397893, 2: -6.876935958515921, 3: -4.022222905476163, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401872359, 1: -7.280843331666635, 2: -6.8775843600822695, 3: -4.024082503007236, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049796086, 1: -7.746883522805141, 2: -7.452942620747088, 3: -3.472005438429948, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049507811, 1: -7.745640030604613, 2: -7.45140744519088, 3: -3.4652948142931526, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049593584, 1: -7.746010019089648, 2: -7.451864221098331, 3: -3.4672914924041685, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049663833, 1: -7.746313039658892, 2: -7.452238320566534, 3: -3.4689267717770904, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049716245, 1: -7.746539123305605, 2: -7.452517436179759, 3: -3.4701468537172278, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.909926834434366, 1: -8.086193019148897, 2: -7.871843233517158, 3: -1.111794501914428, 4: -4.518792722334669}, Best action: 3, Actual action: 3\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.903111728987079, 1: -8.085933008958449, 2: -7.871522233282037, 3: -1.0861861365886876, 4: -4.502313009661819}, Best action: 3, Actual action: 3\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.906832852237983, 1: -8.086074977409654, 2: -7.871697502974882, 3: -1.9024118361254414, 4: -4.511311115776167}, Best action: 3, Actual action: 3\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.909875198830486, 1: -8.08619104914516, 2: -7.871840801413779, 3: -3.2985313002663705, 4: -4.5186678614763585}, Best action: 3, Actual action: 3\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.912141228053721, 1: -8.086277502787654, 2: -7.871947534305746, 3: -4.941534322635315, 4: -4.524147382049596}, Best action: 4, Actual action: 4\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.912537454452002, 1: -8.086292619633912, 2: -7.871966197078904, 3: -5.346000002569649, 4: -4.5251055032771506}, Best action: 4, Actual action: 4\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914036988345012, 1: -8.08634982991424, 2: -7.872036827054617, 3: -6.876715770757672, 4: -5.021472054254146}, Best action: 4, Actual action: 4\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.915264212770391, 1: -8.086396651032276, 2: -7.8720946309040425, 3: -8.1294595652055, 4: -5.8757679034819095}, Best action: 4, Actual action: 4\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.916179186549376, 1: -8.08643155915048, 2: -7.87213772734627, 3: -9.063459655166112, 4: -6.88388062417446}, Best action: 0, Actual action: 0\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.999725870297716, 1: -8.914065005234741, 2: -5.5680467987858995, 3: -415.878770252965, 4: -197.44562108578515}, Best action: 2, Actual action: 2\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984595783, 1: -7.127974844792858, 2: -8.105842417830443, 3: -9.560877082434475, 4: -15.91360436363455}, Best action: 1, Actual action: 1\n",
      "Step: 242\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049806079, 1: -7.746926622908839, 2: -7.452995830751655, 3: -5.081828121130707, 4: -8.742679197682165}, Best action: 3, Actual action: 3\n",
      "Step: 243\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3654292600388365, 1: -8.086423191072775, 2: -7.872127396386138, 3: -8.839563732589706, 4: -6.543353673378561}, Best action: 0, Actual action: 0\n",
      "Step: 244\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000286965133467, 1: -8.91418968392729, 2: -7.496669468257911, 3: -415.87878139423475, 4: -197.44562835778558}, Best action: 2, Actual action: 2\n",
      "Step: 245\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984660568, 1: -7.426412512049525, 2: -8.155857112682291, 3: -9.561069551859129, 4: -15.913636345242868}, Best action: 1, Actual action: 1\n",
      "Step: 246\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919972049814261, 1: -7.7469619169619985, 2: -7.453039403656789, 3: -7.230516041950642, 4: -9.147684290593242}, Best action: 0, Actual action: 0\n",
      "Step: 247\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984658495, 1: -7.07249792577061, 2: -8.154257149955999, 3: -9.561063394790564, 4: -15.913635322155924}, Best action: 1, Actual action: 1\n",
      "Step: 248\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3207205248598965, 1: -7.7469661035643265, 2: -7.453044572301638, 3: -7.30101919972379, 4: -9.195726244209926}, Best action: 3, Actual action: 3\n",
      "Step: 249\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9987948526734, 1: -8.086535370924793, 2: -7.872265890030604, 3: -11.841042966245508, 4: -11.108352265370495}, Best action: 2, Actual action: 2\n",
      "Step: 250\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.861317783404406, 1: -7.746993122592632, 2: -7.453077929126707, 3: -8.522320898701638, 4: -9.505774059343103}, Best action: 2, Actual action: 2\n",
      "Step: 251\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401971664, 1: -7.281190298431976, 2: -6.878012714113551, 3: -4.253442026191273, 4: -6.009962825945945}, Best action: 3, Actual action: 3\n",
      "Step: 252\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.203353231247625, 1: -7.746910257593862, 2: -5.0904995261441215, 3: -5.079989170978212, 4: -8.554884503690381}, Best action: 3, Actual action: 3\n",
      "Step: 253\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.701322341906002, 1: -8.086526400505026, 2: -6.6830906021571, 3: -11.601030805741292, 4: -10.743313866144863}, Best action: 2, Actual action: 2\n",
      "Step: 254\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.134249210975918, 1: -7.74695678373588, 2: -6.50938942995839, 3: -7.2758711456631655, 4: -9.088779672541396}, Best action: 2, Actual action: 2\n",
      "Step: 255\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401959376, 1: -7.281147365709926, 2: -6.8779597107529975, 3: -5.749251885563718, 4: -5.797888815467551}, Best action: 3, Actual action: 3\n",
      "Step: 256\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.00153762652068, 1: -7.746950150816455, 2: -6.015271253160408, 3: -6.750609833557619, 4: -9.012665825952547}, Best action: 2, Actual action: 2\n",
      "Step: 257\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401963008, 1: -7.281160052838314, 2: -6.877975373874465, 3: -6.884848846195807, 4: -5.860559199974602}, Best action: 4, Actual action: 4\n",
      "Step: 258\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401957244, 1: -7.281139914305345, 2: -6.877950511488083, 3: -5.59700198677648, 4: -5.76108124358096}, Best action: 3, Actual action: 3\n",
      "Step: 259\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.096491500303352, 1: -7.746954896607084, 2: -5.761892669009485, 3: -7.126429296020696, 4: -9.067124557733788}, Best action: 2, Actual action: 2\n",
      "Step: 260\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4774544019600055, 1: -7.281149561470778, 2: -6.877962421568865, 3: -6.435931878633893, 4: -6.2571332761771465}, Best action: 4, Actual action: 4\n",
      "Step: 261\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477454401962019, 1: -7.281156595637943, 2: -6.877971105725859, 3: -7.249036477840609, 4: -6.618826350037955}, Best action: 0, Actual action: 0\n",
      "Step: 262\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.57880232462085, 1: -6.72970896176658, 2: -8.739747208846884, 3: -7.8828623739896715, 4: -8.089908095238512}, Best action: 1, Actual action: 1\n",
      "Step: 263\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.998809699229323, 1: -7.281166931773817, 2: -6.877983866387432, 3: -8.44382747737385, 4: -7.809318988439424}, Best action: 2, Actual action: 2\n",
      "Step: 264\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.859615989558887, 1: -6.642211518210458, 2: -6.089150022482042, 3: -3.627817707724039, 4: -8.401447321438201}, Best action: 3, Actual action: 3\n",
      "Step: 265\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.466951899726969, 1: -7.281145308350389, 2: -4.526298184308956, 3: -5.944298445994121, 4: -5.318782223021202}, Best action: 2, Actual action: 2\n",
      "Step: 266\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.849492203306159, 1: -6.6421933256623, 2: -6.089127562546043, 3: -4.939425422507051, 4: -8.384135646957029}, Best action: 0, Actual action: 0\n",
      "Step: 267\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147774344, 1: -4.354900074895994, 2: -7.087477468910213, 3: -8.558112881909873, 4: -8.453808646248095}, Best action: 1, Actual action: 1\n",
      "Step: 268\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.912606615422996, 1: -6.642190026375961, 2: -6.089123489353033, 3: -4.703421350954175, 4: -8.38099611033935}, Best action: 3, Actual action: 3\n",
      "Step: 269\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681677885587229, 1: -7.2811624551993654, 2: -6.406139187825676, 3: -7.926364188529393, 4: -7.293717317307822}, Best action: 2, Actual action: 2\n",
      "Step: 270\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.714329138516432, 1: -6.642210496685118, 2: -6.089148761339646, 3: -7.50026601334598, 4: -8.40047525782116}, Best action: 2, Actual action: 2\n",
      "Step: 271\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458918660177954, 1: -5.765703514551413, 2: -9.570420682644281, 3: -5.401487113176827, 4: -5.2894658251470075}, Best action: 0, Actual action: 0\n",
      "Step: 272\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818007185, 1: -6.1494345482806, 2: -7.348080807814626, 3: -6.80630516748804, 4: -11.18315829533259}, Best action: 1, Actual action: 1\n",
      "Step: 273\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3269338501321934, 1: -5.765710848725577, 2: -9.570439797775846, 3: -5.4036672724240775, 4: -5.291417907873972}, Best action: 4, Actual action: 4\n",
      "Step: 274\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.009978678321511, 1: -5.765707913281028, 2: -9.570432147097323, 3: -5.402794681122596, 4: -5.290636602375545}, Best action: 4, Actual action: 4\n",
      "Step: 275\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.353291270009722, 1: -5.765711092831846, 2: -9.570440433992461, 3: -5.403739835541389, 4: -5.715325585614903}, Best action: 3, Actual action: 3\n",
      "Step: 276\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.146250486970453, 1: -6.642204042447314, 2: -6.91299670683815, 3: -6.341684882555672, 4: -8.394333530838844}, Best action: 0, Actual action: 0\n",
      "Step: 277\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147784814, 1: -6.1657166774875805, 2: -7.0993921082123945, 3: -8.566869856359494, 4: -8.455951314482792}, Best action: 1, Actual action: 1\n",
      "Step: 278\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.55070242845483, 1: -6.642208563843202, 2: -7.5157165640553725, 3: -7.153307280007916, 4: -8.398636003100313}, Best action: 0, Actual action: 0\n",
      "Step: 279\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147786105, 1: -7.052606768304358, 2: -7.100861647246576, 3: -8.567949932344062, 4: -8.456215588921014}, Best action: 1, Actual action: 1\n",
      "Step: 280\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3479846288663015, 1: -6.642210914839867, 2: -7.829113667414455, 3: -7.57532773501213, 4: -8.400873165735458}, Best action: 1, Actual action: 1\n",
      "Step: 281\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3802341306662065, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 282\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 283\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380221726516495, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 284\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.406342723216466, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 285\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 286\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.406347693026088, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 287\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.406349811734401, 1: -1.71, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 288\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.406351718571882, 1: -2.439, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 289\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3802305279465115, 1: -4.264860690000001, 2: -3.1541490000000003, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 290\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090188875704016, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 291\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 292\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090190279325044, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 293\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38023440015206, 1: -5.745237425190002, 2: -4.981774599, 3: -2.439, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 294\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380235138899969, 1: -6.027666961671002, 2: -5.330453039100001, 3: -3.0951000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 295\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380235803773087, 1: -6.281853544503902, 2: -5.644263635190001, 3: -3.6855900000000004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 296\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380236348304171, 1: -6.490032355844048, 2: -5.901274513387711, 3: -4.169201310000001, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 297\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380236754578813, 1: -6.64535456698493, 2: -6.093030329611023, 3: -4.530023708391001, 4: -4.29605721}, Best action: 4, Actual action: 4\n",
      "Step: 298\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3802370310446435, 1: -6.751049778444189, 2: -6.223518244992824, 3: -4.775559742272093, 4: -6.0614845429329005}, Best action: 3, Actual action: 3\n",
      "Step: 299\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192552839504, 1: -3.9775240523587536, 2: -2.799412410319448, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 300\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607749644985724, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 301\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 302\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750001767356, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 303\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192254964335, 1: -3.5743077918930726, 2: -2.301614557892681, 3: -2.439, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 304\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192442744142, 1: -3.8284943747259725, 2: -2.6154251539826814, 3: -3.0951000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 305\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192611745968, 1: -4.057262299275583, 2: -2.8978546904636815, 3: -3.6855900000000004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 306\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192750158463, 1: -4.2446232294817134, 2: -3.1291644808416206, 3: -4.169201310000001, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 307\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090192853428026, 1: -4.384413219508508, 2: -3.301744715442601, 3: -4.530023708391001, 4: -4.29605721}, Best action: 2, Actual action: 2\n",
      "Step: 308\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.38023705548762, 1: -6.7603945338803575, 2: -6.235054980099205, 3: -5.616782100782077, 4: -6.26799987512884}, Best action: 3, Actual action: 3\n",
      "Step: 309\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193126156638, 1: -4.753590050641076, 2: -6.295669928694072, 3: -5.482933638594948, 4: -11.147569837347934}, Best action: 1, Actual action: 1\n",
      "Step: 310\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0261787047684985, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 311\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 312\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.671774538826252, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 313\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.499830544605036, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 314\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 315\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.572319425255656, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 316\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712239478241816, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 317\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.141224160575813 -8.16240033400582 -7.26377357532001 -7.10252645649078 -6.815682848286453 \n",
      "-8.086545241153408 -7.51151456104919 -7.281173716656038 -7.745362646307031 -5.765725107125799 \n",
      "0.0 0.0 -5.106806310067834 -5.540564373169003 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -8.141224160575813, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -8.16240033400582, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.26377357532001, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -7.281173716656038, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -5.231993766234354, 2: -5.242004052472521, 3: -5.106806310067834, 4: -8.443178730475317}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: -2.439, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: -3.0951000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: -3.6855900000000004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: -4.169201310000001, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -3.659542263467536, 3: -4.530023708391001, 4: -4.29605721}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -5.231993766234354, 2: -5.242004052472521, 3: -5.4867453603943925, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: -2.439, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: -3.0951000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: -3.6855900000000004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: -4.169201310000001, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -3.0951000000000004, 3: -4.530023708391001, 4: -4.29605721}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.20951, 3: -3.4985996462019164, 4: 3.1199794606709994}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: 0.2549550268291585, 3: -2.868195471960193, 4: 7.652645165209929}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.031922805714645, 3: -3.422154182146172, 4: 2.08089152083471}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.8245500983966103, 3: -3.763354241396831, 4: -2.438201662807976}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9, 3: -0.8171523637412463, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9, 3: -0.2591705345022344, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9, 3: -0.7906115345022345, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -2.821574022514414, 3: -3.9552806775437914, 4: -5.659765273534752}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9, 3: -4.319531744226592, 4: -5.920780812181633}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.562300150279725 -7.31421529364741 -6.946349868917363 -7.10252645649078 -6.815682848286453 \n",
      "-8.086545241153408 -7.51151456104919 -6.639197939871564 -7.745362646307031 -5.765725107125799 \n",
      "0.0 -4.674229233408704 -4.880014830969325 -5.540564373169003 0.0 \n",
      "0.0 0.0 0.9405460786729612 -0.26631916851737397 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -8.086545241153408, 2: -8.181206391538359, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: -1.071, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: -2.61, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: -3.8704409999999996, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -3.768887818940135, 3: -4.810856030099999, 4: -4.29605721}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -4.674229233408704, 2: -5.187088135258053, 3: -5.186519220007359, 4: -9.016322100800362}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -1.9230535807741043, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -1.9230535807741043, 3: -2.439, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -1.9230535807741043, 3: -3.0951000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -1.9230535807741043, 3: -3.6855900000000004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -1.9230535807741043, 3: -4.169201310000001, 4: -2.4561}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: 0.9405460786729612, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.99, 3: -0.26631916851737397, 4: -1.232281834430437}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.0216639186317766, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.99, 3: -1.7541796909434766, 4: -1.232281834430437}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -4.935794618912196, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.562300150279725 -7.31421529364741 -6.946349868917363 -7.10252645649078 -6.815682848286453 \n",
      "-5.292870767351115 -7.51151456104919 -6.639197939871564 -7.745362646307031 -5.765725107125799 \n",
      "-4.76279913334151 -5.186519220007359 -4.880014830969325 -5.540564373169003 0.0 \n",
      "0.0 -2.9993285981900213 -1.610195553435196 -0.999 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -7.31421529364741, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -6.946349868917363, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -6.639197939871564, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -4.880014830969325, 2: -5.242004052472521, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.610195553435196, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.999, 3: -1.3809815960031089, 4: -1.232281834430437}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -4.935794618912196, 2: -4.6953279, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.562300150279725 -4.94845252936474 -4.3802249868917364 -7.10252645649078 -6.815682848286453 \n",
      "-5.292870767351115 -7.51151456104919 -3.7590197939871555 -7.745362646307031 -5.765725107125799 \n",
      "-4.76279913334151 -5.186519220007359 -2.9270014830969324 -5.540564373169003 0.0 \n",
      "0.0 -2.9993285981900213 -1.8710195553435196 -0.9999 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -7.562300150279725, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -4.94845252936474, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -4.3802249868917364, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -3.7590197939871555, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -2.9270014830969324, 2: -5.242004052472521, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.8710195553435196, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.9999, 3: -1.3809815960031089, 4: -1.232281834430437}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -4.935794618912196, 2: -4.6953279, 3: -5.125795109999999, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.451557915027972 -4.711876252936473 -4.123612498689173 -7.10252645649078 -6.815682848286453 \n",
      "-5.292870767351115 -7.51151456104919 -3.4710019793987152 -7.745362646307031 -5.765725107125799 \n",
      "-4.76279913334151 -5.186519220007359 -2.731700148309694 -5.540564373169003 0.0 \n",
      "0.0 -2.9993285981900213 -1.897101955534352 -0.99999 0.0 \n",
      "0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -5.451557915027972, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -4.711876252936473, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -4.123612498689173, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -3.4710019793987152, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -2.731700148309694, 2: -5.242004052472521, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -1.897101955534352, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -0.99999, 3: -1.3809815960031089, 4: -1.232281834430437}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -4.935794618912196, 2: -4.6953279, 3: -5.125795109999999, 4: -5.12579511}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.059549922536142 -6.709403326441806 -6.343712028922429 -7.10252645649078 -6.815682848286453 \n",
      "-5.292870767351115 -7.51151456104919 -5.937489952443773 -7.745362646307031 -5.765725107125799 \n",
      "-4.76279913334151 -5.186519220007359 -5.242004052472521 -5.540564373169003 0.0 \n",
      "0.0 -2.9993285981900213 -3.7399406155620936 -1.232281834430437 0.0 \n",
      "0.0 0.0 0.0 0.0 -4.6953279 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -6.709403326441806, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -6.343712028922429, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -5.937489952443773, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -5.48471418650197, 2: -5.242004052472521, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380237336771895, 1: -6.86793187672439, 2: -6.367817131758507, 3: -5.540564373169003, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -5.48471418650197, 2: -5.912057547514145, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -4.980314830743436, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -4.980314830743436, 3: -3.840906060384323, 4: -3.7399406155620936}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -4.980314830743436, 3: -3.840906060384323, 4: -4.303345960161505}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -2.9993285981900213, 3: -4.815343707883818, 4: -5.751001782634659}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -4.980314830743436, 3: -3.71354677057235, 4: -4.34799440963833}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -3.267673400427025, 2: -4.2079057439826055, 3: -4.815343707883818, 4: -5.751001782634659}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -4.935794618912196, 2: -7.540418738056671, 3: -5.125795109999999, 4: -6.762954717930009}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.059549922536142 -8.01354296691529 -7.792818574304586 -7.10252645649078 -6.815682848286453 \n",
      "-5.292870767351115 -7.51151456104919 -7.479467851426073 -7.745362646307031 -5.765725107125799 \n",
      "-4.76279913334151 -5.186519220007359 -6.078547929013407 -6.367817131758507 0.0 \n",
      "0.0 -4.193588037120782 -4.1198562412187085 -1.232281834430437 0.0 \n",
      "0.0 0.0 0.0 0.0 -4.935794618912196 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -5.292870767351115, 2: -8.181206391538359, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.76279913334151, 2: -5.987317185279907, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: -1.071, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: -2.61, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: -3.8704409999999996, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -3.259730737837884, 3: -4.810856030099999, 4: -4.29605721}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.193588037120782, 1: -5.905812250481354, 2: -5.647906497991517, 3: -4.815343707883818, 4: -5.751001782634659}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -5.701232260436306, 2: -5.187088135258053, 3: -5.186519220007359, 4: -9.016322100800362}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.9033607737393385, 2: -5.987317185279907, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.291999037046123, 1: -4.3503818976486865, 2: -5.982068077434169, 3: -7.458655591967964, 4: -11.600610185127293}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -4.837240382190878, 2: -5.987317185279907, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.247364613279223, 1: -4.3503818976486865, 2: -6.53045375201014, 3: -8.073906480230658, 4: -13.29791868650738}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -2.61, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -3.9951, 2: -1.71, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -5.24169, 2: -2.439, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -5.3538831, 2: -2.50461, 3: -1.071, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -6.363621, 2: -3.0951000000000004, 3: -2.61, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -7.1905963401, 2: -3.5787113100000005, 3: -3.8704409999999996, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.833757664054096, 1: -7.80760264134861, 2: -3.9395337083910005, 3: -4.810856030099999, 4: -4.29605721}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.009528811919782, 1: -5.1382869854043465, 2: -6.374409682738212, 3: -7.898835801548332, 4: -12.814946687703832}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -6.334705051821725, 2: -5.987317185279907, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -5.701232260436306, 2: -5.187088135258053, 3: -6.351183753502625, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -6.741654426442211, 2: -7.250678641558787, 3: -6.078547929013407, 4: -8.443178730475317}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -5.701232260436306, 2: -6.342332636026665, 3: -6.4767088932127646, 4: -9.016322100800362}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.687361260821137, 1: -5.905812250481354, 2: -5.647906497991517, 3: -4.815343707883818, 4: -5.751001782634659}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.102202926136748, 1: -6.004236613134634, 2: -6.834610818848824, 3: -8.415149722386046, 4: -14.239315224079787}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.352983443360904, 1: -10.511699206069354, 2: -5.520876728695529, 3: -8.93232617904184, 4: -15.666063260273946}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: -5.077920428346636, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: -4.2495966138352985, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: -4.416368430831964, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: -4.552954548952234, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630748222696694, 1: -9.97553744423881, 2: -5.207331838736147, 3: -4.654861451681766, 4: -4.29605721}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.562488281037909, 1: -5.905812250481354, 2: -5.647906497991517, 3: -3.9147257142323357, 4: -5.751001782634659}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.039834892715672, 1: -4.30592479427245, 2: -6.826992531421637, 3: -8.406602529554574, 4: -14.215735862663898}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.577591464367062, 1: -9.940934000699256, 2: -3.659684169111645, 3: -8.0623898806573, 4: -13.266147546090107}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3906445535748215, 1: -9.97553744423881, 2: -5.207331838736147, 3: -4.7559539622722165, 4: -6.869671614691578}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.686637126152987, 1: -5.905812250481354, 2: -5.647906497991517, 3: -6.211557894642496, 4: -5.751001782634659}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.1198562412187085, 1: -4.217031, 2: -4.980314830743436, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -6.741654426442211, 2: -7.250678641558787, 3: -6.1131596861421995, 4: -8.443178730475317}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -6.17755876111051, 2: -6.770731596929979, 3: -6.541009279011161, 4: -9.016322100800362}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.739586995603886, 1: -5.905812250481354, 2: -6.735115765578962, 3: -7.998323227440081, 4: -5.751001782634659}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.739538982832019, 1: -5.905812250481354, 2: -6.733389484706937, 3: -7.996703061853423, 4: -5.751001782634659}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.746517198973046, 1: -5.905812250481354, 2: -6.984288580444143, 3: -8.232179273879165, 4: -6.133411622197539}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.61952631666553, 1: -9.97553744423881, 2: -5.207331838736147, 3: -5.023939239448333, 4: -13.69204416788513}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.094644431644326, 1: -10.321536136200029, 2: -7.958191142765952, 3: -8.642487633287653, 4: -14.866478185109967}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.996247791731055, 1: -9.246775092841165, 2: -6.94381885997646, 3: -8.537673609176412, 4: -14.57732503217393}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7725356403016175, 1: -7.484269376845605, 2: -7.91977169961126, 3: -9.110157812096878, 4: -9.143484487813419}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.19055970622104, 2: -7.026303216548128, 3: -6.579369208050011, 4: -9.016322100800362}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.470487337874183, 2: -7.364139576377037, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.74654190366043, 2: -7.096707167462493, 3: -7.532170487438541, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -6.741654426442211, 2: -7.250678641558787, 3: -8.859498878844475, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.00679285329703, 1: -4.217031, 2: -4.980314830743436, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.950934650278242, 1: -9.97553744423881, 2: -5.207331838736147, 3: -5.889044177454174, 4: -14.0984141228882}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -5.1179387893762796, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -1.7100000000000004, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -2.4390000000000005, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -3.0360510000000005, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -3.4815107511000005, 4: -4.29605721}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.888615310593238, 1: -9.97553744423881, 2: -3.2930071960160503, 3: -7.249518403520927, 4: -15.248189819792513}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6855900000000004, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -4.178828740682312, 4: -5.376545307185502}, Best action: 0, Actual action: 0\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.718161562452189, 1: -4.901680254975563, 2: -4.980314830743436, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.238920006530207, 1: -9.103617893331702, 2: -4.6974373645214635, 3: -7.001071068256882, 4: -11.080403456520706}, Best action: 2, Actual action: 2\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.320107584726272, 1: -9.103617893331702, 2: -1.369743736452146, 3: -3.3803799668684125, 4: -3.762850231873168}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: -2.009492426526238, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: -0.24508002106237226, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: -0.9740800210623723, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: -1.5711310210623726, 4: -2.4561}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.447347143062795, 1: -9.103617893331702, 2: -2.2467192305101844, 3: -4.778683676799751, 4: -6.58887474904914}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.71, 1: -7.907569126655282, 2: -3.997993641318879, 3: -3.6587529791120086, 4: -5.592914289946543}, Best action: 0, Actual action: 0\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -4.4228930391, 3: -1.3809815960031089, 4: -1.232281834430437}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -4.4228930391, 3: -1.3809815960031089, 4: -1.232281834430437}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -4.4228930391, 3: -1.3809815960031089, 4: -2.0213764693316976}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7460448472583865, 1: -3.6472042077103635, 2: -4.980314830743436, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 1, Actual action: 1\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.66396606682661, 1: -9.103617893331702, 2: -7.267578011831983, 3: -6.2878595587942545, 4: -9.638976106111661}, Best action: 0, Actual action: 0\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.815014551148755, 1: -5.313448667870906, 2: -4.980314830743436, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -2.439, 2: -4.4228930391, 3: -4.955585706192664, 4: -8.512726411447419}, Best action: 1, Actual action: 1\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.692835713244196, 1: -7.907569126655282, 2: -3.997993641318879, 3: -5.8460721868168, 4: -8.947145720255431}, Best action: 2, Actual action: 2\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -6.228229878469202, 2: -7.977875160843997, 3: -5.125795109999999, 4: -6.762954717930009}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.059549922536142 -8.01354296691529 -7.792818574304586 -7.10252645649078 -6.815682848286453 \n",
      "-5.901192304082391 -7.51151456104919 -7.479467851426073 -7.745362646307031 -5.765725107125799 \n",
      "-6.7934318489428955 -6.433602744786017 -6.070824858392468 -6.367817131758507 0.0 \n",
      "-7.535131367854047 -7.27808483645529 -5.571065654745343 -4.4228930391 0.0 \n",
      "-7.810490893911743 -6.42693257256861 -6.183471087311281 -4.551693403231887 -5.125795109999999 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -7.059549922536142, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -8.01354296691529, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.792818574304586, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479467851426073, 1: -7.547579407924755, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.737650817085577, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9154439469819255, 1: -7.547579407924755, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -6.070824858392468, 2: -7.250678641558787, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -6.721623160986153, 2: -5.571065654745343, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -4.4228930391, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -2.22518930391, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -5.692109704845741, 3: -2.7024033361671003, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -1.2663809303856377, 3: -0.11425785402668875, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -2.512970930385638, 3: -0.8432578540266888, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -1.8111931008775877, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -4.711816138447389, 3: -3.230075790591104, 4: -4.251387300810473}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -4.580170418803874, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -3.803215599, 2: -6.114887355062336, 3: -6.078395256665816, 4: -6.389889383747444}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -6.2282941665037646, 2: -7.977875160843997, 3: -7.144497832208161, 4: -6.762954717930009}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.293864549428798 -7.121253804663955 -5.161099975867003 -7.10252645649078 -6.815682848286453 \n",
      "-5.901192304082391 -7.51151456104919 -6.062240081681363 -7.745362646307031 -5.765725107125799 \n",
      "-6.7934318489428955 -6.433602744786017 -5.504284864604678 -6.367817131758507 0.0 \n",
      "-7.535131367854047 -7.27808483645529 -4.9984425418805705 -4.880604635189999 -5.425239834768049 \n",
      "-7.810490893911743 -6.42693257256861 -6.183471087311281 -4.551693403231887 -6.2282941665037646 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -5.901192304082391, 2: -8.181206391538359, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.481824099335323, 2: -6.7934318489428955, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.473591408411188, 2: -6.433602744786017, 3: -6.992030698960163, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -5.504284864604678, 2: -7.250678641558787, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -6.721623160986153, 2: -4.9984425418805705, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -6.052294976551808, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 1, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -5.425239834768049, 2: -6.118708306133698, 3: -6.088239980284445, 4: -6.395713116518913}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -7.653545171903841, 2: -7.977875160843997, 3: -7.3416981124576655, 4: -6.762954717930009}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.293864549428798 -7.121253804663955 -5.161099975867003 -7.10252645649078 -6.815682848286453 \n",
      "-7.718380479191908 -7.51151456104919 -6.062240081681363 -7.745362646307031 -5.765725107125799 \n",
      "-7.407420817466627 -6.992030698960163 -6.982885617850959 -6.367817131758507 0.0 \n",
      "-7.535131367854047 -7.27808483645529 -6.647018844621936 -4.880604635189999 -5.750391520689511 \n",
      "-7.810490893911743 -6.42693257256861 -6.183471087311281 -4.551693403231887 -6.762954717930009 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -7.293864549428798, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -7.121253804663955, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -5.161099975867003, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.439180745602392, 1: -6.062240081681363, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -6.982885617850959, 2: -7.250678641558787, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -6.721623160986153, 2: -6.647018844621936, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -4.880604635189999, 2: -6.435423487026157, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860647641281204, 1: -7.907569126655282, 2: -4.551693403231887, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.97335996079993, 1: -7.9382645405556795, 2: -7.977875160843997, 3: -7.3416981124576655, 4: -7.565509865851172}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.12633688092901 -7.930959187117651 -7.537036449421428 -7.10252645649078 -6.815682848286453 \n",
      "-7.718380479191908 -7.51151456104919 -6.439180745602392 -7.745362646307031 -5.765725107125799 \n",
      "-7.407420817466627 -6.992030698960163 -7.090193018506712 -6.367817131758507 0.0 \n",
      "-7.535131367854047 -7.27808483645529 -6.721623160986153 -5.386243056890054 -5.750391520689511 \n",
      "-7.810490893911743 -6.42693257256861 -6.183471087311281 -5.860647641281204 -6.97335996079993 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -8.12633688092901, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -7.930959187117651, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.537036449421428, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.439180745602392, 1: -7.407253399095612, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -6.86944004888008, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1081645141531045, 1: -7.407253399095612, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.350690492077738, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.9726044832675145, 1: -7.407253399095612, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090193018506712, 1: -7.254987885037847, 2: -7.250678641558787, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.181342355666523, 1: -7.383781684899998, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -7.655492636069306, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147282517691302, 1: -7.879568398625834, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.645679478729003, 1: -7.254987885037847, 2: -7.250678641558787, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380237336771895, 1: -6.86793187672439, 2: -6.367817131758507, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: -2.4561}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: -4.29605721}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.40636123013977, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: -6.0614845429329005}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.866487269083704, 1: -5.765725107125799, 2: -9.570476959587127, 3: -7.566215103627103, 4: -9.66291355135573}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.110873459785874, 1: -6.075352368620561, 2: -10.37746159174083, 3: -5.442375199848438, 4: -7.936538752377969}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380237336771895, 1: -6.86793187672439, 2: -4.169310474248513, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.715120725168426, 1: -6.075352368620561, 2: -10.37746159174083, 3: -4.82137900412614, 4: -6.477956431199253}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380237336771895, 1: -6.86793187672439, 2: -5.6966539752125405, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.741617472917319, 1: -6.075352368620561, 2: -10.37746159174083, 3: -6.215952940598001, 4: -10.261202579735096}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.750391520689511, 1: -6.020517305000112, 2: -6.118708306133698, 3: -6.088239980284445, 4: -6.395713116518913}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1148027205647635, 1: -6.16535236862056, 2: -10.37746159174083, 3: -7.245468712952633, 4: -11.63661039661204}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.468974570651605, 1: -6.020517305000112, 2: -6.118708306133698, 3: -6.088239980284445, 4: -6.395713116518913}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.6679500658655035, 1: -7.9382645405556795, 2: -7.977875160843997, 3: -7.3416981124576655, 4: -8.233550855180518}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.585409405687585 -7.318402271594745 -3.4641273295166037 -7.10252645649078 -6.815682848286453 \n",
      "-7.718380479191908 -7.51151456104919 -4.625183321950653 -7.745362646307031 -7.321069784348137 \n",
      "-7.407420817466627 -6.992030698960163 -5.422569289233701 -6.380237336771895 -7.031500737960892 \n",
      "-7.535131367854047 -7.27808483645529 -6.721623160986153 -5.386243056890054 -6.088239980284445 \n",
      "-7.810490893911743 -6.42693257256861 -6.183471087311281 -5.860647641281204 -7.3416981124576655 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -7.585409405687585, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -7.318402271594745, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -3.4641273295166037, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.672093282707489, 1: -4.625183321950653, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.211301800363012, 1: -7.254987885037847, 2: -5.422569289233701, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380237336771895, 1: -6.86793187672439, 2: -8.62169740369971, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -7.745362646307031, 2: -8.187468612377412, 3: -8.057888407415664, 4: -8.403431256682692}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.811767477185885, 1: -6.86793187672439, 2: -8.62169740369971, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -6.471639874942149, 2: -6.435423487026157, 3: -5.386243056890054, 4: -9.249150481139955}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -6.721623160986153, 2: -6.949923354743028, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.183471087311281, 1: -9.103617893331702, 2: -9.159574691113797, 3: -6.727373328763125, 4: -10.527250005942374}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -6.5807738968207525, 2: -6.949923354743028, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.848773965155937, 1: -9.103617893331702, 2: -9.159574691113797, 3: -6.727373328763125, 4: -10.527250005942374}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -6.42693257256861, 3: -7.712908704328054, 4: -15.639814222402155}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.789051771644639, 1: -9.103617893331702, 2: -9.159574691113797, 3: -6.778552716656887, 4: -10.527250005942374}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -7.0333209577489395, 3: -7.712908704328054, 4: -15.639814222402155}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.234466784080809, 1: -9.103617893331702, 2: -9.159574691113797, 3: -7.333565732527955, 4: -10.527250005942374}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -8.460853204598848, 2: -6.949923354743028, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -6.471639874942149, 2: -6.435423487026157, 3: -7.721854877826964, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -6.118708306133698, 3: -6.088239980284445, 4: -6.395713116518913}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -6.471639874942149, 2: -6.475016732733017, 3: -7.6805542754874345, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.860647641281204, 1: -7.907569126655282, 2: -6.103590908571132, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -6.29428857693199, 2: -6.927713266147214, 3: -7.838399796596975, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.584438511443032, 1: -7.907569126655282, 2: -6.103590908571132, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.69283414191521, 1: -7.9382645405556795, 2: -7.977875160843997, 3: -9.110653013115174, 4: -8.233550855180518}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.91420566578253 -8.166179496883794 -7.885200248783926 -7.10252645649078 -6.815682848286453 \n",
      "-7.718380479191908 -7.51151456104919 -4.672093282707489 -8.057888407415664 -7.321069784348137 \n",
      "-7.407420817466627 -6.992030698960163 -6.211301800363012 -7.027921144329714 -7.031500737960892 \n",
      "-7.535131367854047 -7.27808483645529 -7.697267718181374 -6.631035418582657 -6.118708306133698 \n",
      "-7.810490893911743 -7.712908704328054 -8.44582902887155 -6.815689700290718 -7.69283414191521 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.91420566578253, 2: -9.131149776441193, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -7.718380479191908, 2: -8.181206391538359, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.481824099335323, 2: -7.599633461320588, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.481824099335323, 2: -7.599633461320588, 3: -7.407420817466627, 4: -11.459267490648672}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.481824099335323, 2: -7.599633461320588, 3: -7.640752943894631, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.042850584822375, 1: -9.49463758241095, 2: -7.535131367854047, 3: -8.544060263319365, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.27808483645529, 1: -7.911186322350908, 2: -8.146652868047546, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.473591408411188, 2: -7.3325716927300455, 3: -6.992030698960163, 4: -9.016322100800362}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -7.774653751521297, 2: -7.599633461320588, 3: -8.300331403949889, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.473591408411188, 2: -7.3325716927300455, 3: -7.754906173565693, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.211301800363012, 1: -7.254987885037847, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.672093282707489, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -7.885200248783926, 4: -8.089912755379236}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.166179496883794, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.51151456104919, 1: -7.746975639442247, 2: -9.93495931656476, 3: -8.769055735425063, 4: -9.30515201936128}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -7.800944744138223, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.969916698856881, 1: -7.746975639442247, 2: -9.93495931656476, 3: -8.769055735425063, 4: -9.30515201936128}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.607750710491391, 1: -8.473591408411188, 2: -8.56607696940156, 3: -8.75378710800015, 4: -9.016322100800362}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.847421538796516, 1: -7.836975639442252, 2: -9.93495931656476, 3: -8.769055735425063, 4: -9.30515201936128}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.008725338997364, 1: -8.473591408411188, 2: -8.781730120015316, 3: -8.928466159997292, 4: -9.016322100800362}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.145636942977369, 1: -8.214142805097627, 2: -9.93495931656476, 3: -8.769055735425063, 4: -9.30515201936128}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.90276365278381, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.277236905616755, 1: -9.59830162389037, 2: -9.93495931656476, 3: -8.769055735425063, 4: -9.30515201936128}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -9.246353024645451, 2: -8.181206391538359, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.975770706343389, 1: -8.352364238934186, 2: -9.93495931656476, 3: -8.403682750688576, 4: -9.30515201936128}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -7.719097307005835, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.926632888018014, 1: -8.32734198987553, 2: -9.93495931656476, 3: -8.382612110551811, 4: -9.30515201936128}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -8.607926446029806, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.87427376634184, 1: -8.741701944027728, 2: -9.93495931656476, 3: -8.731534761771599, 4: -9.30515201936128}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.326106368197149, 1: -9.24675116533395, 2: -8.591219352368116, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.405691754911391, 2: -9.131149776441193, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -10.189476937450829, 2: -9.034738933684402, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -8.744630174096756, 4: -8.089912755379236}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -8.652983569886532, 4: -8.089912755379236}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -8.673883551432471, 4: -8.261820607395105}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -8.691000636318597, 4: -8.559049283530541}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.57185574020158, 2: -8.750370199676533, 3: -8.703771693352135, 4: -8.910497163277443}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.47687744918202, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.623456307857595, 2: -8.750370199676533, 3: -8.692267264078026, 4: -8.46410194151768}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.73451532994814, 2: -8.750370199676533, 3: -8.701126047241784, 4: -8.807840720790129}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.605608986193142, 2: -8.722664420772713, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.848461471651238, 2: -8.750370199676533, 3: -8.843347125069377, 4: -9.301189672991562}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -7.10252645649078, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -7.86760925562461, 2: -7.348080807846914, 3: -6.815682848286453, 4: -11.193230508696814}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -7.130955752761105, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -7.86760925562461, 2: -7.348080807846914, 3: -7.3576424445651405, 4: -11.193230508696814}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -7.86760925562461, 2: -7.348080807846914, 3: -7.353230648061883, 4: -11.193230508696814}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -7.86760925562461, 2: -7.5867535351406925, 3: -7.546555557169843, 4: -11.193230508696814}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -8.269333360040067, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -7.86760925562461, 2: -9.10911446495514, 3: -8.815784491948733, 4: -11.193230508696814}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.866487269083704, 1: -7.321069784348137, 2: -9.570476959587127, 3: -7.566215103627103, 4: -9.66291355135573}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.510683669285978, 1: -7.031500737960892, 2: -10.37746159174083, 3: -8.33759570149919, 4: -13.095665262409458}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -6.118708306133698, 3: -7.3648201963201485, 4: -6.395713116518913}, Best action: 2, Actual action: 2\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -6.118708306133698, 3: -7.3648201963201485, 4: -6.395713116518913}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -6.468024558581665, 3: -7.3648201963201485, 4: -6.395713116518913}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -6.960705049729626, 3: -7.3648201963201485, 4: -6.395713116518913}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -6.54882720159072, 2: -7.5154048010973655, 3: -7.3648201963201485, 4: -6.720098936032212}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35172016118609, 1: -7.9382645405556795, 2: -7.977875160843997, 3: -9.169517763530953, 4: -8.233550855180518}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.787397996545485 -8.324103677053674 -8.289928655918258 -7.669207651148024 -7.790933396850514 \n",
      "-8.705032917197897 -8.912223167431616 -8.491734285483384 -8.057888407415664 -7.566215103627103 \n",
      "-7.985050267948228 -8.473591408411188 -7.254987885037847 -7.027921144329714 -7.510683669285978 \n",
      "-8.042850584822375 -7.911186322350908 -7.697267718181374 -6.631035418582657 -6.578080240230059 \n",
      "-7.810490893911743 -7.712908704328054 -8.44582902887155 -6.815689700290718 -7.9382645405556795 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.819465353830944, 1: -9.257959194025764, 2: -8.705032917197897, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -8.912223167431616, 2: -9.93495931656476, 3: -9.067870895200443, 4: -9.30515201936128}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.79247018603513, 1: -8.473591408411188, 2: -8.934637144933847, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -7.911186322350908, 2: -8.146652868047546, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -8.829688978352184, 3: -7.712908704328054, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.810490893911743, 1: -10.459590020133016, 2: -9.486729832898945, 3: -8.852903551490643, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.042850584822375, 1: -9.49463758241095, 2: -9.229538538816488, 3: -8.544060263319365, 4: -14.594944059759277}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.985050267948228, 1: -9.276605271761506, 2: -9.041205324226816, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.819465353830944, 1: -9.257959194025764, 2: -9.00313350227322, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.42892959807417, 2: -8.787397996545485, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.4746198666831, 2: -8.324103677053674, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -8.289928655918258, 3: -8.530435091437235, 4: -8.367812337571953}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -7.669207651148024, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -8.196114669890733, 2: -8.050908213751738, 3: -7.790933396850514, 4: -11.193230508696814}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -7.977576816563719, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -8.196114669890733, 2: -8.050908213751738, 3: -8.140930561101664, 4: -11.193230508696814}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -8.196114669890733, 2: -8.050908213751738, 3: -8.10305749477098, 4: -11.193230508696814}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -8.196114669890733, 2: -8.226326474514082, 3: -8.245146285988477, 4: -11.193230508696814}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.866487269083704, 1: -7.964722249910673, 2: -9.570476959587127, 3: -7.566215103627103, 4: -9.66291355135573}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -8.187468612377412, 3: -8.057888407415664, 4: -8.403431256682692}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.491734285483384, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -9.003198847561398, 3: -8.530435091437235, 4: -8.367812337571953}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -9.016900800878075, 3: -8.530435091437235, 4: -8.367812337571953}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -9.068120579205804, 3: -8.530435091437235, 4: -8.514709227190478}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -9.110069577656214, 3: -8.530435091437235, 4: -8.768693949340907}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.4746198666831, 2: -9.164492355547418, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.632884351948022, 2: -9.251027440304647, 3: -9.176282317137133, 4: -10.121228859594362}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.843039098331595, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.890305985951636, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.590786302202414}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.950968014830107, 1: -8.60189945136164, 2: -8.979720360251234, 3: -9.228116336284526, 4: -8.717615535004196}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -7.254987885037847, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -9.130792567138569, 2: -7.877349256090584, 3: -7.697267718181374, 4: -8.42415579743283}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -9.486622885119564, 2: -8.146652868047546, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8362769777311945, 1: -9.130792567138569, 2: -7.877349256090584, 3: -8.26851559493665, 4: -8.42415579743283}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.305880113593222, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.41139058978363, 1: -9.130792567138569, 2: -7.877349256090584, 3: -8.658214714346652, 4: -8.42415579743283}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.631035418582657, 1: -7.410772195426869, 2: -7.623938927165149, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -8.375074119186802, 2: -8.62169740369971, 3: -7.027921144329714, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -7.3959436632833935, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.060126557351268, 1: -9.130792567138569, 2: -8.079213563089294, 3: -8.37369084807644, 4: -8.42415579743283}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.408047441244129, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.723832208175908, 1: -9.130792567138569, 2: -8.438677875114694, 3: -8.609535383196304, 4: -8.42415579743283}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.071466573569529, 1: -9.130792567138569, 2: -8.15919137000921, 3: -8.426164287196597, 4: -8.42415579743283}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -7.486093419345981, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5967562471381, 1: -9.130792567138569, 2: -8.015788163697426, 3: -8.332077443535434, 4: -8.15431736511055}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.929334293414355, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.635521377018364, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.443178730475317}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.971583007014749, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.58329264473254}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.246817481981788, 2: -8.586013727997342, 3: -8.625706656516275, 4: -8.825549602483276}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -8.375074119186802, 2: -8.62169740369971, 3: -7.855156178022873, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.262634877203801, 2: -8.121277876998262, 3: -8.625706656516275, 4: -7.452702115766774}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.259964843644653, 2: -8.11975083307911, 3: -8.625706656516275, 4: -7.448977655647961}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.585132232036623, 2: -8.305720361982374, 3: -8.625706656516275, 4: -8.132149347634703}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.79941013042215, 2: -8.42827004328406, 3: -8.625706656516275, 4: -8.750450481883984}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -8.375074119186802, 2: -8.62169740369971, 3: -8.007919349666805, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.514092954053227, 2: -8.153754977408394, 3: -8.625706656516275, 4: -7.678455082911036}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.511056430302501, 2: -8.149077304111795, 3: -8.625706656516275, 4: -7.6670462377406325}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.686651128512306, 2: -8.419575643090383, 3: -8.625706656516275, 4: -8.53675752511275}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -8.375074119186802, 2: -8.62169740369971, 3: -8.29291069617727, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.715186906341495, 2: -8.4647987912463, 3: -8.625706656516275, 4: -8.716006405730672}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -8.375074119186802, 2: -8.62169740369971, 3: -8.92191742674807, 4: -8.644531848876344}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933826092995956, 1: -7.410772195426869, 2: -7.623938927165149, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.815689700290718, 1: -7.907569126655282, 2: -6.841554745808433, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.86531238853021, 1: -7.161785876778168, 2: -7.623938927165149, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.382615530219388, 1: -7.907569126655282, 2: -6.841554745808433, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619508668956172, 2: -7.977875160843997, 3: -9.169517763530953, 4: -8.233550855180518}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-9.379728491542146 -9.111418132494657 -8.99049077992289 -8.456514979762305 -9.018521310859553 \n",
      "-9.257959194025764 -9.067870895200443 -8.789765878525186 -8.187468612377412 -7.866487269083704 \n",
      "-9.041205324226816 -8.79247018603513 -6.609484876903901 -7.1769138633998715 -7.510683669285978 \n",
      "-8.544060263319365 -8.346319516419326 -8.180910046229545 -7.330026467165956 -6.578080240230059 \n",
      "-8.852903551490643 -8.829688978352184 -8.44582902887155 -7.146234354864481 -7.977875160843997 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.4746198666831, 2: -9.111418132494657, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.99049077992289, 2: -9.212929522243176, 3: -9.026400613559897, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.033085816020986, 1: -8.789765878525186, 2: -8.979720360251234, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -6.609484876903901, 3: -8.625706656516275, 4: -6.727998254484488}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -7.837613331958194, 2: -8.62169740369971, 3: -7.1769138633998715, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.374248717044286, 3: -8.625706656516275, 4: -6.727998254484488}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.275659215209582, 3: -8.625706656516275, 4: -6.727998254484488}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.514188142457662, 3: -8.625706656516275, 4: -7.0224784115808845}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.709543333873841, 3: -8.625706656516275, 4: -7.531634603200554}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.855297842189451, 3: -8.625706656516275, 4: -8.133668923479938}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -7.837613331958194, 2: -8.62169740369971, 3: -7.67368006926428, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.938457372333097, 3: -8.625706656516275, 4: -8.172591410803548}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -7.837613331958194, 2: -8.62169740369971, 3: -8.305680250878325, 4: -8.644531848876344}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890954757705434, 1: -7.330026467165956, 2: -7.623938927165149, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.212563933040816, 1: -7.907569126655282, 2: -7.146234354864481, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -8.598693214110781, 3: -9.169517763530953, 4: -8.233550855180518}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-9.379728491542146 -8.633162125578622 -8.479071647246903 -8.456514979762305 -9.018521310859553 \n",
      "-9.257959194025764 -9.067870895200443 -8.30122388702431 -8.187468612377412 -7.866487269083704 \n",
      "-9.041205324226816 -8.79247018603513 -7.751628170352845 -7.865832740765444 -7.510683669285978 \n",
      "-8.544060263319365 -8.346319516419326 -8.180910046229545 -7.623938927165149 -6.578080240230059 \n",
      "-8.852903551490643 -8.829688978352184 -8.44582902887155 -7.212563933040816 -8.233550855180518 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.42892959807417, 2: -9.379728491542146, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.4746198666831, 2: -8.633162125578622, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -8.479071647246903, 2: -9.212929522243176, 3: -9.026400613559897, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.033085816020986, 1: -8.30122388702431, 2: -8.979720360251234, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -7.751628170352845, 3: -8.625706656516275, 4: -8.439964024425763}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -7.895794049279757, 2: -8.62169740369971, 3: -7.865832740765444, 4: -8.644531848876344}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -8.046487337055295, 3: -8.625706656516275, 4: -8.439964024425763}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -7.895794049279757, 2: -8.62169740369971, 3: -8.204238017091335, 4: -8.644531848876344}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890954757705434, 1: -7.635261220143192, 2: -7.623938927165149, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.578080240230059, 1: -7.084876998009173, 2: -8.498680839049324, 3: -7.3648201963201485, 4: -7.9340199705408025}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.510683669285978, 1: -7.739389264324821, 2: -10.37746159174083, 3: -8.33759570149919, 4: -13.095665262409458}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.866487269083704, 1: -7.964722249910673, 2: -9.570476959587127, 3: -9.09559054421556, 4: -9.66291355135573}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -9.224683597456638, 2: -10.241981546194536, 3: -9.018521310859553, 4: -11.193230508696814}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -10.057506772236177, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -10.057506772236177, 3: -8.56917352725493, 4: -8.456514979762305}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -10.057506772236177, 3: -8.56917352725493, 4: -8.5954286315837}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.305427537242936, 2: -9.212929522243176, 3: -9.026400613559897, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.4746198666831, 2: -9.489269098236035, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.067870895200443, 4: -9.30515201936128}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.432836358081934, 1: -9.257959194025764, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.276605271761506, 2: -9.041205324226816, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.79247018603513, 1: -9.608683579106009, 2: -8.934637144933847, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.114526778577694, 4: -9.30515201936128}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.432836358081934, 1: -9.344836938827404, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.276605271761506, 2: -9.277877468465741, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -8.544060263319365, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -8.544060263319365, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -8.675094839620622, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -8.901653622045496, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -9.169540303628601, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.229538538816488, 3: -9.426575884252514, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -9.525923563640532, 2: -8.346319516419326, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.180910046229545, 1: -9.130792567138569, 2: -8.192801019871512, 3: -8.448215578471249, 4: -8.487398283169345}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -8.398703150733, 2: -10.515868232704962, 3: -8.625706656516275, 4: -8.439964024425763}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.521040556716684, 1: -9.130792567138569, 2: -8.192801019871512, 3: -8.448215578471249, 4: -8.487398283169345}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890954757705434, 1: -7.635261220143192, 2: -9.432315006554626, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.212563933040816, 1: -7.907569126655282, 2: -7.383799628182667, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890954757705434, 1: -7.505702907777381, 2: -9.406111325854024, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70087574860376, 1: -7.907569126655282, 2: -7.383799628182667, 3: -7.3505606734899, 4: -11.254263287166063}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.44582902887155, 1: -9.103617893331702, 2: -9.159574691113797, 3: -8.946151420651479, 4: -10.527250005942374}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.91551333520117, 1: -9.130792567138569, 2: -8.704986682947915, 3: -8.448215578471249, 4: -8.487398283169345}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -9.525923563640532, 2: -9.083355955316394, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.26491896137859, 1: -9.130792567138569, 2: -9.136351653537321, 3: -9.102339881653403, 4: -8.487398283169345}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.021500036747913, 1: -9.130792567138569, 2: -8.835834462635251, 3: -8.536863768779028, 4: -8.487398283169345}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.068967081388452, 1: -9.130792567138569, 2: -8.894435752314928, 3: -8.647132433935983, 4: -8.623532437684105}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.107842590949053, 1: -9.130792567138569, 2: -8.942430208562584, 3: -8.737442470699529, 4: -8.858908390840122}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -9.525923563640532, 2: -8.794205181008245, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.148983272039521, 1: -9.130792567138569, 2: -8.993221172871806, 3: -8.99007709020934, 4: -9.253666131635667}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.145614485902282, 1: -9.525923563640532, 2: -9.18844364775268, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 0, Actual action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.057910306016046, 1: -9.608683579106009, 2: -8.934637144933847, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.120919163170672, 2: -10.631658968116733, 3: -8.625706656516275, 4: -8.439964024425763}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.064438631466796, 2: -10.62571433432022, 3: -8.625706656516275, 4: -8.439964024425763}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.087853934547198, 2: -10.628178818946129, 3: -8.625706656516275, 4: -8.580367262227444}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.107031067770047, 2: -10.630197231854748, 3: -8.625706656516275, 4: -8.823124460386552}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.046462185380747, 1: -9.608683579106009, 2: -8.820330280030063, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.733774597437238, 1: -9.133941217304372, 2: -10.63302955264857, 3: -8.90703819247598, 4: -9.362980199428344}, Best action: 0, Actual action: 0\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.033085816020986, 1: -9.46691423721311, 2: -8.979720360251234, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -8.187468612377412, 3: -9.071309989466954, 4: -8.403431256682692}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.405337749008542, 1: -7.964722249910673, 2: -9.570476959587127, 3: -9.09559054421556, 4: -9.66291355135573}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.407766204992134, 1: -7.739389264324821, 2: -10.37746159174083, 3: -8.33759570149919, 4: -13.095665262409458}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.348839830681978, 1: -7.084876998009173, 2: -8.498680839049324, 3: -7.3648201963201485, 4: -7.9340199705408025}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -8.647605797180638, 3: -9.169517763530953, 4: -9.583932316978844}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-9.42892959807417 -9.404066793456023 -9.212929522243176 -8.990489365699734 -9.224683597456638 \n",
      "-9.091487716132104 -9.17969602072466 -8.588764308484597 -8.364071608414937 -8.180166388521284 \n",
      "-9.108226644522565 -8.742673547771993 -8.69509050495725 -8.575531288203825 -7.978043552577168 \n",
      "-9.395179732632725 -9.027241371544333 -9.014869004214061 -7.890954757705434 -7.3648201963201485 \n",
      "-8.852903551490643 -8.829688978352184 -8.946151420651479 -7.383799628182667 -8.647605797180638 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.404066793456023, 2: -9.568986803774013, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.17969602072466, 4: -9.30515201936128}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.432836358081934, 1: -9.091487716132104, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.108226644522565, 2: -9.158722462172625, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.395179732632725, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.027241371544333, 1: -9.525923563640532, 2: -9.070874830009762, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.051026940547901, 1: -9.608683579106009, 2: -8.742673547771993, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.69509050495725, 1: -9.11590032707752, 2: -10.631130730478763, 3: -8.758647119472625, 4: -9.001054372373163}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.033085816020986, 1: -9.46675274822855, 2: -8.588764308484597, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -8.364071608414937, 3: -9.071309989466954, 4: -8.403431256682692}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.406724995072429, 1: -8.180166388521284, 2: -9.570476959587127, 3: -9.09559054421556, 4: -9.66291355135573}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.40913700827625, 1: -7.978043552577168, 2: -10.37746159174083, 3: -8.33759570149919, 4: -13.095665262409458}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.350069801235893, 1: -7.713048395517235, 2: -8.498680839049324, 3: -7.3648201963201485, 4: -7.9340199705408025}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.890954757705434, 1: -10.011158817814001, 2: -9.485429492208116, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.575531288203825, 1: -9.540311444470415, 2: -8.62169740369971, 3: -9.33797877966434, 4: -8.644531848876344}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -9.079386084175823, 3: -9.071309989466954, 4: -8.403431256682692}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -9.07277328027593, 3: -9.071309989466954, 4: -8.403431256682692}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -9.149136668332487, 3: -9.071309989466954, 4: -8.54712244358125}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -8.593989102993635, 2: -9.211678283150807, 3: -9.071309989466954, 4: -8.795564505728859}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.759564042023, 1: -9.540311444470415, 2: -8.62169740369971, 3: -9.33797877966434, 4: -8.644531848876344}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.40913700827625, 1: -9.068629233197724, 2: -10.37746159174083, 3: -8.33759570149919, 4: -13.095665262409458}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.794676594076677, 1: -9.540311444470415, 2: -8.515622258584315, 3: -9.33797877966434, 4: -8.644531848876344}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.40913700827625, 1: -9.136798435189968, 2: -10.37746159174083, 3: -8.631413599603215, 4: -13.095665262409458}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.945749930355404, 1: -9.540311444470415, 2: -8.760858765612051, 3: -9.33797877966434, 4: -8.644531848876344}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.007044433910071, 1: -9.540311444470415, 2: -8.992813125830459, 3: -9.33797877966434, 4: -8.644531848876344}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.054306685963974, 1: -9.540311444470415, 2: -9.171665792903076, 3: -9.33797877966434, 4: -8.766523982477475}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.09301447039612, 1: -9.540311444470415, 2: -9.318146127235547, 3: -9.33797877966434, 4: -8.977448381473826}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.121894348360945, 1: -9.540311444470415, 2: -9.427435104681004, 3: -9.33797877966434, 4: -9.226848721232361}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -9.139595840442237, 2: -9.399434814002543, 3: -9.071309989466954, 4: -9.97758298887464}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.033085816020986, 1: -9.46675274822855, 2: -9.47127194176398, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.520874488298194, 2: -9.212929522243176, 3: -9.413584387464933, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -8.990489365699734, 2: -10.057506772236177, 3: -9.416767246223545, 4: -10.244588989457231}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.091368262020588, 1: -9.216348141747574, 2: -9.429170228106132, 3: -9.244791071782293, 4: -10.16478185175836}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -9.16305722880665, 2: -10.057506772236177, 3: -9.416767246223545, 4: -10.244588989457231}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.231213181535445, 1: -9.292204609173718, 2: -9.45855857781018, 3: -9.462345295680933, 4: -10.349795775810724}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -9.320152439592372, 2: -10.057506772236177, 3: -9.416767246223545, 4: -10.244588989457231}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.4770733337701, 1: -9.319337980357322, 2: -9.46907060174235, 3: -9.540163044251285, 4: -10.415974068127536}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.63136408735339, 1: -9.540311444470415, 2: -9.805028328672599, 3: -9.33797877966434, 4: -10.441817858023887}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.569857814431336, 1: -9.11590032707752, 2: -10.631130730478763, 3: -8.758647119472625, 4: -9.001054372373163}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.051026940547901, 1: -9.608683579106009, 2: -9.588951238138549, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.051026940547901, 1: -9.608683579106009, 2: -9.599954082865237, 3: -9.052320850181296, 4: -9.016322100800362}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.051026940547901, 1: -9.608683579106009, 2: -9.602689970363594, 3: -9.052320850181296, 4: -9.10485311172833}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.758212939985308, 4: -9.30515201936128}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.76251785572324, 4: -9.30515201936128}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.763349763523017, 4: -9.367688337618764}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448525337760776, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.764031096011035, 4: -9.475813631885956}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.802105177729432, 2: -9.568986803774013, 3: -9.561094731859674, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.42892959807417, 2: -9.673076381248759, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.432836358081934, 1: -9.739268379929632, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.483490409853784, 2: -9.673076381248759, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.524910867789758, 1: -9.740467845376742, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.576232975522936, 2: -9.673076381248759, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.674457542019574, 1: -9.741014856997662, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.707751080754916, 2: -9.673076381248759, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804335039338756, 2: -9.568986803774013, 3: -9.688506757825488, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.520874488298194, 2: -9.610630600934572, 3: -9.413584387464933, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.803834346401288, 2: -9.481902034223998, 3: -9.624766174843424, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.520874488298194, 2: -9.611445691106814, 3: -9.521699086467931, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.62390081131669, 1: -9.46675274822855, 2: -9.542315748152921, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.607471248735044, 1: -9.46675274822855, 2: -9.540518042023365, 3: -9.228116336284526, 4: -9.080067816242252}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.611370947815457, 1: -9.46675274822855, 2: -9.540944743154661, 3: -9.228116336284526, 4: -9.16286171278045}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.614564801362317, 1: -9.46675274822855, 2: -9.541294211381192, 3: -9.228116336284526, 4: -9.306012359894991}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.63088461818863, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.766069739338802, 4: -9.988536437598324}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804336791309252, 2: -9.69381160173462, 3: -9.688729791969223, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.780349979698634, 2: -9.67899811035367, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.80438058433753, 2: -9.722751901407431, 3: -9.712088129076728, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.824149022924601, 2: -9.751037095009018, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.80445038533785, 2: -9.768879377541253, 3: -9.784356645219802, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.65784436374173, 2: -9.618804636363798, 3: -9.624205924251955, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.14644758386578, 2: -10.057506772236177, 3: -9.416767246223545, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.577613305809237, 2: -9.486905811430434, 3: -9.559218767326636, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.144248114125439, 2: -10.057506772236177, 3: -9.526070431881006, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.605370131306955, 2: -9.564721391850927, 3: -9.581701795979788, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.148152264668436, 2: -10.057506772236177, 3: -9.666874092751613, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.624134424971121, 2: -9.697362165758124, 3: -9.596900873847762, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.80438141400329, 2: -9.614043081174195, 3: -9.65792839160793, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.62864792202369, 2: -9.751685889560793, 3: -9.653918058960915, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.629623970467861, 1: -9.46675274822855, 2: -9.54294197044188, 3: -9.667395798433015, 4: -10.375688992069435}, Best action: 1, Actual action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.585099016127382, 1: -9.11590032707752, 2: -10.631130730478763, 3: -9.613329357065407, 4: -9.001054372373163}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584892731721611, 1: -9.11590032707752, 2: -10.631130730478763, 3: -9.607922453724553, 4: -9.001054372373163}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584943431087783, 1: -9.11590032707752, 2: -10.631130730478763, 3: -9.609251330579367, 4: -9.090959478859578}, Best action: 4, Actual action: 4\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584984953868679, 1: -9.11590032707752, 2: -10.631130730478763, 3: -9.61033968072346, 4: -9.24640540797459}, Best action: 1, Actual action: 1\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -9.014869004214061, 3: -9.027075507257377, 4: -9.421917495042845}, Best action: 2, Actual action: 2\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253678875299352, 1: -10.011158817814001, 2: -9.485429492208116, 3: -8.0811586740383, 4: -9.249150481139955}, Best action: 3, Actual action: 3\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -8.347225426392429, 3: -9.027075507257377, 4: -9.421917495042845}, Best action: 2, Actual action: 2\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253457306772553, 1: -10.011158817814001, 2: -9.485429492208116, 3: -8.469368462781697, 4: -9.249150481139955}, Best action: 3, Actual action: 3\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -8.575770748675769, 3: -9.027075507257377, 4: -9.421917495042845}, Best action: 2, Actual action: 2\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253560761034263, 1: -10.011158817814001, 2: -9.485429492208116, 3: -8.912500034484339, 4: -9.249150481139955}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -9.012203534739042, 3: -9.027075507257377, 4: -9.421917495042845}, Best action: 2, Actual action: 2\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253635171840937, 1: -10.011158817814001, 2: -9.485429492208116, 3: -9.366294462153684, 4: -9.249150481139955}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253599817862007, 1: -10.011158817814001, 2: -9.485429492208116, 3: -9.154212719428815, 4: -9.249150481139955}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -9.11882718672494, 3: -9.027075507257377, 4: -9.421917495042845}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672208176060948, 1: -9.525923563640532, 2: -9.070874830009762, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.130792567138569, 2: -9.363175389718299, 3: -9.150116163033644, 4: -9.421917495042845}, Best action: 1, Actual action: 1\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.970617460963794, 1: -9.103617893331702, 2: -9.159574691113797, 3: -8.946151420651479, 4: -10.527250005942374}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -8.829688978352184, 3: -9.476629683105509, 4: -15.639814222402155}, Best action: 2, Actual action: 2\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.970617460963794, 1: -9.103617893331702, 2: -9.159574691113797, 3: -8.946663214530416, 4: -10.527250005942374}, Best action: 3, Actual action: 3\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.029766101604856, 3: -9.476629683105509, 4: -15.639814222402155}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.970617460963794, 1: -9.103617893331702, 2: -9.159574691113797, 3: -9.126825260149914, 4: -10.527250005942374}, Best action: 0, Actual action: 0\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.166518015426746, 1: -9.247852431451365, 2: -9.830280206121891, 3: -9.363873822263116, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584986951922938, 1: -9.162855723914525, 2: -10.631130730478763, 3: -9.610392051556772, 4: -9.258259638777886}, Best action: 1, Actual action: 1\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.238564937913441, 1: -9.434545356485323, 2: -10.160730041121054, 3: -9.515095091540621, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584998446597654, 1: -9.317751590966976, 2: -10.631130730478763, 3: -9.61069333751628, 4: -9.32645624891486}, Best action: 1, Actual action: 1\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.406840370926735, 1: -9.508108705821734, 2: -10.290938492489962, 3: -9.574681404503114, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.58500471199375, 1: -9.551931412876785, 2: -10.631130730478763, 3: -9.610857559290407, 4: -9.36362813812113}, Best action: 4, Actual action: 4\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.584999157805521, 1: -9.31492942751789, 2: -10.631130730478763, 3: -9.610711978926323, 4: -9.330675765069076}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.346758723677763, 1: -9.516284636893495, 2: -10.305410037531836, 3: -9.58130390867124, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.585001576388189, 1: -9.43912731072503, 2: -10.631130730478763, 3: -9.61077537219473, 4: -9.411404985210837}, Best action: 4, Actual action: 4\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.585003742938417, 1: -9.597645647397933, 2: -10.631130730478763, 3: -9.610832159461918, 4: -9.483721682380414}, Best action: 4, Actual action: 4\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.585004977115107, 1: -9.687945716827722, 2: -10.631130730478763, 3: -9.610864508364116, 4: -9.571381982647507}, Best action: 4, Actual action: 4\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.58500589927533, 1: -9.755416714280837, 2: -10.631130730478763, 3: -9.610888679028786, 4: -9.675456201645627}, Best action: 0, Actual action: 0\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627967903021508, 1: -9.316628440363823, 2: -9.54276076521597, 3: -9.619165747763635, 4: -10.25805589848682}, Best action: 1, Actual action: 1\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.404966045764745, 1: -9.431003348146573, 2: -10.631130730478763, 3: -9.61077246188389, 4: -8.968959915954727}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.211371605770575, 1: -9.15673626489976, 2: -10.631130730478763, 3: -9.610674209035269, 4: -8.371670482692116}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.330079126102367, 1: -9.324910337263837, 2: -10.631130730478763, 3: -9.610734455352393, 4: -8.884463857535959}, Best action: 4, Actual action: 4\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.403270869612735, 1: -9.428601775979443, 2: -10.631130730478763, 3: -9.610771601549855, 4: -9.301036191498346}, Best action: 4, Actual action: 4\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.444544782722977, 1: -9.487074920989544, 2: -10.631130730478763, 3: -9.610792548843264, 4: -9.598854271136602}, Best action: 0, Actual action: 0\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.6279299648801, 1: -9.296322229633242, 2: -9.542756614062888, 3: -9.618060866143958, 4: -10.255361092216432}, Best action: 1, Actual action: 1\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.357093688858587, 1: -9.395525439686148, 2: -10.631130730478763, 3: -9.610759752354449, 4: -9.023135826034029}, Best action: 4, Actual action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.156577977274283, 1: -9.296945285457621, 2: -10.631130730478763, 3: -9.610724437212523, 4: -8.403204262223904}, Best action: 4, Actual action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.334848722986418, 1: -9.38458907889347, 2: -10.631130730478763, 3: -9.610755834536137, 4: -9.098072998919816}, Best action: 4, Actual action: 4\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.425473012449993, 1: -9.429142976249357, 2: -10.631130730478763, 3: -9.610771795428274, 4: -9.532484338478657}, Best action: 0, Actual action: 0\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627929187041124, 1: -9.308900236421513, 2: -9.542756528952534, 3: -9.618038212952357, 4: -10.25530584108211}, Best action: 1, Actual action: 1\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.376120866867858, 1: -9.406050871069443, 2: -10.631130730478763, 3: -9.610763522962296, 4: -9.260584182022555}, Best action: 4, Actual action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.419375251020455, 1: -9.416149212832481, 2: -10.631130730478763, 3: -9.610767140570479, 4: -9.37948805345069}, Best action: 4, Actual action: 4\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.505517174448935, 1: -9.436260251284386, 2: -10.631130730478763, 3: -9.610774345105538, 4: -9.672133435544541}, Best action: 1, Actual action: 1\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.317142243896066, 1: -9.515713279238664, 2: -10.30439872420687, 3: -9.58084110897083, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.282964608235693, 1: -9.385676118205934, 2: -10.631130730478763, 3: -9.610755731778811, 4: -8.755754624383753}, Best action: 4, Actual action: 4\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.840220839131447, 1: -8.927950700857313, 2: -10.631130730478763, 3: -9.610718702619495, 4: -6.93272011310407}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.119596045984135, 1: -9.216779459333628, 2: -10.631130730478763, 3: -9.610742068344246, 4: -8.35912609096353}, Best action: 4, Actual action: 4\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.254105303109068, 1: -9.355840266398914, 2: -10.631130730478763, 3: -9.610753318112303, 4: -9.193568649287702}, Best action: 4, Actual action: 4\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.313601180993578, 1: -9.417349377165863, 2: -10.631130730478763, 3: -9.610758294088239, 4: -9.635236510616421}, Best action: 0, Actual action: 0\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627921571164123, 1: -9.049192653098178, 2: -9.54275569563097, 3: -9.617816413934069, 4: -10.254764873276505}, Best action: 1, Actual action: 1\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.143606030942003, 1: -9.242849799799995, 2: -10.631130730478763, 3: -9.610744177387689, 4: -8.153455242949153}, Best action: 4, Actual action: 4\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.18639115514099, 1: -8.84796255607707, 2: -10.631130730478763, 3: -9.610712231723094, 4: -4.800229238495572}, Best action: 4, Actual action: 4\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.81714893437096, 1: -9.108173933056019, 2: -10.631130730478763, 3: -9.610733282353381, 4: -7.477820514760051}, Best action: 4, Actual action: 4\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.09250643828949, 1: -9.22176929028427, 2: -10.631130730478763, 3: -9.610742472012555, 4: -8.87371996954718}, Best action: 4, Actual action: 4\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.20317131909687, 1: -9.267422728048055, 2: -10.631130730478763, 3: -9.610746165293191, 4: -9.53609057284825}, Best action: 0, Actual action: 0\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627919419892907, 1: -8.865325468484757, 2: -9.542755460241048, 3: -9.617753761944842, 4: -10.254612065074786}, Best action: 1, Actual action: 1\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.978487984782774, 1: -9.174895074730706, 2: -10.631130730478763, 3: -9.610738679973203, 4: -7.965369814852548}, Best action: 4, Actual action: 3\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.629974894477257, 1: -9.608683579106009, 2: -9.618210012314252, 3: -9.052320850181296, 4: -10.165085753395303}, Best action: 3, Actual action: 3\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.724156612089288, 2: -9.158722462172625, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.629966271105298, 1: -9.608683579106009, 2: -9.618209796457842, 3: -9.223797279377957, 4: -10.165071007429251}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.72415676668436, 2: -9.287148042513408, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 2, Actual action: 2\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.629970092187211, 1: -9.608683579106009, 2: -9.618209892105465, 3: -9.370417535369256, 4: -10.16507754147932}, Best action: 3, Actual action: 3\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.394305867223771, 1: -9.724156820379726, 2: -9.51564574920711, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 0, Actual action: 0\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.738269494607767, 1: -9.741149481237853, 2: -9.677176086714354, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 2, Actual action: 2\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.69661866481633, 1: -9.676414311181578, 2: -9.93495931656476, 3: -9.7667703137955, 4: -10.164732291064032}, Best action: 1, Actual action: 1\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.629976143825473, 1: -9.608683579106009, 2: -9.618210043587382, 3: -10.010357834185447, 4: -10.16508788978075}, Best action: 1, Actual action: 1\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272548898368, 1: -9.525923563640532, 2: -9.550196492129926, 3: -9.323092489945644, 4: -9.873512464627483}, Best action: 3, Actual action: 3\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.440505814868287, 1: -9.49463758241095, 2: -9.732111493317653, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 0, Actual action: 0\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.642092437481795, 1: -9.72415686505521, 2: -9.721612230015818, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 0, Actual action: 0\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.738320705743488, 1: -9.741149588261365, 2: -9.7775108557392, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 0, Actual action: 0\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.764427790625811, 2: -9.49702549812679, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327321353762, 2: -9.309870478628008, 3: -9.558773586851498, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.357724300095564, 2: -9.380411226625391, 3: -9.44396377862543, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627926908109046, 1: -10.23813044090046, 2: -9.542756279594085, 3: -9.617971843065051, 4: -10.25514396492698}, Best action: 2, Actual action: 2\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.882792562049401, 1: -9.777652282837005, 2: -9.485162591662217, 3: -9.659287813530844, 4: -10.517280954389182}, Best action: 2, Actual action: 2\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.406724995072429, 1: -9.427744894172262, 2: -9.570476959587127, 3: -9.09559054421556, 4: -9.66291355135573}, Best action: 3, Actual action: 3\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.882791388888503, 1: -9.777651362540945, 2: -9.215944554379234, 3: -9.659287469074599, 4: -10.51728066145439}, Best action: 2, Actual action: 2\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.406724995072429, 1: -9.427744873850216, 2: -9.570476959587127, 3: -9.274474143468737, 4: -9.66291355135573}, Best action: 3, Actual action: 3\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.882791981965237, 1: -9.777651827785043, 2: -9.32821139069825, 3: -9.65928764321012, 4: -10.51728080954389}, Best action: 2, Actual action: 2\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.406724995072429, 1: -9.427744887637658, 2: -9.570476959587127, 3: -9.486686904798852, 4: -9.66291355135573}, Best action: 0, Actual action: 0\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.472275818028379, 1: -9.224683597456638, 2: -10.241981546194536, 3: -9.479714651268234, 4: -11.193230508696814}, Best action: 1, Actual action: 3\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656064060589, 2: -10.057506772236177, 3: -9.313174813471187, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.512366761332357, 2: -9.380516486459594, 3: -9.444023302624627, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656121195611, 2: -10.057506772236177, 3: -9.429553857099503, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.590758835397544, 2: -9.476005188825553, 3: -9.44404079401048, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327338277858, 2: -9.616481828262383, 3: -9.558804609645943, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.76442839048549, 2: -9.699331293105676, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.80432734469691, 2: -9.687980999579096, 3: -9.71234518917412, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.663292934762172, 2: -9.68400226996757, 3: -9.716651827530933, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627927435864462, 1: -10.33485227487254, 2: -9.653722245395404, 3: -9.617987213013057, 4: -10.255181452230161}, Best action: 3, Actual action: 3\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.696638422567462, 1: -9.776079294443019, 2: -9.93495931656476, 3: -9.766770341182513, 4: -10.16473917895147}, Best action: 0, Actual action: 0\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327345866952, 2: -9.783082090114272, 3: -9.769292813760954, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.764431245446016, 2: -9.872948568393085, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.79407536706351, 1: -9.741149595379088, 2: -9.805143333304928, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.84019582230449, 1: -9.724156913112592, 2: -9.943170189303672, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.697045833239264, 1: -9.49463758241095, 2: -9.732111583014381, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -8.852903551490643, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -8.852903551490643, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -8.956142231856484, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.134641910209027, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.345702748309048, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.453647770138621, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.548214290679917, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.675583222309035, 1: -9.263518292557709, 2: -9.732111578536333, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.348814593985606, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.014671794025812, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.272187759712706, 1: -10.459590020133016, 2: -9.486729832898945, 3: -8.732256699897953, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.364606246290146, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.186970246852082, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.41794912839418, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.522598327494185, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.673827580644668, 1: -9.276316083737226, 2: -9.732111578170029, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.330633040281965, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.134451283772343, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.306429691809798, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.064217700434291, 4: -15.446958008227519}, Best action: 3, Actual action: 3\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.414930581014284, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.463287362776503, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.67418896707731, 1: -9.363948055826844, 2: -9.73211157824543, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.429257407633166, 1: -10.459590020133016, 2: -9.486729832898945, 3: -9.520039636882887, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.675255040402615, 1: -9.606931989530159, 2: -9.73211157846786, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.675315040315887, 1: -9.62072171728482, 2: -9.732111578480378, 3: -9.594823047476476, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.675601486259987, 1: -9.68655533887031, 2: -9.732111578540144, 3: -9.631288973203594, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.675836085488205, 1: -9.740473074948826, 2: -9.732111578589091, 3: -9.694338558785779, 4: -14.594944059759277}, Best action: 0, Actual action: 0\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.805288886876198, 1: -9.360783454038604, 2: -9.925410715123945, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.448531490770582, 1: -9.46122922645894, 2: -9.732111578335587, 3: -9.176842099116943, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38388103822704, 1: -9.376627399117831, 2: -9.732111578258783, 3: -9.020057459572326, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.455727932113343, 1: -9.47064651688766, 2: -9.732111578344135, 3: -9.282489109720732, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.503073397793704, 1: -9.532602972802284, 2: -9.73211157840038, 3: -9.52000156647636, 4: -14.594944059759277}, Best action: 0, Actual action: 0\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.803802806646598, 1: -9.42751844650939, 2: -9.924654647507502, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.468358438687925, 1: -9.531651960714804, 2: -9.732111578399516, 3: -9.515254468439277, 4: -14.594944059759277}, Best action: 0, Actual action: 0\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804158498218866, 1: -9.578124684889394, 2: -9.924835611410982, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.619515520686612, 1: -9.605682591284275, 2: -9.732111578466723, 3: -9.884787795814502, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.671935724768863, 1: -10.459590020133016, 2: -9.486729832898945, 3: -10.044087910783967, 4: -15.446958008227519}, Best action: 2, Actual action: 2\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843416850738677, 3: -9.476629683105509, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.632890645010123, 1: -10.459590020133016, 2: -9.524743026605357, 3: -9.987652723977453, 4: -15.446958008227519}, Best action: 2, Actual action: 2\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843418418751028, 3: -9.56270481986089, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.681817637232651, 1: -10.459590020133016, 2: -9.609091037746062, 3: -10.05837108242417, 4: -15.446958008227519}, Best action: 2, Actual action: 2\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843419191562774, 3: -9.699795111851282, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.714671623240157, 1: -10.459590020133016, 2: -9.730330675217187, 3: -10.105857752937556, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.901167383332877, 1: -9.766854744836133, 2: -9.732111578536975, 3: -10.271073387117523, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587465288, 1: -9.525923563640532, 2: -9.550565568776216, 3: -9.690717554309652, 4: -9.873512464627483}, Best action: 1, Actual action: 1\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843418773189567, 3: -9.570689390245578, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.67913443143397, 1: -10.459590020133016, 2: -9.741283070026133, 3: -10.108416061407318, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.867260189010171, 1: -9.739266867933761, 2: -9.659250325197137, 3: -10.224569662678027, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587451388, 1: -9.614954294821525, 2: -9.550565435774987, 3: -9.690663599195858, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.368967436283407, 1: -9.516943546057801, 2: -10.306576318603215, 3: -9.58183762509434, 4: -9.421917495042845}, Best action: 0, Actual action: 0\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.29705603547492, 1: -9.430176458549969, 2: -10.631130730478763, 3: -9.68993384284703, 4: -12.298947446174639}, Best action: 1, Actual action: 1\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.475344803619501, 1: -9.51694353089898, 2: -10.30657629177183, 3: -9.581837612815693, 4: -9.421917495042845}, Best action: 4, Actual action: 4\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.515477848075193, 1: -9.516943581105748, 2: -10.306576380638711, 3: -9.581837653483175, 4: -9.421917495042845}, Best action: 4, Actual action: 4\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.557622349076171, 1: -9.516943633828864, 2: -10.306576473959575, 3: -9.581837696188899, 4: -9.47394492048899}, Best action: 4, Actual action: 4\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.592138695395972, 1: -9.516943677009097, 2: -10.306576550389362, 3: -9.581837731164887, 4: -9.563900339085373}, Best action: 1, Actual action: 1\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325849851489, 1: -9.103617893331702, 2: -9.159574691113797, 3: -9.859071750411841, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325485389489, 1: -9.103617893331702, 2: -9.159574691113797, 3: -9.859071216074103, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325576226308, 1: -9.18429228293185, 2: -9.159574691113797, 3: -9.859071349249962, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -7.907569126655282, 2: -7.383799628182667, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177650624, 3: -9.169517763530953, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.47342758059143 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.415210504151288 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.691661648767854 -9.618210077281795 -9.130479658489522 -9.540311444470415 -9.364169107420485 \n",
      "-9.181229515812921 -9.296911881403588 -7.967442449599231 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.158781627958438 -7.907569126655282 -9.169517763530953 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.47342758059143, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.415210504151288, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.691661648767854, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.181229515812921, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.296911881403588, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.967442449599231}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.967442449599231}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.150372629135301}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.466658909553162}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.840640801513146}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.861039943003554, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.19947406703681}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.158781627958438, 2: -8.500535918725445, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.158781627958438, 2: -8.500535918725445, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.324491281442178, 2: -8.500535918725445, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.611003272315566, 2: -8.500535918725445, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -7.907569126655282, 2: -8.165689351278338, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -7.907569126655282, 2: -8.165689351278338, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.095887905256307, 2: -8.165689351278338, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.421491073457478, 2: -8.165689351278338, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.080506961140278, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.018873739750873 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-8.909888807850386 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-8.822908117582626 -9.618210077281795 -9.130479658489522 -9.540311444470415 -9.364169107420485 \n",
      "-8.644502899032227 -8.514557796419174 -7.55378963715157 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.419994663550959 -8.17177957365146 -9.081329659875653 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.018873739750873, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -8.909888807850386, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -8.822908117582626, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.644502899032227, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.514557796419174, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.55378963715157}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.55378963715157}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.773948569807929}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.154603364370772}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.60469560380074}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.639059476826887, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.036556267468375}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.510852564961551, 2: -8.419994663550959, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.259833092653814, 2: -8.17177957365146, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177669566, 3: -8.955190193046793, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.814565619627745 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-8.682853598176878 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-8.539918275526972 -9.618210077281795 -9.130479658489522 -9.540311444470415 -9.364169107420485 \n",
      "-8.372925249646237 -8.194205734911929 -7.374148851467881 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.270333117086208 -8.070882013733048 -8.929543387074954 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.814565619627745, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -8.682853598176878, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -8.539918275526972, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.372925249646237, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.194205734911929, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.44940623334069, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.374148851467881}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.44940623334069, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.374148851467881}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.44940623334069, 2: -10.306575694496093, 3: -9.581837339488898, 4: -7.610475454835772}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.44940623334069, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.019084152058856}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -8.44940623334069, 2: -10.306575694496093, 3: -9.581837339488898, 4: -8.502229527371698}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.426325029266629, 1: -8.510852564961551, 2: -8.270333117086208, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.205609968815846, 1: -9.38026389704004, 2: -10.306575694496093, 3: -9.581837339488898, 4: -11.699757981650901}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -9.130479658489522, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.216249520258097, 1: -9.274448327269047, 2: -10.306575694496093, 3: -9.581837339488898, 4: -11.372248211652703}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -9.278210077258011, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.351132655960786, 1: -9.382841863521403, 2: -10.306575694496093, 3: -9.581837339488898, 4: -11.707737045707368}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -9.502099143301674, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.552033393711378, 1: -9.455627039179497, 2: -10.306575694496093, 3: -9.581837339488898, 4: -11.933014442886735}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.513788682886085, 1: -8.510852564961551, 2: -8.270333117086208, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.259833092653814, 2: -8.070882013733048, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.191883472757734, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.127024696108656 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.030027731090886 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-8.9225944623007 -9.618210077281795 -7.805480243275913 -9.540311444470415 -9.364169107420485 \n",
      "-8.802406563573511 -8.669547283056625 -8.024920397224498 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.42791636334901 -8.25251381430707 -9.213965659438784 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.127024696108656, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.030027731090886, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -8.9225944623007, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.802406563573511, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.669547283056625, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.024920397224498, 1: -8.354248066454662, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -7.805480243275913, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02493103677594, 1: -8.354248066454662, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -8.1807421641161, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.36266869129092, 1: -8.354248066454662, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.510852564961551, 2: -8.42791636334901, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.259833092653814, 2: -8.25251381430707, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.346362948787013, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.318742636815859 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.243047403336861 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.158975702038704 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-9.06548094058917 -8.961666155229905 -8.677573537344625 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.510852564961551 -8.259833092653814 -9.353041542537849 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.318742636815859, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.243047403336861, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.158975702038704, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.06548094058917, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.961666155229905, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.677573537344625, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.510852564961551, 2: -8.556290226000634, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.510852564961551, 2: -8.556290226000634, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.64487583411501, 2: -8.556290226000634, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.259833092653814, 2: -8.395805369948189, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.259833092653814, 2: -8.395805369948189, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.41644811431497, 2: -8.395805369948189, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.353041542537849, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.434762451984552, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.378156491611733 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.309062771367184 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.232295382463313 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-9.14699010768052 -9.052213297324768 -8.930031444625326 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.70333417226225 -8.415544186450475 -9.353041542537849 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.378156491611733, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.309062771367184, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.232295382463313, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.14699010768052, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.052213297324768, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.930031444625326, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.70333417226225, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.415544186450475, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.321453508169538, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.244465625486981 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.160517361943173 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.067241854697945 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-8.963601584603179 -8.84844641177151 -8.718808791172567 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.56567302468182 -8.391931760262374 -9.311289132947016 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.244465625486981, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.160517361943173, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.067241854697945, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.963601584603179, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.84844641177151, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.718808791172567, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.56567302468182, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.391931760262374, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.308130329510181, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.225934866483264 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.139927629454945 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.044364066870491 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-8.938182248905537 -8.820202519449618 -8.688945188308885 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.542194312681104 -8.378778742929484 -9.30246838683581 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.225934866483264, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.139927629454945, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.044364066870491, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.938182248905537, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.820202519449618, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.688945188308885, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.542194312681104, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.378778742929484, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.30215250649213, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.221765859466085 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.135295399409669 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.039217113869466 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-8.93246345509324 -8.8138482855035 -8.682036778340377 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.535488608500874 -8.372621404551573 -9.299501974219565 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.221765859466085, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.135295399409669, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.039217113869466, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.93246345509324, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.8138482855035, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.682036778340377, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.535488608500874, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.372621404551573, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.299470386185197, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.220309850403499 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.133677611559733 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.03741956874113 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-8.930466187013973 -8.811629096888849 -8.679586198210146 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.532862772379096 -8.369833153265166 -9.298270135433159 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220309850403499, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.133677611559733, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03741956874113, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930466187013973, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811629096888849, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.679586198210146, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.532862772379096, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.369833153265166, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.298266976629723, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.21969802397879 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.132997804420905 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036664227168481 -9.618210077281795 -9.258172858774895 -9.540311444470415 -9.364169107420485 \n",
      "-8.929626919028475 -8.81069657671897 -8.678551583187776 -9.253743317946801 -7.713048395517235 \n",
      "-9.208317708371364 -9.116966870763978 -8.53172290320098 -8.368579566396592 -9.297727348587916 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.21969802397879, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.132997804420905, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036664227168481, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929626919028475, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81069657671897, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -8.678551583187776, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -8.53172290320098, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.728156272596566, 1: -8.689219679405543, 2: -8.368579566396592, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.253743317946801, 1: -10.011158817814001, 2: -9.485429492208116, 3: -10.504228585009196, 4: -9.68009507836205}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.833875693610787, 1: -9.540311444470415, 2: -9.960346189145378, 3: -9.695203035252547, 4: -10.941578963035465}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.553026601815716, 1: -10.011158817814001, 2: -9.485429492208116, 3: -10.504228585009196, 4: -9.68009507836205}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.350069801235893, 1: -7.713048395517235, 2: -8.498680839049324, 3: -9.25466507759064, 4: -7.9340199705408025}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.348460321411102, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.473927621436324 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.415475134929252 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.350527927702583 -9.618210077281795 -9.258172858774895 -8.797555961324866 -9.364169107420485 \n",
      "-9.278364364109217 -9.198182626790082 -9.109091790672318 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.991713963700686 -8.368579566396592 -9.440337276779976 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.473927621436324, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.415475134929252, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.350527927702583, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.278364364109217, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.198182626790082, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355454680167, 1: -9.109091790672318, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.297016328696206, 1: -9.258172858774895, 2: -10.631130730478763, 3: -9.689907827057894, 4: -12.298816946722633}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.332355561075682, 1: -9.109091790672318, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -9.010101881824031, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.991713963700686, 2: -9.010101881824031, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -9.082459706967624, 2: -9.010101881824031, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368579566396592, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.509491316230696, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.440337276779976, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.49106338630035 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.434514873667055 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.371683192963735 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-9.301870214403674 -9.22430023822651 -8.956837814934863 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.568683653914139 -8.48353115083144 -9.440337276779976 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.49106338630035, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.434514873667055, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.371683192963735, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.301870214403674, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.22430023822651, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.956837814934863, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.568683653914139, 2: -8.683016062955005, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.568683653914139, 2: -8.683016062955005, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.697502125061867, 2: -8.683016062955005, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.48353115083144, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.41824281908421, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.362414202935787 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.29157133659532 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.212857040661495 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-9.125396711846061 -9.028218568717866 -8.902115498043724 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.634200621407889 -8.477129798541354 -9.41601080555317 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.362414202935787, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.29157133659532, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.212857040661495, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.125396711846061, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.028218568717866, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.902115498043724, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.634200621407889, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.477129798541354, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.351609962422682, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.254574624872648 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.171749583191827 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.079721759102034 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.97746862122448 -8.863854023582757 -8.735802846149895 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.580743724746926 -8.42251704941651 -9.32810096467648 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.254574624872648, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.171749583191827, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.079721759102034, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.97746862122448, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.863854023582757, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.735802846149895, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.580743724746926, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.42251704941651, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.32166088036343, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.23218777904984 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.146875310055375 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.052083677839306 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.946759642043672 -8.829732935604081 -8.699521988221438 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.553565154259633 -8.39279701803603 -9.308867381373963 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.23218777904984, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.146875310055375, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.052083677839306, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.946759642043672, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.829732935604081, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.699521988221438, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.553565154259633, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.39279701803603, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.30822337294266, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.224743128771662 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.138603476412953 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.04289275156995 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.936547501744387 -8.818386113049318 -8.687077553809823 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.541051354301162 -8.378940633887158 -9.302258653917406 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.224743128771662, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.138603476412953, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.04289275156995, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.936547501744387, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.818386113049318, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.687077553809823, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.541051354301162, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.378940633887158, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.302194253074273, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.22166285917619 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.135180954640212 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.039089949600234 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.93232216622248 -8.813691295802759 -8.681877404823013 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53540474592126 -8.372671408378876 -9.299495557060862 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.22166285917619, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.135180954640212, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.039089949600234, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.93232216622248, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.813691295802759, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.681877404823013, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53540474592126, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.372671408378876, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.299489116976549, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.220306807066851 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.133674230074279 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.037415811193645 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.930462012437383 -8.811624458263758 -8.679582550130617 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.532868040868031 -8.369853325588894 -9.298276024740396 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220306807066851, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.133674230074279, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.037415811193645, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930462012437383, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811624458263758, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.679582550130617, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.532868040868031, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.369853325588894, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.298275380731964, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219700975566525 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.133001083962803 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036667871069781 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929630967855315 -8.810701075394794 -8.678556732311304 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531729556640403 -8.36858839095178 -9.297730867847893 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219700975566525, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.133001083962803, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036667871069781, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929630967855315, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810701075394794, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.678556732311304, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531729556640403, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36858839095178, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.297730803447052, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219429412018474 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.132699346687195 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036332607430216 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929258452700239 -8.810287169666934 -8.678096853372745 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531218711376944 -8.368020789887291 -9.297486469800429 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219429412018474, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.132699346687195, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036332607430216, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929258452700239, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810287169666934, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.678096853372745, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531218711376944, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368020789887291, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.541957038940387, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.297486463360347, 4: -9.584948264403135}, Best action: 3, Actual action: 0\n",
      "V:\n",
      "-9.314020503245125 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.237800559161252 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.15311173240139 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-9.059013036001543 -8.954458928890602 -8.838287698586061 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.709208552525238 -8.565787280530444 -9.382618452818996 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.314020503245125, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.237800559161252, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.15311173240139, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.059013036001543, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.954458928890602, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.838287698586061, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.709208552525238, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.565787280530444, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.398552310787121, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.382618452818996, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.26174857941607 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.179720643795635 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.088578493106263 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.987309436784736 -8.874788263094148 -8.749764736753152 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.610849707357572 -8.456499674836431 -9.35150758007644 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.26174857941607, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.179720643795635, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.088578493106263, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.987309436784736, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.874788263094148, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.749764736753152, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.610849707357572, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.456499674836431, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.340278194535372, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.24011790346454 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.155686559405044 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.061873954894494 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.957637727660549 -8.841819697400608 -8.713132997109975 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.570147774552044 -8.411275305057295 -9.32081058625254 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.24011790346454, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.155686559405044, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.061873954894494, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.957637727660549, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.841819697400608, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.713132997109975, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.570147774552044, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.411275305057295, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.316576560424178, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.228772337191929 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.143080374657696 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.047867082952997 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.94207453661444 -8.824527262904933 -8.693919181005299 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.54879909000443 -8.387554544449314 -9.306365550786182 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.228772337191929, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.143080374657696, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.047867082952997, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.94207453661444, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.824527262904933, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.693919181005299, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.54879909000443, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.387554544449314, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.305942148203345, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.223517791381846 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.137241990424272 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.041379989360303 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.934866654844779 -8.816518505383087 -8.685020561536746 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.538911735040683 -8.37656859448964 -9.301213056975005 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.223517791381846, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.137241990424272, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.041379989360303, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.934866654844779, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.816518505383087, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.685020561536746, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.538911735040683, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.37656859448964, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.301170716716724, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.221143786481061 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.134604207201178 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.038449119112418 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.931610132347133 -8.81290014705237 -8.681000163391518 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.534444625990561 -8.37160513998951 -9.299034112306092 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.221143786481061, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.134604207201178, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.038449119112418, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.931610132347133, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81290014705237, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.681000163391518, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.534444625990561, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.37160513998951, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.29902987828026, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.220076981317055 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.133418868130061 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.037132075700066 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.930146750777853 -8.811274167530948 -8.679193519478831 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.532437243865365 -8.369374715405963 -9.298069753632664 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220076981317055, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.133418868130061, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.037132075700066, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930146750777853, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811274167530948, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.679193519478831, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.532437243865365, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.369374715405963, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.298069330230081, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219598164805348 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.13288684978372 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036540944204134 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929489938004593 -8.810544375560658 -8.678382639511842 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531536266124267 -8.368373629026962 -9.297638395369544 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219598164805348, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.13288684978372, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036540944204134, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929489938004593, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810544375560658, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.678382639511842, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531536266124267, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368373629026962, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.297638353029287, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219383313756296 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.132648126395884 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036275695995426 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929195217772696 -8.81021690863633 -8.6780187873737 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531131985970777 -8.36792442885642 -9.297444987085141 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219383313756296, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.132648126395884, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036275695995426, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929195217772696, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81021690863633, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.6780187873737, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531131985970777, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36792442885642, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.297444982851117, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219286913082408 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.132541014536008 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.036156682817786 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92906298090865 -8.810069978787388 -8.677855531985987 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530950591095541 -8.367722878995046 -9.297358222244615 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219286913082408, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.132541014536008, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036156682817786, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92906298090865, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810069978787388, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677855531985987, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530950591095541, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367722878995046, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.297358221821211, 4: -9.584948264403135}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-9.219243660014385 -9.374722228574017 -9.59159501287188 -9.879174204302114 -9.224683597456638 \n",
      "-9.132492955571543 -9.521013400775994 -9.558013399690022 -9.659287949971592 -9.427744915798616 \n",
      "-9.03610328396838 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929003648853755 -8.810004054281949 -8.677782282535498 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530869202817218 -8.367632447574685 -9.297319294059992 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219243660014385, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.768282352570207, 1: -9.132492955571543, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.734233071583306, 2: -9.669364605193126, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.631318026736597, 3: -9.374722228574017, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.511679620168852, 2: -9.460461465664267, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.631318026736597, 3: -9.500446010045458, 4: -15.913640529268028}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.589626121877044, 2: -9.53580140073384, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.631318026736597, 3: -9.645483900026019, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.59159501287188, 2: -9.656858626200567, 3: -9.683143655112422, 4: -9.75566738456948}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627927416074199, 1: -10.331225309495197, 2: -9.640909182377312, 3: -9.558013399690022, 4: -10.255180046496365}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.521013400775994, 1: -9.771773827829662, 2: -9.93495931656476, 3: -9.766770340284207, 4: -10.164738953024552}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.648868694922792, 3: -9.64912017436421, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.728782252026033, 2: -9.656858626200567, 3: -9.683143655112422, 4: -9.75566738456948}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.879174204302114, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.824795156516585, 2: -9.86781696810477, 3: -9.683143655112422, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.775495730762398, 3: -9.817325144491635, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.792365211796266, 2: -9.818388611573267, 3: -9.786465907428784, 4: -9.75566738456948}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.74065072377058, 2: -9.739567565961796, 3: -9.689155974575117, 4: -9.75566738456948}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.614756363797353, 3: -9.803430973531055, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.723421719966877, 2: -9.713307843657722, 3: -9.6476925014706, 4: -9.715643421295475}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.788824118518418, 3: -9.833362816177207, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.762425191670106, 2: -9.772755293289226, 3: -9.862596607895368, 4: -9.806250721450184}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.627927416074199, 1: -10.331225309495197, 2: -9.640909182377312, 3: -9.710291729965828, 4: -10.255180046496365}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.65572609439444, 2: -9.710356974069798, 3: -9.549430159810411, 4: -9.71114583009303}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.366357174105854, 3: -9.787168290553538, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.56045818274508, 2: -9.680928544980855, 3: -9.3413965222193, 4: -9.66629225733134}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -9.703621101402433, 3: -9.809221781667611, 4: -15.913640529268028}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.724563930158068, 2: -9.731621105227228, 3: -9.782073719091384, 4: -9.743555723641924}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.67818308504275, 1: -10.331225309495197, 2: -9.640909182377312, 3: -9.704493604668823, 4: -10.255180046496365}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.882793026744006, 1: -9.77765264737064, 2: -10.104698147238748, 3: -9.659287949971592, 4: -10.517281070422047}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.684331941340073, 1: -10.331225309495197, 2: -9.68811415771472, 3: -9.70605656143937, 4: -10.255180046496365}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.798583175963447, 2: -9.738520992918865, 3: -9.865835469899425, 4: -9.754072241995281}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.743912485238019, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.882845222307035, 2: -9.770026989522691, 3: -9.9922104877131, 4: -9.76993897330668}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.923467113379388, 2: -9.812197262413825, 3: -10.05313462177651, 4: -9.777588166021246}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.94119543392946, 2: -9.830601332134913, 3: -10.07972330461227, 4: -9.800943513390012}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.955475445137303, 2: -9.845425653544535, 3: -10.101140262175962, 4: -9.837671130568829}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.965956149900459, 2: -9.856305850607898, 3: -10.116859074009023, 4: -9.879236681911982}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.837205913502476, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.962207107547666, 2: -9.854523489685496, 3: -10.11123631364801, 4: -9.85856166072235}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.882558241184144, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.976639086907959, 2: -9.894552931327867, 3: -10.132881190883802, 4: -9.938150379921563}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.928861415067978, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.985124174370888, 2: -9.93601220748561, 3: -10.145607004293385, 4: -9.984943493091183}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.963692168566048, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.989295600907488, 2: -9.96732760758424, 3: -10.151863250441522, 4: -10.007947856317685}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.984294915007492, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.99102090725715, 2: -9.985865967055293, 3: -10.154450840348652, 4: -10.017462484849775}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11.425464147787569, 1: -10.141656888373888, 2: -10.057506772236177, 3: -9.994198596862304, 4: -10.244588989457231}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -12.578802324627084, 1: -9.991625466405916, 2: -9.99477879784578, 3: -10.155357549555347, 4: -10.020796475782632}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.935661055479734, 1: -10.331225309495197, 2: -9.862484689572664, 3: -9.729611434686554, 4: -10.255180046496365}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.697310293043389, 1: -9.771773827829662, 2: -9.93495931656476, 3: -9.766770340284207, 4: -10.164738953024552}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -13.259836984669047, 1: -9.804327343736166, 2: -10.166460807923022, 3: -9.837559478885945, 4: -15.913640529268028}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.812752986625435, 1: -9.771773827829662, 2: -9.93495931656476, 3: -9.766770340284207, 4: -10.164738953024552}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.737149805777284, 1: -9.132492955571543, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03610328396838, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929003648853755, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810004054281949, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677782282535498, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530869202817218, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367632447574685, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.35150758007644, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.73392613946722, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.70444117956311 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.15579767284651 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.0619974142739 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.957774904748778 -8.841972116387531 -8.713302351541703 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.570335946157448 -8.411484384619385 -9.35150758007644 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.70444117956311, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.15579767284651, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.0619974142739, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.957774904748778, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.841972116387531, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.713302351541703, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.570335946157448, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.411484384619385, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.319727261512753, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.276425310958215 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.144447759508987 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.049386399454429 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.943762666060477 -8.82640296228942 -8.696003291432687 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.551114768258541 -8.390127520287269 -9.310533831709359 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.276425310958215, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.144447759508987, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.049386399454429, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.943762666060477, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.82640296228942, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.696003291432687, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.551114768258541, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.390127520287269, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.307355799852989, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.228830766371853 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.137987259590934 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.04220806621215 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.93578674023572 -8.817540822484133 -8.686156469426816 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.540173854918685 -8.377970949909647 -9.302122794919365 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.228830766371853, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.137987259590934, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.04220806621215, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.93578674023572, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.817540822484133, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.686156469426816, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.540173854918685, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.377970949909647, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.301804991733729, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.221920815117308 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.134951768714783 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.038835298571982 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.932039220635534 -8.813376911817262 -8.68152990201918 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.535033224465757 -8.372259138295284 -9.299346244124049 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.221920815117308, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.134951768714783, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.038835298571982, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.932039220635534, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.813376911817262, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.68152990201918, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.535033224465757, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.372259138295284, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.299314463805484, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.220264938444025 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.133576129018472 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.037306810020524 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.930340900022804 -8.811489888914227 -8.679433209904698 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.532703566560773 -8.36967062951197 -9.29820019565147 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220264938444025, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.133576129018472, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.037306810020524, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930340900022804, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811489888914227, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.679433209904698, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.532703566560773, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36967062951197, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.298197017619616, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219666429228939 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132957541106885 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036619490118762 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929577211243068 -8.81064134582563 -8.6784903842507 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531655982500778 -8.368506647223088 -9.29769596141123 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219666429228939, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132957541106885, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036619490118762, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929577211243068, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81064134582563, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.6784903842507, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531655982500778, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368506647223088, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297695643608042, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219412335742692 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132679857243799 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03631095249311 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92923439165901 -8.810260435176676 -8.67806715019631 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531185722440343 -8.367984136044823 -9.297470719678941 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219412335742692, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132679857243799, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03631095249311, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92923439165901, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810260435176676, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67806715019631, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531185722440343, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367984136044823, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29747068789862, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219299773943119 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132555252800879 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036172503112088 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929080559013432 -8.810089510014924 -8.677877233349916 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530974703722128 -8.367749670802365 -9.297369758299858 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219299773943119, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132555252800879, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036172503112088, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929080559013432, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810089510014924, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677877233349916, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530974703722128, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367749670802365, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29736975512183, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219249414337424 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132499344105767 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03611038233974 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929011535933045 -8.810012817703381 -8.677792019670424 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530880021856026 -8.367644468728919 -9.297324469078788 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219249414337424, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132499344105767, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03611038233974, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929011535933045, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810012817703381, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677792019670424, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530880021856026, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367644468728919, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297324468760984, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219226833512787 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132474258942851 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.0360825099365 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928980566596112 -8.809978407329012 -8.677753785921125 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53083753991236 -8.36759726656929 -9.297304149779022 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219226833512787, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132474258942851, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.0360825099365, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928980566596112, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809978407329012, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677753785921125, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53083753991236, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36759726656929, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29730414974724, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219216703428085 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132463003757403 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036070004174892 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928966671305435 -8.80996296811715 -8.677736631241277 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530818479156974 -8.367576087952195 -9.297295033047028 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219216703428085, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132463003757403, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036070004174892, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928966671305435, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.80996296811715, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677736631241277, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530818479156974, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367576087952195, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29729503304385, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219212158421929 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132457953796987 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036064393107763 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928960436786403 -8.80995604087378 -8.6777289343042 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530809927004665 -8.367566585560738 -9.297290942575913 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219212158421929, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132457953796987, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036064393107763, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928960436786403, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.80995604087378, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.6777289343042, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530809927004665, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367566585560738, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297290942575595, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219210119190102 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132455687988486 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036061875542762 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928957639491957 -8.80995293276884 -8.677725480854267 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530806089838075 -8.367562322042305 -9.29728910727071 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219210119190102, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.735180250325548, 1: -9.132455687988486, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.707417014682704, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.736525806925545, 1: -9.132455687988486, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036061875542762, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928957639491957, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.80995293276884, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677725480854267, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530806089838075, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367562322042305, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.416658132210662, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.995069877144978 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.183839122495385 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.093154580550427 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.992393978389362 -8.880437753765959 -8.756041948628843 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.61782438736538 -8.464249319294867 -9.450370803590639 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -8.995069877144978, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.183839122495385, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.093154580550427, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.992393978389362, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.880437753765959, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.756041948628843, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.61782438736538, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.464249319294867, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.350055800658197, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.217238078182781 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.160307346103188 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.067008162336876 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.96334240259653 -8.848158225107255 -8.720175805674728 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.577973117416365 -8.419970130462627 -9.33099506178052 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.217238078182781, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.160307346103188, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.067008162336876, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.96334240259653, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.848158225107255, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.720175805674728, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.577973117416365, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.419970130462627, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.320963561487279, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.228183968760863 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.14543091343541 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.050478792706011 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.944976436340013 -8.827751595933348 -8.697501773259274 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.552779748065861 -8.39197749785096 -9.308913651026378 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.228183968760863, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.14543091343541, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.050478792706011, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.944976436340013, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.827751595933348, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.697501773259274, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.552779748065861, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.39197749785096, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.307910500997053, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.2242215347406 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.138324355637447 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.04258261737494 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.936202908194378 -8.818003231327086 -8.686670257030096 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.540744730033438 -8.37860525559271 -9.302154189180701 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.2242215347406, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.138324355637447, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.04258261737494, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.936202908194378, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.818003231327086, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.686670257030096, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.540744730033438, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.37860525559271, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.30205387417777, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.221556314112354 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.135092614050738 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03899179338971 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.932213103766346 -8.813570115295938 -8.681744572551043 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.535271747278937 -8.372524163643265 -9.299436163492537 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.221556314112354, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.135092614050738, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03899179338971, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.932213103766346, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.813570115295938, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.681744572551043, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.535271747278937, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.372524163643265, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.299426131992243, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.220271750887047 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.133638283044865 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03737587004985 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.930417633388723 -8.811575148209693 -8.679527942455215 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.532808824950239 -8.369787583278045 -9.298248123877487 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220271750887047, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.133638283044865, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03737587004985, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930417633388723, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811575148209693, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.679527942455215, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.532808824950239, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.369787583278045, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29824712072746, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219686521443782 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132985324254575 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03665036028286 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929611511425398 -8.81067945713933 -8.67853273015481 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531703033505343 -8.368558926117048 -9.297718224107319 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219686521443782, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132985324254575, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03665036028286, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929611511425398, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81067945713933, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67853273015481, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531703033505343, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368558926117048, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297718123792313, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219423054248155 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132692312540769 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036324791711966 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92924976856885 -8.810277520632058 -8.678086134035619 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531206815595132 -8.368007572883478 -9.297480784304133 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219423054248155, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132692312540769, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036324791711966, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92924976856885, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810277520632058, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.678086134035619, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531206815595132, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368007572883478, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297480774272634, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.21930475346162 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132560840183856 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036178711315396 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929087457017106 -8.810097174463452 -8.677885749403837 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530984166004263 -8.367760184449182 -9.297374281663537 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.21930475346162, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132560840183856, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036178711315396, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929087457017106, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810097174463452, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677885749403837, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530984166004263, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367760184449182, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297374280660389, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219251665575635 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132501850940022 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036113167711136 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92901463079015 -8.8100162564335 -8.677795840481664 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530884267201849 -8.367649185779833 -9.29732649937288 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219251665575635, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132501850940022, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036113167711136, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92901463079015, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.8100162564335, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677795840481664, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530884267201849, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367649185779833, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297326499272563, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219227845298398 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.13247538369493 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036083759661032 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928981955178926 -8.809979950198807 -8.677755500220895 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530839444689882 -8.36759938298876 -9.297305060804039 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219227845298398, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.13247538369493, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036083759661032, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928981955178926, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809979950198807, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677755500220895, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530839444689882, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36759938298876, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297305060794008, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219217157564827 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132463508408371 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03607056489819 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92896729433132 -8.809963660368135 -8.67773740040904 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530819333787822 -8.367577037542024 -9.297295441811896 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219217157564827, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132463508408371, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03607056489819, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92896729433132, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809963660368135, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67773740040904, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67773740040904, 2: -10.306575694496093, 3: -9.581837339488898, 4: -10.91444596454015}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530819333787822, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367577037542024, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.360538852047924, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.311534911184001 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.235038790204745 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.150043100227496 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-9.055603444697214 -8.950670494108017 -8.719223280869548 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.576914756521719 -8.418794173913021 -9.380381420065955 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.311534911184001, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.235038790204745, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.150043100227496, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.055603444697214, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.950670494108017, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.719223280869548, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.576914756521719, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.418794173913021, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.325446607654333, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.239350475999235 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.154833862221402 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.060926513579332 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.95658501508815 -8.84065001676461 -8.700347847368963 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.555942052632183 -8.395491169591311 -9.31541542839935 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.239350475999235, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.154833862221402, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.060926513579332, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.95658501508815, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.84065001676461, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.700347847368963, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.555942052632183, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.395491169591311, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.30992194715818, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.226117460919777 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.14013051213309 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.044589457925655 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.938432731028506 -8.820480812253894 -8.688274574267377 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.54252730474153 -8.380585894157257 -9.303505714827802 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.226117460919777, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.14013051213309, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.044589457925655, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.938432731028506, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.820480812253894, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.688274574267377, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.54252730474153, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.380585894157257, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.302956366703686, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.222095550825983 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.13566172313998 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.039624136822203 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.932915707580225 -8.814350786200249 -8.682497129621026 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53610792180114 -8.373453246445711 -9.299885995743384 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.222095550825983, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.13566172313998, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.039624136822203, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.932915707580225, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.814350786200249, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.682497129621026, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53610792180114, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.373453246445711, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.299831060930977, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.220482552325869 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.133869502584297 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.037632780649218 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.930703089610244 -8.811892321789157 -8.679868872038917 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.533187635598797 -8.370208483998663 -9.298434297093284 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.220482552325869, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.133869502584297, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.037632780649218, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.930703089610244, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.811892321789157, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.679868872038917, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.533187635598797, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.370208483998663, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.298428803612039, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219777989259649 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.133086654732944 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03676294970327 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929736610781411 -8.810818456423789 -8.67868602525375 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.531873361393055 -8.368748179325618 -9.297800190333684 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219777989259649, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.133086654732944, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03676294970327, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929736610781411, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810818456423789, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67868602525375, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.531873361393055, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368748179325618, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29779964098556, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219463782460616 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132737536067353 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036375040074837 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92930560008315 -8.810339555647944 -8.678154946976003 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53128327441778 -8.368092527130866 -9.297517404214554 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219463782460616, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132737536067353, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036375040074837, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92930560008315, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.810339555647944, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.678154946976003, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53128327441778, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.368092527130866, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297517349279744, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219322996190003 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132581106877781 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.0362012298642 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92911247762689 -8.81012497514099 -8.67791662756004 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53101847506671 -8.36779830562968 -9.297390696571005 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219322996190003, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132581106877781, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.0362012298642, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92911247762689, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81012497514099, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67791662756004, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53101847506671, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.36779830562968, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297390691077524, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219259847580306 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132510941755896 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036123268617661 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.929025854019622 -8.81002872668847 -8.67780969517197 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530899661302186 -8.367666290335762 -9.297333862822274 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219259847580306, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132510941755896, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036123268617661, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.929025854019622, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.81002872668847, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67780969517197, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530899661302186, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367666290335762, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297333862272929, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219231516076068 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132479462306742 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036088291451934 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928986990502151 -8.80998554500239 -8.677761716554466 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530846351727185 -8.367607057474649 -9.297308364468465 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219231516076068, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132479462306742, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036088291451934, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928986990502151, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.80998554500239, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677761716554466, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530846351727185, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367607057474649, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297308364413524, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219218804532485 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132465338369428 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036072598188253 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928969553542503 -8.809966170602783 -8.677740189547162 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530822432830178 -8.367580480922419 -9.297296924079236 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219218804532485, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132465338369428, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036072598188253, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928969553542503, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809966170602783, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677740189547162, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530822432830178, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367580480922419, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297296924073748, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219213101156098 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132459001284554 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036065556982837 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92896172998093 -8.809957477756587 -8.677730530839504 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530811700932782 -8.367568556591978 -9.297291791040493 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219213101156098, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132459001284554, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036065556982837, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92896172998093, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809957477756587, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677730530839504, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530811700932782, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367568556591978, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297291791039939, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219210542175988 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.13245615797332 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036062397748134 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.92895821972015 -8.809953577466832 -8.677726197185255 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530806885761393 -8.367563206401549 -9.297289487958391 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219210542175988, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.13245615797332, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036062397748134, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.92895821972015, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809953577466832, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677726197185255, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530806885761393, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367563206401549, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297289487958334, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219209394016977 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132454882241083 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036060980267871 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928956644742078 -8.8099518274912 -8.67772425276799 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530804725297765 -8.367560805886406 -9.297288454615279 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219209394016977, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132454882241083, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036060980267871, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928956644742078, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.8099518274912, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67772425276799, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530804725297765, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367560805886406, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297288454615273, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208878862798 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132454309847557 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036060344275063 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955938083403 -8.809951042314895 -8.67772338034988 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530803755944312 -8.367559728827011 -9.297287990976521 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208878862798, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132454309847557, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036060344275063, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955938083403, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809951042314895, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67772338034988, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530803755944312, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367559728827011, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287990976521, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208647724235 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132454053026926 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036060058918805 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955621020895 -8.809950690023218 -8.677722988914685 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530803321016316 -8.367559245573684 -9.297287782951809 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208647724235, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132454053026926, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036060058918805, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955621020895, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950690023218, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722988914685, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530803321016316, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367559245573684, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29728778295181, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208544017341 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453937797045 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059930885605 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955478761782 -8.809950531957536 -8.67772281328615 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.5308031258735 -8.367559028748335 -9.297287689615608 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208544017341, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453937797045, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059930885605, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955478761782, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950531957536, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.67772281328615, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.5308031258735, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367559028748335, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287689615608, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208497486296 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453886095883 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.03605987343987 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955414933187 -8.809950461036875 -8.677722734485416 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530803038317128 -8.367558931463476 -9.297287647737667 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208497486296, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453886095883, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.03605987343987, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955414933187, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950461036875, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722734485416, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530803038317128, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558931463476, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287647737663, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208476608811 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.13245386289868 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059847665202 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955386294668 -8.809950429216297 -8.677722699129221 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530802999032469 -8.367558887813855 -9.297287628947933 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208476608811, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.13245386289868, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059847665202, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955386294668, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950429216297, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722699129221, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530802999032469, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558887813855, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287628947936, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208467241545 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453852490606 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059836100673 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955373445191 -8.8099504149391 -8.677722683265666 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530802981406293 -8.367558868229214 -9.297287620517391 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208467241545, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453852490606, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059836100673, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955373445191, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.8099504149391, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722683265666, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530802981406293, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558868229214, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29728762051739, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208463038647 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.13245384782072 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059830911912 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955367679903 -8.809950408533224 -8.677722676148028 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530802973497806 -8.367558859442008 -9.297287616734785 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208463038647, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.13245384782072, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059830911912, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955367679903, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950408533224, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722676148028, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530802973497806, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558859442008, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287616734787, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.2192084611529 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453845725445 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059828583827 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955365093142 -8.809950405659047 -8.677722672954495 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53080296994944 -8.367558855499379 -9.297287615037614 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.2192084611529, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453845725445, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059828583827, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955365093142, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950405659047, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722672954495, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53080296994944, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558855499379, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.29728761503761, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.219208460306803 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453844785339 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059827539264 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955363932516 -8.809950404369463 -8.677722671521625 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.530802968357362 -8.3675588537304 -9.297287614276122 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.219208460306803, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453844785339, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059827539264, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955363932516, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950404369463, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722671521625, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.530802968357362, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.3675588537304, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.297287614276124, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.21920845992718 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.132453844363532 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.036059827070591 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.928955363411768 -8.809950403790854 -8.677722670878726 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.53080296764303 -8.367558852936702 -9.297287613934463 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.21920845992718, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.132453844363532, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.036059827070591, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955363411768, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.928955363411768, 3: -10.02375919684575, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.809950403790854, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.677722670878726, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.53080296764303, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.367558852936702, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.36053172868036, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.311531557655544 -9.366896919977998 -8.57803018725187 -8.420033543995388 -9.224683597456638 \n",
      "-9.235035064061712 -9.294970573588841 -9.47233662995791 -9.77765264737064 -9.427744915798616 \n",
      "-9.150038960068573 -9.618210077281795 -9.067153058158357 -8.797555961324866 -9.364169107420485 \n",
      "-8.962565878762797 -8.847295420847551 -8.719217134275057 -8.663570523529504 -7.9340199705408025 \n",
      "-9.208317708371364 -9.116966870763978 -8.576907926972286 -8.418786585524762 -9.380378401889988 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.000358888701657, 1: -9.311531557655544, 2: -9.96801291695827, 3: -415.8787828223711, 4: -197.44562928994208}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.38171789276535, 1: -9.235035064061712, 2: -9.791436765711792, 3: -12.105130373166254, 4: -11.510007098506755}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.804361478878507, 1: -9.150038960068573, 2: -9.924938881140607, 3: -10.868668503560643, 4: -11.459267490648672}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -8.962565878762797, 3: -9.165079227864032, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -8.847295420847551, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.719217134275057, 2: -10.306575694496093, 3: -9.581837339488898, 4: -9.057749183199794}, Best action: 1, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.400093909076153, 2: -9.546017787070763, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843418037723378, 3: -9.116966870763978, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.208317708371364, 1: -10.459590020133016, 2: -9.4099848001925, 3: -10.031029956859639, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.475524159130867, 3: -9.165079227864032, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.49691657081804, 3: -9.165079227864032, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.536850572523864, 3: -9.24022209735627, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.569556519920933, 3: -9.370144118708348, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.593958427273888, 3: -9.523765968155384, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.6105636812085, 3: -9.671165163351612, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.538789405216063, 2: -9.5597413536746, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843418037723378, 3: -9.457779488857362, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.408092805820559, 1: -10.459590020133016, 2: -9.4099848001925, 3: -10.031029956859639, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.57706932568342, 3: -9.516448479882184, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.620138035160451, 2: -9.7064581322296, 3: -9.879418677365559, 4: -14.594944059759277}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.353438358771283, 1: -10.459590020133016, 2: -9.4099848001925, 3: -10.031029956859639, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.438298874120784, 2: -9.393710297560157, 3: -8.639257134590297, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.135558003160371, 2: -9.158846346078718, 3: -7.707934170454124, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.302649602134265, 2: -9.288474674985428, 3: -8.428244655936322, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.405772470258283, 2: -9.36847657304059, 3: -9.0142521155047, 4: -14.594944059759277}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.463979897089846, 2: -9.413633430216361, 3: -9.433739766800661, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.35318954533209, 2: -9.51349679244416, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10.207998151457927, 1: -9.97553744423881, 2: -9.843418037723378, 3: -9.27352192914742, 4: -15.639814222402155}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.237918270637735, 1: -10.459590020133016, 2: -9.4099848001925, 3: -10.031029956859639, 4: -15.446958008227519}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.72084354025623, 1: -9.494106081025667, 2: -9.455162492910956, 3: -9.701871261346467, 4: -14.594944059759277}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.672272587408575, 1: -9.64057482915307, 2: -9.532414171283643, 3: -9.690497393082847, 4: -9.873512464627483}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.1604377405208, 1: -8.719217134275057, 2: -10.306575694496093, 3: -9.559936943099391, 4: -9.057749183199794}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9.14440557338448, 1: -8.81446080704826, 2: -8.576907926972286, 3: -9.859070547352376, 4: -10.527250005942374}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.936070728930694, 1: -8.689219679405543, 2: -8.418786585524762, 3: -8.948487169617962, 4: -11.254263287166063}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -9.70307804190604, 1: -9.619831969550678, 2: -9.742289177669566, 3: -9.733997061611507, 4: -9.584948264403135}, Best action: 4, Actual action: 4\n",
      "[317, 35, 22, 7, 8, 8, 21, 86, 20, 7, 8, 29, 24, 57, 65, 15, 61, 232, 19, 13, 20, 12, 12, 8, 8, 8, 8, 8, 12, 12, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 61, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 34]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TDlambda import TDlambda\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TDlambda(0.9, 0.01, 0.9, 1, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 317)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 35)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 86)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 57)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 65)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 232)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
