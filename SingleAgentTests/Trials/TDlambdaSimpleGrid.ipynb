{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{TD} (\\lambda)$ in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8820125, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.000930625, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0748577944724897, 1: -1.600548344019141, 2: -1.4594979951562501, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.07613141155038, 1: -1.6025002475867889, 2: -1.4691370251199438, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076146781751127, 1: -1.6025238034500024, 2: -1.4692533503703817, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469978515223, 1: -1.6025241346383483, 2: -1.469254985868387, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076146998105948, 1: -1.6025241350282726, 2: -1.4692549877939394, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982204397, 1: -1.6025241352037385, 2: -1.469254988660438, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076146998225592, 1: -1.6025241352116344, 2: -1.4692549886994304, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982487766, 1: -1.6025241352471662, 2: -1.4692549888748963, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982582708, 1: -1.6025241352617166, 2: -1.4692549889467497, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468344932505, 1: -1.6025238842808434, 2: -1.4692537495350284, 3: -1.4427207264678992, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468344395246, 1: -1.602523884198505, 2: -1.4692537491284197, 3: -1.4392138013659186, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468344910456, 1: -1.6025238842774647, 2: -1.469253749518344, 3: -1.4425768264440435, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345121434, 1: -1.6025238843097986, 2: -1.469253749678018, 3: -1.4439539852135357, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076146998259763, 1: -1.6025241352640027, 2: -1.635160353114549, 3: -1.8960129891619162, 4: -2.5600971730008326}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611647450314117, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611647450313915, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187378961, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611641873799118, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669789785, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669836735, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.559496254802825, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5594962548260096, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448975188753, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976333668, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976493562, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976565514, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.559496254831794, 1: -1.6235229951562502, 2: -1.5729530625000003, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561133966984864, 1: -1.6354999885938577, 2: -1.632098709105469, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6362975030580333, 2: -1.6360370521384353, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.6363581252751986, 2: -1.636336421112092, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.6363583571642646, 2: -1.6363375662432817, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.6363584615143443, 2: -1.6363380815523172, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.6363584662100978, 2: -1.6363381047412238, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.6363584873409889, 2: -1.6363382090913035, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.56116474503144, 1: -1.636358495994089, 2: -1.636338251822661, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982598584, 1: -1.7966137373351259, 2: -1.6755800637123721, 3: -1.8984163072605416, 4: -2.5901542802936053}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -1.6025238843210687, 2: -1.469253749733673, 3: -2.4301303432413186, 4: -3.135848212662031}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.4691865932996981, 3: -1.54999530068912, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.4691865932996981, 3: -1.5499953006891143, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.4691865932996981, 3: -1.5499953006891198, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.4691865932996981, 3: -1.549995300689122, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.4655472329596493, 3: -1.5974978853101052, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.4655472329596493, 3: -1.5974978853101052, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.4655472329596493, 3: -1.5974978853101052, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.4655472329596493, 3: -1.5974978853101052, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.5618352039467738, 2: -2.0868153165741794, 3: -1.6188740483895472, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.5618352039467738, 2: -2.0868153165741794, 3: -1.6188740483895472, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.5618352039467738, 2: -2.0868153165741794, 3: -1.6188740483895472, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.5618352039467738, 2: -2.0868153165741794, 3: -1.6188740483895472, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976594972, 1: -1.5618696036052533, 2: -2.0873626911123977, 3: -1.619712936570725, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976594972, 1: -1.56186960338618, 2: -2.0873626876264586, 3: -1.6197129312282896, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976594972, 1: -1.561869603561646, 2: -2.0873626904185096, 3: -1.619712935507295, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4707448976594972, 1: -1.5618696036334994, 2: -2.0873626915618546, 3: -1.6197129372595478, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.646395845347047, 2: -2.0868153165741794, 3: -1.6188740483895472, 4: -2.623528135824133}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.6484505924957376, 3: -1.5974978853101052, 4: -2.567774383232338}, Best action: 3, Actual action: 3\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.6442703867307442, 3: -1.5499953006891223, 4: -2.56683093318664}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -1.6025238843210687, 2: -1.6442026202953073, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6363072681711077, 2: -1.63608527491905, 3: -1.453639924137886, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6363072681711075, 2: -1.6360852749190484, 3: -1.4536399240321634, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6363072681711077, 2: -1.6360852749190495, 3: -1.453639924111123, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6363072681711077, 2: -1.63608527491905, 3: -1.453639924143457, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965813622184, 1: -1.6363584998120924, 2: -1.6363382706769984, 3: -1.9643352593240997, 4: -3.414569914634683}, Best action: 2, Actual action: 2\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.561164187380153, 1: -1.6363072681711077, 2: -1.63608527491905, 3: -2.3707979916704, 4: -3.097846309920767}, Best action: 0, Actual action: 0\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -1.6995777539237495, 2: -1.6442028384572662, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 2, Actual action: 2\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.602510285143189, 2: -1.6442857481892177, 3: -2.39980745429641, 4: -2.5668423563511977}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669848643, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -1.5541379658714014, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669848643, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -1.5541379658713215, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669848643, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -1.5541379658713812, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669848643, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -1.5541379658714056, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7220905209487634, 1: -1.6363072681711077, 2: -1.63608527491905, 3: -2.9172129208982938, 4: -3.5041741116646103}, Best action: 2, Actual action: 2\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5611339669848643, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -2.3806428692715764, 4: -3.1649534920589693}, Best action: 0, Actual action: 0\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.7032806837148389, 2: -1.644285756256965, 3: -2.4010914529917806, 4: -2.566842362350576}, Best action: 2, Actual action: 2\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.601773314674329, 2: -1.6493830661764515, 3: -2.6982415885334095, 4: -2.568467793973159}, Best action: 1, Actual action: 1\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5594962548318423, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -1.5993620846421386, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5594962548318423, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -1.5993620846421386, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5594962548318423, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -1.5993620846421386, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5594962548318423, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -1.5993620846421386, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.65694050503189, 2: -1.6493830664980977, 3: -2.698242533145053, 4: -2.5684677942123435}, Best action: 2, Actual action: 2\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -1.7055335154595836, 2: -2.0868153165741794, 3: -2.851195792261111, 4: -2.6675043857615686}, Best action: 1, Actual action: 1\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072554089506, 1: -1.5618696036675104, 2: -2.087362692103047, 3: -1.6197129380889612, 4: -3.511148059921115}, Best action: 1, Actual action: 1\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.5564377953125001, 2: -2.000930625, 3: -1.4872500000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.559800820390625, 2: -2.0544437812500003, 3: -1.5692625000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.5613141816757814, 2: -2.0785247015625004, 3: -1.6061681250000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4708213414833562, 1: -1.561933903122053, 2: -2.088385838430469, 3: -1.6212809784375002, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.912907256101074, 1: -1.7590897884554393, 2: -2.087362692103047, 3: -1.6197129380889612, 4: -3.511148060435796}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961961826759053, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -1.5993620846421386, 4: -3.551519470841833}, Best action: 3, Actual action: 3\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7331665174485718, 1: -1.6357450553756667, 2: -1.6333089154353906, 3: -2.9293982553642484, 4: -3.57302171604213}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.896199265598376, 1: -1.6295753676342022, 2: -1.60284132165038, 3: -2.38291642996688, 4: -3.5515217633800553}, Best action: 2, Actual action: 2\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.912907256101117, 1: -1.7591894421067553, 2: -2.087362692103047, 3: -2.8575395357107656, 4: -3.511148060435828}, Best action: 1, Actual action: 1\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9522549344477893, 1: -1.5622332814964492, 2: -2.093149609545691, 3: -1.6285817770815185, 4: -3.540453454177186}, Best action: 1, Actual action: 1\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4716331721722795, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.80 -1.71 -1.71 -1.71 -2.05 \n",
      "-1.64 -1.64 -1.64 -1.63 -2.09 \n",
      "0.00 0.00 0.00 0.00 -1.06 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.0761469982598584, 1: -1.7966137384418674, 2: -2.3363806340958444, 3: -1.898416307261756, 4: -2.5901542803087922}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -1.6363584998120924, 2: -2.855732596564863, 3: -1.964335259408015, 4: -3.4145699156841762}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.551234194767138, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6302490453125003, 2: -1.6061681250000002, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.636112899914346, 2: -1.6351254316757815, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.636312862232655, 2: -1.636112899914346, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.636315654809859, 2: -1.636126690419057, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.636328221407277, 2: -1.6361887476902564, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.6363333674289195, 2: -1.6362141601428126, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360422195999256, 2: -1.6347763930860517, 3: -1.4452162281557006, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360342244918977, 2: -1.6347369110710996, 3: -1.4404615160485648, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360398794607358, 2: -1.6347648368431393, 3: -1.4438245411266897, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360421951704749, 2: -1.6347762724467896, 3: -1.4452016998961819, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.6363343672752018, 2: -1.651948948313809, 3: -1.904952718350039, 4: -2.6719019314010795}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636298701149373, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636298692399568, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356510497500054, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511178384323, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446073781409, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446754665678, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.90 -1.71 -1.71 -1.71 -2.05 \n",
      "-1.80 -1.64 -1.64 -1.63 -2.09 \n",
      "-1.64 -1.63 0.00 0.00 -1.06 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2.0761469982598584, 1: -2.478744286188206, 2: -2.3363806340958444, 3: -1.898416307261756, 4: -2.5901542803087922}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982598584, 1: -2.478744286188206, 2: -2.3363806340958444, 3: -1.898416307261756, 4: -2.5901542803087922}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982598584, 1: -2.478744286188206, 2: -2.3363806340958444, 3: -2.6275588396081977, 4: -2.5901542803087922}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761469982598584, 1: -2.478744286188206, 2: -2.3363806340958444, 3: -2.942029203375703, 4: -2.5901542803087922}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.789293768416471, 1: -2.478744286188206, 2: -2.3363806340958444, 3: -3.407357470902893, 4: -2.5901542803087922}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -1.7093126417732944, 2: -2.4121798222552453, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7335103600895736, 1: -1.6363072681711077, 2: -2.8555416947450314, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 1, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -3.285074655849884, 2: -2.4121798222552453, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0761468345194984, 1: -3.3397584811959637, 2: -2.4121798222552453, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.789293619412744, 1: -3.484170705136846, 2: -2.4121798222552453, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -1.713012967434768, 2: -2.4113561388641886, 3: -2.40109881722248, 4: -2.5668423623849845}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7331665314190556, 1: -1.6357450553756667, 2: -2.8304784699419914, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6189882054143323, 3: -1.5505590390831232, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6189882054143323, 3: -1.5505590390831232, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6189882054143323, 3: -1.5505590390831232, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6189882054143323, 3: -1.5505590390831232, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360430107942219, 2: -1.634780300218381, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6189882054143323, 3: -2.379227947085201, 4: -3.161772217001782}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.551234194767138, 3: -1.5977515675874059, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.551234194767138, 3: -1.5977515675874059, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.551234194767138, 3: -1.5977515675874059, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.551234194767138, 3: -1.5977515675874059, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0562228489150014, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.48 -2.43 -2.08 -1.71 -2.05 \n",
      "-1.80 -1.64 -1.71 -1.63 -2.09 \n",
      "-1.64 -1.64 -1.63 -1.60 -1.01 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -2.478744286188206, 2: -3.3390468961786763, 3: -3.622673781554544, 4: -2.5901542803087922}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -1.7999863386925894, 2: -2.855732596564863, 3: -1.964335259408015, 4: -3.4145699156841762}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363522218046496, 1: -1.7999463076257822, 2: -1.6928834496308032, 3: -1.9073866301292581, 4: -2.7023416586810303}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -2.405443933531025, 2: -2.855732596564863, 3: -1.964335259408015, 4: -3.4145699156841762}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -2.8637214857543634, 2: -2.855732596564863, 3: -1.964335259408015, 4: -3.4145699156841762}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -3.0101714756516524, 2: -2.855732596564863, 3: -2.6875450860612933, 4: -3.4145699156841762}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7106965827735383, 1: -3.070142746514592, 2: -2.855732596564863, 3: -3.6418204523302946, 4: -3.4145699156841762}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.1740758111476666, 2: -3.3390468961786763, 3: -3.622673781554544, 4: -2.5901542803087922}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.178712617618493, 2: -3.3390468961786763, 3: -3.622673781554544, 4: -2.5901542803087922}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.181204567316529, 2: -3.3390468961786763, 3: -3.622673781554544, 4: -3.257040395081001}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6796448441255514, 1: -3.080560488587849, 2: -2.855732596564863, 3: -4.061642278906905, 4: -3.4145699156841762}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -1.6363072681711077, 2: -2.8555416947450314, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.6360430107942219, 2: -2.3986495707107003, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6358064442541018, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: -1.445210134116774, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: -1.4404585051904184, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: -1.4438215302685433, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: -1.4451986890380355, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6362508049614557, 2: -1.6519073717866688, 3: -1.9049311459049705, 4: -2.671632135531626}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.34 -2.43 -2.08 -1.71 -2.05 \n",
      "-2.87 -2.42 -1.71 -1.63 -2.09 \n",
      "-1.69 -1.64 -1.63 -1.60 -1.01 \n",
      "-1.62 -1.63 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -3.5359878470806017, 2: -3.3390468961786763, 3: -3.622673781554544, 4: -4.278650501268003}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -2.8507991489631848, 3: -2.4301303433701937, 4: -3.135848212757832}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.5359878470806017, 2: -3.2023102677477246, 3: -3.622673781554544, 4: -4.278650501268003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -2.8507991489631848, 3: -3.7368843512126766, 4: -3.135848212757832}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -2.4286588854692077, 2: -2.4113561388641886, 3: -2.40109881722248, 4: -2.5668423623849845}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.076137961055931, 1: -2.4286588854692077, 2: -2.4113561388641886, 3: -2.40109881722248, 4: -2.5668423623849845}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7892855445608973, 1: -2.4286588854692077, 2: -2.4113561388641886, 3: -2.40109881722248, 4: -2.5668423623849845}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -3.2554110189275507, 3: -3.7278429683104206, 4: -3.135848212757832}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -3.371964278574014, 3: -3.751445003388829, 4: -3.135848212757832}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -3.397296859754318, 3: -3.7565748510778407, 4: -3.753621873609627}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.32647576233696, 1: -2.4286588854692077, 2: -2.4113561388641886, 3: -4.0135391123952475, 4: -2.5668423623849845}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -1.7117537109752015, 2: -2.769938714752852, 3: -2.698242564529209, 4: -2.5684677942202896}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -1.6295753676342022, 2: -2.644721561342924, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.8878936732872895, 3: -1.5977515675874059, 4: -2.7968054177652304}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -1.6328451115964024, 2: -1.6718573038660063, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.5692625000000002, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6302490453125003, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.5692625000000002, 3: -2.2205017267031257, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.5692625000000002, 3: -1.965250863351563, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.5692625000000002, 3: -2.147500863351563, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.5692625000000002, 3: -2.222132238351563, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.05692625, 3: -2.2246646331410163, 4: -2.1896023064062495}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9, 3: -1.7561102625, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9, 3: -1.413004035909375, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9, 3: -1.595254035909375, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.54 -3.49 -2.43 -2.08 -2.05 \n",
      "-2.87 -2.42 -1.71 -2.64 -2.09 \n",
      "-1.69 -1.64 -1.63 -1.62 -1.01 \n",
      "-1.62 -1.64 -1.62 -0.99 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -3.5359878470806017, 2: -3.8460918354911797, 3: -3.622673781554544, 4: -4.278650501268003}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -3.0811550689926914, 2: -2.865431951319563, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -2.423973500269951, 2: -2.8555416947450314, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362383737135733, 1: -1.7141495323709313, 2: -2.3986495707107003, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -2.4677504327349897, 2: -2.8555416947450314, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.062501687886699, 1: -1.7141495323709313, 2: -2.3986495707107003, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.6351254316757815, 2: -1.6703821321496406, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.443803878125, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.4547916283941407, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.443803878125, 3: -1.4425045458267773, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.443803878125, 3: -1.43910571104542, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.443803878125, 3: -1.4424687361235449, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.443803878125, 3: -1.443845894893037, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.323225, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.0443803878125, 3: -1.4438541771944626, 4: -2.1056375554836326}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.323225, 3: -1.745948114128125, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.323225, 3: -1.4097750132642117, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.323225, 3: -1.5920250132642118, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.323225, 3: -1.6666563882642118, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.62 -3.49 -2.43 -2.08 -2.05 \n",
      "-3.08 -2.86 -1.71 -2.64 -2.09 \n",
      "-1.69 -2.40 -1.63 -1.62 -1.01 \n",
      "-1.62 -1.64 -1.62 -0.99 0.00 \n",
      "-1.64 -1.44 -1.03 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -3.8337800156879043, 2: -3.8460918354911797, 3: -3.622673781554544, 4: -4.278650501268003}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.8337800156879043, 2: -3.8460918354911797, 3: -3.622673781554544, 4: -4.278650501268003}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.8337800156879043, 2: -3.8460918354911797, 3: -4.196633141214635, 4: -4.278650501268003}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -3.0811550689926914, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -1.7999463076257822, 2: -1.6928834496308032, 3: -1.9073866301292581, 4: -2.7023416586810303}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9781107580521615, 1: -2.431072889812812, 2: -2.3986495707107003, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6349890119459254, 1: -2.0706372382605682, 2: -1.6718573038660063, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7331665314190556, 1: -1.7077541528677576, 2: -2.8304784699419914, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.446779765017476, 1: -2.0706372382605682, 2: -1.6718573038660063, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.6191249244403458, 2: -1.8878936732872895, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.99, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.85 -3.49 -2.43 -2.08 -2.05 \n",
      "-3.30 -2.86 -2.73 -2.64 -2.09 \n",
      "-1.80 -2.43 -2.07 -1.62 -1.01 \n",
      "-1.62 -1.64 -1.62 -1.00 0.00 \n",
      "-1.64 -1.44 -1.03 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -3.87975819010139, 2: -3.8460918354911797, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -3.490621047482062, 3: -3.7577442421868574, 4: -4.207396484804921}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -2.4286588854692077, 2: -3.070158630156814, 3: -4.021517053002881, 4: -2.5668423623849845}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7331665314190556, 1: -2.793418015831761, 2: -2.8304784699419914, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.356730778996356, 2: -3.070158630156814, 3: -4.021517053002881, 4: -2.5668423623849845}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.5904123748609655, 2: -3.070158630156814, 3: -4.021517053002881, 4: -2.5668423623849845}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.725881672806499, 2: -3.070158630156814, 3: -4.021517053002881, 4: -3.235826549770336}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -2.9173148451540483, 2: -2.769938714752852, 3: -2.698242564529209, 4: -2.5684677942202896}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0756570878250007, 1: -2.9173148451540483, 2: -2.769938714752852, 3: -2.698242564529209, 4: -2.5684677942202896}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7888479499207506, 1: -2.9173148451540483, 2: -2.769938714752852, 3: -2.698242564529209, 4: -2.5684677942202896}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.471066799585901, 1: -2.9173148451540483, 2: -2.769938714752852, 3: -2.698242564529209, 4: -2.5684677942202896}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074835283703147, 1: -2.9173148451540483, 2: -2.769938714752852, 3: -2.698242564529209, 4: -3.2373056927404633}, Best action: 3, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.798871870462701, 2: -2.644721561342924, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072561011182, 1: -2.1136234570544876, 2: -2.087362692103047, 3: -2.9524808725527487, 4: -3.511148060435829}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072561011182, 1: -2.1136234570544876, 2: -2.087362692103047, 3: -2.9524808725527487, 4: -3.511148060435829}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072561011182, 1: -2.1136234570544876, 2: -2.7995000498137728, 3: -2.9524808725527487, 4: -3.511148060435829}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0056222848915002, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.85 -3.53 -3.39 -2.70 -2.05 \n",
      "-3.30 -2.86 -2.79 -2.80 -1.92 \n",
      "-1.80 -2.43 -2.07 -1.62 -1.00 \n",
      "-1.62 -1.64 -1.62 -1.00 0.00 \n",
      "-1.64 -1.44 -1.03 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3.8525841913875936, 1: -3.87975819010139, 2: -4.262673537624715, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8525841913875936, 1: -3.87975819010139, 2: -4.262673537624715, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.40585161416271, 1: -3.87975819010139, 2: -4.262673537624715, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -3.304809697100513, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -1.7999463076257822, 2: -3.3050136629647877, 3: -1.9073866301292581, 4: -2.7023416586810303}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -1.6194179676335616, 2: -1.6895092388717934, 3: -1.907166917670102, 4: -2.699593823942802}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636112899914346, 1: -1.979751537527177, 2: -1.648049906020326, 3: -1.8960914076071633, 4: -2.561077913596039}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362987096858295, 1: -2.3871932456939766, 2: -1.6895092388717934, 3: -1.907166917670102, 4: -2.699593823942802}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -2.8896843795197786, 2: -3.3050136629647877, 3: -1.9073866301292581, 4: -2.7023416586810303}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -2.978286522994798, 2: -3.3050136629647877, 3: -1.9073866301292581, 4: -2.7023416586810303}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -3.0081528184246413, 2: -3.3050136629647877, 3: -2.635721833417625, 4: -2.7023416586810303}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -3.0203830664031623, 2: -3.3050136629647877, 3: -3.5967601341566247, 4: -2.7023416586810303}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -3.0191525531542327, 2: -3.3050136629647877, 3: -3.3518804933182107, 4: -2.7023416586810303}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -3.021606773955577, 2: -3.3050136629647877, 3: -3.8402853998839093, 4: -3.3591309093997372}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.089990687633709, 1: -3.0203710264435966, 2: -1.6895092388717934, 3: -1.907166917670102, 4: -2.699593823942802}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6356511350982714, 1: -1.7133617359387525, 2: -1.6703821321496406, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9781107580521615, 1: -2.431072889812812, 2: -3.0493588278796775, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.032734154258205, 1: -1.7133617359387525, 2: -1.6703821321496406, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.6227756562500002, 2: -1.6266259067217188, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.94 -3.53 -3.39 -2.70 -2.05 \n",
      "-3.24 -2.86 -2.79 -2.80 -1.92 \n",
      "-3.14 -2.44 -2.07 -1.62 -1.00 \n",
      "-1.91 -1.71 -1.63 -1.00 0.00 \n",
      "-1.65 -1.44 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.554055912903553, 1: -3.9350297011344884, 2: -4.262673537624715, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -3.2384942025959216, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1379325228305777, 1: -3.2106455411075987, 2: -3.3050136629647877, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -3.7655747637523604, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -4.144322826272859, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -3.4145699156841762}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -4.264342289559515, 2: -3.4413905077884483, 3: -4.085603117047533, 4: -4.0072586232726}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -2.884057606055049, 2: -2.8555416947450314, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -2.793418015831761, 2: -2.8304784699419914, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.0706372382605682, 2: -2.4906088247849407, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.885368178125, 2: -1.6266259067217188, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.26 -3.53 -3.39 -2.70 -2.05 \n",
      "-3.71 -2.88 -2.83 -2.80 -1.92 \n",
      "-3.21 -2.44 -2.49 -1.62 -1.00 \n",
      "-1.91 -1.71 -1.63 -1.00 0.00 \n",
      "-1.65 -1.44 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.554055912903553, 1: -4.389710362686361, 2: -4.262673537624715, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.533458403846014, 2: -3.825423948849012, 3: -3.7577442421868574, 4: -4.207396484804921}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -2.884057606055049, 2: -3.57070260410937, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9781107580521615, 1: -2.8692887648846983, 2: -3.0493588278796775, 3: -2.44393078009719, 4: -3.146849082118449}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -3.2106455411075987, 2: -3.3050136629647877, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -1.907166917670102, 4: -2.699593823942802}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -1.907166917670102, 4: -2.699593823942802}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -2.6355218950797927, 4: -2.699593823942802}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -3.5965862877718795, 4: -2.699593823942802}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -3.348287154476191, 4: -2.699593823942802}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.0206877409421815, 2: -3.111254416640807, 3: -3.836875963316539, 4: -3.35663037978795}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -1.979751537527177, 2: -1.648049906020326, 3: -1.8960914076071633, 4: -2.561077913596039}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.6140201472376687, 3: -1.444109317269276, 4: -2.6628329559007646}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -1.979751537527177, 2: -2.2345335375901465, 3: -1.8960914076071633, 4: -2.561077913596039}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -1.979751537527177, 2: -2.7457945821689007, 3: -1.8960914076071633, 4: -2.561077913596039}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -1.979751537527177, 2: -2.8934883162652603, 3: -2.6254431809225185, 4: -2.561077913596039}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -1.979751537527177, 2: -2.906309593064155, 3: -2.829458010644301, 4: -2.561077913596039}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -2.701573899149731, 2: -2.9359088212804396, 3: -3.3004471016030172, 4: -2.561077913596039}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.48900597027788, 2: -2.945929742911484, 3: -3.4599020960064673, 4: -2.561077913596039}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9258566698019526, 2: -2.951489138807216, 3: -3.548364362660092, 4: -3.2305809013723956}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.6140201472376687, 3: -3.040525851712449, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.00323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.28 -3.57 -3.39 -2.70 -2.05 \n",
      "-3.71 -2.92 -2.83 -2.80 -1.92 \n",
      "-3.25 -2.87 -2.49 -1.62 -1.00 \n",
      "-3.09 -1.71 -1.63 -1.00 0.00 \n",
      "-2.62 -1.63 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.554055912903553, 1: -4.389710362686361, 2: -4.391145036575006, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.554055912903553, 1: -4.389710362686361, 2: -4.391145036575006, 3: -4.5578022791597785, 4: -4.278650501268003}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.554055912903553, 1: -4.389710362686361, 2: -4.391145036575006, 3: -4.5578022791597785, 4: -4.793571956153883}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.711866512494189, 1: -4.289665510307513, 2: -3.8789502327362726, 3: -4.085603117047533, 4: -4.410206991827844}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.554055912903553, 1: -4.345582911388929, 2: -4.391145036575006, 3: -4.5578022791597785, 4: -4.969882212376623}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.791108809474451, 1: -4.289665510307513, 2: -3.8789502327362726, 3: -4.085603117047533, 4: -4.410206991827844}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -3.7610355411060805, 2: -3.57070260410937, 3: -2.9195254383243268, 4: -3.5058937574355293}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.607519661674616, 1: -4.289665510307513, 2: -3.652710628316332, 3: -4.085603117047533, 4: -4.410206991827844}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2854742445254175, 1: -3.7610355411060805, 2: -3.57070260410937, 3: -4.150648152768662, 4: -3.5058937574355293}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.9840725720621557, 2: -3.825423948849012, 3: -3.7577442421868574, 4: -4.207396484804921}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.57356975799483, 1: -3.9840725720621557, 2: -3.825423948849012, 3: -3.7577442421868574, 4: -4.207396484804921}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.151948479775296, 1: -3.9840725720621557, 2: -3.825423948849012, 3: -3.7577442421868574, 4: -4.207396484804921}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.554055912903553, 1: -4.672009159791855, 2: -4.391145036575006, 3: -4.5578022791597785, 4: -5.269278160555515}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.153470950348571, 1: -3.9840725720621557, 2: -3.825423948849012, 3: -4.8326019038444405, 4: -4.207396484804921}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.782321434070867, 2: -3.39189592598966, 3: -4.021517053002881, 4: -4.133907798970157}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.5735323897012083, 2: -2.769938714752852, 3: -2.698242564529209, 4: -4.17218999716461}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.782321434070867, 2: -3.4247660698676254, 3: -4.021517053002881, 4: -4.133907798970157}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.5735323897012083, 2: -2.769938714752852, 3: -3.9438847730456974, 4: -4.17218999716461}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -2.424462983504743, 2: -2.0868153165741794, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.04959747057527, 1: -2.424462983504743, 2: -2.0868153165741794, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.765133698223496, 1: -2.424462983504743, 2: -2.0868153165741794, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9125988113582073, 1: -2.424462983504743, 2: -2.0868153165741794, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3773005818923885, 1: -2.424462983504743, 2: -2.7990019380825033, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072561011182, 1: -1.9236393710865063, 2: -2.809638619023187, 3: -2.9524808725527487, 4: -3.511148060435829}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.00056222848915, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.55 -3.98 -3.72 -3.26 -2.67 \n",
      "-4.09 -3.51 -2.83 -2.80 -1.90 \n",
      "-3.25 -2.87 -2.49 -1.62 -1.00 \n",
      "-3.09 -1.71 -1.63 -1.00 0.00 \n",
      "-2.62 -1.63 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4.554055912903553, 1: -4.677343833307812, 2: -4.640863177977999, 3: -4.5578022791597785, 4: -5.269864336921425}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.554055912903553, 1: -4.677343833307812, 2: -4.640863177977999, 3: -4.5578022791597785, 4: -5.269864336921425}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.044190880742233, 1: -4.677343833307812, 2: -4.640863177977999, 3: -4.5578022791597785, 4: -5.269864336921425}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.119660558246779, 1: -4.677343833307812, 2: -4.640863177977999, 3: -4.5578022791597785, 4: -5.269864336921425}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.439253619403122, 1: -4.677343833307812, 2: -4.640863177977999, 3: -5.047600074035399, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -3.9840725720621557, 2: -4.276880117188566, 3: -4.944975067475788, 4: -4.207396484804921}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -3.7610355411060805, 2: -3.57070260410937, 3: -4.302212284297792, 4: -3.5058937574355293}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -3.7610355411060805, 2: -3.57070260410937, 3: -4.302212284297792, 4: -3.5058937574355293}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -3.7610355411060805, 2: -3.57070260410937, 3: -4.302212284297792, 4: -4.0903633192663325}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.06559544207874, 2: -2.8304784699419914, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.798871870462701, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.621278594742671, 1: -1.8678624924440348, 2: -1.8878936732872895, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.493122848787834, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0815573669924126, 1: -1.8678624924440348, 2: -1.8878936732872895, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.68 -4.21 -3.72 -3.26 -2.67 \n",
      "-4.09 -3.76 -2.93 -2.66 -1.90 \n",
      "-3.25 -2.87 -2.49 -1.89 -1.00 \n",
      "-3.09 -1.71 -1.63 -1.00 0.00 \n",
      "-2.62 -1.63 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -4.677343833307812, 2: -4.801803768717918, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.289665510307513, 2: -4.611728890180238, 3: -4.085603117047533, 4: -4.410206991827844}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.289665510307513, 2: -4.611728890180238, 3: -4.085603117047533, 4: -4.410206991827844}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.289665510307513, 2: -4.611728890180238, 3: -4.617898836513255, 4: -4.410206991827844}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -3.2479666019841167, 2: -3.3050136629647877, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.091554709848942, 1: -3.1239285537592196, 2: -3.111254416640807, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -3.7289559751760546, 2: -3.3050136629647877, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9781107580521615, 1: -2.8692887648846983, 2: -3.0493588278796775, 3: -3.7618104437013073, 4: -3.146849082118449}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -1.7133617359387525, 2: -2.4996531296212137, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: -1.9725820304765627, 2: -1.8727110759737668, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -2.3945619506102815, 2: -2.4996531296212137, 3: -2.3626349955570984, 4: -3.0864142916065656}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.056063629761972, 1: -3.1239285537592196, 2: -3.111254416640807, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -3.2611127957318677, 2: -2.4996531296212137, 3: -3.6563795770347634, 4: -3.0864142916065656}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6285446924364495, 1: -1.885368178125, 2: -1.872257590672172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.5351649660483533, 2: -2.4906088247849407, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8967457492444033, 2: -1.8878936732872895, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.000056222848915, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.80 -4.21 -3.72 -3.26 -2.67 \n",
      "-4.38 -3.76 -2.93 -2.66 -1.90 \n",
      "-3.74 -2.98 -2.54 -1.90 -1.00 \n",
      "-3.12 -3.09 -1.87 -1.00 0.00 \n",
      "-2.62 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -4.968825803426917, 2: -4.801803768717918, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.452114055506095, 2: -4.276880117188566, 3: -4.944975067475788, 4: -4.207396484804921}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.452114055506095, 2: -4.276880117188566, 3: -4.944975067475788, 4: -4.207396484804921}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.452114055506095, 2: -4.276880117188566, 3: -4.944975067475788, 4: -4.728730801172478}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.782321434070867, 2: -3.7196388043260655, 3: -4.021517053002881, 4: -4.133907798970157}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.5735323897012083, 2: -3.263707417322957, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5137510994481995, 1: -2.6911227097826567, 2: -3.472831654407496, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5137510994481995, 1: -2.6911227097826567, 2: -3.472831654407496, 3: -2.851195797588738, 4: -2.667504385834673}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5137510994481995, 1: -2.6911227097826567, 2: -3.472831654407496, 3: -2.851195797588738, 4: -3.3274289911095525}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9129072561011182, 1: -1.9025916396467564, 2: -2.809638619023187, 3: -2.9524808725527487, 4: -3.511148060435829}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000056222848914, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.97 -4.45 -3.78 -3.57 -2.71 \n",
      "-4.38 -3.76 -2.93 -2.66 -1.90 \n",
      "-3.74 -2.98 -2.54 -1.90 -1.00 \n",
      "-3.12 -3.09 -1.87 -1.00 0.00 \n",
      "-2.62 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -4.968825803426917, 2: -5.066670658106169, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.37712229115151, 2: -4.611728890180238, 3: -4.991818546220339, 4: -4.410206991827844}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -3.7432968385963044, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9781107580521615, 1: -3.288558926536298, 2: -3.0493588278796775, 3: -3.7618104437013073, 4: -3.146849082118449}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -3.7610355411060805, 2: -3.882974453223112, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.244249864101141, 1: -3.288558926536298, 2: -3.0493588278796775, 3: -3.7618104437013073, 4: -3.146849082118449}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.5351649660483533, 2: -2.683168066774061, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.885368178125, 2: -1.872257590672172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.99999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.05 -4.45 -3.78 -3.57 -2.71 \n",
      "-4.41 -3.87 -2.93 -2.66 -1.90 \n",
      "-3.95 -3.15 -2.68 -1.90 -1.00 \n",
      "-3.12 -3.09 -1.89 -1.00 0.00 \n",
      "-2.62 -1.87 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.047402456142556, 2: -5.066670658106169, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.610568557745156, 2: -4.611728890180238, 3: -4.991818546220339, 4: -4.410206991827844}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.610568557745156, 2: -4.611728890180238, 3: -4.991818546220339, 4: -4.410206991827844}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.610568557745156, 2: -4.611728890180238, 3: -4.991818546220339, 4: -4.913288362563338}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -4.278376592745186, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -4.278376592745186, 3: -3.977163501727681, 4: -3.9522412291127598}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -4.278376592745186, 3: -3.977163501727681, 4: -4.496539518492611}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -4.278376592745186, 3: -3.977163501727681, 4: -4.604733979638914}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.175306140903281, 2: -4.278376592745186, 3: -4.519218786572189, 4: -4.9584250529999565}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.1239285537592196, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.6184979424635504, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8727110759737668, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.07 -4.45 -3.78 -3.57 -2.71 \n",
      "-4.61 -3.87 -2.93 -2.66 -1.90 \n",
      "-3.96 -3.15 -2.68 -1.90 -1.00 \n",
      "-3.37 -3.09 -1.89 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.066670658106169, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.452114055506095, 2: -4.517698920687285, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -3.8697496010629417, 2: -3.882974453223112, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.288558926536298, 2: -3.3241708198125544, 3: -3.7618104437013073, 4: -3.146849082118449}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.288558926536298, 2: -3.3241708198125544, 3: -3.7618104437013073, 4: -3.146849082118449}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.288558926536298, 2: -3.3241708198125544, 3: -3.7618104437013073, 4: -3.7636326647277887}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -3.299599611355283, 2: -3.1613460765357915, 3: -3.846437925792371, 4: -3.0864142916065656}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -3.299599611355283, 2: -3.1613460765357915, 3: -3.846437925792371, 4: -3.0864142916065656}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.229931298040554, 1: -3.299599611355283, 2: -3.1613460765357915, 3: -3.846437925792371, 4: -3.708637005361975}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.885368178125, 2: -1.8972217090672172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.09 -4.52 -3.78 -3.57 -2.71 \n",
      "-4.61 -3.88 -2.93 -2.66 -1.90 \n",
      "-3.96 -3.32 -2.68 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.094945273689921, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.634482550882463, 2: -4.517698920687285, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -3.782321434070867, 2: -4.1132020875801, 3: -4.021517053002881, 4: -4.133907798970157}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.06559544207874, 2: -3.570959874740127, 3: -2.9293982581932716, 4: -3.5730217181458626}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -3.882974453223112, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.06559544207874, 2: -3.570959874740127, 3: -4.338149132930049, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.681278998327065, 2: -2.683168066774061, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8985499084250002, 2: -1.8972217090672172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.13 -4.63 -4.02 -3.57 -2.71 \n",
      "-4.61 -3.92 -3.39 -2.66 -1.90 \n",
      "-3.96 -3.32 -2.68 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.126010954189788, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.634482550882463, 2: -4.644766256385273, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -3.9171963053185586, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.389521112995336, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.706002509754929, 2: -2.683168066774061, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8967457492444033, 2: -1.8988121375825395, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9999998999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.15 -4.60 -4.02 -3.57 -2.71 \n",
      "-4.61 -4.05 -3.42 -2.66 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.149705347866093, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.597090075843176, 2: -4.644766256385273, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.052113668533883, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.422592082941571, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.706002509754929, 2: -2.7059988168963898, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8996745344244403, 2: -1.8988121375825395, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.000000562228489, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.17 -4.64 -4.02 -3.57 -2.71 \n",
      "-4.61 -4.08 -3.44 -2.66 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.165108662871998, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.655968223959654, 2: -4.644766256385273, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.1132020875801, 3: -4.021517053002881, 4: -4.133907798970157}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.655968223959654, 2: -4.621905438570862, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.1132020875801, 3: -5.045895110542687, 4: -4.133907798970157}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.5735323897012083, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.6581162941682073, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8996745344244403, 2: -1.899881441460792, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.99999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.61 -4.08 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.269864336921425}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.494655481281917, 1: -5.270686503158211, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.695576546598497}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.611728890180238, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.083329546006974, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4355222873213767, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.706002509754929, 2: -2.7091188998767097, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8985499084250002, 2: -1.8997217659067218, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.00000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.19 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.67 -4.09 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.189880831526321, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.672421734990257, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.091667132021602, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4367692310782436, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7090135529651804, 2: -2.7091188998767097, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.89985629990375, 2: -1.8997217659067218, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.208133218465205, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.682385134924625, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.0936506531062715, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4383267038132104, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709788670306491, 2: -2.7091188998767097, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.899967449392444, 2: -1.899881441460792, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000562228488, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.68 -4.09 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.214489403220886, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.684483184003333, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.094512078650251, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4385542221485945, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709788670306491, 2: -2.709863884025906, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.89985629990375, 2: -1.8999721761856723, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.000000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.09 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.216174688478736, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.6851373375898815, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.09481037972324, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.438843670854937, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709920727399424, 2: -2.709863884025906, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.899967449392444, 2: -1.8999881669163332, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.09 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.216690872301251, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.685386582046711, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.094980247971901, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.438923307759558, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709920727399424, 2: -2.7099732053883057, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8999857608965, 2: -1.8999721761856723, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.99999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.216883100739742, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.685499653272892, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.095040235107414, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4389551544817416, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709980804093317, 2: -2.7099732053883057, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999967448987443, 2: -1.8999881669163332, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000056222849, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.216963864256575, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.685545953343022, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.095070007504586, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4389825075120375, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709980804093317, 2: -2.7099925291646074, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8999857608965, 2: -1.8999972176145172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.2169986021228905, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.685568161097215, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.095085251247247, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4389878839832337, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.70999231946319, 2: -2.7099925291646074, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8999985891802624, 2: -1.8999972176145172, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.999999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.217014904168074, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.6855789021350835, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.095091990169674, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4389951706910793, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7099981050800164, 2: -2.7099925291646074, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999967448987443, 2: -1.8999988189686585, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9999999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.66 -4.13 -3.43 -2.71 \n",
      "-4.69 -4.10 -3.44 -2.70 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.217022710151196, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -4.685584033257241, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.095095614628109, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6789235426957467, 1: -3.4389958981385615, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.141913328584583, 3: -4.897406694161213, 4: -4.133907798970157}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.141913328584583, 3: -4.897406694161213, 4: -4.133907798970157}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.141913328584583, 3: -4.897406694161213, 4: -4.661856097062843}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.431381021186974, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.704679814036219, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999996744898338, 2: -1.8999988189686585, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000005622285, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.32 -4.66 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.21 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.32 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.345851818277348, 3: -5.321189515412161, 4: -5.70554475050697}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.345851818277348, 3: -5.742282459025067, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.655968223959654, 2: -4.6860815184666125, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.2136917532204325, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.3241708198125544, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7099981050800164, 2: -2.709997934600434, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999996744898338, 2: -1.8999998821245685, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.99999999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.230112099784914, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.6860815184666125, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.0957259457087005, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.436083211606514, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.709467503188395, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999674489794, 2: -1.8999998821245685, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000562228, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.09 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.218393386369916, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685317399429878, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.093884238062409, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438492638473765, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099467025895367, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999674489794, 2: -1.8999999882352272, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.999999999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.68 -4.09 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2167916852909615, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.684973517464916, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.094763226265468, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389276724637154, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.70999465707579, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999967448975, 2: -1.8999999882352272, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000056222, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2166898869479, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685378338069854, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095036055261763, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438990601218398, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099994609438705, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999967448975, 2: -1.8999999988257996, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -0.9999999999999999, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.216898720918698, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.6855411789305785, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095089700509687, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389988412108647, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999447760705, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999996744896, 2: -1.8999999988257996, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000005622, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.216996025383881, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685580730837783, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.09509849058053, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389998615414425, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.709999994002158, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999996744896, 2: -1.8999999998828079, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2170234618539, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.68558843603091, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099791862535, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999836656937, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999992683843, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999674488, 2: -1.8999999998828079, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000000562, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217029573476293, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.6855897562661655, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099972427914, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999980489114, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.709999999879386, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999674488, 2: -1.8999999999883037, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030753445408, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589964093244, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099996427949, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999997501106, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999747557, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999967447, 2: -1.8999999999883037, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000000056, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030960129678, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589994914599, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999536029, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999999626557, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999927395, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999967447, 2: -1.8999999999988326, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030993865437, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999296029, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999936889, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438999999992732, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.709999999997956, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999996744, 2: -1.8999999999988326, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0000000000000004, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030999089243, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999902509, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.0950999999902775, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999999982326, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999993227, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999996744, 2: -1.8999999999998833, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030999867493, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.6855899999859245, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999998161, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999999994894, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999998006, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999673, 2: -1.8999999999998833, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030999980663, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999997735, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999999563, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438999999999847, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.709999999999933, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999673, 2: -1.8999999999999884, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030999997054, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999999561, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999999879, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438999999999951, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999999804, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999966, 2: -1.8999999999999884, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217030999999501, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999999896, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999999963, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438999999999985, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999999933, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999966, 2: -1.8999999999999988, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2170309999999, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999999972, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999999988, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.4389999999999947, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999999977, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999995, 2: -1.8999999999999988, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.44 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.71 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.00 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2170309999999755, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.685589999999991, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.095099999999995, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.438999999999998, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.7099999999999995, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -1.8999999999999995, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -1.0, 3: -1.6735759734093751, 4: -2.146275}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.471631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.71 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.06 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.43 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.49 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.228369882100633, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.70972968295934, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.060452954231154, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4275161861702026, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7099981050800164, 2: -2.7099996616284243, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8999985891802624, 2: -1.899999721761047, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.00000000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.67 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.09 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.49 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.220685126096223, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.6718787822684416, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.086983889887315, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4378505943176147, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.709999239715085, 2: -2.7099996616284243, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.166899276214551, 1: -1.8999998602270873, 2: -1.899999721761047, 3: -2.238561615779839, 4: -2.7496331263581957}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598055387645212, 1: -1.4872500000000002, 2: -2.365510855280297, 3: -1.6735759734093751, 4: -2.146275}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.11 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.48 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2139113188678285, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.688814321425707, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.111804984087618, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4788452914323216, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099996616284243, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.70 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.11 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.224337164889943, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.699939727310898, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.112907779770633, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.442984392102744, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999661628424, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.227145492621651, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.694963276223851, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.098494450611853, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4393984255062255, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999966162844, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.222489940503787, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.6879746928911885, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095600806774524, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390398411802177, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999996616284, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.218637234168272, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.6860385570601455, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095166216293773, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439003983980981, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.709999999966163, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217385683680718, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.6856623993827515, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095108235135508, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390003983843944, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999999966164, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217097323643908, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685600647773434, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100984858614, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390000398370693, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999999996616, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217042127470239, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.6855914709053605, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100114619812, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.43900000398357, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.709999999999966, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217032729679857, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590194237562, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.09510001307532, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390000003983436, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999999999964, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031254049846, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590024791858, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100001468861, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439000000039833, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7099999999999995, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031035716654, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590003081334, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951000001630184, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439000000003983, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031004849643, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000374883, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100000017916, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390000000003984, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000640089, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000044817, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951000000019535, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.43900000000004, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000082519, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000005281, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100000000212, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439000000000004, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.21703100001043, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000000615, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100000000023, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.4390000000000005, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000001296, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000000071, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.095100000000002, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000000159, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000000008, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000000019, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.685590000000001, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031000000003, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217031, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.68559, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.533517151069669, 1: -4.0951, 2: -4.821700374988048, 3: -4.302212284297792, 4: -4.4549867776969405}, Best action: 1, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389958981385615, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.35 -4.71 -4.15 -3.56 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.90 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.349453581937661, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.710787515779199, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.151094479509337, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.5634321766874164, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8961999510564738, 1: -2.98651594819426, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.096797600016204, 1: -3.6022651780244854, 2: -3.702896748691621, 3: -3.8444670460450396, 4: -4.17218999716461}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.10745478930548, 1: -2.98651594819426, 2: -3.177113651338557, 3: -2.9216427294948506, 4: -3.5515222731038336}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389995898138563, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.32 -4.87 -4.29 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.324470377778479, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.874758919787113, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.291912551224513, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389999589813858, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.34 -4.78 -4.11 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.340257434388257, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.784215967748997, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.114781238509913, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389999958981385, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.27 -4.70 -4.10 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.272884065759197, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.703423497623851, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.097068122189738, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.438999999589814, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.69 -4.10 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.230197563349019, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.688170439174472, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.095296812052849, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389999999589813, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.2194286031938315, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.685927752791375, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.095119681188672, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.438999999995898, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.10 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.44 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.71 -1.90 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.217411137096191, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.685631746159802, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.095101968117206, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4389999999995897, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.71, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -1.9, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.22 -4.69 -4.11 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.48 -2.99 -1.90 \n",
      "-3.96 -3.44 -2.72 -2.08 -1.41 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.220449304671791, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.693068360765873, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.111707728061554, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -3.4759056249999594, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7920125, 3: -2.7229691188067444, 4: -3.4173867458232143}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.293171191081727, 1: -3.9961869061852973, 2: -3.439, 3: -3.7618104437013073, 4: -4.481231753195879}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9353285033512773, 1: -2.7988011237847323, 2: -2.7920125, 3: -3.9578869118806748, 4: -3.4173867458232143}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -2.08225, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.405, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.28 -4.82 -4.33 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.57 -2.99 -1.90 \n",
      "-3.96 -3.54 -2.80 -2.08 -1.04 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.279890396171113, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.226794439618026, 1: -4.979862404305912, 2: -4.81853523517382, 3: -4.944975067475788, 4: -5.04306707256328}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.375585815544605, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.331681368583442, 1: -4.375585815544605, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.841830045410932, 1: -4.375585815544605, 2: -4.465080345746294, 3: -4.897406694161213, 4: -4.717673827491912}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.86172964034393, 1: -4.029086706085478, 2: -3.570959874740127, 3: -4.353548966372999, 4: -3.5730217181458626}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111587526744728, 1: -2.98651594819426, 2: -3.177113651338557, 3: -3.977754106824097, 4: -3.5515222731038336}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8973915449887495, 1: -2.514479884876134, 2: -2.0822499999999997, 3: -2.5793861541507006, 4: -2.7968054177652304}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958795184509099, 1: -1.0405, 2: -2.093165555938797, 3: -1.6286062159981556, 4: -3.5453169476290274}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8571631741432832, 1: 0.0, 2: 0.0, 3: 0.0, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.36 -4.94 -4.24 -3.70 -2.71 \n",
      "-4.73 -4.10 -3.57 -2.82 -1.90 \n",
      "-3.96 -3.54 -2.80 -1.93 -1.00 \n",
      "-3.37 -2.75 -1.90 -1.05 0.00 \n",
      "-2.69 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.364163619989136, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.733517000513949, 1: -4.876579792043617, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.494655481281917, 1: -5.2705651324152125, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6425094573077175, 1: -4.876579792043617, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -3.956614324315733, 2: -4.278376592745186, 3: -4.687838922263012, 4: -4.992570630477347}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.3654876241601914, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.689856687771981, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8974020137223766, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.000000000323225, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.23 -4.94 -4.24 -3.70 -2.71 \n",
      "-4.63 -4.10 -3.57 -2.82 -1.90 \n",
      "-4.05 -3.54 -2.80 -1.93 -1.00 \n",
      "-3.42 -2.75 -1.90 -1.05 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.233452619223671, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475547624927732, 1: -4.633456766359379, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.047594734225228, 2: -4.278376592745186, 3: -4.687838922263012, 4: -4.992570630477347}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.423017237991083, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.7069334843936685, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8997402015031437, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000000000323226, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.19 -4.94 -4.24 -3.70 -2.71 \n",
      "-4.66 -4.10 -3.57 -2.82 -1.90 \n",
      "-4.08 -3.54 -2.80 -1.93 -1.00 \n",
      "-3.44 -2.75 -1.90 -1.05 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.18747309505477, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475547624927732, 1: -4.657963104984503, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.083296275616627, 2: -4.278376592745186, 3: -4.687838922263012, 4: -4.992570630477347}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.4361124367051428, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.7095881300540308, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8999740201634052, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000000000032323, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.20 -4.94 -4.24 -3.70 -2.71 \n",
      "-4.68 -4.10 -3.57 -2.82 -1.90 \n",
      "-4.09 -3.54 -2.80 -1.93 -1.00 \n",
      "-3.44 -2.75 -1.90 -1.05 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.200482640191914, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475547624927732, 1: -4.6774858064266995, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.092672970458365, 2: -4.278376592745186, 3: -4.687838922263012, 4: -4.992570630477347}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.438539701517443, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.7099482911721715, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8999974020176496, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000000000003233, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.21 -4.94 -4.24 -3.70 -2.71 \n",
      "-4.68 -4.10 -3.57 -2.82 -1.90 \n",
      "-4.09 -3.54 -2.80 -1.93 -1.00 \n",
      "-3.44 -2.75 -1.90 -1.05 0.00 \n",
      "-2.71 -1.90 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5.494655481281917, 1: -5.21161193776606, 2: -5.469168884829656, 3: -5.756786644247787, 4: -5.70554475050697}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475547624927732, 1: -4.683708407629463, 2: -5.012557993336467, 3: -4.991818546220339, 4: -5.395132150869615}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.302578626286471, 1: -4.094661239159514, 2: -4.278376592745186, 3: -4.687838922263012, 4: -4.992570630477347}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.083443967020553, 1: -3.4389325545942167, 2: -3.5336063027688236, 3: -3.9614418083625944, 4: -3.896390116264386}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0438784449103578, 1: -3.9942553368145464, 2: -2.709993776934424, 3: -3.5622150927301424, 4: -3.5683520964963176}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644806872046186, 1: -1.9725820304765627, 2: -1.8999997402018958, 3: -3.039278312736532, 4: -2.6628329559007646}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.8939043125000001, 2: -1.0000000000000324, 3: -1.665102707583743, 4: -2.0249386340624995}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "[130, 37, 23, 36, 26, 24, 11, 17, 20, 11, 22, 25, 15, 17, 11, 9, 13, 11, 9, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 7, 7, 7, 7, 7, 8, 9, 9, 9, 7, 7, 7, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TDlambda import TDlambda\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TDlambda(0.9, 0.01, 0.9, 0.5, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 317)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 35)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 86)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 57)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 65)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 232)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 61)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
