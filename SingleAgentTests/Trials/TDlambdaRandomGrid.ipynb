{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\text{TD} (\\lambda)$ in a random grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61775, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8820125, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.000930625, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8417720929765626, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4052375000000001, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.45875065625, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4662240453125002, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.469587070390625, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.85052413514133, 1: -1.5895605937500004, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0495918849757317, 1: -1.5618266436409673, 2: -2.0866791032033207, 3: -1.618665292265625, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049632377345189, 1: -1.5618887009121667, 2: -2.0876665714418854, 3: -1.6201786535507814, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049650598911445, 1: -1.5619166266842064, 2: -2.0881109321492395, 3: -1.6208596661291017, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0496580606428267, 1: -1.5619280622878566, 2: -2.088292897858901, 3: -1.621138540779924, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4709552480345878, 1: -1.5613946673217296, 2: -2.0798054059424724, 3: -1.6081308903332907, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470952070338731, 1: -1.5612224607349774, 2: -2.07706521882817, 3: -1.603931369851601, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4709546150747081, 1: -1.5613603657820871, 2: -2.0792595926916464, 3: -1.6072943949297258, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4709556571440907, 1: -1.5614168378988786, 2: -2.08015818878874, 3: -1.608671553699218, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0496593905844502, 1: -1.646421106431936, 2: -2.0883253305154743, 3: -1.6211882460007263, 4: -2.623600646350644}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049659457863554, 1: -1.682888161088566, 2: -2.088326971219113, 3: -1.6211907604890619, 4: -2.6507183831947017}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560454160508, 1: -1.6026482666058692, 2: -1.502473308004241, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.437750067875295, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560433979995, 1: -1.6026474389227359, 2: -1.5022518065872879, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.850556043652425, 1: -1.6026475432728156, 2: -1.5022797323593275, 3: -1.4872500000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560437669166, 1: -1.6026475902303514, 2: -1.5022922989567455, 3: -1.5692625000000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.850556043813801, 1: -1.6026476094594624, 2: -1.5022974449783881, 3: -1.6028466187500003, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049659475653991, 1: -1.6925310488980727, 2: -2.088327405066081, 3: -1.629261759284067, 4: -2.657889055367083}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0496594757036593, 1: -1.6925579704646851, 2: -2.08832740627732, 3: -1.6339627802896068, 4: -2.6579090748604504}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0496594757230557, 1: -1.6925684837565835, 2: -2.0883274067503277, 3: -2.388741952130039, 4: -2.657916892785033}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5963456822031232, 1: -1.5614391507275212, 2: -2.0805132351704354, 3: -1.6092156860849585, 4: -3.2758700346872907}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647807668836, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647806703218, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647808457876, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647809247474, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348957607526, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.46986478095618, 1: -1.559800820390625, 2: -2.0544437812500003, 3: -1.5692625000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647809568357, 1: -1.5613141816757814, 2: -2.0785247015625004, 3: -1.6061681250000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647809571308, 1: -1.5619951942541017, 2: -2.0893611157031255, 3: -1.6227756562500002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4698647809572516, 1: -1.562274068904924, 2: -2.0937986272937117, 3: -1.629576440296875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.576034896077184, 1: -1.6067548408937826, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.59639604732521, 1: -1.7591687287229403, 2: -2.0805132463605727, 3: -1.6092157032345946, 4: -3.275907487441553}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775983, 1: -1.611477033146529, 2: -2.2034647196200217, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775175, 1: -1.610555069686944, 2: -1.9567323598098791, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775772, 1: -1.6112360822652643, 2: -2.138982359809879, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775798, 1: -1.6112667278312887, 2: -2.147183609809879, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775918, 1: -1.6114046328783984, 2: -2.1840892348098793, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5760348960775967, 1: -1.61146110499519, 2: -2.1992020882473793, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560438349749, 1: -1.6026476181438503, 2: -2.7998451693682096, 3: -1.6180141176188543, 4: -3.4458411483429012}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048280346, 1: -1.759199511140113, 2: -2.080513246360786, 3: -1.6117128677419494, 4: -3.275907488151817}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290805294, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251680083814415, 1: -1.5810765845997097, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.039578272512698, 1: -1.5623458050485624, 2: -2.0949401077686165, 3: -1.631325835660714, 4: -2.8611952135886995}, Best action: 1, Actual action: 1\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795896540562, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795891733278, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795900398265, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795904297508, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.039733281392836, 1: -1.745795175676923, 2: -2.0949402778423334, 3: -1.6313260963100897, 4: -2.861310482067193}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0397338537399183, 1: -1.764240945923869, 2: -2.0949402784703053, 3: -1.6313260972724986, 4: -2.8613109076787917}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.039733941067097, 1: -1.7670553519504428, 2: -2.0949402785661193, 3: -2.3845067486648155, 4: -2.8613109726174653}, Best action: 1, Actual action: 1\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795906288185, 1: -1.5802939664624436, 2: -2.38053499446412, 3: -2.0690191486040153, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795906263338, 1: -1.5791326631545939, 2: -2.3620560940923014, 3: -2.0406989947774736, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795906277908, 1: -1.5798136757329142, 2: -2.3728925082329266, 3: -2.0573065260274737, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4718795906283875, 1: -1.5800925503837364, 2: -2.3773300198235128, 3: -2.0641073100743488, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0397339483772594, 1: -1.6669568438738491, 2: -2.0949402785741396, 3: -2.5876639508926957, 4: -2.8613109780534844}, Best action: 1, Actual action: 1\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3974230026008, 1: -1.5801890719655243, 2: -2.378865891358135, 3: -2.066461136181049, 4: -3.128496111273694}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115757804665655, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115721442768877, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115777992457258, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115803439817028, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600342929, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.45875065625, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.4872500000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115813919193362, 1: -1.5623016499143458, 2: -2.094237502066407, 3: -1.6302490453125003, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115813938448885, 1: -1.5624395549614556, 2: -2.0964318759298832, 3: -1.6336120703906252, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115813947113872, 1: -1.562501612232655, 2: -2.097419344168448, 3: -1.6351254316757815, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5115813950662185, 1: -1.5625270246852112, 2: -2.09782371241214, 3: -1.635745153122053, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.724544254398938, 1: -1.761162140910487, 2: -2.379224804520701, 3: -2.0670111946677414, 4: -3.371751652142049}, Best action: 1, Actual action: 1\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4776994737336646, 1: -1.5625365241820355, 2: -2.0979748703862984, 3: -1.635976812852564, 4: -3.2118103054814546}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.472307035193372, 1: -1.6279066511858935, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723056036822628, 1: -1.6275235556191732, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723067488134525, 1: -1.6278300112794173, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5942903791808811, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.594734739888235, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723071835410375, 1: -1.6279463514247854, 2: -2.000930625, 3: -1.4872500000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723072046719285, 1: -1.6279520063936235, 2: -2.0544437812500003, 3: -1.5692625000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723072141808295, 1: -1.6279545511296005, 2: -2.0785247015625004, 3: -1.6061681250000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4723072180747245, 1: -1.627955593198983, 2: -2.088385838430469, 3: -1.6212809784375002, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7521026951897363, 1: -1.6273798867778864, 2: -2.0980023055384525, 3: -1.6360188590627625, 4: -3.415863401018824}, Best action: 1, Actual action: 1\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5948441763461474, 1: -1.6142074506000847, 2: -1.52695037333375, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.594843852894914, 1: -1.6120965335879853, 2: -1.5165260917925178, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.59484408478398, 1: -1.6136098948731417, 2: -1.523999480855018, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.594844095218988, 1: -1.6136779961309737, 2: -1.5243357833628304, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5948441421765238, 1: -1.6139844517912179, 2: -1.5258491446479867, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5948441614056348, 1: -1.614109945384088, 2: -1.5264688660942582, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3558055638453763, 1: -1.6279559432358726, 2: -2.091698249037244, 3: -1.6263574697888799, 4: -3.0978027379745248}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5948441681379013, 1: -1.6141538817016572, 2: -2.3701344499062618, 3: -1.9424224659161053, 4: -3.140517477329278}, Best action: 0, Actual action: 0\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.646734417019524, 1: -1.6141643740015665, 2: -2.7083351931520805, 3: -1.9625284842447441, 4: -3.3919734749685597}, Best action: 1, Actual action: 1\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8252242406207566, 1: -1.0614164213741777, 2: -2.744484920692221, 3: -1.9646775838520418, 4: -3.4188511976954645}, Best action: 1, Actual action: 1\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.759747301313084, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5964096223588353, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348669118046, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.617679876476703, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4872500000000002, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5692625000000002, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6061681250000002, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.607828878125, 1: -1.4954512500000001, 2: -1.0305, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6153022671875001, 1: -1.532356875, 2: -1.61775, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6156385696953126, 1: -1.534017628125, 2: -1.6441762500000001, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.617151930980469, 1: -1.5414910171875, 2: -1.763094375, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6177716524267405, 1: -1.5445513700085938, 2: -1.8117913471875, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4333538483657724, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4332100650726873, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4335165207329315, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4336544257800412, 1: -1.4872500000000002, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953244775850155, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953256227162051, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953261380252406, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953261612141472, 2: -1.0305, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953262655642269, 2: -1.61775, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953262702599804, 2: -1.6441762500000001, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953262913908715, 2: -1.763094375, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -1.5953263000439715, 2: -1.8117913471875, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6178968356903485, 1: -1.7570518129368753, 2: -1.8216280987521754, 3: -1.9068054259366665, 4: -2.695072826150824}, Best action: 0, Actual action: 0\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.61767987647681, 1: -2.370029068720072, 2: -1.829505153036338, 3: -1.9457044594387058, 4: -3.181563742282477}, Best action: 0, Actual action: 0\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.360380263125162, 1: -1.6279559444145641, 2: -2.091709403037825, 3: -2.472630192662642, 4: -3.1012045987231804}, Best action: 1, Actual action: 1\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.380412302623478, 1: -2.863878482290495, 2: -1.8354513272108983, 3: -1.975068282522954, 4: -3.5488025116630744}, Best action: 2, Actual action: 2\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7951121539039523, 1: -2.947855202354459, 2: -1.8364624455607177, 3: -1.9800614595590993, 4: -3.611249699987034}, Best action: 2, Actual action: 2\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.943892625833608, 1: -2.9779832479846733, 2: -2.5715435809924734, 3: -1.9818528449033963, 4: -3.6336536678708686}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9612894436958386, 1: -2.9815061036093122, 2: -2.8484077909390284, 3: -1.982062310595712, 4: -3.636273351379136}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9908801438596906, 1: -2.9874982204053127, 2: -3.319333329592675, 3: -2.7040329882884167, 4: -3.6407292392220283}, Best action: 3, Actual action: 3\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0029969438742876, 1: -2.9899518724135183, 2: -3.512167920935097, 3: -3.6563025751645752, 4: -3.6425538361927265}, Best action: 1, Actual action: 1\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9956196071566157, 1: -1.7570605827463552, 2: -1.8216282042648777, 3: -1.9068059469870475, 4: -2.6950793426694752}, Best action: 1, Actual action: 1\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4337101457650854, 1: -1.560887386645037, 2: -2.071733450044489, 3: -1.5957600766965347, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4337101457626342, 1: -1.5608873834055708, 2: -2.071733398497425, 3: -1.5957599976972028, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4337101457640913, 1: -1.5608873853311231, 2: -2.071733429137217, 3: -1.5957600446547386, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.433710145764688, 1: -1.5608873861196368, 2: -2.071733441684212, 3: -1.5957600638838496, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9949301383967355, 1: -1.6631848015202162, 2: -1.8216282042414051, 3: -1.9068059468711342, 4: -2.6950793412198064}, Best action: 1, Actual action: 1\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3905507038079907, 1: -1.560887386385257, 2: -2.0717334459108154, 3: -1.5957600703614023, 4: -3.10067869533448}, Best action: 1, Actual action: 1\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365349269, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386364906394, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365261712, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365277702, 1: -1.0305, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365349653, 1: -1.61775, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.546133492741847, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6814071574458107, 1: -1.5924607465359433, 2: -2.071733446813133, 3: -1.595760071744265, 4: -3.3169668256708724}, Best action: 1, Actual action: 1\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.46863863653802, 1: -1.8670557734400623, 2: -2.131139621926233, 3: -1.6868040182777513, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365379844, 1: -1.864148749457019, 2: -2.116783947935896, 3: -1.664802985342369, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365380113, 1: -1.8663431233204957, 2: -2.127620362076521, 3: -1.681410516592369, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4686386365380224, 1: -1.8672417194175894, 2: -2.132057873667107, 3: -1.6882113006392439, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6821610318473286, 1: -1.6497116707958714, 2: -2.0717334468154727, 3: -1.5957600717478493, 4: -3.3175274255227007}, Best action: 3, Actual action: 3\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730543, 1: -1.9035222232927889, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.682164987234485, 1: -1.6755449683004249, 2: -2.0717334468154847, 3: -1.0595760071747802, 4: -3.317530366847475}, Best action: 3, Actual action: 3\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9949688763029036, 1: -2.362415064854842, 2: -1.821628204242724, 3: -1.906805946877647, 4: -2.6950793413012564}, Best action: 2, Actual action: 2\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876321895, 1: -2.362416450093618, 2: -1.821628204242724, 3: -1.906805946877647, 4: -2.6950793413012564}, Best action: 2, Actual action: 2\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9949688763245432, 1: -2.3624166432406475, 2: -2.557681665860879, 3: -1.906805946877647, 4: -2.6950793413012564}, Best action: 3, Actual action: 3\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876324774, 1: -2.3624166600793504, 2: -2.7644506765202284, 3: -1.906805946877647, 4: -2.6950793413012564}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.435852206162368, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.904829345622645, 2: -1.9688692857059582, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.9048350005914831, 2: -1.9722323107840831, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.9048375453274602, 2: -1.9737456720692395, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.9048376598405792, 2: -1.9738137733270715, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.9048381751496146, 2: -1.9741202289873157, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5461334927730646, 1: -1.9048383861686646, 2: -1.9742457225801857, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9949688763250357, 1: -2.362416679130202, 2: -2.9983835214920185, 3: -1.4433910620397892, 4: -2.6950793413012564}, Best action: 3, Actual action: 3\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9949688763250366, 1: -2.362416679190749, 2: -2.999127004560522, 3: -1.4470625833657311, 4: -2.6950793413012564}, Best action: 3, Actual action: 3\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876325037, 1: -2.3624166792217, 2: -2.9995070634925627, 3: -2.2187037850951166, 4: -2.6950793413012564}, Best action: 3, Actual action: 3\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876325037, 1: -2.362416679234371, 2: -2.999662660095621, 3: -3.234931319426912, 4: -2.6950793413012564}, Best action: 1, Actual action: 1\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.68216749927122, 1: -1.6919515019095925, 2: -2.0717334468154927, 3: -2.428108819992362, 4: -3.317532234860792}, Best action: 1, Actual action: 1\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.497942577830191, 1: -1.8675744908170655, 2: -2.1337011892200746, 3: -1.690729791908161, 4: -3.201316936815442}, Best action: 3, Actual action: 3\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4979426644100062, 1: -1.867574490836302, 2: -2.133701189315069, 3: -1.690729792053746, 4: -3.201317001198357}, Best action: 3, Actual action: 3\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4979427034282917, 1: -1.867574490844971, 2: -2.133701189357879, 3: -2.438564110834519, 4: -3.2013170302133296}, Best action: 1, Actual action: 1\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.497942708547312, 1: -1.8675744908461083, 2: -2.1337011893634954, 3: -2.754704185701498, 4: -3.201317034019961}, Best action: 1, Actual action: 1\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.497942716280355, 1: -2.599492786671677, 2: -2.13370118937198, 3: -3.2322808737395636, 4: -3.201317039770445}, Best action: 2, Actual action: 2\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.497942717653224, 1: -3.0181867469828347, 2: -2.1337011893734865, 3: -3.3170664007048196, 4: -3.2013170407913445}, Best action: 2, Actual action: 2\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4979427191679213, 1: -3.480135144637213, 2: -2.841668082331535, 3: -3.41061095123231, 4: -3.201317041917711}, Best action: 0, Actual action: 0\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.731516505541235, 1: -1.904838479735379, 2: -1.9743013669553666, 3: -1.9648581971631176, 4: -3.4211100387837967}, Best action: 1, Actual action: 1\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158812352, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.326253856170174, 1: -3.5648671979561577, 2: -3.2600979752645958, 3: -3.427769192029851, 4: -3.201317042124313}, Best action: 0, Actual action: 0\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.682167499272344, 1: -2.915466137096785, 2: -2.0717334468154927, 3: -2.428111182643894, 4: -3.3175322348616287}, Best action: 2, Actual action: 2\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.682167499272344, 1: -2.9154583201658046, 2: -2.0717334468154927, 3: -2.428111182631934, 4: -3.3175322348616287}, Best action: 2, Actual action: 2\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.682167499272344, 1: -2.9155676549635765, 2: -2.7852774366020983, 3: -2.428111182799219, 4: -3.3175322348616287}, Best action: 3, Actual action: 3\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.731545874912936, 1: -2.4185394099963755, 2: -1.9743013678666579, 3: -1.964859943438425, 4: -3.4211318785828277}, Best action: 3, Actual action: 3\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.768470834990003, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816082, 1: -2.9477682504882554, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.304636990778284, 1: -3.643939351763108, 2: -3.6505777471507708, 3: -3.443781303176183, 4: -3.2013170423171142}, Best action: 4, Actual action: 4\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3362857348686408, 1: -3.6442885926312045, 2: -3.6523023934129757, 3: -3.4438520244519744, 4: -3.201317042317966}, Best action: 4, Actual action: 4\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3387804984846805, 1: -3.6443161221094194, 2: -3.6524383414535424, 3: -3.443857599171313, 4: -3.8131985085094167}, Best action: 0, Actual action: 0\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.682167499272344, 1: -2.9156062652562706, 2: -3.5972118119338696, 3: -2.872409797264159, 4: -3.3175322348616287}, Best action: 0, Actual action: 0\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876325037, 1: -3.0573670324830604, 2: -2.9996841407458867, 3: -3.590072033899948, 4: -2.6950793413012564}, Best action: 4, Actual action: 4\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876325037, 1: -3.057367067391476, 2: -2.9996841407474575, 3: -3.5900720598664746, 4: -2.6950793413012564}, Best action: 4, Actual action: 4\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.994968876325037, 1: -3.0573670828274246, 2: -2.999684140748152, 3: -3.590072071348461, 4: -3.3525222005841435}, Best action: 0, Actual action: 0\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0018098590069933, 1: -2.6027201235947217, 2: -3.493275884671592, 3: -3.4200511540721754, 4: -3.6423750801308774}, Best action: 1, Actual action: 1\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3077001877442282, 1: -3.057367087575366, 2: -2.9996841407483656, 3: -3.5900720748802035, 4: -4.0041288547666145}, Best action: 2, Actual action: 2\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7519834069911453, 1: -3.0573670896876886, 2: -2.9996841407484607, 3: -3.590072076451449, 4: -4.294023655325228}, Best action: 2, Actual action: 2\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8795641635260045, 1: -3.057367090294265, 2: -3.6297125680811266, 3: -3.590072076902649, 4: -4.377270098964224}, Best action: 1, Actual action: 1\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7911027867390645, 1: -2.915606411189009, 2: -3.6002806259359854, 3: -2.8771129604860146, 4: -3.3175322348616287}, Best action: 3, Actual action: 3\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7928920323541777, 1: -2.915606411396462, 2: -3.6002849884624446, 3: -2.87711964635032, 4: -3.3175322348616287}, Best action: 3, Actual action: 3\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.793969981490779, 1: -2.9156064115214444, 2: -3.6002876167106797, 3: -3.518182906145435, 4: -3.3175322348616287}, Best action: 1, Actual action: 1\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9072776607196045, 1: -3.64432478755534, 2: -3.652481133779079, 3: -3.443859353924112, 4: -4.433804156127413}, Best action: 3, Actual action: 3\n",
      "Step: 242\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074410567488678, 1: -3.644324789042778, 2: -3.65248114112445, 3: -3.443859354225318, 4: -4.433910684083493}, Best action: 3, Actual action: 3\n",
      "Step: 243\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.9696469812408206, 2: -3.855102837439225, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 244\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.9696469523916518, 2: -3.8550951169341756, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 245\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 246\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.9696469568632127, 2: -3.855096313596269, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 247\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.969646957729711, 2: -3.8550965454853348, 3: -1.61775, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 248\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.9696469581196356, 2: -3.8550966498354144, 3: -1.8820125, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 249\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7571773158816153, 1: -2.9696469582793097, 2: -3.855096692566772, 3: -1.99022799375, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 250\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028445, 1: -2.4268249792176912, 2: -1.974301367874635, 3: -2.2821430826053573, 4: -3.42113206976131}, Best action: 2, Actual action: 2\n",
      "Step: 251\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.794345929543996, 1: -3.8079661734161756, 2: -3.600288533344659, 3: -4.2386000933684835, 4: -3.3175322348616287}, Best action: 4, Actual action: 4\n",
      "Step: 252\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7943461394418483, 1: -3.8085826021255054, 2: -3.6002885338564306, 3: -4.23900231388563, 4: -3.3175322348616287}, Best action: 4, Actual action: 4\n",
      "Step: 253\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.79434617082107, 1: -3.8086747567287054, 2: -3.600288533932939, 3: -4.23906244488147, 4: -3.9189543337240824}, Best action: 2, Actual action: 2\n",
      "Step: 254\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7943461776105383, 1: -3.8086946960617514, 2: -3.600288533949493, 3: -4.239075455321652, 4: -4.338257811318392}, Best action: 2, Actual action: 1\n",
      "Step: 255\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.907414623228082, 1: -3.644324788802147, 2: -3.652481139936147, 3: -0.8983846931906138, 4: -4.433893450439849}, Best action: 3, Actual action: 3\n",
      "Step: 256\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.907414619373467, 1: -3.6443247888021117, 2: -3.652481139935974, 3: -0.8982047116646765, 4: -4.4338934479267875}, Best action: 3, Actual action: 3\n",
      "Step: 257\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146201627875, 1: -3.644324788802119, 2: -3.6524811399360093, 3: -1.7174031429406114, 4: -4.4338934484413945}, Best action: 3, Actual action: 3\n",
      "Step: 258\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.907414620486013, 1: -3.644324788802122, 2: -3.652481139936024, 3: -2.798297124975603, 4: -4.433893448652125}, Best action: 3, Actual action: 3\n",
      "Step: 259\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.645689623418972, 1: -2.9696469583928673, 2: -3.8550967229564956, 3: -2.067188781604315, 4: -4.226461993932906}, Best action: 3, Actual action: 3\n",
      "Step: 260\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.5887668931030534, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 261\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6446755050703756, 1: -2.9696469583928273, 2: -3.855096722945781, 3: -1.1067082892927251, 4: -4.225707870175931}, Best action: 3, Actual action: 3\n",
      "Step: 262\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.5887647699319265, 2: -1.7964337143271074, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 263\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.588762441216485, 2: -1.4258138298566374, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 264\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 265\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.426824979251229, 2: -4.129904306307631, 3: -2.282143086644195, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 266\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.6347935253268613, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 267\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.129935433321926, 3: -1.1282143086644163, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 268\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.129940561964689, 3: -1.944448424172601, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 269\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.6347935253268586, 2: -2.140103428839187, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 270\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.6347935253268564, 2: -1.8090899539049135, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 271\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.8911024539049135, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 272\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.8947930164049136, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 273\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.9114005476549136, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 274\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.9182013317017885, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 275\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 276\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 277\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.919445165036711, 3: -1.4722104308598989, 4: -2.6376175981859307}, Best action: 3, Actual action: 3\n",
      "Step: 278\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 279\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 280\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 281\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 282\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 283\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0018098590069933, 1: -3.974843562929738, 2: -3.493275884671592, 3: -3.4200511540721754, 4: -3.6423750801308774}, Best action: 0, Actual action: 0\n",
      "Step: 284\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.360380263125162, 1: -3.008839403044598, 2: -2.091709403037825, 3: -2.472630192662661, 4: -3.1012045987231804}, Best action: 2, Actual action: 2\n",
      "Step: 285\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.360380263125162, 1: -3.008839403044598, 2: -2.091709403037825, 3: -2.472630192662661, 4: -3.1012045987231804}, Best action: 2, Actual action: 2\n",
      "Step: 286\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.360380263125162, 1: -3.008839403044598, 2: -2.803455556764421, 3: -2.472630192662661, 4: -3.1012045987231804}, Best action: 0, Actual action: 0\n",
      "Step: 287\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -1.6165085752344897, 2: -2.0980023116607875, 3: -1.6360188684456491, 4: -3.415908936804581}, Best action: 1, Actual action: 1\n",
      "Step: 288\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8574312244317677, 1: -1.8148833374571005, 2: -2.751007834246434, 3: -1.9650653707569985, 4: -3.4237010561539294}, Best action: 1, Actual action: 1\n",
      "Step: 289\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: -3.297272672924809, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 290\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: -3.293298986930368, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 291\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: -3.2954933607938446, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 292\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: -3.2963919568909383, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 293\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.6326241094991483, 3: -3.296561619007382, 4: -2.655399448667348}, Best action: 2, Actual action: 2\n",
      "Step: 294\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.4731477930965595, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 295\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -0.5773651784085112, 3: -3.296604246577716, 4: -2.7980715007412162}, Best action: 2, Actual action: 2\n",
      "Step: 296\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.4697671093268696, 3: -3.296665779942878, 4: -3.0040201722209567}, Best action: 2, Actual action: 2\n",
      "Step: 297\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.4730748250777896, 3: -1.713140226583156, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 298\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.473056441275047, 3: -1.4465248542215945, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 299\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.473062096243885, 3: -1.5285373542215945, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 300\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.473064411953624, 3: -1.5621214729715946, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 301\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -1.3243101142460083, 3: -3.296674766677223, 4: -3.034098260660561}, Best action: 2, Actual action: 2\n",
      "Step: 302\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5870348841612052, 1: -1.628053576664773, 2: -3.4730650983120914, 3: -2.134098966842334, 4: -2.97896457329756}, Best action: 0, Actual action: 0\n",
      "Step: 303\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8574312244317677, 1: -1.704600592879684, 2: -2.751007834246434, 3: -1.9650653707569985, 4: -3.4237010561539294}, Best action: 1, Actual action: 1\n",
      "Step: 304\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.316475323234048, 1: -3.974843562929738, 2: -3.493275884671592, 3: -3.4200511540721754, 4: -3.6423750801308774}, Best action: 0, Actual action: 0\n",
      "Step: 305\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8349217412881442, 1: -3.008839403044598, 2: -3.531850988728703, 3: -2.472630192662661, 4: -3.1012045987231804}, Best action: 3, Actual action: 3\n",
      "Step: 306\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.834921694339169, 1: -3.008839403044598, 2: -3.5318509580944966, 3: -2.472630192662661, 4: -3.1012045987231804}, Best action: 3, Actual action: 3\n",
      "Step: 307\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8574312244317677, 1: -3.857107203667845, 2: -2.751007834246434, 3: -1.9650653707569985, 4: -3.4237010561539294}, Best action: 0, Actual action: 0\n",
      "Step: 308\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.482090456826832, 2: -2.0980023116607875, 3: -1.6360188684456491, 4: -3.415908936804581}, Best action: 3, Actual action: 3\n",
      "Step: 309\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.4820905210006448, 2: -2.0980023116607875, 3: -1.6360188684456491, 4: -3.415908936804581}, Best action: 3, Actual action: 3\n",
      "Step: 310\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 311\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 312\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 313\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 314\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 315\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 316\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 317\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 318\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560438349749, 1: -2.50484044224286, 2: -2.799845171905021, 3: -1.6180141176399188, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 319\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 320\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 321\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 322\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560438349749, 1: -2.50484044224286, 2: -2.799845171905021, 3: -1.6490514117639918, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 323\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593710657814589, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 324\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -1.611486900906966, 2: -2.206105492194561, 3: -1.9680772780004028, 4: -3.4613694859896125}, Best action: 1, Actual action: 1\n",
      "Step: 325\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -2.2577429015145736, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 326\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 327\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -1.4661486900906966, 2: -2.206105492194561, 3: -1.9680772780004028, 4: -3.4613694859896125}, Best action: 1, Actual action: 1\n",
      "Step: 328\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0397339495832956, 1: -2.445300515451806, 2: -2.0949402785754634, 3: -2.621180989840915, 4: -2.8613109789503235}, Best action: 0, Actual action: 0\n",
      "Step: 329\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -1.759199532322489, 2: -2.080513246360786, 3: -1.9241691035283297, 4: -3.2759074881523054}, Best action: 1, Actual action: 1\n",
      "Step: 330\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5289250161395453, 1: -2.445300515451806, 2: -2.0949402785754634, 3: -2.621180989840915, 4: -2.8613109789503235}, Best action: 2, Actual action: 2\n",
      "Step: 331\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9850549370896937, 1: -2.445300515451806, 2: -2.0949402785754634, 3: -2.621180989840915, 4: -2.8613109789503235}, Best action: 2, Actual action: 2\n",
      "Step: 332\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1291246505126558, 1: -2.445300515451806, 2: -2.806395653503672, 3: -2.621180989840915, 4: -2.8613109789503235}, Best action: 1, Actual action: 1\n",
      "Step: 333\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -2.3710866627082847, 2: -2.379224805300048, 3: -2.067011195862144, 4: -3.3717521803499486}, Best action: 3, Actual action: 3\n",
      "Step: 334\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 335\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -2.3710866627082847, 2: -2.379224805300048, 3: -1.1067011195862144, 4: -3.3717521803499486}, Best action: 3, Actual action: 3\n",
      "Step: 336\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.796427906864834, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 337\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.425814967406301, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 338\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 339\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.616266217406301, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 340\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.6531718424063009, 3: -1.61775, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 341\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.669779373656301, 3: -1.8820125, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 342\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5135155600344012, 1: -1.6346610787439497, 2: -1.6765801577031758, 3: -1.99022799375, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 343\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -2.2577429015145736, 3: -2.1152477917253854, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 344\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -2.2577429015145736, 3: -2.115247203682701, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 345\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -2.2577429015145736, 3: -2.1152477189917365, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 346\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -2.2577429015145736, 3: -2.1152479300107863, 4: -2.0875500000000002}, Best action: 1, Actual action: 2\n",
      "Step: 347\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729962766022792, 1: -2.726427464427927, 2: -3.504490115286445, 3: -2.621180989840915, 4: -2.8613109789503235}, Best action: 3, Actual action: 3\n",
      "Step: 348\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -1.5810820020154805, 2: -3.2489308919225985, 3: -2.1152480802762166, 4: -4.229208749116962}, Best action: 1, Actual action: 1\n",
      "Step: 349\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.737006357830394, 1: -1.6346610787439497, 2: -1.6778794940643953, 3: -2.010903304847594, 4: -2.662163022006092}, Best action: 1, Actual action: 1\n",
      "Step: 350\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -1.474780694789539, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 351\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -1.474780694789522, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 352\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -1.4747806947895339, 4: -0.9}, Best action: 4, Actual action: 3\n",
      "Step: 353\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -1.4747806947895417, 4: -2.762629926030308}, Best action: 3, Actual action: 3\n",
      "Step: 354\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.115713617011548, 3: -1.6631626314353238, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 355\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.1157136170115383, 3: -1.6631626314353087, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 356\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.115713617011542, 3: -1.6631626314353143, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 357\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.115713617011543, 3: -1.6631626314353165, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 358\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6959169587451488, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 359\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 360\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.1157136170115436, 3: -1.4713162631435317, 4: -2.5536142681209784}, Best action: 3, Actual action: 3\n",
      "Step: 361\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.77321512713198, 1: -2.3121734673184196, 2: -2.1157136170115436, 3: -1.8948989132056497, 4: -2.8686009162734205}, Best action: 0, Actual action: 0\n",
      "Step: 362\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -1.5028285353066755, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 363\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 4\n",
      "Step: 364\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 365\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518011, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 366\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -1.502828535025306, 3: -1.4872500000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 367\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -1.5028285354152302, 3: -1.5692625000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 368\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -1.502828535590696, 3: -1.6061681250000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 369\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -1.5028285356625495, 3: -1.6212809784375002, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 370\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7441939240978452, 1: -1.7779443300642044, 2: -1.6778915800471994, 3: -2.0110956195259577, 4: -2.667507875971727}, Best action: 2, Actual action: 2\n",
      "Step: 371\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -2.3710866627082847, 2: -2.379224805300048, 3: -1.5983382710144765, 4: -3.3717521803499486}, Best action: 3, Actual action: 3\n",
      "Step: 372\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7441939246240676, 1: -1.7779444708898204, 2: -2.3624431575267364, 3: -2.0110956195400376, 4: -2.667507876363039}, Best action: 0, Actual action: 0\n",
      "Step: 373\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6251691054081348, 1: -2.446661209687082, 2: -3.3439367703251692, 3: -2.115248085233152, 4: -4.299857495444075}, Best action: 0, Actual action: 0\n",
      "Step: 374\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 375\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -2.206105492194561, 3: -1.9680772780004028, 4: -3.4613694859896125}, Best action: 3, Actual action: 3\n",
      "Step: 376\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: -2.4941425951803264, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 377\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 378\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 379\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.598808149627957, 1: 0.0, 2: 0.0, 3: 0.0, 4: -1.619463667332581}, Best action: 1, Actual action: 1\n",
      "Step: 380\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8102640504792356, 1: -2.3121734673184196, 2: -2.1157136170115436, 3: -2.6014757251499834, 4: -2.9124819043040264}, Best action: 0, Actual action: 0\n",
      "Step: 381\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -2.9754700754234396, 3: -1.6287642058576717, 4: -3.57675789317595}, Best action: 3, Actual action: 3\n",
      "Step: 382\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5988372528681853, 1: -2.6318409447568962, 2: 0.0, 3: 0.0, 4: -1.6194767637906837}, Best action: 2, Actual action: 2\n",
      "Step: 383\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.633675052372323, 1: -1.7779445008148984, 2: -2.9359947716376693, 3: -2.0110956195430294, 4: -2.6675078764461926}, Best action: 1, Actual action: 1\n",
      "Step: 384\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.4820905465114547, 2: -2.0980023116607875, 3: -1.5387173664130873, 4: -3.415908936804581}, Best action: 3, Actual action: 3\n",
      "Step: 385\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -1.5148637291861573, 4: -3.1160181223566465}, Best action: 3, Actual action: 3\n",
      "Step: 386\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6997615541835414, 1: -2.3121734673184196, 2: -2.1157136170115436, 3: -2.6014765029296893, 4: -2.912481952606973}, Best action: 2, Actual action: 2\n",
      "Step: 387\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7228340466655165, 1: -2.3121734673184196, 2: -2.1157136170115436, 3: -2.601476505848589, 4: -2.912481952788247}, Best action: 2, Actual action: 2\n",
      "Step: 388\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -1.544098155441039, 3: -3.0845280012291063, 4: -3.1160181223642027}, Best action: 2, Actual action: 2\n",
      "Step: 389\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.4820905465114547, 2: -2.0980023116607875, 3: -2.9515347283166338, 4: -3.415908936804581}, Best action: 2, Actual action: 2\n",
      "Step: 390\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.4820905465114547, 2: -2.0980023116607875, 3: -3.0011397237356925, 4: -3.415908936804581}, Best action: 2, Actual action: 2\n",
      "Step: 391\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -2.4820905465114547, 2: -2.8091821036113167, 3: -3.0142629910903445, 4: -3.415908936804581}, Best action: 1, Actual action: 1\n",
      "Step: 392\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.834921859327087, 1: -3.008839403044598, 2: -3.531851065749112, 3: -3.0304918057691315, 4: -3.1012045987231804}, Best action: 0, Actual action: 0\n",
      "Step: 393\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -1.6325801749865534, 2: -3.2389232330189444, 3: -3.1595788222731582, 4: -3.1160181223643786}, Best action: 1, Actual action: 1\n",
      "Step: 394\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5058821276718173, 1: -3.008839403044598, 2: -3.531851065749112, 3: -3.0304918057691315, 4: -3.1012045987231804}, Best action: 0, Actual action: 0\n",
      "Step: 395\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.75216393006721, 1: -3.592167460561285, 2: -4.087739991693766, 3: -3.021584953187332, 4: -3.415908936804581}, Best action: 0, Actual action: 0\n",
      "Step: 396\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.634657831896153, 1: -2.991489214680363, 2: -2.9361937844912376, 3: -2.0110956195430303, 4: -2.667507876446222}, Best action: 3, Actual action: 3\n",
      "Step: 397\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -2.3710866627082847, 2: -2.379224805300048, 3: -2.8733396645170295, 4: -3.3717521803499486}, Best action: 1, Actual action: 1\n",
      "Step: 398\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.258971207478818, 1: -3.6386906900771456, 2: -4.118096398952865, 3: -3.02175879628464, 4: -3.415908936804581}, Best action: 3, Actual action: 3\n",
      "Step: 399\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6355974854347775, 1: -3.3725339812631323, 2: -3.2575375888686384, 3: -3.1612750554499818, 4: -3.1160181223643826}, Best action: 0, Actual action: 0\n",
      "Step: 400\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.634657839371033, 1: -2.991537997462225, 2: -2.9361937860049006, 3: -3.467637215388609, 4: -2.667507876446222}, Best action: 0, Actual action: 0\n",
      "Step: 401\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.552973745377988, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 402\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -2.726442630829125, 2: -3.504500011363227, 3: -2.8323051659740006, 4: -2.8613109789503235}, Best action: 1, Actual action: 1\n",
      "Step: 403\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -3.6717953324595762, 2: -2.379224805300048, 3: -2.87333966793149, 4: -3.3717521803499486}, Best action: 2, Actual action: 2\n",
      "Step: 404\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -3.6786851277910655, 2: -2.379224805300048, 3: -2.8733396679381236, 4: -3.3717521803499486}, Best action: 2, Actual action: 2\n",
      "Step: 405\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7245449647138154, 1: -3.68438042958985, 2: -3.065094572823044, 3: -2.8733396679436067, 4: -3.3717521803499486}, Best action: 0, Actual action: 0\n",
      "Step: 406\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.4789877527014834, 2: -3.504500011363227, 3: -2.8323051659740006, 4: -2.8613109789503235}, Best action: 3, Actual action: 3\n",
      "Step: 407\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.54660949346489, 2: -3.504500011363227, 3: -2.8323051659740006, 4: -2.8613109789503235}, Best action: 3, Actual action: 3\n",
      "Step: 408\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.1670612658109607, 1: -2.4466612139207498, 2: -3.343936771182487, 3: -2.115248085233152, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 409\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.5635350033014617, 2: -3.504500011363227, 3: -2.728752577290253, 4: -2.8613109789503235}, Best action: 3, Actual action: 3\n",
      "Step: 410\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.167061265811004, 1: -2.4466612139207498, 2: -3.343936771182487, 3: -3.3218143961284206, 4: -4.299857496081598}, Best action: 0, Actual action: 0\n",
      "Step: 411\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -2.206105492194561, 3: -1.8800782036244796, 4: -3.4613694859896125}, Best action: 3, Actual action: 3\n",
      "Step: 412\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: -2.4545430117113165, 3: -1.7406010573884088, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 413\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: -2.4545430117111997, 3: -1.7406010573878317, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 414\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: -2.4545430117112597, 3: -1.7406010573881268, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 415\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5457487290860203, 1: -1.9159843056815584, 2: -2.454543011711284, 3: -1.7406010573882476, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 416\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 417\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560438349749, 1: -2.50484044224286, 2: -2.799845171905021, 3: -2.1668723957995017, 4: -3.445841150229335}, Best action: 0, Actual action: 0\n",
      "Step: 418\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8505560438349749, 1: -2.50484044224286, 2: -2.799845171905021, 3: -2.1668723957995017, 4: -3.445841150229335}, Best action: 0, Actual action: 0\n",
      "Step: 419\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5840059998898273, 1: -2.50484044224286, 2: -2.799845171905021, 3: -2.1668723957995017, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 420\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0618697989001173, 1: -2.50484044224286, 2: -2.799845171905021, 3: -2.1668723957995017, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 421\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: -3.210446335168477, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 422\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.790898527379428, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 423\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.807506058629428, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 424\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 425\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -1.323225, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 426\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -1.4052375000000001, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 427\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -1.442143125, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 428\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4377500681907462, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -1.4572559784375, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 429\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.8178174657718524, 3: -2.001274450313098, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 430\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.817790300197153, 3: -1.990733025804205, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 431\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.8178182259691926, 3: -2.0015694399448303, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 432\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6276657812907704, 1: -2.385989932127035, 2: -2.817829661572843, 3: -2.0060069515354164, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 433\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2200649313601013, 1: -2.50484044224286, 2: -2.799845171905021, 3: -1.3814574056259894, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 434\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2200761493923626, 1: -2.50484044224286, 2: -2.799845171905021, 3: -1.381512803316169, 4: -3.445841150229335}, Best action: 3, Actual action: 3\n",
      "Step: 435\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.530795808151823, 1: -2.385989932127035, 2: -2.8178343490569073, 3: -2.0078258992273708, 4: -3.3203526686267795}, Best action: 3, Actual action: 3\n",
      "Step: 436\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6874602795749194, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -1.4597317640146577, 4: -2.580246428465575}, Best action: 3, Actual action: 3\n",
      "Step: 437\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6743072941590467, 1: -2.385989932127035, 2: -2.817834754833398, 3: -2.2832058300228963, 4: -3.427071397408901}, Best action: 3, Actual action: 3\n",
      "Step: 438\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6909027395897949, 1: -1.5955869280887085, 2: -3.210446335168477, 3: -2.895379303531519, 4: -2.582806327794137}, Best action: 1, Actual action: 1\n",
      "Step: 439\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 440\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 441\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -3.1904703820557625, 2: -2.080513246360786, 3: -1.9241691035283297, 4: -3.2759074881523054}, Best action: 3, Actual action: 3\n",
      "Step: 442\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -3.1904703820557625, 2: -2.080513246360786, 3: -1.9241691035283297, 4: -3.2759074881523054}, Best action: 3, Actual action: 3\n",
      "Step: 443\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3226005799070615, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -1.7406010573882889, 4: -3.116801037666662}, Best action: 3, Actual action: 3\n",
      "Step: 444\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.742372038398336, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 445\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 446\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 447\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 448\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 449\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.322600579881857, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -1.7802282307388289, 4: -3.116801037647919}, Best action: 3, Actual action: 3\n",
      "Step: 450\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.322600579890283, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -1.8234444383655435, 4: -3.1168010376541844}, Best action: 3, Actual action: 3\n",
      "Step: 451\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7308394603310562, 1: -2.1029109152150913, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 452\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.322600579890448, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -0.5172746142944455, 4: -3.116801037654307}, Best action: 3, Actual action: 3\n",
      "Step: 453\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3226005798908806, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -1.3801350821371343, 4: -3.1168010376546285}, Best action: 3, Actual action: 3\n",
      "Step: 454\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.322600579890995, 1: -1.9159843056815584, 2: -2.454543011711292, 3: -2.3843006536737144, 4: -3.1168010376547137}, Best action: 1, Actual action: 1\n",
      "Step: 455\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 456\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 457\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 458\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 459\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: -1.61775, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 460\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: -1.8820125, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 461\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -1.5529737453780603, 2: -3.489064123201957, 3: -1.99022799375, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 462\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -1.9404780602932885, 2: -2.9756110261754998, 3: -2.3616910166745537, 4: -3.5768627076789503}, Best action: 1, Actual action: 1\n",
      "Step: 463\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -2.3121734673184196, 2: -3.3748968915966646, 3: -2.601476506773195, 4: -2.912481952845669}, Best action: 1, Actual action: 1\n",
      "Step: 464\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 465\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -1.1312173467318418, 2: -3.3748968915966646, 3: -2.601476506773195, 4: -2.912481952845669}, Best action: 1, Actual action: 1\n",
      "Step: 466\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.008839403044598, 2: -3.531851065749112, 3: -3.0304918057691315, 4: -3.1012045987231804}, Best action: 1, Actual action: 1\n",
      "Step: 467\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5226335083451596, 1: -3.974843562929738, 2: -3.493275884671592, 3: -3.4200511540721754, 4: -3.6423750801308774}, Best action: 3, Actual action: 3\n",
      "Step: 468\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.4046641457074305, 1: -1.628053576664773, 2: -3.473065556611465, 3: -2.941176773798927, 4: -3.574185234628805}, Best action: 1, Actual action: 1\n",
      "Step: 469\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 470\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -4.355175166517603, 3: -3.590072077063887, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 471\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 472\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: -2.758979191210874, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 473\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 474\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 475\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.678693603565413, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 476\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.4046641457074305, 1: -2.4473450390238707, 2: -3.473065556611465, 3: -2.941176773798927, 4: -3.574185234628805}, Best action: 1, Actual action: 1\n",
      "Step: 477\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -4.355175166517603, 3: -2.018362787249998, 4: -4.407018599641358}, Best action: 3, Actual action: 2\n",
      "Step: 478\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -4.355175166517603, 3: -2.0367588494403828, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 479\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: -3.1066639545801937, 3: -1.8154706542586578, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 480\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: -3.1059613947535483, 3: -1.8077608070526714, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 481\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: -3.1062678504137926, 3: -1.8111238321307963, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 482\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4358522061623675, 1: -1.453713201132249, 2: -3.1063933440066624, 3: -1.8125009909002885, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 483\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.4046641457074305, 1: -3.9906087434137385, 2: -3.473065556611465, 3: -2.941176773798927, 4: -3.574185234628805}, Best action: 3, Actual action: 3\n",
      "Step: 484\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5226335083451596, 1: -3.974843562929738, 2: -3.493275884671592, 3: -2.9354265430198017, 4: -3.6423750801308774}, Best action: 3, Actual action: 3\n",
      "Step: 485\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.4046641457074305, 1: -4.009522198225897, 2: -3.473065556611465, 3: -3.5718131772259323, 4: -3.574185234628805}, Best action: 0, Actual action: 0\n",
      "Step: 486\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6309443932402607, 1: -3.849590810138258, 2: -2.751007834246434, 3: -1.9650653707569985, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 487\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.679548597131451, 1: -3.579884315772568, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 488\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045435985484, 2: -3.531851065749112, 3: -3.0304918057691315, 4: -3.1012045987231804}, Best action: 3, Actual action: 3\n",
      "Step: 489\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.7530456110170047, 2: -3.531851065749112, 3: -3.0304918057691315, 4: -3.1012045987231804}, Best action: 3, Actual action: 3\n",
      "Step: 490\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6309443932402607, 1: -3.849590810138258, 2: -2.751007834246434, 3: -2.7331400871184055, 4: -3.4237010561539294}, Best action: 0, Actual action: 0\n",
      "Step: 491\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.242131658163059, 1: -3.376744129426289, 2: -3.257615277943289, 3: -3.161282134866909, 4: -3.1160181223643826}, Best action: 4, Actual action: 4\n",
      "Step: 492\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.242131658163059, 1: -3.376744129426289, 2: -3.257615277943289, 3: -3.161282134866909, 4: -3.1160181223643826}, Best action: 4, Actual action: 4\n",
      "Step: 493\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.242131658163059, 1: -3.376744129426289, 2: -3.257615277943289, 3: -3.161282134866909, 4: -3.7355764913515883}, Best action: 3, Actual action: 3\n",
      "Step: 494\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 495\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -4.255375479121072, 2: -3.3748968915966646, 3: -2.601476506773195, 4: -2.912481952845669}, Best action: 3, Actual action: 3\n",
      "Step: 496\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: -3.007195970486288, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 497\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -4.255375479369901, 2: -3.3748968915966646, 3: -1.1601476506773194, 4: -2.912481952845669}, Best action: 3, Actual action: 3\n",
      "Step: 498\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: -2.7311412036454916, 3: -1.839719597048629, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 499\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: -2.6501110928904903, 3: -1.439570901962202, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 500\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: -2.6870167178904905, 3: -1.621820901962202, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 501\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.695916958745149, 1: -1.9724272904120284, 2: -2.7021295713279905, 3: -1.6964522769622021, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 502\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5988381854201272, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: 0.0, 4: -1.619477183439058}, Best action: 3, Actual action: 3\n",
      "Step: 503\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5988381854201272, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: 0.0, 4: -1.619477183439058}, Best action: 3, Actual action: 3\n",
      "Step: 504\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 505\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 506\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5988381854201272, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -1.61775, 4: -1.619477183439058}, Best action: 0, Actual action: 4\n",
      "Step: 507\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5988381854201272, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -2.267182880269708, 4: -1.619477183439058}, Best action: 0, Actual action: 0\n",
      "Step: 508\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -2.0480566507193125, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 509\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -2.0480566507193125, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 510\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -1.5594737942058432, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 511\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 512\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -2.3616910166745537, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 513\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -2.3616910166745537, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 514\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9294705211286596, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -2.4437517216179763, 4: -2.9557911996030484}, Best action: 3, Actual action: 3\n",
      "Step: 515\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.1660053354167195, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 516\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.925737708333014, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -1.1440931388451905, 4: -2.9541114338450076}, Best action: 3, Actual action: 3\n",
      "Step: 517\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.165842772714241, 2: -1.8267154424646046, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 518\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 519\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.0976232188880037, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 520\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.565559703769237, 1: -2.4466612139207498, 2: -3.343936771182487, 3: -3.173409137667583, 4: -4.299857496081598}, Best action: 1, Actual action: 1\n",
      "Step: 521\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.733544639464938, 1: -2.991542539912568, 2: -2.936193786145846, 3: -3.6140326418784734, 4: -2.667507876446222}, Best action: 4, Actual action: 4\n",
      "Step: 522\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.733544639464938, 1: -2.991542539912568, 2: -2.936193786145846, 3: -3.6140326418784734, 4: -2.667507876446222}, Best action: 4, Actual action: 4\n",
      "Step: 523\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.733544639464938, 1: -2.991542539912568, 2: -2.936193786145846, 3: -3.6140326418784734, 4: -3.3274321675660623}, Best action: 0, Actual action: 0\n",
      "Step: 524\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.08941320075741, 4: -2.8613109789503235}, Best action: 4, Actual action: 4\n",
      "Step: 525\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.08941320075741, 4: -2.8613109789503235}, Best action: 4, Actual action: 4\n",
      "Step: 526\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.08941320075741, 4: -3.5037929908447945}, Best action: 3, Actual action: 3\n",
      "Step: 527\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.565559703769237, 1: -3.7264739208271225, 2: -3.343936771182487, 3: -3.173409137667583, 4: -4.299857496081598}, Best action: 0, Actual action: 0\n",
      "Step: 528\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -3.1904703820557625, 2: -2.080513246360786, 3: -2.5972624638246065, 4: -3.2759074881523054}, Best action: 2, Actual action: 2\n",
      "Step: 529\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -3.1904703820557625, 2: -2.080513246360786, 3: -2.5972624638246065, 4: -3.2759074881523054}, Best action: 2, Actual action: 2\n",
      "Step: 530\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.596396048281003, 1: -3.1904703820557625, 2: -2.7932670541883153, 3: -2.5972624638246065, 4: -3.2759074881523054}, Best action: 0, Actual action: 0\n",
      "Step: 531\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049659475728271, 1: -2.4230168732944604, 2: -2.0883274068774877, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 0, Actual action: 0\n",
      "Step: 532\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049659475728271, 1: -2.4230168732944604, 2: -2.0883274068774877, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 0, Actual action: 0\n",
      "Step: 533\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7651901229127267, 1: -2.4230168732944604, 2: -2.0883274068774877, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 2, Actual action: 2\n",
      "Step: 534\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.914357551889228, 1: -2.4230168732944604, 2: -2.0883274068774877, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 2, Actual action: 2\n",
      "Step: 535\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3789705249203474, 1: -2.4230168732944604, 2: -2.800377940258514, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 1, Actual action: 1\n",
      "Step: 536\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2416067630311636, 1: -3.1904703820557625, 2: -3.923520698553082, 3: -2.5972624638246065, 4: -3.2759074881523054}, Best action: 3, Actual action: 3\n",
      "Step: 537\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -2.206105492194561, 3: -1.7156120530742514, 4: -3.4613694859896125}, Best action: 3, Actual action: 3\n",
      "Step: 538\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -1.6735551385529943, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 539\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -1.6735551385529943, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 540\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -1.6735551385529943, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 541\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -1.6735551385529943, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 542\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -1.6735551385529943, 4: -2.710186654331647}, Best action: 3, Actual action: 3\n",
      "Step: 543\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 544\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6906579037848333, 1: -1.8631079043222347, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 0, Actual action: 0\n",
      "Step: 545\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6906579037848333, 1: -1.8631079043222347, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 0, Actual action: 0\n",
      "Step: 546\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4384986924441985, 1: -1.8631079043222347, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 1, Actual action: 1\n",
      "Step: 547\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.8680023497517537, 2: -3.7538091688611233, 3: -2.2947324929313972, 4: -3.2378577474183747}, Best action: 1, Actual action: 1\n",
      "Step: 548\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -1.5594737942058432, 3: -2.298061713884433, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 549\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -1.5594737942058432, 3: -2.2980617138843176, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 550\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -1.5594737942058432, 3: -2.2980617138843775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 551\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -1.5594737942058432, 3: -2.298061713884402, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 552\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.321701282618795, 1: -3.7309404764144816, 2: -3.343936771182487, 3: -3.173409137667583, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 553\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.321701292445935, 1: -3.7309404764512024, 2: -3.343936771182487, 3: -3.173409137667583, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 554\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -1.9615471449024398, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 555\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -1.961547144902439, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 556\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.106803808632046, 2: -3.45972125141576, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 557\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 558\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 559\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 560\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 561\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 562\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 563\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -1.706471218500036, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 564\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -1.7733422202437081, 2: -3.7538091688611233, 3: -2.335978515092157, 4: -3.2473765115240174}, Best action: 1, Actual action: 1\n",
      "Step: 565\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3217012930286125, 1: -3.7309404764533793, 2: -3.343936771182487, 3: -2.6856381999591563, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 566\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -1.5015576527548913, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 567\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9304541172599965, 1: -2.1511163327816747, 2: -3.7490044893854617, 3: -2.298061713884419, 4: -4.18567568609232}, Best action: 0, Actual action: 0\n",
      "Step: 568\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3226005798910077, 1: -1.6569304800651632, 2: -2.454543011711292, 3: -2.6841829724889297, 4: -3.116801037654723}, Best action: 1, Actual action: 1\n",
      "Step: 569\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.700551300518117, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -2.8412235903544563, 4: -3.6947373928686584}, Best action: 0, Actual action: 0\n",
      "Step: 570\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3226005798910077, 1: -3.253139601426191, 2: -2.454543011711292, 3: -2.6841829724889297, 4: -3.116801037654723}, Best action: 0, Actual action: 0\n",
      "Step: 571\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7272065937635195, 1: -2.385989932127035, 2: -2.8178349044053443, 3: -2.5402118743175546, 4: -3.4664086390772777}, Best action: 1, Actual action: 1\n",
      "Step: 572\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -2.206105492194561, 3: -1.7063658571068705, 4: -3.4613694859896125}, Best action: 3, Actual action: 3\n",
      "Step: 573\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1255563354160047, 1: -3.573602776580438, 2: -2.454543011711292, 3: -2.6841829724889297, 4: -3.116801037654723}, Best action: 2, Actual action: 4\n",
      "Step: 574\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.508054448159554, 1: -3.6510586444110067, 2: -2.454543011711292, 3: -2.6841829724889297, 4: -3.116801037654723}, Best action: 2, Actual action: 2\n",
      "Step: 575\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.256362450298482, 1: -3.1904703820557625, 2: -3.9331487844950073, 3: -2.5452112211880125, 4: -3.2759074881523054}, Best action: 3, Actual action: 3\n",
      "Step: 576\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546481721782945, 1: -3.6588401673197435, 2: -3.2070753903334195, 3: -2.6841829724889297, 4: -3.538499513631576}, Best action: 3, Actual action: 3\n",
      "Step: 577\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.289898038355547, 1: -3.470667779842096, 2: -3.7538091688611233, 3: -2.33597863344328, 4: -3.24737653883711}, Best action: 0, Actual action: 0\n",
      "Step: 578\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 579\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7190114190066528, 1: -2.0445008346007527, 2: -3.2708431423171156, 3: -2.0045528780511757, 4: -3.9175517220912357}, Best action: 0, Actual action: 0\n",
      "Step: 580\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.292399249395389, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 581\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7272065937635195, 1: -3.49236784263286, 2: -2.8178349044053443, 3: -2.5402118743175546, 4: -3.4664086390772777}, Best action: 3, Actual action: 3\n",
      "Step: 582\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.202110675780095, 1: -2.5567976259300695, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 1, Actual action: 1\n",
      "Step: 583\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5414834865882194, 1: -2.0445008346007527, 2: -3.2708598716733155, 3: -2.0045538727630117, 4: -3.9175641624587403}, Best action: 3, Actual action: 3\n",
      "Step: 584\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7126036201524952, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 585\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.459256661146788, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 586\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 587\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566617121783, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 588\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.556665497806012, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 589\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.5566654978220014, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 590\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.5566654978291965, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 591\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.556665497832143, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 592\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618502218, 1: -1.6080522319500026, 2: -1.4965542318518628, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 593\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618494107, 1: -1.6038920541070294, 2: -1.4760101437384145, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 594\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 595\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.554646617073125, 1: -2.0445008346007527, 2: -3.2708599088918624, 3: -1.8309551855215147, 4: -3.917564190135382}, Best action: 3, Actual action: 3\n",
      "Step: 596\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.6241443384736265, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 597\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3297881974317485, 1: -3.4706923961523803, 2: -3.7538091688611233, 3: -2.3359786334441184, 4: -3.2473765388373033}, Best action: 0, Actual action: 0\n",
      "Step: 598\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7272065937635195, 1: -3.494861125325681, 2: -2.8178349044053443, 3: -3.290111386958777, 4: -3.4664086390772777}, Best action: 0, Actual action: 0\n",
      "Step: 599\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7272065937635195, 1: -3.4948611263002296, 2: -2.8178349044053443, 3: -3.2901142490157445, 4: -3.4664086390772777}, Best action: 0, Actual action: 0\n",
      "Step: 600\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.220087192866508, 1: -2.50484044224286, 2: -2.799845171905021, 3: -3.563629404652802, 4: -3.445841150229335}, Best action: 1, Actual action: 1\n",
      "Step: 601\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -2.206105492194561, 3: -3.8710453884246427, 4: -3.4613694859896125}, Best action: 2, Actual action: 2\n",
      "Step: 602\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2563624502984823, 1: -3.1904703820557625, 2: -3.9331487844950077, 3: -3.4893609946507658, 4: -3.2759074881523054}, Best action: 1, Actual action: 1\n",
      "Step: 603\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3217012930288625, 1: -3.7309404764533802, 2: -3.343936771182487, 3: -3.1704349750084133, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 604\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3217012930288625, 1: -3.7309404764533802, 2: -3.343936771182487, 3: -3.1704349750085012, 4: -4.299857496081598}, Best action: 3, Actual action: 3\n",
      "Step: 605\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112063755, 1: -3.0940084709944546, 2: -3.489064123201957, 3: -3.2474149495751914, 4: -3.6947373928686584}, Best action: 1, Actual action: 1\n",
      "Step: 606\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -2.991542539912568, 2: -2.936193786145846, 3: -3.6140326418784734, 4: -4.248465323107352}, Best action: 2, Actual action: 2\n",
      "Step: 607\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -3.6874041807759745, 2: -4.238441546521652, 3: -2.8733396679465177, 4: -3.3717521803499486}, Best action: 3, Actual action: 3\n",
      "Step: 608\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -2.991542539912568, 2: -3.521024509651264, 3: -3.6140326418784734, 4: -4.248465323107352}, Best action: 1, Actual action: 1\n",
      "Step: 609\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -1.6481684602194293, 4: -2.912481952845669}, Best action: 3, Actual action: 3\n",
      "Step: 610\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -1.6481684602194293, 4: -2.912481952845669}, Best action: 3, Actual action: 3\n",
      "Step: 611\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6901793249390997, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -1.712539676792166, 4: -2.7358518617653265}, Best action: 0, Actual action: 0\n",
      "Step: 612\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -2.005800301634991, 4: -2.955504859400784}, Best action: 3, Actual action: 3\n",
      "Step: 613\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -2.005800301634991, 4: -2.955504859400784}, Best action: 3, Actual action: 3\n",
      "Step: 614\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191566263488, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 615\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 616\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191561290865, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 617\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.165845037745787, 2: -1.8414975583723947, 3: -2.0055935534116367, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 618\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.165845037745787, 2: -1.8414975583723947, 3: -2.0055935534116367, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 619\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.165845037745787, 2: -1.8414975583723947, 3: -2.0055935534116367, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 620\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7687043527669988, 1: -2.165845037745787, 2: -1.8414975583723947, 3: -2.0055935534116367, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 621\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.7284415853212556, 4: -2.6814639410444268}, Best action: 3, Actual action: 3\n",
      "Step: 622\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618504998, 1: -1.6094786203210025, 2: -1.5035981250419868, 3: -2.8174014894815005, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 623\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618504998, 1: -1.6094786203207876, 2: -1.5035981250409254, 3: -2.817401489296166, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 624\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618504998, 1: -1.6094786203209204, 2: -1.503598125041581, 3: -2.8174014894106576, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 625\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4592566618504998, 1: -1.6094786203209748, 2: -1.5035981250418495, 3: -2.817401489457542, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 626\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 627\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 628\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 629\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 630\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 3\n",
      "Step: 631\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.4708475, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 632\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.381654805625, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 633\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 634\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 635\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 636\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 637\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5440440203086137, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 638\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.740883380371036, 1: -1.6094786203209845, 2: -1.503598125041898, 3: -2.817401489466042, 4: -2.6327674543632744}, Best action: 2, Actual action: 2\n",
      "Step: 639\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.337606059529297, 1: -2.1511163327816747, 2: -3.7490154576255557, 3: -2.298061713884419, 4: -4.18568384234986}, Best action: 1, Actual action: 1\n",
      "Step: 640\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -1.5288160560089543, 4: -2.955504859400784}, Best action: 3, Actual action: 3\n",
      "Step: 641\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -1.528816056291421, 4: -2.955504859400784}, Best action: 3, Actual action: 3\n",
      "Step: 642\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4523036195250234, 1: -2.165845037745787, 2: -1.8414975583723947, 3: -2.0055935534116367, 4: -3.345887761030384}, Best action: 2, Actual action: 2\n",
      "Step: 643\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -2.769015985831765, 4: -2.955504859400784}, Best action: 3, Actual action: 3\n",
      "Step: 644\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5933582130269905, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -2.938026372761074, 4: -3.5768627076789503}, Best action: 0, Actual action: 0\n",
      "Step: 645\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112064051, 1: -4.000957268454407, 2: -3.489064123201957, 3: -3.2474149495752185, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 646\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112064051, 1: -4.000957268454442, 2: -3.489064123201957, 3: -3.2474149495752185, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 647\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.337606059529297, 1: -2.9108346104556597, 2: -3.7490154576255557, 3: -2.298061713884419, 4: -4.18568384234986}, Best action: 3, Actual action: 3\n",
      "Step: 648\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.337606059529297, 1: -2.9081882727186628, 2: -3.7490154576255557, 3: -2.298061713884419, 4: -4.18568384234986}, Best action: 3, Actual action: 3\n",
      "Step: 649\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.337606059529297, 1: -2.90935385424095, 2: -3.7490154576255557, 3: -2.9912361596348216, 4: -4.18568384234986}, Best action: 1, Actual action: 1\n",
      "Step: 650\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.006122623249357, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -2.938026372761074, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 651\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.018319904373973, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -2.938026372761074, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 652\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.452303674551745, 1: -2.165845037745787, 2: -3.4529272561502897, 3: -2.0055935534116367, 4: -3.3458878019496288}, Best action: 3, Actual action: 3\n",
      "Step: 653\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.452303674539456, 1: -2.165845037745787, 2: -3.4524038504483947, 3: -2.0055935534116367, 4: -3.3458878019404903}, Best action: 3, Actual action: 3\n",
      "Step: 654\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4523036745452083, 1: -2.165845037745787, 2: -3.4526488435589795, 3: -2.7250901336045894, 4: -3.3458878019447678}, Best action: 1, Actual action: 1\n",
      "Step: 655\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5931066182623423, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 656\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 657\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 658\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 659\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262331, 1: -1.4872500000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 660\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5931066182623321, 1: -1.5692625000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 661\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -1.712539676792166, 4: -2.7358518617653265}, Best action: 3, Actual action: 3\n",
      "Step: 662\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -1.712539676792166, 4: -2.7358518617653265}, Best action: 3, Actual action: 3\n",
      "Step: 663\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.6524413345076947, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 664\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -0.5551846127063345, 4: -2.7358518617653265}, Best action: 3, Actual action: 3\n",
      "Step: 665\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.639428315104972, 2: -1.349699536292131, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 666\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.6379624950215905, 2: -1.1731747944366662, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 667\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.6394758563067469, 2: -1.3554247944366662, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 668\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.639543957564579, 2: -1.3636260444366661, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 669\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.639850413224823, 2: -1.400531669436666, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 670\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.6399759068176931, 2: -1.415644522874166, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 671\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -1.629444475177358, 4: -2.7358518617653265}, Best action: 3, Actual action: 3\n",
      "Step: 672\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -1.6395904200915858, 4: -2.7358518617653265}, Best action: 3, Actual action: 3\n",
      "Step: 673\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.9724272904120284, 2: -2.7053872697935577, 3: -2.395664472883561, 4: -2.7358518617653265}, Best action: 1, Actual action: 1\n",
      "Step: 674\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 675\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 676\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 677\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 678\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.588764312443104, 2: -1.7236234209673218, 3: -2.7388083084827644, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 679\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.588764312443104, 2: -1.7236234209673218, 3: -2.7388083084827644, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 680\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.588764312443104, 2: -1.7236234209673218, 3: -2.7388083084827644, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 681\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -1.588764312443104, 2: -1.7236234209673218, 3: -2.7388083084827644, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 682\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -3.6443247888021224, 2: -3.6524811399360253, 3: -2.1411155085706333, 4: -4.433893448677837}, Best action: 3, Actual action: 3\n",
      "Step: 683\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -3.6443247888021224, 2: -3.6524811399360253, 3: -2.1411155085706333, 4: -4.433893448677837}, Best action: 3, Actual action: 3\n",
      "Step: 684\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -3.6443247888021224, 2: -3.6524811399360253, 3: -2.8484151127992763, 4: -4.433893448677837}, Best action: 3, Actual action: 3\n",
      "Step: 685\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -3.6443247888021224, 2: -3.6524811399360253, 3: -3.781696940578971, 4: -4.433893448677837}, Best action: 1, Actual action: 1\n",
      "Step: 686\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -3.6443247888021224, 2: -3.6524811399360253, 3: -4.522638003634258, 4: -4.433893448677837}, Best action: 1, Actual action: 1\n",
      "Step: 687\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -4.2163355578099315, 2: -3.6524811399360253, 3: -4.94799951173769, 4: -4.433893448677837}, Best action: 2, Actual action: 2\n",
      "Step: 688\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -4.308856753722833, 2: -3.6524811399360253, 3: -4.9693515692823995, 4: -4.433893448677837}, Best action: 2, Actual action: 2\n",
      "Step: 689\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9074146205254507, 1: -4.68161479878009, 2: -4.2237578373417834, 3: -5.055376735189342, 4: -4.433893448677837}, Best action: 0, Actual action: 0\n",
      "Step: 690\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.794346179478611, 1: -2.5465369396227553, 2: -3.777098098040183, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 1, Actual action: 1\n",
      "Step: 691\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3534363831469767, 1: -4.685823496852889, 2: -4.244541531528444, 3: -5.0563480192562205, 4: -4.433893448677837}, Best action: 0, Actual action: 0\n",
      "Step: 692\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.794346179478611, 1: -3.8709371643113264, 2: -3.777098098040183, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 2, Actual action: 2\n",
      "Step: 693\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.794346179478611, 1: -4.053175744922956, 2: -3.777098098040183, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 2, Actual action: 2\n",
      "Step: 694\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.794346179478611, 1: -4.166588132086173, 2: -4.337159269216567, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 0, Actual action: 0\n",
      "Step: 695\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -2.8773105088888764, 3: -1.791277241079423, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 696\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -2.8773105088888764, 3: -1.791277241079423, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 697\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -1.453713201132249, 2: -3.10648238203833, 3: -1.8134780886415076, 4: -4.221414574443345}, Best action: 1, Actual action: 1\n",
      "Step: 698\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.1299408624979685, 3: -1.1422574011241142, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 699\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.1299408624979685, 3: -1.1422574011241142, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 700\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.9201435773025899, 3: -1.8202742776924645, 4: -2.9464804874893615}, Best action: 3, Actual action: 3\n",
      "Step: 701\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402690223827, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 702\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.1299408624979685, 3: -2.3696725278929023, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 703\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.4268249792512293, 2: -4.1299408624979685, 3: -3.1975290556549703, 4: -3.421132069761311}, Best action: 1, Actual action: 1\n",
      "Step: 704\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -1.7205452434190167, 4: -4.2259042668008755}, Best action: 3, Actual action: 3\n",
      "Step: 705\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 706\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -3.31330115607574, 2: -1.7236234209673218, 3: -2.7388083084827644, 4: -3.879100724159225}, Best action: 2, Actual action: 2\n",
      "Step: 707\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -2.10531526128449, 4: -4.2259042668008755}, Best action: 3, Actual action: 3\n",
      "Step: 708\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -2.3187592285453844, 4: -4.2259042668008755}, Best action: 3, Actual action: 3\n",
      "Step: 709\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.9104455112897223, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 710\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.232974399415388, 1: -3.3133011691049696, 2: -2.710941553671337, 3: -2.7388083084827644, 4: -3.879100733848086}, Best action: 0, Actual action: 0\n",
      "Step: 711\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.9201435773025899, 3: -2.38433753428471, 4: -2.9464804874893615}, Best action: 2, Actual action: 2\n",
      "Step: 712\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -1.9201435773025899, 3: -2.3844892772820443, 4: -2.9464804874893615}, Best action: 2, Actual action: 2\n",
      "Step: 713\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1184965104526885, 1: -4.145250731469095, 2: -3.997634101647162, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 0, Actual action: 0\n",
      "Step: 714\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -2.8773105088888764, 3: -2.9287202978043676, 4: -4.407018599641358}, Best action: 2, Actual action: 2\n",
      "Step: 715\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -2.8773105088888764, 3: -2.928721080008451, 4: -4.407018599641358}, Best action: 2, Actual action: 2\n",
      "Step: 716\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -3.5183525630888774, 3: -2.9287216122144573, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 717\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -3.6716860018037725, 3: -2.9287216517215104, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 718\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -4.086946822806427, 3: -3.565136810060401, 4: -4.407018599641358}, Best action: 3, Actual action: 3\n",
      "Step: 719\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9251557354449873, 1: -3.925351538375737, 2: -4.256996126179568, 3: -4.40488650016149, 4: -4.407018599641358}, Best action: 0, Actual action: 0\n",
      "Step: 720\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.190882099657686, 1: -4.011071269818004, 2: -3.473065556611465, 3: -3.9856739219267814, 4: -3.574185234628805}, Best action: 0, Actual action: 0\n",
      "Step: 721\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -2.751007834246434, 3: -2.7622047813653827, 4: -3.4237010561539294}, Best action: 2, Actual action: 2\n",
      "Step: 722\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045629114089, 2: -3.531851065749112, 3: -4.120231018236092, 4: -3.1012045987231804}, Best action: 4, Actual action: 4\n",
      "Step: 723\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045629114089, 2: -3.531851065749112, 3: -4.120231018236092, 4: -3.1012045987231804}, Best action: 4, Actual action: 4\n",
      "Step: 724\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045629114089, 2: -3.531851065749112, 3: -4.120231018236092, 4: -3.7220961848380942}, Best action: 2, Actual action: 2\n",
      "Step: 725\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045629114089, 2: -3.531851065749112, 3: -4.120231018236092, 4: -4.3179197403467136}, Best action: 2, Actual action: 2\n",
      "Step: 726\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -3.753045629114089, 2: -4.113984469831692, 3: -4.120231018236092, 4: -4.697761786510597}, Best action: 1, Actual action: 1\n",
      "Step: 727\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.06006188769397, 1: -4.011071269818004, 2: -3.473065556611465, 3: -3.9856739219267814, 4: -3.574185234628805}, Best action: 2, Actual action: 2\n",
      "Step: 728\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5226335083451596, 1: -3.974843562929738, 2: -3.493275884671592, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 2, Actual action: 2\n",
      "Step: 729\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5226335083451596, 1: -3.974843562929738, 2: -3.493275884671592, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 2, Actual action: 2\n",
      "Step: 730\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5226335083451596, 1: -3.974843562929738, 2: -4.078881055051149, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 0, Actual action: 0\n",
      "Step: 731\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.125998872400518, 3: -2.7622047813653827, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 732\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 733\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 734\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.125571781248199, 3: -1.5812204781365382, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 735\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.125722152124633, 3: -2.022830167062884, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 736\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.12574442898726, 3: -2.8061982161195997, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 737\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -2.0857369513660964, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 738\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -1.9834515899258556, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 739\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -2.0000591211758554, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 740\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -2.0068599052227305, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 741\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 742\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 743\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.6356063821735773, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 1, Actual action: 1\n",
      "Step: 744\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 745\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 746\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 747\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 748\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402749857716, 2: -2.8948237347673205, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 749\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 750\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 751\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402749857716, 2: -2.8948237347673205, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 752\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402749857716, 2: -2.8948237347673205, 3: -1.4872500000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 753\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402749857716, 2: -2.8948237347673205, 3: -1.5692625000000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 754\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.5696402749857716, 2: -2.8948237347673205, 3: -1.6028466187500003, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 755\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 756\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4764889859985217, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 757\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 758\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 759\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.4872500000000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 760\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.5618813750000002, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 761\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.505526749705084, 1: -1.496939222265469, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 762\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5053509597971413, 1: -1.4757693198523445, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 763\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -2.428345970149353, 4: -4.2259042668008755}, Best action: 3, Actual action: 3\n",
      "Step: 764\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -3.00119565100011, 3: -2.7388083084827644, 4: -3.8791007343098767}, Best action: 3, Actual action: 3\n",
      "Step: 765\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.9711112410014402, 4: -2.8509354799504485}, Best action: 3, Actual action: 3\n",
      "Step: 766\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056600870235304, 1: -1.5129966743261551, 2: -4.500624707483263, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 767\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056545879396608, 1: -1.5123344345523162, 2: -4.384984681568328, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 768\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 769\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 770\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 771\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 772\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.934353997164571, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 773\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.4649176521750746, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 774\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972160921, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 775\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 776\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 777\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 778\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.4649176521751226, 3: -1.5692625000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 779\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.464917652175123, 3: -1.6061681250000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 780\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.4649176521751235, 3: -1.6227756562500002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 781\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.4649176521751235, 3: -1.629576440296875, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 782\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.6302834700580784, 2: -2.4649176521751235, 3: -1.6308512581650563, 4: -2.651320067248375}, Best action: 1, Actual action: 1\n",
      "Step: 783\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: -2.298564438286979, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 784\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.585051395576567, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 785\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635965477314487, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 786\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 787\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635983698880743, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 788\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.633951753159743, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 789\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.6339517531597454, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 790\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.6339517531597465, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 791\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.633951753159747, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 792\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234465, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 793\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.0633951753159745, 4: -2.2328963976990748}, Best action: 3, Actual action: 3\n",
      "Step: 794\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 795\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 796\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 797\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -1.6063381237435979, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 798\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -4.695674249610679, 3: -2.3846981084145424, 4: -2.9464804874893615}, Best action: 3, Actual action: 3\n",
      "Step: 799\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.7682994476411278, 2: -2.8948237347673205, 3: -1.6098957822743247, 4: -2.7188219388411694}, Best action: 3, Actual action: 3\n",
      "Step: 800\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.7682994476411278, 2: -2.8948237347673205, 3: -1.6098957822743247, 4: -2.7188219388411694}, Best action: 3, Actual action: 3\n",
      "Step: 801\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -1.768299447641128, 2: -2.8948237347673205, 3: -2.3650051618696355, 4: -2.7188219388411694}, Best action: 1, Actual action: 1\n",
      "Step: 802\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -3.00119565100011, 3: -2.6341944415873355, 4: -3.8791007343098767}, Best action: 3, Actual action: 3\n",
      "Step: 803\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.6638833827298325, 4: -2.847745460783589}, Best action: 3, Actual action: 3\n",
      "Step: 804\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.663883382729814, 4: -2.8477454607835884}, Best action: 3, Actual action: 3\n",
      "Step: 805\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056581840707417, 1: -1.5127675068767958, 2: -4.460607585543956, 3: -2.098177661298479, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 806\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056581840707417, 1: -1.5127675068767958, 2: -4.460607585543951, 3: -2.0981776612982066, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 807\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056581840707417, 1: -1.5127675068767958, 2: -4.460607585543952, 3: -2.098177661298293, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 808\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5056581840707417, 1: -1.5127675068767958, 2: -4.460607585543953, 3: -2.0981776612983287, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 809\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -2.634793525326857, 2: -4.695674249610679, 3: -2.95813403341634, 4: -2.9464804874893615}, Best action: 1, Actual action: 1\n",
      "Step: 810\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -3.00119565100011, 3: -2.725034417861048, 4: -3.8791007343098767}, Best action: 3, Actual action: 3\n",
      "Step: 811\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.5477626894274106, 4: -2.847745460783589}, Best action: 3, Actual action: 3\n",
      "Step: 812\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -1.5441346788989974, 4: -2.847745460783589}, Best action: 3, Actual action: 3\n",
      "Step: 813\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.524263958876887, 1: -1.5127675068767958, 2: -4.460607585543953, 3: -2.0981776612983514, 4: -3.986538102623509}, Best action: 1, Actual action: 1\n",
      "Step: 814\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5261906093446695, 1: -1.5127675068767958, 2: -4.460607585543953, 3: -2.0981776612983514, 4: -3.9879708080776135}, Best action: 1, Actual action: 1\n",
      "Step: 815\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5402858072302257, 1: -2.2766184312578845, 2: -4.460607585543953, 3: -2.0981776612983514, 4: -3.99845234960526}, Best action: 3, Actual action: 3\n",
      "Step: 816\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 817\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 818\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299657823543, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 819\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 820\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6180970244946584, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -2.9964771175250577, 4: -2.847745460783589}, Best action: 0, Actual action: 0\n",
      "Step: 821\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.76847083500253, 1: -3.43341462475722, 2: -4.695674249610679, 3: -2.9588281452323084, 4: -2.9464804874893615}, Best action: 0, Actual action: 0\n",
      "Step: 822\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.634680849274616, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.7324375552569347, 4: -2.8068256305737034}, Best action: 0, Actual action: 0\n",
      "Step: 823\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7453699147489847, 1: -1.7994358682322067, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 0, Actual action: 0\n",
      "Step: 824\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -1.9713232523092723, 4: -3.1281476955423115}, Best action: 3, Actual action: 3\n",
      "Step: 825\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -1.9713232523092723, 4: -3.1281476955423115}, Best action: 3, Actual action: 3\n",
      "Step: 826\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6272072072576078, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 827\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6272072072576078, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 828\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6272072072576078, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 829\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6272072072576078, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 830\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6272072072576078, 4: -2.648148789594489}, Best action: 3, Actual action: 3\n",
      "Step: 831\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 832\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 833\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 834\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 835\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262333, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 836\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 837\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 838\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 839\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 840\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4872500000000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 841\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6336120703906252, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 842\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 843\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 844\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6302490453125003, 1: -1.4872500000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 845\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262333, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.6351254316757815, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 846\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262333, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.6358064442541018, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 847\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262333, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.636112899914346, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 848\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.593106618262333, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.636238393507216, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 849\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -1.5402369294718499, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 850\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363094929317987, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 851\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4523036745454285, 1: -1.853282150181402, 2: -3.4526582057887354, 3: -2.8136852219472654, 4: -3.345887801944931}, Best action: 1, Actual action: 1\n",
      "Step: 852\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7301426121472283, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -3.3152033570747963, 4: -2.912481952845669}, Best action: 0, Actual action: 0\n",
      "Step: 853\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.7802585172926086, 2: -2.8862541632493444, 3: -4.099421644982031, 4: -2.955504859400784}, Best action: 1, Actual action: 1\n",
      "Step: 854\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -1.8308702905673373, 2: -2.7053872697935577, 3: -2.7991766761587176, 4: -2.7358518617653265}, Best action: 1, Actual action: 1\n",
      "Step: 855\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.7970696489166287, 2: -2.4649176521751235, 3: -2.4600605021507636, 4: -3.266905676386616}, Best action: 1, Actual action: 1\n",
      "Step: 856\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: -2.298564438286981, 3: -1.6312028931351568, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 857\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: -2.298564438286981, 3: -1.6312028931351568, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 858\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: -2.298564438286981, 3: -1.6312028931351568, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 859\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -1.6228521556846196, 2: -2.298564438286981, 3: -1.6312028931351568, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 860\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -3.250597806623883, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: -3.8429276062657522}, Best action: 3, Actual action: 3\n",
      "Step: 861\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -3.250597806623883, 2: -1.6352782889218858, 3: -1.6310038959105506, 4: -3.8429276062657522}, Best action: 3, Actual action: 3\n",
      "Step: 862\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 863\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 864\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -2.58 -2.82 -2.80 -2.66 \n",
      "0.00 0.00 0.00 0.00 0.00 -2.04 -2.34 -3.04 -2.76 -3.26 \n",
      "0.00 0.00 0.00 0.00 -1.61 -1.67 -3.34 -3.49 -3.32 -3.17 \n",
      "0.00 0.00 0.00 0.00 0.00 -2.45 -2.89 -2.98 -3.00 -3.37 \n",
      "0.00 0.00 0.00 0.00 -1.64 -1.64 -2.50 -2.91 -2.43 -3.25 \n",
      "0.00 0.00 0.00 0.00 0.00 -1.63 -1.72 -1.39 -0.65 -3.92 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -1.63 -1.80 -3.57 -3.18 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -1.17 -1.72 -1.81 -3.93 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -1.82 -2.95 -2.73 -3.94 \n",
      "0.00 0.00 0.00 0.00 0.00 -1.92 -2.85 -2.87 -2.97 -4.43 \n",
      "\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.432860978279934, 3: -2.0237199803366113, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.432860978279934, 3: -2.0237199803366113, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.432860978279934, 3: -2.0237199803366113, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.432860978279934, 3: -2.0237199803366113, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -1.3986860533069072, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -1.3986860533069072, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -1.3986860533069072, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -1.3986860533069072, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5469875306858358, 1: -1.820025375570338, 2: -1.6281796694051431, 3: -2.0237199803366113, 4: -2.5332553651401315}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -2.2929285051862176, 4: -3.00724855528138}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.4981477372790741, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -2.6174734054966766, 4: -3.2485882567747453}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6125234369048314, 1: -1.820025375570338, 2: -1.6845113332369959, 3: -2.0237199803366113, 4: -2.575144998657093}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.593147656405044, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -2.7931479745438788, 4: -3.379224258182471}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5612125842442266, 1: -2.66844283172242, 2: -3.2950281828381494, 3: -2.853985848026186, 4: -3.424464821850752}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5546638241778323, 1: -2.0445008346007527, 2: -3.270859908940516, 3: -2.621314015342469, 4: -3.9175641901715617}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -1.6737650412890313, 4: -2.6814639410890244}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7410800142867362, 1: -1.6094786203209845, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -2.6329136762588368}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4523036745454285, 1: -3.6466077337330214, 2: -3.4526582057887354, 3: -2.8136852219472654, 4: -3.345887801944931}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.337606059529297, 1: -3.785085100261147, 2: -3.7490154576255557, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.470692396179706, 2: -3.7538091688611233, 3: -2.3359786334441184, 4: -3.2473765388373033}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5546638241778323, 1: -3.183706197783516, 2: -3.270859908940516, 3: -2.621314015342469, 4: -3.9175641901715617}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7679040933111665, 1: -3.342730881537958, 2: -3.2950281828381494, 3: -2.856934182869865, 4: -3.4266572773488826}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7698942683444763, 1: -3.346149655282384, 2: -3.2950281828381494, 3: -2.8569625715657634, 4: -3.42667838789287}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8004165145683175, 1: -1.820025375570338, 2: -3.2444137491906058, 3: -2.0237199803366113, 4: -2.57772326233843}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.601809012591142, 1: -3.2083981324631416, 2: -3.270859908940516, 3: -2.621314015342469, 4: -3.9175641901715617}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.624265379144443, 2: -3.418061140370249, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6848110697846534, 1: -3.209087362092469, 2: -3.270859908940516, 3: -1.5671314015342468, 4: -3.9175641901715617}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.624265379144443, 2: -3.418061140370249, 3: -1.8762193958592328, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.624265379144443, 2: -3.418061140370249, 3: -1.692797504726711, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.624265379144443, 2: -3.418061140370249, 3: -1.774810004726711, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -1.624265379144443, 2: -3.418061140370249, 3: -1.8083941234767111, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7410800142867362, 1: -3.758846070515046, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -2.6329136762588368}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.0412834451143462, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.038791174441403, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.0406790926446354, 3: -1.61775, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.040816997691745, 3: -1.8820125, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.0408790549629447, 3: -2.000930625, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5447874402259707, 1: -2.8517290675266516, 2: -2.040904467415501, 3: -2.0496275971875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8004125761523735, 1: -2.916862480062397, 2: -3.244370456587706, 3: -2.0237199803366113, 4: -2.577723208295594}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -1.4978774749506452, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5366247148040044, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.3050000000000002, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.323225, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5392988375337364, 1: -1.534017628125, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.2658987779666866, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.2658988249242222, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393081823697412, 1: -1.5463674035507813, 2: -1.3050000000000002, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393082339006448, 1: -1.5464355048086134, 2: -1.323225, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393084657897107, 1: -1.5467419604688575, 2: -1.4052375000000001, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393084762247187, 1: -1.5467557509735685, 2: -1.4089280625000002, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393085231822545, 1: -1.5468178082447679, 2: -1.4255355937500003, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393085424113655, 1: -1.5468432206973242, 2: -1.4323363777968752, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.2658988527342596, 3: -1.8166449226586199, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.2658988527000687, 3: -1.8119526014075427, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.2658988527356008, 3: -1.816828987770824, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6354023815654037, 2: -2.265898852750151, 3: -1.8188258679865876, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -1.5402369294718499, 3: -2.343669774410325, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -1.5402369294718499, 3: -2.343669774410325, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -1.5402369294718499, 3: -2.343669774410325, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -1.5402369294718499, 3: -2.343669774410325, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.963801881451117, 2: -2.8862541632493444, 3: -4.099421644982031, 4: -2.955504859400784}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -3.000256047440943, 2: -3.8545036852055516, 3: -3.6140326418784734, 4: -4.248465323107352}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.242131658163059, 1: -3.376744129426289, 2: -3.257615277943289, 3: -2.4335524848937933, 4: -3.4037314409314896}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -3.3152033570747963, 4: -2.912481952845669}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -3.3152033570747963, 4: -2.912481952845669}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -3.3152033570747963, 4: -3.5503585770895594}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.5036949447058103, 2: -2.7053872697935577, 3: -2.7991766761587176, 4: -2.7358518617653265}, Best action: 1, Actual action: 1\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -1.6345094594696656, 3: -1.6465935686280295, 4: -3.039077690272842}, Best action: 2, Actual action: 2\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -1.7192507600868685, 2: -2.4649176521751235, 3: -2.4600605021507636, 4: -3.266905676386616}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -1.6312028931351568, 4: -3.333318206420599}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -0.9, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 -1.84 -3.09 -2.58 -2.82 -2.80 -2.66 \n",
      "0.00 0.00 0.00 -2.04 -1.82 -1.69 -3.25 -3.04 -2.76 -3.26 \n",
      "0.00 0.00 -1.54 -1.76 -1.64 -2.54 -3.75 -3.49 -3.32 -3.17 \n",
      "0.00 0.00 0.00 0.00 -1.58 -2.81 -2.93 -2.98 -3.61 -3.37 \n",
      "0.00 0.00 0.00 0.00 -1.64 -1.64 -2.71 -3.37 -3.24 -3.25 \n",
      "0.00 0.00 0.00 0.00 0.00 -1.64 -2.38 -1.39 -0.65 -3.92 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -1.74 -1.80 -3.57 -3.18 \n",
      "0.00 0.00 0.00 0.00 0.27 -1.23 -1.17 -1.72 -1.81 -3.93 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 -1.82 -2.95 -2.73 -3.94 \n",
      "0.00 0.00 0.00 0.00 0.00 -1.92 -2.85 -2.87 -2.97 -4.43 \n",
      "\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: -1.6083201886775063, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: -1.6083201886775063, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: -1.6083201886775063, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: -1.6083201886775063, 3: -1.4872500000000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -1.5618102281296125, 2: -1.6083201886775063, 3: -1.5618813750000002, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6087971409406023, 1: -2.8517290675266516, 2: -2.0409149575529293, 3: -2.069729471632008, 4: -3.3290520846223846}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -2.08208102165345, 2: -3.418061140370249, 3: -1.818411730898818, 4: -2.9846542362800768}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6087971409406023, 1: -2.8517290675266516, 2: -2.5770049977833356, 3: -2.069729471632008, 4: -3.3290520846223846}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6087971409406023, 1: -2.8517290675266516, 2: -2.999964639179181, 3: -2.069729471632008, 4: -3.3290520846223846}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6087971409406023, 1: -2.8517290675266516, 2: -3.144493819558688, 3: -2.7834538191851275, 4: -3.3290520846223846}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -1.4978774749506447, 3: -1.62820644386014, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -1.4978774749506447, 3: -1.62820644386014, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -1.4978774749506447, 3: -1.62820644386014, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -1.4978774749506447, 3: -1.62820644386014, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -2.701437818957919, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -2.701437818957919, 2: -3.210446335168477, 3: -2.749773881240509, 4: -2.582624261768672}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -2.701437818957919, 2: -3.210446335168477, 3: -2.749773881240509, 4: -3.2501880782094914}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5639039405588377, 1: -3.6623681666218624, 2: -3.6319427892273137, 3: -3.0411866762066806, 4: -3.7296898431338272}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7017583492527297, 1: -3.2092280883291537, 2: -3.270859908940516, 3: -1.694946730016913, 4: -3.9175641901715617}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -2.08208102165345, 2: -3.418061140370249, 3: -3.1120302290727992, 4: -2.9846542362800768}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.543335188001673, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -3.338272422233393, 4: -2.6814639410890244}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.470692396179706, 2: -3.7538091688611233, 3: -3.7190680972121593, 4: -3.2473765388373033}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.470692396179706, 2: -3.7538091688611233, 3: -3.7190680972121593, 4: -3.2473765388373033}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.470692396179706, 2: -3.7538091688611233, 3: -3.7190680972121593, 4: -3.855112650341946}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.10712580519403, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -3.338272422233393, 4: -2.6814639410890244}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.102420350374048, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -3.338272422233393, 4: -2.6814639410890244}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.129429865107963, 1: -3.1068038086320455, 2: -3.4597212514154925, 3: -3.338272422233393, 4: -3.3401321863910125}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -2.9780866550023686, 2: -2.9756110261754998, 3: -3.0580324326874244, 4: -3.5768627076789503}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -3.6874041807759745, 2: -4.238441546521652, 3: -3.6144045025115985, 4: -3.3717521803499486}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -3.6874041807759745, 2: -4.238441546521652, 3: -3.6144045025115985, 4: -3.3717521803499486}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -3.6874041807759745, 2: -4.238441546521652, 3: -3.6144045025115985, 4: -3.968294484118454}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -2.9780866550023686, 2: -4.249005434190712, 3: -3.0580324326874244, 4: -3.5768627076789503}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -3.3748968915966646, 3: -3.4784726892824747, 4: -4.222380216137544}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.242131658163059, 1: -3.376744129426289, 2: -3.257615277943289, 3: -3.8833614090711683, 4: -3.4037314409314896}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -4.151398895997321, 2: -4.302521018624823, 3: -3.0580324326874244, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -4.244364171068659, 2: -4.306333175935717, 3: -3.0580324326874244, 4: -3.5768627076789503}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.928834209568071, 1: -2.963801881451117, 2: -3.9893453034282236, 3: -4.099421644982031, 4: -2.955504859400784}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.748293557738284, 1: -3.785085100261147, 2: -3.7490154576255557, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5639039405588377, 1: -3.6623681666218624, 2: -3.6319427892273137, 3: -3.4205181214724485, 4: -3.7296898431338272}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.900114710048773, 2: -3.7538091688611233, 3: -3.7190680972121593, 4: -4.485716920758339}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7017583492527297, 1: -3.2092280883291537, 2: -3.270859908940516, 3: -3.5693749089158273, 4: -3.9175641901715617}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112064051, 1: -4.0009572684544485, 2: -3.489064123201957, 3: -3.561906215103313, 4: -3.6947373928686584}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1729968985195196, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.6273083952956555, 4: -4.215835556518121}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2563624502984823, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -3.4893609965078536, 4: -3.2759074881523054}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.220087192866508, 1: -3.8054293012861122, 2: -2.799845171905021, 3: -3.563629404652802, 4: -3.445841150229335}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -3.2226612238409453, 2: -3.818485984637077, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -3.2226612238409453, 2: -3.818485984637077, 3: -3.041464648152696, 4: -2.6579189945004136}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -3.2226612238409453, 2: -3.818485984637077, 3: -3.041464648152696, 4: -3.3187062849953763}, Best action: 3, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -3.2226612238409453, 2: -3.818485984637077, 3: -3.041464648152696, 4: -4.19061511480348}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.220087192866508, 1: -3.8054293012861122, 2: -3.71484374682267, 3: -3.563629404652802, 4: -3.445841150229335}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -3.2226612238409453, 2: -3.818485984637077, 3: -3.8124170910371413, 4: -4.089748763820538}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9245706395440125, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -3.4893609965078536, 4: -3.2759074881523054}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.927011037240706, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -3.4893609965078536, 4: -3.2759074881523054}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.92802863536923, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -3.4893609965078536, 4: -3.881075814218598}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617348311488352, 1: -3.375167798544845, 2: -4.13499395527063, 3: -3.871045388678209, 4: -3.4613694859896125}, Best action: 0, Actual action: 0\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -4.195031686157689, 2: -3.818485984637077, 3: -4.2848468126353705, 4: -4.44105931554402}, Best action: 0, Actual action: 0\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5851374039070074, 1: -4.249094324071731, 2: -3.818485984637077, 3: -4.295794496812964, 4: -4.449200287190584}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.162475037555377, 1: -4.259747827174638, 2: -3.818485984637077, 3: -4.297951831191303, 4: -4.450804534967675}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.520256902501858, 1: -4.261796749072149, 2: -3.818485984637077, 3: -4.298366737875549, 4: -4.451113069950748}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883266313054046, 1: -4.263875607737593, 2: -4.374822246019741, 3: -4.298787706755301, 4: -4.451426112933953}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.928463955998865, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -4.249113900985804, 4: -4.715265137233664}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301308926866548, 1: -3.8054293012861122, 2: -3.766409197362128, 3: -3.563629404652802, 4: -3.445841150229335}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301332755809159, 1: -3.8054293012861122, 2: -3.766409637073138, 3: -3.563629404652802, 4: -3.445841150229335}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301373429130481, 1: -3.8054293012861122, 2: -3.76641038761031, 3: -3.563629404652802, 4: -4.035715446708695}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.064651995323084, 1: -4.712351740988906, 2: -5.270554010311282, 3: -4.298998053168503, 4: -4.451582531785471}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301394625126482, 1: -3.8054293012861122, 2: -3.7664107787360503, 3: -4.7385513635317675, 4: -5.026226102687089}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0712171365192775, 1: -4.76207585176098, 2: -5.302974460662855, 3: -4.3806935053027045, 4: -4.451588193267861}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301398131548045, 1: -3.8054293012861122, 2: -4.825002873348003, 3: -4.98967577703813, 4: -5.190084782499991}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.466982636096892, 1: -3.375167798544845, 2: -4.13499395527063, 3: -3.871045388678209, 4: -3.4613694859896125}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3217012930288625, 1: -3.7309404764533802, 2: -3.343936771182487, 3: -4.376242812212024, 4: -4.299857496081598}, Best action: 0, Actual action: 0\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.509116527156777, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -4.253309217550488, 4: -4.71800258129212}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.509946091843814, 1: -4.146253485580225, 2: -3.9331487844950077, 3: -4.2533123173763725, 4: -4.7180046039285095}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.51013201416986, 1: -4.146253485580225, 2: -4.479165393890457, 3: -4.253313012110428, 4: -4.718005057242481}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.157399595599516, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.6273083952956555, 4: -4.215835556518121}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.157399595599793, 1: -3.572321724674382, 2: -3.504500011363227, 3: -3.6273083952956555, 4: -4.215835556518121}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.157399595610179, 1: -3.572321724674382, 2: -4.089095010340537, 3: -3.6273083952956555, 4: -4.215835556518121}, Best action: 1, Actual action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -3.823617133387886, 2: -3.8545036852055516, 3: -3.6140326418784734, 4: -4.248465323107352}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -3.823617133387886, 2: -3.8545036852055516, 3: -3.6140326418784734, 4: -4.248465323107352}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -4.330296489761758, 2: -4.309856938079123, 3: -4.7082455244374595, 4: -3.5768627076789503}, Best action: 4, Actual action: 4\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -4.330296489761758, 2: -4.309856938079123, 3: -4.7082455244374595, 4: -3.5768627076789503}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.022268948259758, 1: -4.330296489761758, 2: -4.309856938079123, 3: -4.70824552443746, 4: -4.154945063987845}, Best action: 0, Actual action: 0\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7443011656699055, 1: -3.7309404764533802, 2: -3.343936771182487, 3: -4.376242812212024, 4: -4.299857496081598}, Best action: 2, Actual action: 2\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.157399595614489, 1: -4.5184030222245575, 2: -4.870835934127688, 3: -3.6273083952956555, 4: -4.215835556518121}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.744356543165229, 1: -3.7309404764533802, 2: -4.17251347730773, 3: -4.376242812212024, 4: -4.299857496081598}, Best action: 1, Actual action: 1\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -3.823617133387886, 2: -3.8545036852055516, 3: -4.793902008686421, 4: -4.248465323107352}, Best action: 1, Actual action: 1\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5255255048875247, 1: -3.649621082235262, 2: -4.125228479836035, 3: -3.249957172075874, 4: -3.415908936804581}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -4.261166540637162, 3: -3.4784726892824747, 4: -4.222380216137544}, Best action: 3, Actual action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -2.7053872697935577, 3: -2.7991766761587176, 4: -2.7358518617653265}, Best action: 2, Actual action: 2\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -4.261166540637162, 3: -3.4392109574610292, 4: -4.222380216137544}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.9562996025227894, 3: -2.7991766761587176, 4: -2.7358518617653265}, Best action: 4, Actual action: 4\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.7376583957246314, 3: -2.7991766761587176, 4: -2.7358518617653265}, Best action: 4, Actual action: 4\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.8700474955439583, 3: -2.7991766761587176, 4: -3.389625194206447}, Best action: 3, Actual action: 3\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.640029041501495, 2: -2.761423475105624, 3: -1.9600489655068412, 4: -3.360963364079684}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: -1.636360044448089, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: -1.636360044448089, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: -1.636360044448089, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: -1.636360044448089, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -1.5358815611260088, 3: -1.636360044448089, 4: -2.5259071291061908}, Best action: 2, Actual action: 2\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6380130686756726, 1: -1.9343539972291415, 2: -2.7810635483212645, 3: -1.6465935686280295, 4: -3.039077690272842}, Best action: 0, Actual action: 0\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -1.693192623857568, 2: -2.761423475105624, 3: -1.9600489655068412, 4: -3.360963364079684}, Best action: 1, Actual action: 1\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3831717564711736, 1: -2.441516286095612, 2: -2.4649176521751235, 3: -2.4600605021507636, 4: -3.266905676386616}, Best action: 0, Actual action: 0\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.8699458736980272, 3: -2.5374308436528104, 4: -3.3880081662053425}, Best action: 3, Actual action: 3\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -3.371281921252568, 2: -2.761423475105624, 3: -1.9600489655068412, 4: -3.360963364079684}, Best action: 3, Actual action: 3\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1922097198865442, 1: -2.441516286095612, 2: -2.4649176521751235, 3: -2.4600605021507636, 4: -3.266905676386616}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -1.7385737079072658, 4: -3.333318206420599}, Best action: 3, Actual action: 3\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -1.0738573707907264, 4: -3.333318206420599}, Best action: 3, Actual action: 3\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.7698244703404884, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.4173617254506903, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -1.4373476655439854, 4: -3.333318206420599}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.6924601929959628, 3: -2.377424174931635, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.6814403679155334, 3: -2.2020744205654053, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.6889137569780335, 3: -2.3209925455654052, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -1.5010075968749998, 2: -1.6919741097991272, 3: -2.369689517752905, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -1.230975, 4: -2.3035111875000003}, Best action: 3, Actual action: 3\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -1.230975, 4: -2.3035111875000003}, Best action: 3, Actual action: 3\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: 0.2745000000000001, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: 0.2745000000000001, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: -0.6502049999999999, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: -1.106687475, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: -1.6939374749999998, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -1.5105110351509272, 3: -1.9344163499999998, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -1.2364132910208996, 4: -2.3035111875000003}, Best action: 3, Actual action: 3\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.6108784846180628, 2: -2.0525458692420218, 3: -1.9989802523164109, 4: -2.895018699326385}, Best action: 1, Actual action: 1\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.958795561673333, 2: -4.460607585543953, 3: -1.9201769256846744, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.958795561673333, 2: -4.460607585543953, 3: -1.0920176925684673, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.7845343309804584, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.4220357836690407, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.6042857836690407, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6362876035223783, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.6789171586690408, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5442514620511456, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.096473329496803, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -2.9588281671561987, 4: -2.9464804874893615}, Best action: 4, Actual action: 4\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.096473329496803, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -2.9588281671561987, 4: -2.9464804874893615}, Best action: 4, Actual action: 4\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.096473329496803, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -2.9588281671561987, 4: -3.581297243615319}, Best action: 3, Actual action: 3\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8229947570749296, 1: -3.252748563756971, 2: -2.8948237347673205, 3: -3.629144175149854, 4: -2.7188219388411694}, Best action: 0, Actual action: 0\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -1.6244531020234467, 2: -1.7151094910719125, 3: -2.400687949398196, 4: -2.3035111875000003}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.096473329496803, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -2.931308849018513, 4: -3.669891667937443}, Best action: 3, Actual action: 3\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.096473329496803, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -3.2983102051350013, 4: -3.909360052803452}, Best action: 0, Actual action: 0\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -2.5081264659183535, 2: -3.10648238203833, 3: -1.8134780886415076, 4: -4.221414574443345}, Best action: 3, Actual action: 3\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -2.0510994601665096, 2: -1.7160651398886786, 3: -1.7324375553338323, 4: -2.8068256305833335}, Best action: 2, Actual action: 2\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.270948796120768, 1: -3.925351538375737, 2: -4.292748883302243, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 1, Actual action: 1\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7315461320028454, 1: -2.8258894225957287, 2: -4.1299408624979685, 3: -3.3871962296230036, 4: -3.421132069761311}, Best action: 0, Actual action: 0\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -2.5081264659183535, 2: -3.10648238203833, 3: -3.5270413626898103, 4: -4.221414574443345}, Best action: 1, Actual action: 1\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.939088810420979, 1: -4.145250764636396, 2: -3.9976346294121425, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 0, Actual action: 0\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.270948796120768, 1: -4.089276427841647, 2: -4.292748883302243, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 1, Actual action: 1\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.606222787593833, 1: -4.145250764636396, 2: -3.9976346294121425, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 2, Actual action: 2\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.787582660352392, 1: -4.145250764636396, 2: -3.9976346294121425, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 2, Actual action: 2\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.896975769231355, 1: -4.145250764636396, 2: -4.537847512765049, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 1, Actual action: 1\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.682443382903264, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -4.433893448677837}, Best action: 4, Actual action: 4\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.682443382903264, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -4.433893448677837}, Best action: 4, Actual action: 4\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.682443382903264, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -4.934843038296832}, Best action: 0, Actual action: 0\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.955320458328859, 1: -5.182318717372345, 2: -5.466240370832313, 3: -4.239079035047729, 4: -4.453626051884599}, Best action: 3, Actual action: 3\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2356210012633255, 1: -2.8258894225957287, 2: -4.1299408624979685, 3: -3.3871962296230036, 4: -3.421132069761311}, Best action: 1, Actual action: 1\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5201080420208, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -5.193478816613544}, Best action: 0, Actual action: 0\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956240832473729, 1: -5.2047634457947405, 2: -5.480885556127926, 3: -4.520972500972625, 4: -4.453626051884599}, Best action: 4, Actual action: 4\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956265199691943, 1: -5.2053576776060915, 2: -5.481273292384833, 3: -4.535463750754085, 4: -4.453626051884599}, Best action: 4, Actual action: 4\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9563416869880035, 1: -5.207222937074109, 2: -5.482490374187714, 3: -4.580950950096066, 4: -4.952799707214985}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235739547827636, 1: -4.991108628620268, 2: -4.1299408624979685, 3: -3.3871962296230036, 4: -3.421132069761311}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.340502630047002, 1: -3.252748563756971, 2: -2.8948237347673205, 3: -3.629144175149854, 4: -2.7188219388411694}, Best action: 4, Actual action: 4\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3405026306150973, 1: -3.252748563756971, 2: -2.8948237347673205, 3: -3.629144175149854, 4: -2.7188219388411694}, Best action: 4, Actual action: 4\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3405026337307175, 1: -3.252748563756971, 2: -2.8948237347673205, 3: -3.629144175149854, 4: -3.374127964345464}, Best action: 2, Actual action: 2\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5113493097089865, 1: -3.4335577051013884, 2: -4.695674249610679, 3: -3.9817455180081542, 4: -3.946602736256614}, Best action: 1, Actual action: 1\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -3.00119565100011, 3: -2.867575764717264, 4: -3.8791007343098767}, Best action: 3, Actual action: 3\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -3.3141930867831304, 4: -4.2259042668008755}, Best action: 1, Actual action: 1\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -2.9696469583928375, 2: -3.8550967229485713, 3: -3.3141930867831304, 4: -4.2259042668008755}, Best action: 1, Actual action: 1\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -3.6023787321374825, 2: -3.8550967229485713, 3: -3.3141930867831304, 4: -4.2259042668008755}, Best action: 3, Actual action: 3\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -3.00119565100011, 3: -3.9462279080825624, 4: -3.8791007343098767}, Best action: 2, Actual action: 2\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260568673786846, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -5.4781998561183025}, Best action: 2, Actual action: 2\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260636969525452, 1: -4.7808815220939875, 2: -4.713963878398076, 3: -5.078285526710677, 4: -5.478203577782264}, Best action: 2, Actual action: 2\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260644217594723, 1: -4.7808815220939875, 2: -5.189707129342249, 3: -5.078285526710677, 4: -5.47820397275388}, Best action: 1, Actual action: 1\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260644915368251, 1: -4.7808815220939875, 2: -5.337284673250003, 3: -5.078285526710677, 4: -5.478204010777901}, Best action: 1, Actual action: 1\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260646364521757, 1: -5.250602185105529, 2: -5.643777405865033, 3: -5.078285526710677, 4: -5.4782040897471385}, Best action: 3, Actual action: 3\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.260646764174325, 1: -5.668012684664504, 2: -5.7283030320257255, 3: -5.078285526710677, 4: -5.478204111525548}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.644939612147118, 1: -5.005648200902415, 2: -3.8550967229485713, 3: -4.704007544679775, 4: -4.2259042668008755}, Best action: 0, Actual action: 0\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956344407023953, 1: -5.207289269302725, 2: -5.482533655966885, 3: -4.330118386107762, 4: -5.009999239932567}, Best action: 3, Actual action: 3\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961616777, 1: -4.980756652363281, 2: -4.1299408624979685, 3: -3.903699767249129, 4: -3.421132069761311}, Best action: 4, Actual action: 4\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961615964, 1: -4.9807566470572935, 2: -4.1299408624979685, 3: -3.903699479705561, 4: -3.421132069761311}, Best action: 4, Actual action: 4\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961616922, 1: -4.980756653313074, 2: -4.1299408624979685, 3: -3.9036998187205696, 4: -4.013230183482793}, Best action: 3, Actual action: 3\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.23573796161725, 1: -4.980756655453003, 2: -4.1299408624979685, 3: -3.903699934688211, 4: -4.665860231125057}, Best action: 3, Actual action: 3\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.511349324284171, 1: -4.108388912448116, 2: -4.695674249610679, 3: -3.981745525164661, 4: -3.9466027366465957}, Best action: 0, Actual action: 0\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -2.0510994601665096, 2: -4.366621297643023, 3: -1.7324375553338323, 4: -2.8068256305833335}, Best action: 3, Actual action: 3\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6397080988462198, 1: -3.71866676237369, 2: -1.7151094910719125, 3: -2.4006888229787298, 4: -2.3035111875000003}, Best action: 0, Actual action: 0\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: -2.076762208906761, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -1.6160160161280168, 2: -3.5530218692565554, 3: -1.636360044448089, 4: -3.3820932597301887}, Best action: 1, Actual action: 1\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.635529256761349, 1: -2.2946606985574998, 2: -1.6929732057796734, 3: -2.385587341311662, 4: -3.0694077438457565}, Best action: 0, Actual action: 0\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -1.9343539972291415, 2: -2.7810635483212645, 3: -1.6465935686280295, 4: -3.039077690272842}, Best action: 3, Actual action: 3\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -2.729174306366065, 2: -3.5530218692565554, 3: -1.636360044448089, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: -2.947191337511496, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7707694950390933, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7816059091797185, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7831192704648746, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0326965729279887, 1: -3.71866676237369, 2: -1.7151094910719125, 3: -2.4006888229787298, 4: -2.3035111875000003}, Best action: 2, Actual action: 2\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -2.0510994601665096, 2: -4.366621297643016, 3: -2.5782840933144873, 4: -2.8068256305833335}, Best action: 1, Actual action: 1\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0350431721311946, 1: -4.108388305178532, 2: -4.695674249610679, 3: -3.9817455251646594, 4: -3.9466027366465957}, Best action: 0, Actual action: 0\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -4.799239601525486, 2: -3.10648238203833, 3: -3.664110843163432, 4: -4.221414574443345}, Best action: 2, Actual action: 2\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.270948796120768, 1: -4.96002188736972, 2: -4.292748883302243, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 0, Actual action: 0\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1828219083419538, 1: -3.974843562929738, 2: -3.9765472647586977, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 0, Actual action: 0\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9212483260885045, 1: -4.472349070896537, 2: -4.927532323858879, 3: -4.120231018236092, 4: -4.862505226951104}, Best action: 0, Actual action: 0\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5255255048875247, 1: -3.649621082235262, 2: -4.125228479836035, 3: -4.26071977628175, 4: -3.415908936804581}, Best action: 4, Actual action: 4\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5255255048875247, 1: -3.649621082235262, 2: -4.125228479836035, 3: -4.26071977628175, 4: -3.415908936804581}, Best action: 4, Actual action: 4\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5255255048875247, 1: -3.649621082235262, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.008477132492168}, Best action: 0, Actual action: 0\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -3.6874041807759745, 2: -4.238441546521652, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 1, Actual action: 1\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.239349936917292, 1: -3.649621082235262, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.688914621979709}, Best action: 1, Actual action: 1\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.442735435819778, 1: -4.472349070896537, 2: -4.927532323858879, 3: -4.120231018236092, 4: -4.862505226951104}, Best action: 3, Actual action: 3\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.1257417435406705, 3: -0.6532820093821582, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.1257417435406705, 3: -0.6532820093821582, 4: -3.4237010561539294}, Best action: 3, Actual action: 3\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -1.387170734536608, 4: -3.1281476955423115}, Best action: 3, Actual action: 3\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -2.5961010544823875, 2: -2.4649176521751235, 3: -2.4600605021507636, 4: -3.266905676386616}, Best action: 3, Actual action: 3\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -1.9343539972291415, 2: -2.7810635483212645, 3: -2.463326635206632, 4: -3.039077690272842}, Best action: 1, Actual action: 1\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823596468574, 1: -2.2946606985574998, 2: -1.6929732057796734, 3: -2.385587341311662, 4: -3.0694077438457565}, Best action: 2, Actual action: 2\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.011071269818004, 2: -4.326090905788886, 3: -3.9856739219267814, 4: -3.574185234628805}, Best action: 4, Actual action: 4\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.011071269818004, 2: -4.326090905788886, 3: -3.9856739219267814, 4: -3.574185234628805}, Best action: 4, Actual action: 4\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.011071269818004, 2: -4.326090905788886, 3: -3.9856739219267814, 4: -4.152508563512212}, Best action: 3, Actual action: 3\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.011071269818004, 2: -4.326090905788886, 3: -3.9856739219267814, 4: -4.7196589094317805}, Best action: 3, Actual action: 3\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.011071269818004, 2: -4.326090905788886, 3: -4.526963268953371, 4: -5.0728502083666305}, Best action: 1, Actual action: 1\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -4.214312511199164, 2: -4.366621297643016, 3: -2.5782966048569738, 4: -2.8068256305833335}, Best action: 3, Actual action: 3\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -4.214312496606079, 2: -4.366621297643016, 3: -2.5782966048569325, 4: -2.8068256305833335}, Best action: 3, Actual action: 3\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -4.214312503663304, 2: -4.366621297643016, 3: -3.2462499104198286, 4: -2.8068256305833335}, Best action: 4, Actual action: 4\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -4.214312504860968, 2: -4.366621297643016, 3: -3.611510480442081, 4: -2.8068256305833335}, Best action: 4, Actual action: 4\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.958091422794862, 1: -4.214312506246051, 2: -4.366621297643016, 3: -4.0339296452860784, 4: -3.454211323830833}, Best action: 0, Actual action: 0\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8139781523505882, 1: -1.7994358682322067, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 1, Actual action: 1\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6533521955475736, 1: -4.214312506294316, 2: -4.366621297643016, 3: -4.048649421456709, 4: -3.5269015765253053}, Best action: 0, Actual action: 0\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8139781523505882, 1: -3.229158865216755, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 0, Actual action: 0\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6795486158473025, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -3.49487650126892, 4: -3.1281476955423115}, Best action: 0, Actual action: 0\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -3.376744129426289, 2: -3.257615277943289, 3: -3.8833614090711683, 4: -3.4037314409314896}, Best action: 2, Actual action: 2\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005291236809, 1: -3.895384850428029, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.8792197406731965}, Best action: 1, Actual action: 1\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.44727046904025, 1: -4.472349070896537, 2: -4.927532323858879, 3: -2.5491991155905414, 4: -4.862505226951104}, Best action: 3, Actual action: 3\n",
      "Step: 242\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.447270468934776, 1: -4.472349070896537, 2: -4.927532323858879, 3: -2.5491991028886427, 4: -4.862505226951104}, Best action: 3, Actual action: 3\n",
      "Step: 243\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.1257417435406705, 3: -3.8536939263106826, 4: -3.4237010561539294}, Best action: 4, Actual action: 4\n",
      "Step: 244\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.1257417435406705, 3: -3.8536939527086944, 4: -3.4237010561539294}, Best action: 4, Actual action: 4\n",
      "Step: 245\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -3.849590810138258, 2: -4.1257417435406705, 3: -3.8536939617760337, 4: -4.015567961100076}, Best action: 1, Actual action: 1\n",
      "Step: 246\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -3.816968846820828, 2: -4.326090905788886, 3: -4.508627578364811, 4: -5.069137231022448}, Best action: 1, Actual action: 1\n",
      "Step: 247\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -4.799239601525486, 2: -4.798818317891175, 3: -3.664110843163432, 4: -4.221414574443345}, Best action: 3, Actual action: 3\n",
      "Step: 248\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -4.799239601525486, 2: -4.798818317891239, 3: -3.664110843163432, 4: -4.221414574443345}, Best action: 3, Actual action: 3\n",
      "Step: 249\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.895962124050903, 1: -4.799239601525486, 2: -4.7988183178912776, 3: -4.234340867278723, 4: -4.221414574443345}, Best action: 0, Actual action: 0\n",
      "Step: 250\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.066034814887786, 1: -4.555807831944617, 2: -4.326090905788886, 3: -4.508629164250323, 4: -5.069137552164264}, Best action: 0, Actual action: 0\n",
      "Step: 251\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313102547403013, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -3.494880100524573, 4: -3.1281476955423115}, Best action: 4, Actual action: 4\n",
      "Step: 252\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313086989527903, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -3.4948801005047776, 4: -3.1281476955423115}, Best action: 4, Actual action: 4\n",
      "Step: 253\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313106179705998, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -3.4948801005291945, 4: -3.7466144029435036}, Best action: 3, Actual action: 3\n",
      "Step: 254\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -2.5961010544823875, 2: -2.4649176521751235, 3: -3.4900916584614095, 4: -3.266905676386616}, Best action: 2, Actual action: 2\n",
      "Step: 255\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -2.5961010544823875, 2: -2.4649176521751235, 3: -3.490091658456989, 4: -3.266905676386616}, Best action: 2, Actual action: 2\n",
      "Step: 256\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -4.73976454084587, 2: -4.1257417435406705, 3: -3.8536939673238435, 4: -5.182434537658579}, Best action: 3, Actual action: 3\n",
      "Step: 257\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113062708752, 1: -3.5800064597147596, 2: -3.7015516539770728, 3: -3.792768866075876, 4: -4.461391704687265}, Best action: 1, Actual action: 1\n",
      "Step: 258\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.08693628056652, 1: -3.582453267315069, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 4, Actual action: 4\n",
      "Step: 259\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936296450193, 1: -3.5824532705315124, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.035801894047803}, Best action: 4, Actual action: 4\n",
      "Step: 260\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936329152351, 1: -3.5824532771536997, 2: -3.1914384814151884, 3: -3.2966752756889814, 4: -3.662579723583501}, Best action: 2, Actual action: 2\n",
      "Step: 261\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.222996675202587, 1: -4.624858355618378, 2: -4.326090905788886, 3: -4.508629221577384, 4: -5.069137563772995}, Best action: 0, Actual action: 0\n",
      "Step: 262\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.44727046904117, 1: -4.472349070896537, 2: -4.927532323858879, 3: -4.966656062425564, 4: -4.862505226951104}, Best action: 0, Actual action: 0\n",
      "Step: 263\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -3.376744129426289, 2: -4.383149000195734, 3: -3.8833614090711683, 4: -3.4037314409314896}, Best action: 1, Actual action: 1\n",
      "Step: 264\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0798897917394115, 1: -4.472349070896537, 2: -4.927532323858879, 3: -4.966656262609992, 4: -4.862505226951104}, Best action: 0, Actual action: 0\n",
      "Step: 265\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -3.9001087551100464, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.879219744164915}, Best action: 1, Actual action: 1\n",
      "Step: 266\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.502339206764276, 1: -4.472349070896537, 2: -4.927532323858879, 3: -4.966656347904911, 4: -4.862505226951104}, Best action: 1, Actual action: 1\n",
      "Step: 267\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.029265271482382, 1: -4.624883640706646, 2: -4.326090905788886, 3: -4.508629221598376, 4: -5.069137563777246}, Best action: 2, Actual action: 2\n",
      "Step: 268\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -3.974843562929738, 2: -3.9765472647586977, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 4, Actual action: 4\n",
      "Step: 269\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -3.974843562929738, 2: -3.9765472647586977, 3: -3.8551200400988797, 4: -3.6423750801308774}, Best action: 4, Actual action: 4\n",
      "Step: 270\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -3.974843562929738, 2: -3.9765472647586977, 3: -3.8551200400988797, 4: -4.214561322919098}, Best action: 3, Actual action: 3\n",
      "Step: 271\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936352760076, 1: -3.5824532819342636, 2: -5.0064363957145614, 3: -3.2966752756889814, 4: -5.1205438198095115}, Best action: 3, Actual action: 3\n",
      "Step: 272\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -1.692716058403397, 4: -3.333318206420599}, Best action: 3, Actual action: 3\n",
      "Step: 273\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823597216899, 1: -2.2946606985574998, 2: -4.352644839696327, 3: -2.385587341311662, 4: -3.0694077438457565}, Best action: 1, Actual action: 1\n",
      "Step: 274\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.0327954083087527, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.4006888229787298, 4: -2.3035111875000003}, Best action: 0, Actual action: 0\n",
      "Step: 275\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -2.298564438286981, 3: -3.1445631150846673, 4: -3.333318206420599}, Best action: 2, Actual action: 2\n",
      "Step: 276\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -3.974843562929738, 2: -3.9765472647586977, 3: -3.9748905243671357, 4: -4.625547524590847}, Best action: 1, Actual action: 1\n",
      "Step: 277\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.556952251297743, 1: -4.96002188736972, 2: -4.292748883302243, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 2, Actual action: 2\n",
      "Step: 278\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.556952251297743, 1: -4.96002188736972, 2: -4.292748883302243, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 2, Actual action: 2\n",
      "Step: 279\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.556952251297743, 1: -4.96002188736972, 2: -4.806401483805041, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 4, Actual action: 4\n",
      "Step: 280\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.556952251297743, 1: -4.96002188736972, 2: -5.015090892718237, 3: -4.8520285075397, 4: -4.407018599641358}, Best action: 4, Actual action: 4\n",
      "Step: 281\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.556952251297743, 1: -4.96002188736972, 2: -5.343538725454298, 3: -4.8520285075397, 4: -4.910386925673635}, Best action: 0, Actual action: 0\n",
      "Step: 282\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -5.087812796439002, 2: -3.9765472647586977, 3: -4.021977515357738, 4: -4.656271786212215}, Best action: 2, Actual action: 2\n",
      "Step: 283\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -5.0881771704407415, 2: -3.9765472647586977, 3: -4.021980541034049, 4: -4.656273760466007}, Best action: 2, Actual action: 2\n",
      "Step: 284\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -5.092678731019745, 2: -4.518658010930415, 3: -4.022017920938044, 4: -4.656298150853364}, Best action: 3, Actual action: 3\n",
      "Step: 285\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038552649200492, 1: -4.624883699053147, 2: -4.602107805026984, 3: -4.508629221598424, 4: -5.0691375637772556}, Best action: 3, Actual action: 3\n",
      "Step: 286\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0385526590508025, 1: -4.624883699053209, 2: -4.602108991091522, 3: -4.508629221598424, 4: -5.0691375637772556}, Best action: 3, Actual action: 3\n",
      "Step: 287\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936352760677, 1: -3.582453281934385, 2: -5.006493231943891, 3: -3.4438261416647236, 4: -5.120580905449149}, Best action: 3, Actual action: 3\n",
      "Step: 288\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936352760677, 1: -3.582453281934385, 2: -5.006493231161088, 3: -3.443821032914618, 4: -5.12058090493837}, Best action: 3, Actual action: 3\n",
      "Step: 289\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936352760677, 1: -3.582453281934385, 2: -5.00649323141673, 3: -4.033878808326752, 4: -5.120580905105176}, Best action: 1, Actual action: 1\n",
      "Step: 290\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.934831116675952, 1: -4.96002188736972, 2: -5.443908142217187, 3: -4.8520285075397, 4: -5.406038366478023}, Best action: 3, Actual action: 3\n",
      "Step: 291\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.653995366506782, 1: -4.799239601525486, 2: -4.7988183178912935, 3: -5.0839502408802355, 4: -4.221414574443345}, Best action: 4, Actual action: 4\n",
      "Step: 292\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.653995366506782, 1: -4.799239601525486, 2: -4.7988183178912935, 3: -5.0839502408802355, 4: -4.221414574443345}, Best action: 4, Actual action: 4\n",
      "Step: 293\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.653995366506784, 1: -4.799239601525486, 2: -4.7988183178912935, 3: -5.083950240880236, 4: -4.741487262743444}, Best action: 0, Actual action: 0\n",
      "Step: 294\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038552660640163, 1: -4.624883699053219, 2: -4.602109182464627, 3: -4.487343757339004, 4: -5.0691375637772556}, Best action: 3, Actual action: 3\n",
      "Step: 295\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086936352760677, 1: -5.323200117483677, 2: -5.006493231602848, 3: -5.4180968679317765, 4: -5.120580905226618}, Best action: 0, Actual action: 0\n",
      "Step: 296\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -4.202667609843167, 2: -3.7015516539770728, 3: -3.8485080401681455, 4: -4.497761515782181}, Best action: 2, Actual action: 2\n",
      "Step: 297\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992369243, 1: -4.975576765485177, 2: -4.927532323858879, 3: -4.9666563668856085, 4: -4.862505226951104}, Best action: 4, Actual action: 4\n",
      "Step: 298\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992383733, 1: -4.975576765544682, 2: -4.927532323858879, 3: -4.9666563668856085, 4: -4.862505226951104}, Best action: 4, Actual action: 4\n",
      "Step: 299\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992385733, 1: -4.975576765552897, 2: -4.927532323858879, 3: -4.9666563668856085, 4: -5.324879756525505}, Best action: 2, Actual action: 2\n",
      "Step: 300\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992385926, 1: -4.975576765553687, 2: -4.927532323858879, 3: -4.9666563668856085, 4: -5.468298388631974}, Best action: 2, Actual action: 2\n",
      "Step: 301\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386326, 1: -4.97557676555533, 2: -5.38405441471158, 3: -4.9666563668856085, 4: -5.766179052913361}, Best action: 3, Actual action: 3\n",
      "Step: 302\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -4.2026676098432345, 2: -5.481654200292901, 3: -3.848508040168148, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 303\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -2.5961010544823875, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -3.266905676386616}, Best action: 1, Actual action: 1\n",
      "Step: 304\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823597216899, 1: -3.7129449786172386, 2: -4.352644839696327, 3: -2.385587341311662, 4: -3.0694077438457565}, Best action: 3, Actual action: 3\n",
      "Step: 305\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 306\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: -2.076762208906761, 3: -2.152943552053625, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 307\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: -2.076762208906761, 3: -2.152943552053625, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 308\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: -2.076762208906761, 3: -2.152943552053625, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 309\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.591146702506704, 1: -1.624895318078129, 2: -2.076762208906761, 3: -2.152943552053625, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 310\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6445089811144322, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -1.799061476769491, 4: -3.3820932597301887}, Best action: 0, Actual action: 0\n",
      "Step: 311\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -3.4252248105064393, 2: -2.761423475105624, 3: -2.0978111423967616, 4: -3.360963364079684}, Best action: 3, Actual action: 3\n",
      "Step: 312\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 313\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.8699747269540947, 3: -2.8035274202659615, 4: -3.3884672852319273}, Best action: 3, Actual action: 3\n",
      "Step: 314\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.8699747269540947, 3: -2.8035274202659615, 4: -3.3884672852319273}, Best action: 3, Actual action: 3\n",
      "Step: 315\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8503891273417463, 1: -2.99027149662423, 2: -3.8699747269540947, 3: -3.451209952442025, 4: -3.3884672852319273}, Best action: 0, Actual action: 0\n",
      "Step: 316\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -4.369670194612886, 2: -3.8545036852055516, 3: -4.804557904142596, 4: -4.248465323107352}, Best action: 2, Actual action: 2\n",
      "Step: 317\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7487860837579574, 1: -4.335527202266672, 2: -4.238441546521652, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 0, Actual action: 0\n",
      "Step: 318\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.157399595614527, 1: -4.529228297638936, 2: -4.877899426335567, 3: -4.683045922511135, 4: -4.215835556518121}, Best action: 0, Actual action: 0\n",
      "Step: 319\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.510193049002765, 1: -4.5264987240185715, 2: -5.056739291758402, 3: -4.253313240178662, 4: -4.718005206057004}, Best action: 3, Actual action: 3\n",
      "Step: 320\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -4.13499395527063, 3: -3.871045388678209, 4: -3.4613694859896125}, Best action: 4, Actual action: 4\n",
      "Step: 321\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -4.13499395527063, 3: -3.871045388678209, 4: -3.4613694859896125}, Best action: 4, Actual action: 4\n",
      "Step: 322\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -4.13499395527063, 3: -3.871045388678209, 4: -4.049846232250548}, Best action: 3, Actual action: 3\n",
      "Step: 323\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -4.13499395527063, 3: -3.871045388678209, 4: -4.616339708166139}, Best action: 3, Actual action: 3\n",
      "Step: 324\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.510193049002765, 1: -4.5264987240185715, 2: -5.056739291758402, 3: -4.523233976543256, 4: -4.718005206057004}, Best action: 0, Actual action: 0\n",
      "Step: 325\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -4.770673496364027, 2: -5.3085801820255, 3: -4.792971061799418, 4: -4.4515891721775445}, Best action: 4, Actual action: 4\n",
      "Step: 326\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -4.770673496364027, 2: -5.3085801820255, 3: -4.792971061799418, 4: -4.4515891721775445}, Best action: 4, Actual action: 4\n",
      "Step: 327\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -4.770673496364027, 2: -5.3085801820255, 3: -4.792971061799418, 4: -4.950946146681566}, Best action: 1, Actual action: 1\n",
      "Step: 328\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.243966957899291, 1: -4.5264987240185715, 2: -5.056739291758402, 3: -4.560265427391199, 4: -4.718005206057004}, Best action: 1, Actual action: 1\n",
      "Step: 329\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.899258634582175, 1: -4.529228297638936, 2: -4.877899426335567, 3: -4.683045922511135, 4: -4.215835556518121}, Best action: 4, Actual action: 4\n",
      "Step: 330\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.899340689089414, 1: -4.529228297638936, 2: -4.877899426335567, 3: -4.683045922511135, 4: -4.215835556518121}, Best action: 4, Actual action: 4\n",
      "Step: 331\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.89942045563642, 1: -4.529228297638936, 2: -4.877899426335567, 3: -4.683045922511135, 4: -4.736410356431489}, Best action: 1, Actual action: 1\n",
      "Step: 332\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976291159666816, 1: -4.335527202266672, 2: -4.238441546521652, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 2, Actual action: 2\n",
      "Step: 333\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976294745785339, 1: -4.335527202266672, 2: -4.238441546521652, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 2, Actual action: 2\n",
      "Step: 334\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.97629800392869, 1: -4.335527202266672, 2: -4.756981807334704, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 3, Actual action: 3\n",
      "Step: 335\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976298250729279, 1: -4.335527202266672, 2: -4.883546909302338, 3: -4.2821850664448045, 4: -4.775515088510161}, Best action: 3, Actual action: 3\n",
      "Step: 336\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976298905494101, 1: -4.335527202266672, 2: -5.219325591275367, 3: -4.796788410464772, 4: -4.775515088510161}, Best action: 1, Actual action: 1\n",
      "Step: 337\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.879219744164915}, Best action: 2, Actual action: 2\n",
      "Step: 338\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -4.125228479836035, 3: -4.26071977628175, 4: -4.879219744164915}, Best action: 2, Actual action: 2\n",
      "Step: 339\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -4.653957916650792, 3: -4.26071977628175, 4: -4.879219744164915}, Best action: 3, Actual action: 3\n",
      "Step: 340\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -4.755070204367114, 2: -4.383149002867376, 3: -3.8833614090711683, 4: -3.4037314409314896}, Best action: 4, Actual action: 4\n",
      "Step: 341\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -4.755070204367114, 2: -4.383149002867376, 3: -3.8833614090711683, 4: -3.4037314409314896}, Best action: 4, Actual action: 4\n",
      "Step: 342\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -4.755070204367114, 2: -4.383149002867376, 3: -3.8833614090711683, 4: -3.9973956112476556}, Best action: 3, Actual action: 3\n",
      "Step: 343\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -4.755070204367114, 2: -4.383149002867376, 3: -3.8833614090711683, 4: -4.646802313523551}, Best action: 3, Actual action: 3\n",
      "Step: 344\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.507618174093065, 1: -4.255375479406486, 2: -4.261166540637162, 3: -3.771442256363947, 4: -4.222380216137544}, Best action: 0, Actual action: 0\n",
      "Step: 345\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.597462046501285, 1: -4.330296489761758, 2: -4.309856938079123, 3: -4.70824552443746, 4: -5.137210131817389}, Best action: 2, Actual action: 2\n",
      "Step: 346\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.879573689523834, 1: -4.369670194612886, 2: -4.8743479638671525, 3: -4.804557904142596, 4: -4.248465323107352}, Best action: 0, Actual action: 0\n",
      "Step: 347\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8994592441946825, 1: -5.099527146167674, 2: -4.877899426335567, 3: -4.683045922511135, 4: -5.552093475530327}, Best action: 3, Actual action: 3\n",
      "Step: 348\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.899459244428959, 1: -5.0995346964990755, 2: -4.877899426335567, 3: -4.683045922511135, 4: -5.552098402121567}, Best action: 3, Actual action: 3\n",
      "Step: 349\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8994592444709415, 1: -5.0995360495235085, 2: -4.877899426335567, 3: -5.161571789485133, 4: -5.5520992849700095}, Best action: 2, Actual action: 2\n",
      "Step: 350\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.899459244479062, 1: -5.0995363112291505, 2: -4.877899426335567, 3: -5.459813480438158, 4: -5.55209945573294}, Best action: 2, Actual action: 2\n",
      "Step: 351\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.899459244487252, 1: -5.099536575175621, 2: -5.338888477965367, 3: -5.760608836626602, 4: -5.552099627958013}, Best action: 0, Actual action: 0\n",
      "Step: 352\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292990034216094, 1: -5.115650560486034, 2: -5.056739291758402, 3: -4.561170041026644, 4: -4.718005206057004}, Best action: 3, Actual action: 3\n",
      "Step: 353\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.29299003429626, 1: -5.115650562441005, 2: -5.056739291758402, 3: -4.561170041028124, 4: -4.718005206057004}, Best action: 3, Actual action: 3\n",
      "Step: 354\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292990034391693, 1: -5.115650564768283, 2: -5.056739291758402, 3: -5.050664737337354, 4: -4.718005206057004}, Best action: 4, Actual action: 4\n",
      "Step: 355\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292990034407133, 1: -5.115650565144806, 2: -5.056739291758402, 3: -5.305844369626344, 4: -4.718005206057004}, Best action: 4, Actual action: 4\n",
      "Step: 356\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292990034425901, 1: -5.11565056560249, 2: -5.056739291758402, 3: -5.616029513900993, 4: -5.193384737511874}, Best action: 2, Actual action: 2\n",
      "Step: 357\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.29299003443162, 1: -5.115650565741958, 2: -5.056739291758402, 3: -5.710551090083841, 4: -5.660157953229121}, Best action: 2, Actual action: 2\n",
      "Step: 358\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292990034435177, 1: -5.1156505658286955, 2: -5.501632755500146, 3: -5.769335419564934, 4: -5.950450938320609}, Best action: 1, Actual action: 1\n",
      "Step: 359\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.405898018344925, 1: -5.099536650271557, 2: -5.761505196811453, 3: -5.8461887221929345, 4: -5.552099676958111}, Best action: 1, Actual action: 1\n",
      "Step: 360\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976299122817343, 1: -4.968622675956147, 2: -5.33077402182295, 3: -5.3471510304528325, 4: -4.775515088510161}, Best action: 4, Actual action: 4\n",
      "Step: 361\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976299122817344, 1: -4.968622677842969, 2: -5.330774022072258, 3: -5.347151031683984, 4: -4.775515088510161}, Best action: 4, Actual action: 4\n",
      "Step: 362\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976299122817345, 1: -4.968622680078529, 2: -5.330774022367645, 3: -5.347151033142686, 4: -5.245718730544247}, Best action: 1, Actual action: 1\n",
      "Step: 363\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -5.052845004686676, 3: -4.510661219994015, 4: -4.879219744164915}, Best action: 3, Actual action: 3\n",
      "Step: 364\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.125576565641772, 1: -4.755070204367114, 2: -4.383149002867376, 3: -5.12553826564132, 4: -5.146066989911625}, Best action: 0, Actual action: 0\n",
      "Step: 365\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.597462046501285, 1: -4.330296489761758, 2: -5.154128864559706, 3: -4.70824552443746, 4: -5.137210131817389}, Best action: 1, Actual action: 1\n",
      "Step: 366\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.820097813271201, 1: -4.755070204367114, 2: -4.383149002867376, 3: -5.125538348802756, 4: -5.146067006751816}, Best action: 2, Actual action: 2\n",
      "Step: 367\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -5.052845007133136, 3: -5.117317184509542, 4: -4.879219744164915}, Best action: 0, Actual action: 3\n",
      "Step: 368\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.291774591879446, 1: -4.755070204367114, 2: -5.483341819739467, 3: -5.1255383844869, 4: -5.146067013977856}, Best action: 1, Actual action: 1\n",
      "Step: 369\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386247, 1: -4.975576765555012, 2: -5.098563561028503, 3: -4.357249860538308, 4: -5.708367155042535}, Best action: 3, Actual action: 3\n",
      "Step: 370\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.919526506752336, 1: -4.74026439717871, 2: -4.1257417435406705, 3: -4.465372146659572, 4: -5.182760693915757}, Best action: 0, Actual action: 0\n",
      "Step: 371\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.305830397616989, 1: -4.973860625665953, 2: -5.55275320609771, 3: -5.125538385550275, 4: -5.14606701419319}, Best action: 1, Actual action: 1\n",
      "Step: 372\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386247, 1: -4.975576765555012, 2: -5.098563561028503, 3: -5.141105419343767, 4: -5.708367155042535}, Best action: 1, Actual action: 1\n",
      "Step: 373\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.631203299294583, 1: -5.094840096471219, 2: -5.357361811422149, 3: -5.105089441765268, 4: -4.656309861578935}, Best action: 0, Actual action: 0\n",
      "Step: 374\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386247, 1: -5.148832348984114, 2: -5.098563561028503, 3: -5.197062087325465, 4: -5.708367155042535}, Best action: 2, Actual action: 2\n",
      "Step: 375\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386247, 1: -5.536621430764697, 2: -5.098563561028503, 3: -5.232399367402721, 4: -5.708367155042535}, Best action: 2, Actual action: 2\n",
      "Step: 376\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.172769992386247, 1: -5.625950109864952, 2: -5.539692840535938, 3: -5.240539443285732, 4: -5.708367155042535}, Best action: 0, Actual action: 0\n",
      "Step: 377\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.531005296588101, 1: -5.139066088143898, 2: -5.052845007482605, 3: -5.532213651522488, 4: -4.879219744164915}, Best action: 0, Actual action: 0\n",
      "Step: 378\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976299122817345, 1: -5.374183942501008, 2: -5.330774022476747, 3: -5.347151033681469, 4: -5.805331848128123}, Best action: 0, Actual action: 0\n",
      "Step: 379\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -4.615947803240779, 2: -4.647595364554694, 3: -4.376242812212024, 4: -4.299857496081598}, Best action: 4, Actual action: 4\n",
      "Step: 380\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -4.615947803240779, 2: -4.647595364554694, 3: -4.376242812212024, 4: -4.299857496081598}, Best action: 4, Actual action: 4\n",
      "Step: 381\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -4.615947803240779, 2: -4.647595364554694, 3: -4.376242812212024, 4: -4.8128703214342545}, Best action: 3, Actual action: 3\n",
      "Step: 382\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112064051, 1: -4.0009572684544485, 2: -4.262015113813759, 3: -3.561906215103313, 4: -3.6947373928686584}, Best action: 3, Actual action: 3\n",
      "Step: 383\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -4.615947803240779, 2: -4.647595364554694, 3: -4.222768315454886, 4: -4.876829625771543}, Best action: 3, Actual action: 3\n",
      "Step: 384\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -4.615947803240779, 2: -4.647595364554694, 3: -4.72439534932135, 4: -5.204141265369411}, Best action: 1, Actual action: 1\n",
      "Step: 385\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670682, 1: -4.369670194612886, 2: -4.874347963941224, 3: -4.804557904142596, 4: -4.248465323107352}, Best action: 4, Actual action: 4\n",
      "Step: 386\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670694, 1: -4.369670194612886, 2: -4.874347963941224, 3: -4.804557904142596, 4: -4.248465323107352}, Best action: 4, Actual action: 4\n",
      "Step: 387\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670709, 1: -4.369670194612886, 2: -4.874347963941224, 3: -4.804557904142596, 4: -4.76610344402769}, Best action: 1, Actual action: 1\n",
      "Step: 388\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.474169699084387, 1: -5.139066088143898, 2: -5.052845007482639, 3: -5.532480720633908, 4: -4.879219744164915}, Best action: 4, Actual action: 4\n",
      "Step: 389\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.474482782637448, 1: -5.139066088143898, 2: -5.052845007482639, 3: -5.532480831612377, 4: -4.879219744164915}, Best action: 4, Actual action: 4\n",
      "Step: 390\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.47455340078169, 1: -5.139066088143898, 2: -5.052845007482639, 3: -5.532480856644332, 4: -5.340089967190073}, Best action: 2, Actual action: 2\n",
      "Step: 391\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.474566275837228, 1: -5.139066088143898, 2: -5.052845007482639, 3: -5.532480861208143, 4: -5.610839021295387}, Best action: 2, Actual action: 2\n",
      "Step: 392\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.474580091149485, 1: -5.139066088143898, 2: -5.498088956809202, 3: -5.532480866105245, 4: -5.901360698230969}, Best action: 1, Actual action: 1\n",
      "Step: 393\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.512000665607455, 1: -5.649357747674796, 2: -5.912160053971025, 3: -5.2426724642811555, 4: -5.708367155042535}, Best action: 3, Actual action: 3\n",
      "Step: 394\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.512002139872581, 1: -5.64935780812888, 2: -5.91216101592902, 3: -5.242672469790034, 4: -5.708367155042535}, Best action: 3, Actual action: 1\n",
      "Step: 395\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482185230696, 1: -5.094840096471219, 2: -5.357361811422149, 3: -5.105089441765268, 4: -4.656309861578935}, Best action: 4, Actual action: 4\n",
      "Step: 396\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482163692262, 1: -5.094840096471219, 2: -5.357361811422149, 3: -5.105089441765268, 4: -4.656309861578935}, Best action: 4, Actual action: 4\n",
      "Step: 397\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7434821749839555, 1: -5.094840096471219, 2: -5.357361811422149, 3: -5.105089441765268, 4: -5.137241974036831}, Best action: 1, Actual action: 1\n",
      "Step: 398\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.93777766922337, 1: -4.96002188736972, 2: -5.444297473888468, 3: -5.1773341426560116, 4: -5.407960992015212}, Best action: 0, Actual action: 0\n",
      "Step: 399\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482180739084, 1: -5.409083921718051, 2: -5.357361811422149, 3: -5.105089441765268, 4: -5.927074987197772}, Best action: 3, Actual action: 3\n",
      "Step: 400\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038552660645188, 1: -4.624883699053219, 2: -4.602109183069679, 3: -5.118069858694262, 4: -5.0691375637772556}, Best action: 2, Actual action: 2\n",
      "Step: 401\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482182035687, 1: -5.68179747519731, 2: -5.357361811422149, 3: -5.138217382462967, 4: -6.1050205808429885}, Best action: 3, Actual action: 3\n",
      "Step: 402\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482182434302, 1: -5.765637743592128, 2: -5.357361811422149, 3: -5.552243399227499, 4: -6.159726355970607}, Best action: 2, Actual action: 2\n",
      "Step: 403\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.743482182481569, 1: -5.775579463193012, 2: -5.357361811422149, 3: -5.843782318783997, 4: -6.166213328010184}, Best action: 2, Actual action: 2\n",
      "Step: 404\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7434821825182265, 1: -5.783289739072937, 2: -5.775199248394156, 3: -6.069884601865474, 4: -6.171244283021835}, Best action: 0, Actual action: 0\n",
      "Step: 405\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.512003074173402, 1: -5.597638267270322, 2: -5.912161625560306, 3: -5.976973264427764, 4: -5.708367155042535}, Best action: 0, Actual action: 0\n",
      "Step: 406\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.474587040447093, 1: -5.990920147220499, 2: -6.219750762245683, 3: -5.532480868568555, 4: -6.047497213831856}, Best action: 0, Actual action: 0\n",
      "Step: 407\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.177819614770849, 1: -5.374189871306969, 2: -5.3307740224767475, 3: -5.347151033681473, 4: -5.805335716674008}, Best action: 0, Actual action: 0\n",
      "Step: 408\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.408279366516631, 1: -5.567865932429151, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -5.552099677138269}, Best action: 0, Actual action: 0\n",
      "Step: 409\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2929900344365395, 1: -5.75293792017547, 2: -6.051163597827836, 3: -5.791869618668157, 4: -6.061730933891965}, Best action: 0, Actual action: 0\n",
      "Step: 410\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -5.308649644920965, 2: -5.3085801820255, 3: -4.792971061799418, 4: -5.749146883675071}, Best action: 3, Actual action: 3\n",
      "Step: 411\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -5.308649644920965, 2: -5.3085801820255, 3: -4.792971061799418, 4: -5.749146883675071}, Best action: 3, Actual action: 3\n",
      "Step: 412\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -5.308649644920965, 2: -5.3085801820255, 3: -5.26160366623747, 4: -5.749146883675071}, Best action: 0, Actual action: 0\n",
      "Step: 413\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.072352295095215, 1: -5.308649644920965, 2: -5.3085801820255, 3: -5.657688652386902, 4: -5.749146883675071}, Best action: 0, Actual action: 0\n",
      "Step: 414\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.515840588536646, 1: -5.308649644920965, 2: -5.3085801820255, 3: -5.947064763857436, 4: -5.749146883675071}, Best action: 2, Actual action: 2\n",
      "Step: 415\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.857596044285272, 1: -5.308649644920965, 2: -5.3085801820255, 3: -6.016270243646533, 4: -5.749146883675071}, Best action: 2, Actual action: 2\n",
      "Step: 416\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.133099673095825, 1: -5.308649644920965, 2: -5.730807965643205, 3: -6.07205972848067, 4: -5.749146883675071}, Best action: 1, Actual action: 1\n",
      "Step: 417\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.636025691871156, 1: -5.75293792017547, 2: -6.051163597827836, 3: -5.791869618668157, 4: -6.061730933891965}, Best action: 0, Actual action: 0\n",
      "Step: 418\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.236340367087185, 1: -5.996045774907733, 2: -6.240638553254862, 3: -6.09296596901392, 4: -5.749146883675071}, Best action: 4, Actual action: 4\n",
      "Step: 419\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.265004042476595, 1: -6.21297913010879, 2: -6.382187567523552, 3: -6.098770363280275, 4: -5.749146883675071}, Best action: 4, Actual action: 4\n",
      "Step: 420\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.275240487992031, 1: -6.290450928153812, 2: -6.4327379157479285, 3: -6.100843243497151, 4: -6.131723664144316}, Best action: 3, Actual action: 3\n",
      "Step: 421\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.27913114270633, 1: -6.319896307004756, 2: -6.451951025448169, 3: -6.101631101076796, 4: -6.600264671923387}, Best action: 3, Actual action: 3\n",
      "Step: 422\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.301398063734087, 1: -4.551340331515149, 2: -4.801019023436333, 3: -4.98481904768442, 4: -5.186915766596691}, Best action: 0, Actual action: 0\n",
      "Step: 423\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.27756149216793, 1: -6.308016827030114, 2: -6.4441996647647155, 3: -4.388164097748973, 4: -6.411235909638283}, Best action: 3, Actual action: 3\n",
      "Step: 424\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -2.8178349044053443, 3: -3.2901153512973993, 4: -3.4664086390772777}, Best action: 2, Actual action: 2\n",
      "Step: 425\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.385288705768192, 1: -4.551340331515149, 2: -4.801019023436333, 3: -4.98481904768442, 4: -5.186915766596691}, Best action: 0, Actual action: 0\n",
      "Step: 426\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.27807924064873, 1: -6.311935267828951, 2: -6.446756447385957, 3: -4.448914344231464, 4: -6.473586956643105}, Best action: 3, Actual action: 3\n",
      "Step: 427\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.278100003123353, 1: -6.312092403060953, 2: -6.446858978124839, 3: -4.503317981821172, 4: -6.476087325218176}, Best action: 3, Actual action: 3\n",
      "Step: 428\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.242773986858439, 1: -4.551340331515149, 2: -4.801019023436333, 3: -4.98481904768442, 4: -5.186915766596691}, Best action: 1, Actual action: 1\n",
      "Step: 429\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -4.13499395527063, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 2, Actual action: 2\n",
      "Step: 430\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342511794044576, 1: -5.75293792017547, 2: -6.051163597827836, 3: -5.791869618668157, 4: -6.061730933891965}, Best action: 1, Actual action: 1\n",
      "Step: 431\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884203618137845, 1: -5.567865932429151, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -5.552099677138269}, Best action: 4, Actual action: 4\n",
      "Step: 432\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8842036232927635, 1: -5.567865932429151, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -5.552099677138269}, Best action: 4, Actual action: 4\n",
      "Step: 433\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884203627522228, 1: -5.567865932429151, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -5.952410706195825}, Best action: 1, Actual action: 1\n",
      "Step: 434\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.01265416599754, 1: -5.374189871306969, 2: -5.3307740224767475, 3: -5.347151033681473, 4: -5.805335716674008}, Best action: 2, Actual action: 2\n",
      "Step: 435\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166196688, 1: -5.374189871306969, 2: -5.3307740224767475, 3: -5.347151033681473, 4: -5.805335716674008}, Best action: 2, Actual action: 2\n",
      "Step: 436\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166378752, 1: -5.374189871306969, 2: -5.75100436045384, 3: -5.347151033681473, 4: -5.805335716674008}, Best action: 3, Actual action: 3\n",
      "Step: 437\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.597462046501285, 1: -5.439724180258346, 2: -5.154129172138317, 3: -4.70824552443746, 4: -5.137210131817389}, Best action: 0, Actual action: 0\n",
      "Step: 438\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884203628607615, 1: -5.95783680347568, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -6.283429265606172}, Best action: 2, Actual action: 2\n",
      "Step: 439\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884203628733105, 1: -6.016490583991941, 2: -5.763059026493487, 3: -5.8465033727035465, 4: -6.321700857393032}, Best action: 2, Actual action: 2\n",
      "Step: 440\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.88420362874816, 1: -6.023527096954132, 2: -6.144383714109073, 3: -5.8465033727035465, 4: -6.326292182100862}, Best action: 3, Actual action: 3\n",
      "Step: 441\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -5.177838990279449, 2: -4.647595364554694, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 2, Actual action: 2\n",
      "Step: 442\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884203628745263, 1: -6.022173060299253, 2: -5.90794241286816, 3: -5.249202582559657, 4: -6.325408673183554}, Best action: 3, Actual action: 3\n",
      "Step: 443\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.74438930126025, 1: -5.177838990279449, 2: -5.616613628328792, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 0, Actual action: 0\n",
      "Step: 444\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5639039405588377, 1: -3.6623681666218624, 2: -3.6319427892273137, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 0, Actual action: 0\n",
      "Step: 445\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357281466532879, 1: -5.623261272129937, 2: -4.801019023436333, 3: -4.98481904768442, 4: -5.186915766596691}, Best action: 2, Actual action: 2\n",
      "Step: 446\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.278132752996698, 1: -6.312340261711697, 2: -6.44702070589445, 3: -5.835290208434816, 4: -6.48003130374855}, Best action: 3, Actual action: 3\n",
      "Step: 447\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.278132753011834, 1: -6.312340261826247, 2: -6.4470207059691935, 3: -5.83529133208636, 4: -6.480031305571296}, Best action: 3, Actual action: 3\n",
      "Step: 448\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2781327530137885, 1: -6.312340261841045, 2: -6.447020705978849, 3: -6.21011525735578, 4: -6.480031305806764}, Best action: 3, Actual action: 3\n",
      "Step: 449\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.278132753014589, 1: -6.312340261847105, 2: -6.447020705982803, 3: -6.704695275712719, 4: -6.480031305903188}, Best action: 0, Actual action: 0\n",
      "Step: 450\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.278132753014537, 1: -6.312340261846713, 2: -6.447020705982548, 3: -6.62382486630001, 4: -6.480031305896963}, Best action: 0, Actual action: 0\n",
      "Step: 451\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613100805243389, 1: -6.312340261847918, 2: -6.447020705983334, 3: -6.8729154959595204, 4: -6.480031305916139}, Best action: 1, Actual action: 1\n",
      "Step: 452\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755576, 1: -6.204865146590095, 2: -6.051163597827836, 3: -5.791869618668157, 4: -6.061730933891965}, Best action: 3, Actual action: 3\n",
      "Step: 453\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.467005780698436, 1: -4.5683044309119865, 2: -6.176746360649921, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 0, Actual action: 0\n",
      "Step: 454\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.35728210724289, 1: -5.623267716039879, 2: -6.351494441994074, 3: -4.98481904768442, 4: -5.186915766596691}, Best action: 3, Actual action: 3\n",
      "Step: 455\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -4.974718367307265, 3: -3.2901153512973993, 4: -3.4664086390772777}, Best action: 3, Actual action: 3\n",
      "Step: 456\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -4.97471836727089, 3: -3.2901153512973993, 4: -3.4664086390772777}, Best action: 3, Actual action: 3\n",
      "Step: 457\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3572821073758625, 1: -5.623267717377242, 2: -6.352545523878136, 3: -4.335225667591791, 4: -5.186915766596691}, Best action: 3, Actual action: 3\n",
      "Step: 458\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -4.974718367288869, 3: -5.209051030833965, 4: -3.4664086390772777}, Best action: 4, Actual action: 4\n",
      "Step: 459\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -4.9747183672875765, 3: -4.974673168418667, 4: -3.4664086390772777}, Best action: 4, Actual action: 4\n",
      "Step: 460\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -3.494861126675562, 2: -4.974718367288529, 3: -5.14733148712025, 4: -4.054431861560322}, Best action: 1, Actual action: 1\n",
      "Step: 461\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755155, 1: -6.204865133050207, 2: -6.051163597827836, 3: -5.414498320568232, 4: -6.061730933891965}, Best action: 3, Actual action: 3\n",
      "Step: 462\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.179529631849399, 1: -4.5683044309119865, 2: -6.176746356700851, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 1, Actual action: 1\n",
      "Step: 463\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.287005193199531, 1: -5.177838990279449, 2: -5.558292622246365, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 1, Actual action: 1\n",
      "Step: 464\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670717, 1: -5.595320047308987, 2: -4.874347963941224, 3: -4.804557904142596, 4: -5.783252622028596}, Best action: 3, Actual action: 3\n",
      "Step: 465\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -2.963801881451117, 2: -3.9893453034282236, 3: -4.099421644982031, 4: -2.955504859400784}, Best action: 4, Actual action: 4\n",
      "Step: 466\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -2.963801881451117, 2: -3.9893453034282236, 3: -4.099421644982031, 4: -2.955504859400784}, Best action: 4, Actual action: 4\n",
      "Step: 467\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -2.963801881451117, 2: -3.9893453034282236, 3: -4.099421644982031, 4: -3.5895094220547135}, Best action: 1, Actual action: 1\n",
      "Step: 468\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -2.99027149662423, 2: -3.8699747269540947, 3: -4.85017531610365, 4: -3.3884672852319273}, Best action: 1, Actual action: 1\n",
      "Step: 469\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -4.2026676098432345, 2: -5.470408936294993, 3: -3.5002696208649158, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 470\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -4.2026676098432345, 2: -5.470408936294993, 3: -3.5002696208649158, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 471\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -2.8462720827432006, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -3.266905676386616}, Best action: 1, Actual action: 1\n",
      "Step: 472\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5110029068716417, 1: -2.552082294844605, 2: -4.85347816989545, 3: -3.566174697703242, 4: -3.333318206420599}, Best action: 0, Actual action: 0\n",
      "Step: 473\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -4.74026439717871, 2: -4.1257417435406705, 3: -4.465372146659572, 4: -5.182760693915757}, Best action: 2, Actual action: 2\n",
      "Step: 474\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -5.5977995266021265, 2: -5.912161625620553, 3: -5.977045831125718, 4: -5.708367155042535}, Best action: 1, Actual action: 1\n",
      "Step: 475\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -5.788003416160073, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.17431995732119}, Best action: 1, Actual action: 1\n",
      "Step: 476\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -4.96002188736972, 2: -5.444297473888468, 3: -5.1773341426560116, 4: -5.407960992015212}, Best action: 1, Actual action: 1\n",
      "Step: 477\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956344407071322, 1: -5.207289270457922, 2: -5.48253365672065, 3: -4.492142437462526, 4: -5.010000236080775}, Best action: 3, Actual action: 3\n",
      "Step: 478\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961617359, 1: -4.980756656167369, 2: -4.1299408624979685, 3: -3.760319851857868, 4: -4.883725909157627}, Best action: 3, Actual action: 3\n",
      "Step: 479\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -3.9817455251646594, 4: -3.9466027366465957}, Best action: 4, Actual action: 4\n",
      "Step: 480\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -3.9817455251646594, 4: -3.9466027366465957}, Best action: 4, Actual action: 4\n",
      "Step: 481\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -3.9817455251646594, 4: -4.491408490348402}, Best action: 3, Actual action: 3\n",
      "Step: 482\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: -3.623333536736053, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 483\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 484\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 485\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -0.9, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 486\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.3050000000000002, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 487\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 488\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 489\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.532356875, 3: -1.61775, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 490\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.54896440625, 3: -1.8820125, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 491\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.5564377953125001, 3: -2.000930625, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 492\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.5594981481335939, 3: -2.0496275971875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 493\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: -3.623333536736053, 3: -1.601989365499837, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 494\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: -3.623333536736053, 3: -1.6018177575723287, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 495\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: -3.623333536736053, 3: -1.6019556626194384, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 496\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -1.5775461828318336, 2: -3.623333536736053, 3: -1.60201213473623, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 497\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.958795561673333, 2: -4.460607585543953, 3: -1.6787177658280164, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 498\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.703575354633892, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 499\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.703575354633892, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 500\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 501\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 502\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5797299658179171, 1: -2.448385838736233, 2: -1.705674773972891, 3: -2.05899007730279, 4: -2.665781577978282}, Best action: 0, Actual action: 0\n",
      "Step: 503\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359881655426076, 1: -1.7560877434800495, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 0, Actual action: 0\n",
      "Step: 504\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -1.624895318078129, 2: -2.076762208906761, 3: -2.152943552053625, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 505\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.4006888229787298, 4: -2.3035111875000003}, Best action: 4, Actual action: 4\n",
      "Step: 506\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.4006888229787298, 4: -2.3035111875000003}, Best action: 4, Actual action: 4\n",
      "Step: 507\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.4006888229787298, 4: -2.9961951806250005}, Best action: 3, Actual action: 3\n",
      "Step: 508\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1200646424615464, 1: -1.7560877434800495, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 1, Actual action: 1\n",
      "Step: 509\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: -1.4668625763850975, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 510\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: -1.466862573149794, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 511\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: -1.4668625750753463, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 512\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: -1.46686257586386, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 513\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0531917631795085, 1: -2.448385838736233, 2: -1.7078273715367507, 3: -2.059015975970968, 4: -2.667381093019638}, Best action: 2, Actual action: 2\n",
      "Step: 514\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -1.5444442111516514, 2: -2.530500091531223, 3: -2.4300264287280053, 4: -3.1497562117371833}, Best action: 1, Actual action: 1\n",
      "Step: 515\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -3.0151517444285854, 4: -2.847745460783589}, Best action: 4, Actual action: 4\n",
      "Step: 516\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -3.0151517444285854, 4: -2.847745460783589}, Best action: 4, Actual action: 4\n",
      "Step: 517\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -2.8710424744982856, 2: -3.185230149012602, 3: -3.0151517444285854, 4: -3.491448369313066}, Best action: 1, Actual action: 1\n",
      "Step: 518\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -3.8550967229485713, 3: -4.701852302990399, 4: -4.2259042668008755}, Best action: 2, Actual action: 2\n",
      "Step: 519\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2606468787544935, 1: -5.787684045431547, 2: -5.752536482581051, 3: -4.684912314853019, 4: -5.4782041177694065}, Best action: 3, Actual action: 3\n",
      "Step: 520\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.080288647325803, 3: -4.701852302990399, 4: -4.2259042668008755}, Best action: 4, Actual action: 4\n",
      "Step: 521\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.128241265059249, 3: -4.701852302990399, 4: -4.2259042668008755}, Best action: 4, Actual action: 4\n",
      "Step: 522\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.2334741597968035, 3: -4.701852302990399, 4: -4.745572882788797}, Best action: 3, Actual action: 3\n",
      "Step: 523\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.291909700495694, 1: -3.3133011697259684, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 0, Actual action: 0\n",
      "Step: 524\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -2.019092404780661, 4: -3.3310493686990714}, Best action: 3, Actual action: 3\n",
      "Step: 525\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.340502635504096, 1: -3.252748563756971, 2: -4.274337884644279, 3: -3.629144175149854, 4: -4.575994430153568}, Best action: 1, Actual action: 1\n",
      "Step: 526\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -4.9385369836791515, 2: -3.185230149012602, 3: -3.0151517444285854, 4: -4.9611878008982675}, Best action: 3, Actual action: 3\n",
      "Step: 527\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.958795561673333, 2: -4.460607585543953, 3: -2.718053496243897, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 528\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.9796693862542032, 4: -3.081244103506604}, Best action: 1, Actual action: 1\n",
      "Step: 529\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -1.8007981323440871, 2: -3.4408574194138493, 3: -1.9796693862294386, 4: -3.081244103506604}, Best action: 1, Actual action: 1\n",
      "Step: 530\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -2.5387263004331193, 2: -3.4408574194138493, 3: -1.9796693863233126, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 531\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -2.855810172604629, 2: -3.4408574194138493, 3: -1.979669386335831, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 532\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.179305327253734, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 533\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.1793053272265284, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 534\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.1793053272337235, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 535\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.001773627431305, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.17930532723667, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 536\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0537731988899206, 1: -2.448385838736233, 2: -3.3620463947534, 3: -2.059015978354769, 4: -2.6673812402443864}, Best action: 3, Actual action: 3\n",
      "Step: 537\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 538\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8429007271954596, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 539\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5213288339768116, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.179305327238089, 4: -3.53586954762489}, Best action: 3, Actual action: 3\n",
      "Step: 540\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764198584311914, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.1793053272382656, 4: -3.7164735657178305}, Best action: 3, Actual action: 3\n",
      "Step: 541\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196194, 1: -2.981975449309703, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 542\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7617865779140427, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -0.4256338064249898, 4: -3.7146799374602137}, Best action: 3, Actual action: 3\n",
      "Step: 543\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8429007271961604, 1: -2.752197172345037, 2: -1.2447633832042417, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 544\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196159, 1: -2.7434194678589345, 2: -1.1484374080481068, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 545\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 546\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0537731988926953, 1: -2.448385838736233, 2: -3.362046412858601, 3: -2.069958401283552, 4: -2.667381240244387}, Best action: 3, Actual action: 3\n",
      "Step: 547\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.636194674494174, 1: -3.8561414714686233, 2: -2.530500091531223, 3: -3.1744249083176914, 4: -3.703309531014141}, Best action: 0, Actual action: 0\n",
      "Step: 548\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.58 0.00 0.00 -1.52 -1.84 -3.09 -2.75 -4.06 -4.65 -6.05 \n",
      "0.00 0.00 0.00 -1.84 -2.71 -3.27 -3.73 -3.63 -5.18 -5.56 \n",
      "0.00 0.00 -1.54 -1.76 -1.64 -3.34 -3.75 -3.61 -5.03 -5.53 \n",
      "0.00 0.00 0.00 0.00 -1.58 -2.81 -3.99 -4.71 -4.19 -5.37 \n",
      "0.00 0.00 0.00 0.00 -1.64 -2.76 -3.39 -3.77 -5.13 -5.53 \n",
      "0.00 0.00 0.00 0.00 -1.80 -2.46 -3.27 -4.20 -4.47 -5.71 \n",
      "0.00 0.00 0.00 0.00 -2.08 -1.84 -2.55 -5.01 -4.62 -5.58 \n",
      "0.00 0.00 0.00 0.00 -1.74 -2.55 -1.17 -4.05 -4.80 -5.15 \n",
      "0.00 0.00 0.00 -1.77 -0.16 -1.60 -3.34 -3.33 -4.13 -4.75 \n",
      "0.00 0.00 0.00 -1.80 -1.44 -2.96 -3.19 -3.31 -4.25 -5.07 \n",
      "\n",
      "Action values: {0: -2.049581173854572, 1: -2.080095047098895, 2: -1.6083201886775063, 3: -1.583184099457752, 4: -2.946022846613221}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -2.080095047098895, 2: -1.6083201886775063, 3: -1.583184099457752, 4: -2.946022846613221}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -2.080095047098895, 2: -1.6083201886775063, 3: -2.3406975305065543, 4: -2.946022846613221}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -3.3470172233766333, 2: -3.2950281828381494, 3: -3.090851939985805, 4: -3.4266837450284346}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -1.835064897770724, 4: -2.5777232082956463}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -1.835064897770724, 4: -2.5777232082956463}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5221762150752651, 1: -2.183278080386992, 2: -3.5756132627886967, 3: -1.62820644386014, 4: -4.020093984889381}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -2.3089737022296344, 4: -2.5777232082956463}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9224863203135305, 1: -2.183278080386992, 2: -3.5756132627886967, 3: -1.62820644386014, 4: -4.020093984889381}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.402928440610048, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: -1.5181868876838907, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: -1.5181868876838907, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: -1.5181868876838907, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: -1.5181868876838907, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -2.080095047098895, 2: -2.5925488420684855, 3: -3.122268511134846, 4: -2.946022846613221}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.049581173854572, 1: -2.080095047098895, 2: -2.5926311570775407, 3: -3.1223222216782545, 4: -2.946022846613221}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -1.5740448637277904, 3: -3.033971402049483, 4: -3.6293976258321927}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6428345469040515, 1: -2.183278080386992, 2: -3.5756132627886967, 3: -1.7617905248084322, 4: -4.020093984889381}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.4040504034598054, 3: -1.556668324811622, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.404046086901128, 3: -1.5555131437710301, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.4040486316371052, 3: -1.5561941563493504, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.404049673706488, 3: -1.5564730310001726, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.643130687878356, 1: -2.183278080386992, 2: -3.5756132627886967, 3: -1.6728037235111903, 4: -4.020093984889381}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.6182365419114224, 2: -3.4040500552046753, 3: -2.4106815321665658, 4: -3.18860420253353}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: -3.0563655520293, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: -2.275364498413186, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8918480583025774, 1: -2.080095047098895, 2: -2.592654579584356, 3: -3.1223375048639515, 4: -2.946022846613221}, Best action: 1, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8925684551986297, 1: -2.080095047098895, 2: -2.592654586521473, 3: -3.1223375093904204, 4: -2.946022846613221}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.23410134753719, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1192665252034164, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: -2.275364498413186, 3: -2.3202774675915374, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: -2.275364498413186, 3: -2.3277508566540375, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: -2.275364498413186, 3: -2.3311138817321626, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.470689395843584, 1: -1.596081204247604, 2: -2.275364498413186, 3: -2.332491040501655, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6182649749638813, 2: -2.4663068863117203, 3: -3.051768573899548, 4: -3.642632047749197}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: -3.0563655520293, 3: -1.9498292531268218, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: -3.0563655520293, 3: -1.9497908852895973, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: -3.0563655520293, 3: -1.949818811061637, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -1.5926888454130388, 2: -3.0563655520293, 3: -1.9498302466652873, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.755166321715124, 2: -2.2658988527533466, 3: -1.81926449556541, 4: -2.7481776952786685}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: -1.8483218084810589, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: -1.8483218084810589, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: -1.8483218084810589, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.6363242189090663, 2: -3.208155054245165, 3: -1.8483218084810589, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: -2.000930625, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: -2.0544437812500003, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: -2.0785247015625004, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.520602324972719, 3: -2.088385838430469, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -1.4711555883095015, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -1.4709960467802774, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -1.4711339518273872, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -1.4711904239441786, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -1.4711970289863623, 4: -2.4393164247098813}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -1.6316166990884124, 2: -1.673781522716333, 3: -2.0901295449139146, 4: -2.619363370456204}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -1.799061476769491, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -1.799061476769491, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: -2.947191337511496, 3: -1.6342788273881836, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: -2.947191337511496, 3: -1.6342788273881836, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: -2.947191337511496, 3: -1.6342788273881836, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.625814886863139, 2: -2.947191337511496, 3: -1.6342788273881836, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -1.5580202669814398, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5006914456681388, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6260682833984386, 2: -3.1089054697145246, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.3050000000000002, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -1.73555526815353, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 1, Actual action: 1\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.16361946744941736, 1: -3.856141471466209, 2: -2.530500091531223, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 0, Actual action: 0\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.5532603406197794, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.83 -1.70 -1.94 -2.18 -2.42 -3.09 -2.75 -4.06 -4.65 -6.05 \n",
      "0.00 -1.60 -1.60 -1.84 -2.71 -3.27 -3.73 -3.63 -5.18 -5.56 \n",
      "0.00 0.00 -1.54 -1.68 -1.64 -3.34 -3.75 -3.61 -5.03 -5.53 \n",
      "0.00 0.00 0.00 -1.73 -1.58 -2.81 -3.99 -4.71 -4.19 -5.37 \n",
      "0.00 0.00 -1.64 -1.64 -1.64 -2.76 -3.39 -3.77 -5.13 -5.53 \n",
      "0.00 0.00 0.00 -1.63 -1.41 -2.46 -3.27 -4.20 -4.47 -5.71 \n",
      "0.00 0.00 0.00 0.00 -2.08 -1.84 -2.55 -5.01 -4.62 -5.58 \n",
      "0.00 0.00 0.00 0.00 -2.01 -0.26 -1.17 -4.05 -4.80 -5.15 \n",
      "0.00 0.00 0.00 -1.77 -1.95 -1.60 -3.34 -3.33 -4.13 -4.75 \n",
      "0.00 0.00 0.00 -1.80 -1.44 -2.96 -3.19 -3.31 -4.25 -5.07 \n",
      "\n",
      "Action values: {0: -2.763603493900178, 1: -1.8345007204488861, 2: -2.5926545863973205, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.596144388808626, 1: -2.447855344300802, 2: -3.0563655520293, 3: -1.9498346205190886, 4: -3.2378682870418993}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -1.9392492334247324, 2: -3.404050150065713, 3: -2.778878368012239, 4: -3.4623856966643474}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.630406317954896, 1: -2.447855344300802, 2: -3.0563655520293, 3: -1.9498346205190886, 4: -3.2378682870418993}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -1.596081204247604, 2: -2.275364498413186, 3: -2.3329658233757535, 4: -3.1244189976992907}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -1.0596081204247603, 2: -2.275364498413186, 3: -2.3329658233757535, 4: -3.1244189976992907}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5393085453623083, 1: -1.5468471205502319, 2: -1.6509442271096433, 3: -1.8951333114341244, 4: -2.549095480023762}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8382948816420446, 1: -2.8517290675266516, 2: -3.1591914829116585, 3: -3.0173261029909644, 4: -3.3290520846223846}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6431383678152276, 1: -2.183278080386992, 2: -3.5756132627886967, 3: -2.541121457096001, 4: -4.020093984889381}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.712603620152493, 1: -3.8896246753417745, 2: -3.418061140370249, 3: -3.1121594756284243, 4: -2.9846542362800768}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -3.3470172233766333, 2: -3.2950281828381494, 3: -3.0918743370462716, 4: -3.4266837450284346}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -2.419628279118454, 4: -2.5777232082956463}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -3.3470172233766333, 2: -3.2950281828381494, 3: -3.169086339790575, 4: -3.4266837450284346}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -3.3470172233766333, 2: -3.2950281828381494, 3: -3.7492688576012654, 4: -3.4266837450284346}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.064133139840897, 1: -5.696790909443338, 2: -4.9747183672893085, 3: -5.289070956865118, 4: -5.609871858760523}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357282107394513, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -4.652689750524111, 4: -5.186915766596691}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.07509201190862, 1: -5.696790909443338, 2: -4.9747183672893085, 3: -5.289070956865118, 4: -5.609871858760523}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357282107394513, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -5.394790852556751, 4: -5.186915766596691}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357282107394513, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -5.675660710729075, 4: -5.186915766596691}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357282107394513, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -5.763379170882851, 4: -5.620093347602989}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.357282107394513, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -5.779901454161983, 4: -5.882999364115944}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5900476867943, 1: -5.696790909443338, 2: -5.868595794306556, 3: -5.289070956865118, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589935863545812, 1: -5.696790909443338, 2: -5.868043580733778, 3: -5.289070956865118, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -3.8042041823241353, 2: -3.210446335168477, 3: -2.749773881240509, 4: -4.2060864066086365}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -3.3470172233766333, 2: -5.20725053908086, 3: -5.018063784773061, 4: -3.4266837450284346}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7017583492527297, 1: -4.394892694401812, 2: -3.270859908940516, 3: -3.5693749447007317, 4: -3.9175641901715617}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.731861745778494, 1: -3.900121889452441, 2: -3.7538091688611233, 3: -4.404930634000523, 4: -4.485721605319233}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -4.324663591794833, 2: -5.207787254738201, 3: -5.018354215033139, 4: -3.4266837450284346}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -4.388843589904991, 2: -5.207797088900048, 3: -5.0183595365439695, 4: -3.4266837450284346}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -4.442752999841077, 2: -5.207805349321956, 3: -5.0183640064647745, 4: -4.018282207975876}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7703993068436406, 1: -4.456595457156116, 2: -5.2078074703716535, 3: -5.0183651542177925, 4: -4.507757912455213}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589374015586704, 1: -5.696790909443338, 2: -5.865269022911015, 3: -3.86239304854609, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589374384803399, 1: -5.696790909443338, 2: -5.86527084620334, 3: -3.8627114310716553, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375087603456, 1: -5.696790909443338, 2: -5.8652743168209005, 3: -4.4156734400284785, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -3.8042041823241353, 2: -3.210446335168477, 3: -4.391824202950688, 4: -4.2060864066086365}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2021106757804514, 1: -3.8042041823241353, 2: -3.210446335168477, 3: -4.391437217916007, 4: -4.2060864066086365}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.657689238322099, 1: -5.6232677175648185, 2: -6.352692946591304, 3: -5.795541176240054, 4: -6.131861882779304}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.051163597827836, 3: -5.555003464475895, 4: -6.061730933891965}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -3.6623681666218624, 2: -3.6319427892273137, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -3.6623681666218624, 2: -3.6319427892273137, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -3.6623681666218624, 2: -4.205067938196856, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.609948112064051, 1: -4.0009572684544485, 2: -4.262015113813759, 3: -4.964548780210234, 4: -3.6947373928686584}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.190294787434068, 2: -4.668377810627301, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.4927377498704075, 2: -4.865721843617012, 3: -4.563135175505298, 4: -3.7296898431338272}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.607014152479294, 2: -4.940287196319311, 3: -4.563135175505298, 4: -4.294017757251783}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.653810339347633, 2: -4.970821708250901, 3: -4.563135175505298, 4: -5.038648439930425}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.656326314567083, 2: -4.972463382081592, 3: -4.563135175505298, 4: -5.1400390584371305}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.179759667088528, 1: -5.485556923922058, 2: -6.176746356701945, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.054497490803789, 2: -6.447020705983276, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.051163597827836, 3: -4.764077802236748, 4: -6.061730933891965}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.051163597827836, 3: -4.763972052858539, 4: -6.061730933891965}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.106980418736335, 1: -5.485556923922058, 2: -6.176746356701945, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1469915380427524, 1: -5.485556923922058, 2: -6.176746356701945, 3: -5.764088121421653, 4: -5.247903523305219}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.164529447096024, 1: -5.485556923922058, 2: -6.176746356701945, 3: -5.764088121421653, 4: -5.6755922062077495}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.28700542953378, 1: -5.032676542956129, 2: -5.558292670104051, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -5.374189871306969, 2: -6.179826327187801, 3: -5.881486310413012, 4: -5.805335716674008}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.017168140265884, 1: -5.990939315911989, 2: -6.21976326981688, 3: -5.532480868568598, 4: -6.047499746615025}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -4.255375479406486, 2: -4.261166540637162, 3: -3.771442256363947, 4: -4.222380216137544}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.125538386572347, 4: -5.146067014400159}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -4.255375479406486, 2: -4.261166540637162, 3: -5.428830318759996, 4: -4.222380216137544}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -4.255375479406486, 2: -4.261166540637162, 3: -5.29704486098033, 4: -4.222380216137544}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -4.255375479406486, 2: -4.261166540637162, 3: -5.402341981541223, 4: -4.742365996685165}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -4.2026676098432345, 2: -5.470408936294993, 3: -4.481433825982611, 4: -4.497761515782182}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.102936252040563, 1: -5.334775955102935, 2: -5.006493231603862, 3: -5.425650108606269, 4: -5.120580905227279}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038552660645188, 1: -4.624883699053219, 2: -5.7676064775856055, 3: -5.118069858694262, 4: -5.0691375637772556}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -4.799239601525486, 2: -4.7988183178912935, 3: -5.083950240880236, 4: -5.735025665007315}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -5.152059951072767, 2: -5.444297473888468, 3: -5.1773341426560116, 4: -5.407960992015212}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961617359, 1: -4.980756656167369, 2: -4.1299408624979685, 3: -4.555892637839487, 4: -4.883725909157627}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956344407071322, 1: -5.207289270457922, 2: -5.48253365672065, 3: -4.753081077442854, 4: -5.010000236080775}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235737961617359, 1: -4.980756656167369, 2: -5.162989758978508, 3: -4.555892637839487, 4: -4.883725909157627}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -4.799239601525486, 2: -5.590867509647065, 3: -5.083950240880236, 4: -5.735025665007315}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.956344407071322, 1: -5.207289270457922, 2: -5.48253365672065, 3: -5.245104816955356, 4: -5.010000236080775}, Best action: 0, Actual action: 0\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -5.349376881631506, 2: -5.444297473888468, 3: -5.1773341426560116, 4: -5.407960992015212}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -5.67938174001455, 2: -5.647098719009382, 3: -5.083950240880236, 4: -5.735025665007315}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.214312506641937, 2: -4.366621297643016, 3: -4.1546659652966165, 4: -4.050440064623608}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.214312506641937, 2: -4.366621297643016, 3: -4.1546659652966165, 4: -4.050440064623608}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.214312506641937, 2: -4.366621297643016, 3: -4.1546659652966165, 4: -4.585900458807483}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -3.250597806623883, 2: -1.6352782889218858, 3: -1.1650648686900267, 4: -3.8429276062657522}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.214312506641937, 2: -4.366621297643016, 3: -2.2591691401685834, 4: -3.549143857908552}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -5.731036744647363, 2: -5.6480518991245585, 3: -4.8543668540104346, 4: -5.735025665007315}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.214312506641937, 2: -4.366621297643016, 3: -5.562476357087402, 4: -4.322667328392316}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631838290371301, 1: -4.980756656167369, 2: -5.469628726196354, 3: -4.555892637839487, 4: -4.883725909157627}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -4.030916651742919, 4: -3.331049368699072}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -4.030916651742919, 4: -3.331049368699072}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -4.030916651742919, 4: -3.9312549255161553}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -4.030916651742919, 4: -4.723226157736297}, Best action: 3, Actual action: 3\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.340502635504096, 1: -3.906706507360757, 2: -4.274337884644279, 3: -3.629144175149854, 4: -4.575994430153568}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -3.250597806623883, 2: -1.6352782889218858, 3: -3.8484531366782484, 4: -3.8429276062657522}, Best action: 2, Actual action: 2\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.946628530532571, 2: -4.366621297643016, 3: -5.691823215883427, 4: -4.336880020397549}, Best action: 0, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.1083883051801084, 2: -4.695674249610679, 3: -4.35264544543007, 4: -4.820586340122786}, Best action: 1, Actual action: 1\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -4.939636622161343, 2: -3.185230149012602, 3: -3.5466156066461547, 4: -4.961905315007897}, Best action: 2, Actual action: 2\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.76997672905492, 1: -3.3133011697259684, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 1, Actual action: 1\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.76997672905492, 1: -3.3133011697259684, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 1, Actual action: 1\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.76997672905492, 1: -3.9151040644506314, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 0, Actual action: 0\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952438472148, 1: -4.980756656167369, 2: -5.469651841186775, 3: -4.439370267861472, 4: -4.883725909157627}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952443715884, 1: -4.980756656167369, 2: -5.4696518422486315, 3: -4.439446316348581, 4: -4.883725909157627}, Best action: 3, Actual action: 3\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952444786598, 1: -4.980756656167369, 2: -5.469651842465451, 3: -4.939911676152668, 4: -4.883725909157627}, Best action: 4, Actual action: 4\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952445181238, 1: -4.980756656167369, 2: -5.469651842545366, 3: -5.534268742430832, 4: -4.883725909157627}, Best action: 4, Actual action: 4\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952445380734, 1: -4.980756656167369, 2: -5.469651842585764, 3: -5.834724831652606, 4: -5.34419057733344}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2606468787544935, 1: -5.787684045431547, 2: -5.752536482581051, 3: -5.072900774869887, 4: -5.4782041177694065}, Best action: 3, Actual action: 3\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -4.251762250552203, 4: -5.0862420413957175}, Best action: 3, Actual action: 3\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.236037347288012, 1: -5.495335482014656, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 4, Actual action: 4\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.236842551036356, 1: -5.4958608774604505, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -3.8791007343098767}, Best action: 4, Actual action: 4\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.23776886423426, 1: -5.496465296822083, 2: -5.31111679989344, 3: -4.0726783541594545, 4: -4.429981668221988}, Best action: 3, Actual action: 3\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -4.939636622161343, 2: -4.393968150632741, 3: -3.5466156066461547, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.958795561673333, 2: -4.460607585543953, 3: -3.0368914968366094, 4: -4.001357430419479}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -1.4395848079755362, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -1.4395848079755362, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -1.7961442159860261, 4: -3.7235654418916977}, Best action: 3, Actual action: 3\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -1.4389742525899734, 3: -2.6230828486771616, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -1.4389742525899734, 3: -2.6230828486771616, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -1.4389742525899734, 3: -2.6230828486771616, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -1.4389742525899734, 3: -2.6230828486771616, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -1.6674817155250843, 4: -3.7235654418916977}, Best action: 3, Actual action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4407399979726616, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4407399979726616, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (9, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.4374380456671825, 3: -2.0386262147212793, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.4374380456671825, 3: -2.0386262147212793, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.4374380456671825, 3: -2.0386262147212793, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -1.4374380456671825, 3: -2.0386262147212793, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5766191562688545, 1: -1.6168979782180493, 2: -3.888280578259649, 3: -2.343669774410325, 4: -4.277800856851135}, Best action: 0, Actual action: 0\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6424667724669364, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -2.6329136762588368}, Best action: 0, Actual action: 0\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -3.418061140370249, 3: -3.1121594756284243, 4: -2.9846542362800768}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -3.418061140370249, 3: -3.1121594756284243, 4: -2.9846542362800768}, Best action: 4, Actual action: 4\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -3.418061140370249, 3: -3.1121594756284243, 4: -3.61603535501487}, Best action: 3, Actual action: 3\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -2.447855344300802, 2: -3.0563655520293, 3: -2.6206197651931418, 4: -3.2378682870418993}, Best action: 1, Actual action: 1\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -1.6816146309823399, 2: -2.2658988527533466, 3: -1.81926449556541, 4: -2.7481776952786685}, Best action: 1, Actual action: 1\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.363231406295463, 1: -1.6168979782180493, 2: -3.888280578259649, 3: -2.343669774410325, 4: -4.277800856851135}, Best action: 1, Actual action: 1\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.1139620603108793, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.6362760420201476, 4: -2.9898254268029403}, Best action: 3, Actual action: 3\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.1139620603108793, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -1.6362760420201476, 4: -2.9898254268029403}, Best action: 3, Actual action: 3\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.63634589850908, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -3.2328333034257275, 4: -3.239519404355012}, Best action: 0, Actual action: 0\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3732134165545022, 1: -2.7410585572803243, 2: -3.888280578259649, 3: -2.343669774410325, 4: -4.277800856851135}, Best action: 3, Actual action: 3\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.373664812533331, 1: -2.8618594349152926, 2: -3.888280578259649, 3: -2.343669774410325, 4: -4.277800856851135}, Best action: 3, Actual action: 3\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -1.7256778462921052, 2: -3.208155054245165, 3: -1.8483218084810589, 4: -2.7267977287779703}, Best action: 1, Actual action: 1\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.1139620603108793, 1: -1.6371058809040528, 2: -3.3310519635354363, 3: -3.5085252447077933, 4: -2.9898254268029403}, Best action: 1, Actual action: 1\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -2.7810635483212645, 3: -2.463326637410386, 4: -3.039077690272842}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -1.4142606227841332, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.8055300540285917, 2: -2.947191337511496, 3: -1.6342788273881836, 4: -2.7799258251218935}, Best action: 3, Actual action: 3\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.8055300540285917, 2: -2.947191337511496, 3: -1.0634278827388184, 4: -2.7799258251218935}, Best action: 3, Actual action: 3\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6363556543290856, 1: -1.8055300540285917, 2: -2.947191337511496, 3: -1.8560473459971178, 4: -2.7799258251218935}, Best action: 0, Actual action: 0\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6361689822669947, 1: -2.6957227331671634, 2: -1.6864316126617802, 3: -2.090160388276966, 4: -2.628770293591887}, Best action: 0, Actual action: 0\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -3.106929338699023, 2: -3.208155054245165, 3: -1.8483218084810589, 4: -2.7267977287779703}, Best action: 3, Actual action: 3\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -3.108484045991162, 2: -3.208155054245165, 3: -1.8483218084810589, 4: -2.7267977287779703}, Best action: 3, Actual action: 3\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4568745631369704, 1: -3.109039185529446, 2: -3.208155054245165, 3: -2.5819728457177638, 4: -2.7267977287779703}, Best action: 0, Actual action: 0\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -2.9523822172417273, 2: -2.2658988527533466, 3: -1.81926449556541, 4: -2.7481776952786685}, Best action: 3, Actual action: 3\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -1.5468471205502319, 2: -1.6509442271096433, 3: -1.8951333114341244, 4: -2.549095480023762}, Best action: 1, Actual action: 1\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -1.6342275145897853, 2: -3.1295293047904362, 3: -2.0386262147212793, 4: -3.652419385142195}, Best action: 1, Actual action: 1\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0568629012890876, 1: -2.6957227331671634, 2: -1.6864316126617802, 3: -2.090160388276966, 4: -2.628770293591887}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -3.4252248105064393, 2: -2.761423475105624, 3: -2.7557403087706613, 4: -3.360963364079684}, Best action: 3, Actual action: 3\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -4.352814392143214, 2: -3.8699747269540947, 3: -4.85017531610365, 4: -3.3884672852319273}, Best action: 4, Actual action: 4\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -4.352814392143214, 2: -3.8699747269540947, 3: -4.85017531610365, 4: -3.3884672852319273}, Best action: 4, Actual action: 4\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -4.352814392143214, 2: -3.8699747269540947, 3: -4.85017531610365, 4: -3.9835052295610542}, Best action: 2, Actual action: 2\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -5.377645593653239, 2: -4.261166540637162, 3: -5.455535862464754, 4: -5.588798121119952}, Best action: 2, Actual action: 2\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.017168140265884, 1: -5.990939315911989, 2: -6.21976326981688, 3: -5.265958437257021, 4: -6.047499746615025}, Best action: 3, Actual action: 3\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.18488403924959, 4: -5.146067014400159}, Best action: 4, Actual action: 4\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.18488403924959, 4: -5.146067014400159}, Best action: 4, Actual action: 4\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.18488403924959, 4: -5.582920983104144}, Best action: 3, Actual action: 3\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.18488403924959, 4: -5.691855404251879}, Best action: 3, Actual action: 3\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -4.352814392143214, 2: -5.454710209869597, 3: -4.85017531610365, 4: -5.669356124393828}, Best action: 1, Actual action: 1\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -4.74026439717871, 2: -6.052863663853859, 3: -4.465372146659572, 4: -5.182760693915757}, Best action: 3, Actual action: 3\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.313113412934631, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.481433825982611, 4: -4.497761515782182}, Best action: 0, Actual action: 0\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1216684425800345, 1: -5.377645593653239, 2: -5.847391434264326, 3: -5.455535862464754, 4: -5.588798121119952}, Best action: 0, Actual action: 0\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.154129172138317, 3: -4.70824552443746, 4: -5.137210131817389}, Best action: 3, Actual action: 3\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.154129172138317, 3: -4.70824552443746, 4: -5.137210131817389}, Best action: 3, Actual action: 3\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.154129172138317, 3: -5.184503427238089, 4: -5.137210131817389}, Best action: 4, Actual action: 4\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.154129172138317, 3: -5.757379754511906, 4: -5.137210131817389}, Best action: 4, Actual action: 4\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.154129172138317, 3: -6.042947089520929, 4: -5.574861219953823}, Best action: 2, Actual action: 2\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670717, 1: -5.595320047308987, 2: -4.874347963941224, 3: -4.189448440970782, 4: -5.783252622028596}, Best action: 3, Actual action: 3\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -5.798793396581048, 2: -6.179826327187801, 3: -5.881486310413012, 4: -5.805335716674008}, Best action: 1, Actual action: 1\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.017168140265884, 1: -5.990939315911989, 2: -6.21976326981688, 3: -5.839626219122823, 4: -6.047499746615025}, Best action: 3, Actual action: 3\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3193402739946665, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.385967471134999, 4: -5.927586995619066}, Best action: 0, Actual action: 0\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -6.188826441921272, 2: -6.179826327187801, 3: -5.881486310413012, 4: -5.805335716674008}, Best action: 4, Actual action: 4\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -6.353846867913198, 2: -6.179826327187801, 3: -5.881486310413012, 4: -5.805335716674008}, Best action: 4, Actual action: 4\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -6.388248358366825, 2: -6.179826327187801, 3: -5.881486310413012, 4: -6.182855502173347}, Best action: 3, Actual action: 3\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670717, 1: -5.595320047308987, 2: -4.874347963941224, 3: -6.283057064341716, 4: -5.783252622028596}, Best action: 2, Actual action: 2\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670717, 1: -5.595320047308987, 2: -4.874347963941224, 3: -6.279360926825216, 4: -5.783252622028596}, Best action: 2, Actual action: 2\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -6.387942732428581, 2: -6.179826327187801, 3: -5.643959389294072, 4: -6.172048427387104}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.392215444670717, 1: -5.595320047308987, 2: -6.306455025334001, 3: -6.2822104962148115, 4: -5.783252622028596}, Best action: 0, Actual action: 0\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.28700542953378, 1: -5.947433036427596, 2: -5.558292670104051, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 0, Actual action: 0\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -5.93666411424883, 2: -6.176746356701945, 3: -5.764088121421653, 4: -6.311078425941315}, Best action: 3, Actual action: 3\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.6736193735565585, 2: -4.983747103072227, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 1, Actual action: 1\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -3.785085100261147, 2: -3.7490154576255557, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 2, Actual action: 2\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6840027478918085, 1: -4.0009572684544485, 2: -4.262015113813759, 3: -4.964548780210234, 4: -3.6947373928686584}, Best action: 4, Actual action: 4\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6840027478918085, 1: -4.0009572684544485, 2: -4.262015113813759, 3: -4.964548780210234, 4: -3.6947373928686584}, Best action: 4, Actual action: 4\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6840027478918085, 1: -4.0009572684544485, 2: -4.262015113813759, 3: -4.964548780210234, 4: -4.262211027510479}, Best action: 1, Actual action: 1\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -4.23164440339428, 2: -3.9893453034282236, 3: -4.099421644982031, 4: -4.518452181605565}, Best action: 2, Actual action: 2\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.012654166436412, 1: -6.3910129221657614, 2: -6.179826327187801, 3: -6.148376408140241, 4: -6.280611759047846}, Best action: 0, Actual action: 0\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.88420362874854, 1: -6.023704409237823, 2: -6.17534590921009, 3: -5.529414240668554, 4: -6.326407878365969}, Best action: 3, Actual action: 3\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.905755146064683, 1: -5.947433036427596, 2: -5.558292670104051, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 4, Actual action: 4\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.905912050173263, 1: -5.947433036427596, 2: -5.558292670104051, 3: -5.49377041015622, 4: -5.2886805489510635}, Best action: 4, Actual action: 4\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.906056431224562, 1: -5.947433036427596, 2: -5.558292670104051, 3: -5.49377041015622, 4: -5.712699299545468}, Best action: 3, Actual action: 3\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6840027478918085, 1: -5.545929789541308, 2: -4.262015113813759, 3: -4.964548780210234, 4: -5.712244518418229}, Best action: 2, Actual action: 2\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.88420362874854, 1: -6.023704409237823, 2: -6.17534590921009, 3: -5.915846667974961, 4: -6.326407878365969}, Best action: 0, Actual action: 0\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -5.93666411424883, 2: -6.176746356701945, 3: -5.338515733072695, 4: -6.311078425941315}, Best action: 3, Actual action: 3\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.843559389442422, 2: -4.983747103072227, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 1, Actual action: 1\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -3.785085100261147, 2: -4.72567214472017, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 1, Actual action: 1\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -4.23164440339428, 2: -6.247448892613042, 3: -4.099421644982031, 4: -4.518452181605565}, Best action: 3, Actual action: 3\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -4.23164440339428, 2: -6.247726049389954, 3: -4.099421644982031, 4: -4.518452181605565}, Best action: 3, Actual action: 3\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -4.23164440339428, 2: -6.247807421343556, 3: -4.630473696933648, 4: -4.518452181605565}, Best action: 1, Actual action: 1\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -3.4252248105064393, 2: -2.761423475105624, 3: -4.423316211778065, 4: -3.360963364079684}, Best action: 2, Actual action: 2\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.766116823181719, 1: -5.398318999061428, 2: -5.4533802513862915, 3: -4.85017531610365, 4: -5.6684883264834705}, Best action: 0, Actual action: 0\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -3.6466077337330214, 2: -3.4526582057887354, 3: -2.8136852219472654, 4: -3.345887801944931}, Best action: 3, Actual action: 3\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3737835659771265, 1: -2.8936397805666947, 2: -3.888280578259649, 3: -3.3096653903282585, 4: -4.277800856851135}, Best action: 1, Actual action: 1\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8129889727684128, 1: -3.4252248105064393, 2: -4.6810930576065, 3: -4.423316211778065, 4: -3.360963364079684}, Best action: 0, Actual action: 0\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -4.447316412216015, 2: -6.247825159934859, 3: -5.003497859978001, 4: -4.518452181605565}, Best action: 1, Actual action: 1\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.271744788875443, 1: -5.39831899906144, 2: -5.4533802513862915, 3: -4.85017531610365, 4: -5.6684883264834705}, Best action: 0, Actual action: 0\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.439724180258346, 2: -5.750724764699548, 3: -6.138650502089469, 4: -6.047470664736741}, Best action: 1, Actual action: 1\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.573413349559115, 1: -5.377645593653239, 2: -5.849695164581123, 3: -5.455535862464754, 4: -5.588798121119952}, Best action: 1, Actual action: 1\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -4.74026439717871, 2: -6.052863663853859, 3: -5.456674637888168, 4: -5.182760693915757}, Best action: 1, Actual action: 1\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.102936252040563, 1: -5.334775955102935, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.120580905227279}, Best action: 0, Actual action: 0\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.5074048038707275, 2: -6.052863663853859, 3: -5.456674637888168, 4: -5.182760693915757}, Best action: 4, Actual action: 4\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.734831894726593, 2: -6.052863663853859, 3: -5.456674637888168, 4: -5.182760693915757}, Best action: 4, Actual action: 4\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.822626081079979, 2: -6.052863663853859, 3: -5.456674637888168, 4: -5.616312231463339}, Best action: 3, Actual action: 3\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.481433825982611, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.481433825982611, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -3.266905676386616}, Best action: 4, Actual action: 4\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -3.266905676386616}, Best action: 4, Actual action: 4\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.313062984670375, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -3.8728841655118207}, Best action: 0, Actual action: 0\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007407097008028, 1: -5.39831899906144, 2: -5.4533802513862915, 3: -4.85017531610365, 4: -5.6684883264834705}, Best action: 3, Actual action: 3\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.573413349559115, 1: -5.770641783897928, 2: -5.849695164581123, 3: -5.455535862464754, 4: -5.588798121119952}, Best action: 3, Actual action: 3\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0075669363849835, 1: -5.39831899906144, 2: -5.4533802513862915, 3: -5.8040015802068154, 4: -5.6684883264834705}, Best action: 1, Actual action: 1\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.358278965157256, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623580867600707, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.4900916584676915, 4: -5.522575723626292}, Best action: 3, Actual action: 3\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -2.7810635483212645, 3: -2.8132821412113587, 4: -3.039077690272842}, Best action: 2, Actual action: 2\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.166491255309343, 4: -4.497761515782182}, Best action: 3, Actual action: 3\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.630682520435173, 1: -4.500658439941332, 2: -5.271645682276203, 3: -4.299025965477137, 4: -5.527209552100781}, Best action: 3, Actual action: 3\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -4.691424906519477, 3: -2.8132821412113587, 4: -3.039077690272842}, Best action: 3, Actual action: 3\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -4.54027052470481, 3: -2.8132821412113587, 4: -3.039077690272842}, Best action: 3, Actual action: 3\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -2.572923673928961, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -1.8055300540285917, 2: -2.947191337511496, 3: -3.280387028090384, 4: -2.7799258251218935}, Best action: 1, Actual action: 1\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6260682833984386, 2: -3.1089054697145246, 3: -1.796947181034058, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6260682833984386, 2: -3.1089054697145246, 3: -1.796947181034058, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6260682833984386, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6260682833984386, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.59 -1.70 -2.46 -2.54 -2.58 -4.47 -3.21 -4.40 -5.61 -5.72 \n",
      "0.00 -2.28 -2.62 -2.85 -3.42 -3.57 -3.75 -4.95 -5.40 -6.05 \n",
      "0.00 0.00 -1.65 -2.27 -2.63 -3.34 -4.19 -4.68 -5.56 -5.84 \n",
      "0.00 0.00 -1.64 -2.73 -3.31 -3.35 -4.52 -5.75 -5.60 -6.15 \n",
      "0.00 0.00 -2.09 -2.23 -2.11 -3.36 -5.05 -5.57 -5.39 -5.99 \n",
      "0.00 0.00 0.00 -1.62 -2.54 -3.04 -3.83 -4.50 -5.21 -5.71 \n",
      "0.00 0.00 -0.16 0.00 -2.08 -1.84 -2.55 -5.12 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 -2.01 -0.26 -2.03 -4.24 -5.14 -5.36 \n",
      "0.00 0.00 0.00 -1.77 -1.95 -1.60 -3.63 -4.34 -5.47 -5.01 \n",
      "0.00 0.00 -2.37 -1.64 -2.20 -2.77 -3.55 -4.19 -4.77 -5.08 \n",
      "\n",
      "Action values: {0: -2.763603493900178, 1: -3.0515136422431066, 2: -2.5926545863973205, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -1.6961068289073975, 2: -2.466307123921491, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -1.5280243153799389, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -3.41024115297373, 2: -2.275364498413186, 3: -2.3329658233757535, 4: -3.1244189976992907}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.0787389880140092, 2: -3.0563655520293, 3: -2.6206197651931418, 4: -3.2378682870418993}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.0787389880140092, 2: -3.0563655520293, 3: -2.6206197651931418, 4: -3.2378682870418993}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -1.5280243153799389, 3: -3.316227731049596, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -1.5280243153799389, 3: -3.1288485246210547, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -1.5280243153799389, 3: -3.165754149621055, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -1.5280243153799389, 3: -3.180867003058555, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.0787389880140092, 2: -3.0563655520293, 3: -1.1650852602123454, 4: -3.2378682870418993}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -3.41024115297373, 2: -3.2569695519534245, 3: -2.3329658233757535, 4: -3.1244189976992907}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -3.41024115297373, 2: -3.2633819246150604, 3: -2.3329658233757535, 4: -3.1244189976992907}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3928924035796855, 1: -3.41024115297373, 2: -3.264542223884548, 3: -3.022998899271936, 4: -3.1244189976992907}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -2.504307542957469, 2: -2.466307123921491, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.086417896163934, 1: -2.5043376335169243, 2: -2.466307123921491, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6431383678152276, 1: -3.9253201391366344, 2: -3.5756132627886967, 3: -2.541121457096001, 4: -4.020093984889381}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6431383678152276, 1: -3.9253201391366344, 2: -3.5756132627886967, 3: -2.541121457096001, 4: -4.020093984889381}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6431383678152276, 1: -3.9253201391366344, 2: -3.5756132627886967, 3: -3.212420525957361, 4: -4.020093984889381}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -4.183844888469229, 4: -2.5777232082956463}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -4.183844888469229, 4: -2.5777232082956463}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.800412576156201, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -4.183844888469229, 4: -3.2457281195490384}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -3.8042041823241353, 2: -3.210446335168477, 3: -4.391669870532966, 4: -4.2060864066086365}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.657707592184124, 1: -5.605940122070471, 2: -6.352692946591304, 3: -5.795541409812726, 4: -6.131865599436364}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -5.93666411424883, 2: -6.176746356701945, 3: -5.404761697425145, 4: -6.311078425941315}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.051163597827836, 3: -6.279687509030582, 4: -6.061730933891965}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.051163597827836, 3: -6.279687509030582, 4: -6.061730933891965}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.406558874023331, 3: -6.279687509030582, 4: -6.061730933891965}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.470502525278998, 3: -6.279687509030582, 4: -6.061730933891965}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.2048651331371385, 2: -6.701777376186192, 3: -6.279687509030582, 4: -6.416175149841689}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8424293739115, 1: -6.023704409237823, 2: -6.17534590921009, 3: -5.990133300239991, 4: -6.326407878365969}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.252854306182028, 2: -6.752568115093129, 3: -6.279687509030582, 4: -6.666993613579645}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.549054925398593, 1: -6.023704409237823, 2: -6.17534590921009, 3: -5.990133300239991, 4: -6.326407878365969}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.9061037632587245, 1: -5.947433036427596, 2: -5.558292670104051, 3: -5.716826098184538, 4: -6.160603896805591}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.478517173818904, 1: -6.023704409237823, 2: -6.17534590921009, 3: -6.001230392808281, 4: -6.326407878365969}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547638513043166, 1: -6.023704409237823, 2: -6.17534590921009, 3: -6.342570339594758, 4: -6.326407878365969}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.187414528392317, 1: -6.391015795785025, 2: -6.179826327187801, 3: -6.150241085177392, 4: -6.28071337155649}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.187414528392317, 1: -6.391015795785025, 2: -6.179826327187801, 3: -6.150241085177392, 4: -6.28071337155649}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.000290192565655, 1: -5.595320047308987, 2: -6.528138887728478, 3: -6.282467574969518, 4: -5.783252622028596}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -5.804885281665515, 2: -5.619468644999817, 3: -5.386007694492624, 4: -5.927595140848987}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.573413349559115, 1: -5.770802185686172, 2: -5.849695164581123, 3: -5.662186159606709, 4: -5.588798121119952}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.000290192565655, 1: -6.077374286914709, 2: -6.528138887728478, 3: -6.282467574969518, 4: -5.783252622028596}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.000290192565655, 1: -6.1924677152858, 2: -6.528138887728478, 3: -6.282467574969518, 4: -5.783252622028596}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.000290192565655, 1: -6.227050314719388, 2: -6.528138887728478, 3: -6.282467574969518, 4: -6.162759886046022}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6840027478918085, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -4.964548780210234, 4: -5.713453080324176}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.603884268228999, 2: -6.795318762439236, 3: -6.279687509030582, 4: -6.878107921461656}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.60395034559046, 2: -6.7953202327129025, 3: -6.279687509030582, 4: -6.8781151820723565}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.342652814755158, 1: -6.603955967478698, 2: -6.795320357804372, 3: -6.61451563321783, 4: -6.878115799808008}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -5.722270290300231, 2: -6.447020705983276, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.169304216618703, 1: -6.603956016423105, 2: -6.795320358893424, 3: -6.623908502514458, 4: -6.878115805186042}, Best action: 0, Actual action: 0\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.469363444491173, 2: -6.447020705983276, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.589576556740203, 2: -6.447020705983276, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.654329604373658, 2: -6.766788842444781, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.6596800451613545, 2: -6.851926171851188, 3: -6.854569551108148, 4: -6.480031305914727}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.67267070962492, 2: -7.0586363334113456, 3: -6.854569551108148, 4: -6.796828488382401}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.533605483834902, 1: -6.674056050876382, 2: -7.08068017225492, 3: -6.854569551108148, 4: -6.90568695180746}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.84558099028976, 1: -6.676646622362724, 2: -7.121901885892183, 3: -6.854569551108148, 4: -7.109250969769255}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.060871293928312, 1: -6.6039574774811545, 2: -6.7953203914031235, 3: -6.90429860628417, 4: -6.878115965727767}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.561449730542888, 1: -6.614638531316355, 2: -6.17534590921009, 3: -6.747581503585947, 4: -6.326407878365969}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.561449730524894, 1: -6.614638530341245, 2: -6.17534590921009, 3: -6.747581503058291, 4: -6.326407878365969}, Best action: 2, Actual action: 2\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.561449730592004, 1: -6.614638533978071, 2: -6.5195647773811825, 3: -6.747581505026268, 4: -6.326407878365969}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5614497306057595, 1: -6.6146385347234835, 2: -6.746898796039569, 3: -6.74758150542963, 4: -6.326407878365969}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.561449730618812, 1: -6.614638535430853, 2: -6.962630493382528, 3: -6.747581505812406, 4: -6.657031169313031}, Best action: 0, Actual action: 0\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.062321358908527, 1: -6.788363536064392, 2: -6.795320391421598, 3: -6.904457940087427, 4: -6.878115965818996}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.05471943727838, 1: -6.61463853585969, 2: -7.093416235422848, 3: -6.747581506044461, 4: -7.302886685561525}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.187414528392317, 1: -6.391015795785025, 2: -6.179826327187801, 3: -6.315255144957749, 4: -6.28071337155649}, Best action: 2, Actual action: 2\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.187414528392317, 1: -6.391015795785025, 2: -6.179826327187801, 3: -6.3152551449278995, 4: -6.28071337155649}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.187414528392317, 1: -6.391015795785025, 2: -6.523641957740899, 3: -6.315255145025095, 4: -6.28071337155649}, Best action: 0, Actual action: 0\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.9061037632587245, 1: -5.947433036427596, 2: -6.468389315464933, 3: -5.716826098184538, 4: -6.160603896805591}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.9061037632587245, 1: -5.947433036427596, 2: -6.468389315464871, 3: -5.716826098184538, 4: -6.160603896805591}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.9061037632587245, 1: -5.947433036427596, 2: -6.468389315465152, 3: -6.10231174934793, 4: -6.160603896805591}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -4.949397702308247, 2: -4.983747103072227, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089211562, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -4.964548780210234, 4: -5.713453080324176}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.380650606788051, 4: -4.18568384234986}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.380650606788051, 4: -4.708972296538373}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.380650606788051, 4: -5.0138375872283625}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.146257567768504, 1: -4.221335972421993, 2: -3.4597212514154925, 3: -3.338272422233393, 4: -4.662432993262021}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -2.6329136762588368}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -2.6329136762588368}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -3.2959514453955414}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -2.8174014894660444, 4: -3.608772858532229}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -2.9523826365117447, 2: -2.2658988527533466, 3: -3.085594141785243, 4: -2.7481776952786685}, Best action: 2, Actual action: 2\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.146257567768504, 1: -4.221335972421993, 2: -3.4597212514154925, 3: -3.7517803188495873, 4: -4.662432993262021}, Best action: 2, Actual action: 2\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.64611208943762, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -5.086648165979623, 4: -5.713453080324176}, Best action: 3, Actual action: 3\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.146257567768504, 1: -4.221335972421993, 2: -5.366157139585044, 3: -3.7982991468068503, 4: -4.662432993262021}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -3.1342972055812646, 3: -4.475262405720059, 4: -4.235384933750292}, Best action: 2, Actual action: 2\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.146257567768504, 1: -4.221335972421993, 2: -5.0999491562811095, 3: -3.818423398924026, 4: -4.662432993262021}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -3.7588524773087477, 2: -4.306352673686588, 3: -4.507950604547837, 4: -4.242004294012917}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.033108775365987, 4: -4.518452181605565}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.033108775365987, 4: -4.518452181605565}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.594101101510071, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.033108775365987, 4: -5.011791485261064}, Best action: 0, Actual action: 0\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.034904491850555, 4: -5.171407649378602}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8329635828047675, 1: -5.183292764049227, 2: -4.6094757910718265, 3: -4.516061141919648, 4: -4.243646677830709}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7017583492527297, 1: -4.394892694401812, 2: -4.574178773792677, 3: -3.5693749447007317, 4: -3.9175641901715617}, Best action: 3, Actual action: 3\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -3.418061140370249, 3: -3.4778764161174336, 4: -4.095970824515132}, Best action: 2, Actual action: 2\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.452494565374148, 1: -3.900121889452441, 2: -3.7538091688611233, 3: -4.404930634000523, 4: -4.485721605319233}, Best action: 2, Actual action: 2\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -5.47129140906242, 2: -4.983747103072227, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 2, Actual action: 2\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714225301, 2: -6.795320391421876, 3: -6.90446032878185, 4: -6.878115965820363}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228433, 2: -6.795320391421876, 3: -6.90446032878185, 4: -6.878115965820363}, Best action: 2, Actual action: 2\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228646, 2: -7.083741556193907, 3: -6.90446032878185, 4: -6.878115965820363}, Best action: 4, Actual action: 4\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228678, 2: -7.222806027216875, 3: -6.90446032878185, 4: -6.878115965820363}, Best action: 4, Actual action: 4\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228719, 2: -7.4061386671240745, 3: -6.90446032878185, 4: -7.159085528896531}, Best action: 3, Actual action: 3\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -5.93666411424883, 2: -6.176746356701945, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 1, Actual action: 1\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -4.7954166328558685, 4: -5.713453080324176}, Best action: 3, Actual action: 3\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.559626666149956, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.835340089943605, 4: -5.171408375869267}, Best action: 0, Actual action: 0\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.452494565374148, 1: -3.900121889452441, 2: -6.249454015974501, 3: -4.404930634000523, 4: -4.485721605319233}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.515061397071473, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.8353578362162315, 4: -5.171408375884}, Best action: 0, Actual action: 0\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -5.589185737946126, 2: -6.176746356701945, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.734474685638128, 1: -5.947433036427596, 2: -6.468389315465189, 3: -6.268525813248812, 4: -6.160603896805591}, Best action: 0, Actual action: 0\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.336043047081166, 3: -6.264102855934735, 4: -6.812934318808099}, Best action: 3, Actual action: 3\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -5.471291414402984, 2: -7.067665010953697, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 1, Actual action: 1\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.744502953978366, 2: -7.105223439320772, 3: -6.74758150606541, 4: -7.361193865304372}, Best action: 1, Actual action: 1\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346051789143913, 1: -6.391015795785025, 2: -6.685918379126221, 3: -6.315255145039334, 4: -6.28071337155649}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346051789143913, 1: -6.391015795785025, 2: -6.685918379126221, 3: -6.315255145039334, 4: -6.28071337155649}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346051789143913, 1: -6.391015795785025, 2: -6.685918379126221, 3: -6.315255145039334, 4: -6.615449168116406}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1770204487445675, 1: -6.239076618444486, 2: -6.528138887728478, 3: -6.282467574969518, 4: -6.588015558081064}, Best action: 0, Actual action: 0\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.844919587101278, 2: -7.105223439320772, 3: -6.74758150606541, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.8779797532503855, 2: -7.105223439320772, 3: -6.74758150606541, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712494158794614, 1: -5.947433036427596, 2: -6.468389315465189, 3: -6.268525813248851, 4: -6.160603896805591}, Best action: 1, Actual action: 1\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.346051789143913, 1: -6.391015795785025, 2: -6.685918379126221, 3: -6.900595013246067, 4: -7.086489435578088}, Best action: 0, Actual action: 0\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.880811841385481, 2: -7.105223439320772, 3: -6.591635825490938, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712340894743048, 1: -6.872545536637491, 2: -6.468389315465189, 3: -6.268525813248851, 4: -6.160603896805591}, Best action: 4, Actual action: 4\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712328355373038, 1: -6.835719873180248, 2: -6.468389315465189, 3: -6.268525813248851, 4: -6.160603896805591}, Best action: 4, Actual action: 4\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712339077183072, 1: -6.867207720471572, 2: -6.468389315465189, 3: -6.268525813248851, 4: -6.506149546093088}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -5.388169550204951, 4: -5.713453080324176}, Best action: 3, Actual action: 3\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.61398268668603, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.83538096192284, 4: -5.1714083759032}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6139826029938655, 1: -4.894243537138095, 2: -4.7256754286748315, 3: -4.835380961922403, 4: -5.1714083759032}, Best action: 2, Actual action: 2\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982750066614, 1: -4.894243537138095, 2: -5.200364640094096, 3: -4.835380961923171, 4: -5.1714083759032}, Best action: 3, Actual action: 3\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694036, 1: -5.216117155178917, 2: -4.616122730275589, 3: -4.5162389912677465, 4: -4.243682692323699}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7822673566940255, 1: -5.216117155178917, 2: -4.616122730275589, 3: -4.5162389912677465, 4: -4.243682692323699}, Best action: 4, Actual action: 4\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694195, 1: -5.216117155178921, 2: -4.61612273027559, 3: -4.5162389912677465, 4: -4.761751250014567}, Best action: 3, Actual action: 3\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.738546344009264, 1: -2.9523826365117447, 2: -4.727830764033407, 3: -3.085594141785243, 4: -2.7481776952786685}, Best action: 0, Actual action: 0\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -5.405670326271191, 3: -3.4778764161174336, 4: -4.095970824515132}, Best action: 3, Actual action: 3\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -2.8517290675266516, 2: -3.1591914829116585, 3: -3.0173261029909644, 4: -3.3290520846223846}, Best action: 1, Actual action: 1\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.026849828041952, 1: -2.9523826365117447, 2: -4.727830764033407, 3: -3.085594141785243, 4: -2.7481776952786685}, Best action: 4, Actual action: 4\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.140142051953303, 1: -2.9523826365117447, 2: -4.727830764033407, 3: -3.085594141785243, 4: -2.7481776952786685}, Best action: 4, Actual action: 4\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.199616059629899, 1: -2.9523826365117447, 2: -4.727830764033407, 3: -3.085594141785243, 4: -3.4008417027035884}, Best action: 1, Actual action: 1\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -3.6466077337330214, 2: -3.4526582057887354, 3: -4.2816321974461236, 4: -3.345887801944931}, Best action: 4, Actual action: 4\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -3.6466077337330214, 2: -3.4526582057887354, 3: -4.2816321974461236, 4: -3.345887801944931}, Best action: 4, Actual action: 4\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -3.6466077337330214, 2: -3.4526582057887354, 3: -4.2816321974461236, 4: -3.9447578997698876}, Best action: 2, Actual action: 2\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.987895545583616, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.033108775365987, 4: -5.429126215476942}, Best action: 0, Actual action: 0\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784696792, 1: -4.894243537138095, 2: -5.560517925805721, 3: -5.084383569211711, 4: -5.1714083759032}, Best action: 1, Actual action: 1\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.363126819640219, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.033108775365987, 4: -5.429126215476942}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -3.6466077337330214, 2: -5.570145068063061, 3: -4.2816321974461236, 4: -5.538656080903052}, Best action: 1, Actual action: 1\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -3.4252248105064393, 2: -4.834267186837453, 3: -4.423316211778065, 4: -3.360963364079684}, Best action: 4, Actual action: 4\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -3.4252248105064393, 2: -4.834267186837453, 3: -4.423316211778065, 4: -3.360963364079684}, Best action: 4, Actual action: 4\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -3.4252248105064393, 2: -4.834267186837453, 3: -4.423316211778065, 4: -3.958476661312513}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -3.2483159967657804, 4: -3.039077690272842}, Best action: 4, Actual action: 4\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -3.2483159967657804, 4: -3.039077690272842}, Best action: 4, Actual action: 4\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.2088321451316126, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -3.2483159967657804, 4: -3.665560698148286}, Best action: 0, Actual action: 0\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.026623019083283, 2: -4.834267186837453, 3: -4.423316211778065, 4: -4.513003489335887}, Best action: 1, Actual action: 1\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.8321876005278286, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.606494333668329, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -3.2483159967657804, 4: -4.8677519195420595}, Best action: 3, Actual action: 3\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -2.5372816816368986, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -1.6222188773193558, 2: -2.947191337511496, 3: -3.280387028090384, 4: -2.7799258251218935}, Best action: 1, Actual action: 1\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -1.5580202669814398, 3: -1.6509968118717286, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -1.5580202669814398, 3: -1.6509968118717286, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -1.5580202669814398, 3: -1.6509968118717286, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -1.5580202669814398, 3: -1.6509968118717286, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -2.076762208906761, 3: -2.152943552053625, 4: -3.6683785041078747}, Best action: 2, Actual action: 2\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.334775955102935, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.120580905227279}, Best action: 4, Actual action: 4\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.334775955102935, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.120580905227279}, Best action: 4, Actual action: 4\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.334775955102935, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.559728623756825}, Best action: 1, Actual action: 1\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.2408087355305115, 1: -4.870480873440701, 2: -4.366621297643016, 3: -5.694912394634602, 4: -4.33721946077166}, Best action: 0, Actual action: 0\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -4.868532671290008, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.570753386334632}, Best action: 1, Actual action: 1\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.267592337297957, 1: -4.870480873440701, 2: -4.366621297643016, 3: -5.694912394634602, 4: -4.33721946077166}, Best action: 4, Actual action: 4\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.094621787454657, 1: -4.870480873440701, 2: -4.366621297643016, 3: -5.694912394634602, 4: -4.33721946077166}, Best action: 4, Actual action: 4\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.197825962782094, 1: -4.870480873440701, 2: -4.366621297643016, 3: -5.694912394634602, 4: -4.8468697093022115}, Best action: 2, Actual action: 2\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2046403370036, 1: -4.870480873440701, 2: -4.366621297643016, 3: -5.694912394634602, 4: -4.955301452744548}, Best action: 2, Actual action: 2\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -5.734783094979414, 2: -5.648121029824797, 3: -5.140221108288437, 4: -5.735025665007315}, Best action: 3, Actual action: 3\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237929063046501, 1: -4.870480873440701, 2: -5.85573395052395, 3: -5.694912394634602, 4: -5.484998602398395}, Best action: 1, Actual action: 1\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.434808987320674, 2: -4.695674249610679, 3: -4.344550456549273, 4: -4.814566704016307}, Best action: 3, Actual action: 3\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086395205763347, 1: -3.906706507360757, 2: -4.274337884644279, 3: -3.629144175149854, 4: -4.575994430153568}, Best action: 3, Actual action: 3\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086395205763347, 1: -3.906706507360757, 2: -4.274337884644279, 3: -3.629144175149854, 4: -4.575994430153568}, Best action: 3, Actual action: 3\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086395205763347, 1: -3.906706507360757, 2: -4.274337884644279, 3: -4.202521199386367, 4: -4.575994430153568}, Best action: 1, Actual action: 1\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.774465160968218, 2: -4.460607585543953, 3: -3.0368914968366094, 4: -4.001357430419479}, Best action: 1, Actual action: 1\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -2.774465160968218, 2: -4.460607585543953, 3: -3.0368914968366094, 4: -4.001357430419479}, Best action: 1, Actual action: 1\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -3.424763296481079, 2: -4.460607585543953, 3: -3.0368914968366094, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.2023538015412902, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -2.681362362133678, 4: -3.081244103506604}, Best action: 0, Actual action: 0\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9504323846959524, 1: -3.856141471466209, 2: -2.530500091531223, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 0, Actual action: 0\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -2.010153108210322, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 1, Actual action: 1\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.723267256119956, 1: -3.856141471466209, 2: -2.530500091531223, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 2, Actual action: 2\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -2.8852170873120047, 2: -3.623333536736053, 3: -1.6020396716982144, 4: -3.5540930432190474}, Best action: 3, Actual action: 3\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -2.448385838736233, 2: -3.362046412878114, 3: -1.7697468018446614, 4: -2.667381240244387}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -2.448385838736233, 2: -3.362046412878114, 3: -1.7697468018446614, 4: -2.667381240244387}, Best action: 3, Actual action: 3\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -2.448385838736233, 2: -3.362046412878114, 3: -2.510469589678642, 4: -2.667381240244387}, Best action: 1, Actual action: 1\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3269662474361152, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -2.681362362133678, 4: -3.081244103506604}, Best action: 3, Actual action: 3\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -4.12627784761493, 2: -4.460607585543953, 3: -3.4951314815217605, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -4.126928505434056, 2: -4.460607585543953, 3: -3.496128658256053, 4: -4.001357430419479}, Best action: 3, Actual action: 3\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.551872201323938, 1: -4.939636622161343, 2: -4.393971784795843, 3: -3.568337285302715, 4: -4.961905315007897}, Best action: 0, Actual action: 0\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -4.434808987320674, 2: -4.695674249610679, 3: -4.591223892502319, 4: -4.814566704016307}, Best action: 1, Actual action: 1\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2606468787544935, 1: -5.787684045431547, 2: -5.752536482581051, 3: -5.083850274354616, 4: -5.4782041177694065}, Best action: 3, Actual action: 3\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2606468787544935, 1: -5.787684045431547, 2: -5.752536482581051, 3: -5.083850274354616, 4: -5.4782041177694065}, Best action: 3, Actual action: 3\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.2606468787544935, 1: -5.787684045431547, 2: -5.752536482581051, 3: -5.526303749662701, 4: -5.4782041177694065}, Best action: 0, Actual action: 0\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.207289270457922, 2: -5.48253365672065, 3: -5.434552374379778, 4: -5.010000236080775}, Best action: 4, Actual action: 4\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.207289270457922, 2: -5.48253365672065, 3: -5.434552374379778, 4: -5.010000236080775}, Best action: 4, Actual action: 4\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.207289270457922, 2: -5.48253365672065, 3: -5.434552374379778, 4: -5.459100214833505}, Best action: 1, Actual action: 1\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -4.768723970375186, 4: -5.0862420413957175}, Best action: 3, Actual action: 3\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -4.768723970375186, 4: -5.0862420413957175}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237969075319339, 1: -5.496595934555097, 2: -5.31111679989344, 3: -4.189801232194782, 4: -4.813638996070624}, Best action: 3, Actual action: 3\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.435936103704742, 1: -4.939636622161343, 2: -4.393971784795843, 3: -3.568337285302715, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.435942754504949, 1: -4.939636622161343, 2: -4.393971784795843, 3: -3.568337285302715, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436031450379915, 1: -4.939636622161343, 2: -4.393971784795843, 3: -4.147186929625471, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.544192454820367, 1: -4.1271536800016175, 2: -4.460607585543953, 3: -5.461345990076347, 4: -4.001357430419479}, Best action: 0, Actual action: 0\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6378686444807986, 1: -2.8852170873120047, 2: -3.623333536736053, 3: -3.1052071980988645, 4: -3.5540930432190474}, Best action: 0, Actual action: 0\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.029951308092239, 1: -3.250597806623883, 2: -5.030321684891242, 3: -3.849017539147606, 4: -3.8429276062657522}, Best action: 0, Actual action: 0\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823597216899, 1: -3.712944978627115, 2: -4.352644839696327, 3: -1.8396678542728142, 4: -3.0694077438457565}, Best action: 3, Actual action: 3\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823597216899, 1: -3.712944978627115, 2: -4.352644839696327, 3: -1.8396678542728142, 4: -3.0694077438457565}, Best action: 3, Actual action: 3\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -2.152943552053625, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -2.152943552053625, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -2.8591786323687987, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -0.16260682833984386, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -1.5583577870179475}, Best action: 1, Actual action: 1\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027293877088, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294303076, 2: -2.5707253976680087, 3: -2.0297907212833124, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.76 -2.47 -2.46 -3.58 -2.92 -4.47 -3.80 -4.40 -5.66 -6.85 \n",
      "-1.61 -3.12 -3.06 -3.02 -3.89 -3.70 -4.40 -5.84 -6.17 -6.63 \n",
      "0.00 0.00 -1.65 -3.09 -4.24 -4.15 -5.08 -5.53 -5.96 -6.71 \n",
      "0.00 0.00 -1.64 -2.73 -3.31 -4.03 -4.67 -5.75 -6.24 -6.39 \n",
      "0.00 0.00 -2.09 -2.23 -2.11 -4.42 -5.05 -5.59 -5.62 -5.99 \n",
      "0.00 0.00 0.00 -1.77 -2.53 -3.28 -3.93 -4.50 -5.21 -5.71 \n",
      "0.00 0.00 -1.56 -1.61 -1.51 -2.76 -2.55 -5.26 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 0.84 -0.26 -3.06 -5.02 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -2.89 -3.93 -4.48 -5.47 -5.43 \n",
      "0.00 0.00 -2.37 -1.64 -3.07 -3.27 -3.63 -4.51 -4.83 -5.48 \n",
      "\n",
      "Action values: {0: -2.763603493900178, 1: -3.0515136422431066, 2: -2.8968313156748327, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.763603493900178, 1: -3.0515136422431066, 2: -2.8968313156748327, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.414879179449162, 1: -3.0515136422431066, 2: -2.8968313156748327, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -2.504371996952083, 2: -2.466307123921491, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.455088947452513, 1: -2.975144281066258, 2: -3.404050150065713, 3: -2.778878368012239, 4: -3.4623856966643474}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -2.9168630892777445, 2: -3.244370456629783, 3: -4.183844888469229, 4: -5.091985832961612}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -3.8896246753417745, 2: -5.405670326271413, 3: -4.021768644653803, 4: -4.095970824515132}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -5.303473020998916, 2: -5.56052925120849, 3: -5.0844009261508205, 4: -5.1714083759032}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.146257567768504, 1: -4.221335972421993, 2: -5.23498050721888, 3: -5.174744057257799, 4: -4.662432993262021}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7017583492527297, 1: -4.394892694401812, 2: -4.574178773792677, 3: -4.919991151825498, 4: -3.9175641901715617}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.968503698338021, 1: -4.470591737762952, 2: -5.207809614991362, 3: -5.018366314725132, 4: -5.002672879805659}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.891355142513264, 1: -4.394892694401812, 2: -4.574178773792677, 3: -4.919991151825498, 4: -3.9175641901715617}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.913717636036803, 1: -4.394892694401812, 2: -4.574178773792677, 3: -4.919991151825498, 4: -3.9175641901715617}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.024570028670926, 1: -4.394892694401812, 2: -4.574178773792677, 3: -4.919991151825498, 4: -4.464983413056121}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -5.53052305130153, 4: -5.713453080324176}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -6.468389315465189, 3: -5.955329008825412, 4: -6.478647041216095}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.881676455298851, 2: -7.105223439320772, 3: -6.712413883983727, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -6.468389315465189, 3: -6.93258814690936, 4: -6.478647041216095}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -6.468389315465189, 3: -6.976788429383013, 4: -6.478647041216095}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -6.786234277073322, 3: -7.041152034108659, 4: -6.478647041216095}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -6.844369495400941, 3: -7.044805531881145, 4: -6.478647041216095}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.712338812345598, 1: -6.8664299448918396, 2: -7.051160947905526, 3: -7.057801305060097, 4: -6.795568807506647}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.634352458746231, 4: -6.8153185404544105}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.172616694033318, 1: -6.564711870710831, 2: -6.176746356701945, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.854569551108148, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.657707592184124, 1: -6.356570825035127, 2: -6.352692946591304, 3: -5.795541409812726, 4: -6.131865599436364}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.657707592184124, 1: -6.356570825035127, 2: -6.352692946591304, 3: -5.795541409812726, 4: -6.131865599436364}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0485139088875535, 1: -6.356570825035127, 2: -6.352692946591304, 3: -5.795541409812726, 4: -6.131865599436364}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375258588495, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -4.3955898615736615, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375258588495, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -4.3955898615736615, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -3.8042041823241353, 2: -6.09963994872803, 3: -4.391669870532966, 4: -4.2060864066086365}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1461803373816615, 1: -6.379705679845099, 2: -4.574178773792677, 3: -4.919991151825498, 4: -6.4000720015945545}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.452494565374148, 1: -5.556341977230056, 2: -6.249984247654176, 3: -4.404930634000523, 4: -4.485721605319233}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.146180407262607, 1: -6.379707383998614, 2: -4.925411690919692, 3: -4.919991151825498, 4: -6.400073113554724}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -5.4298541585098805, 2: -5.405670326271413, 3: -4.021768644653803, 4: -4.095970824515132}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -5.4298541583927475, 2: -5.405670326271413, 3: -4.021768644653803, 4: -4.095970824515132}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -3.1591914829116585, 3: -3.0173261029909644, 4: -3.3290520846223846}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -3.1591914829116585, 3: -3.0173261029909644, 4: -3.3290520846223846}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -3.1591914829116585, 3: -3.6457667537217775, 4: -3.3290520846223846}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.146180416431941, 1: -6.379707607606816, 2: -5.315948958802081, 3: -4.802447447194424, 4: -6.400073259459076}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -5.105901580518649, 3: -5.173739875483163, 4: -3.3290520846223846}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -4.764801327298453, 3: -4.951171960256985, 4: -3.3290520846223846}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.636203659715008, 1: -3.8830189749610344, 2: -4.88637935305621, 3: -5.030501622063921, 4: -3.92943739700637}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8107112848519527, 1: -3.9253201391366344, 2: -3.5756132627886967, 3: -4.191419080948453, 4: -4.020093984889381}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.035385563363734, 2: -3.244370456629783, 3: -4.183844888469229, 4: -5.091985832961612}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.968503698338021, 1: -5.03687012459642, 2: -5.207809614991362, 3: -5.018366314725132, 4: -5.002672879805659}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.322327130560199, 2: -6.09963994872803, 3: -4.391669870532966, 4: -4.2060864066086365}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.322326095554255, 2: -6.09963994872803, 3: -4.391669870532966, 4: -4.2060864066086365}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.322327569952291, 2: -6.09963994872803, 3: -4.391669870532966, 4: -4.727538630013859}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.079433594913292, 1: -5.036870124599746, 2: -5.207809614991362, 3: -5.018366314725132, 4: -5.002672879805659}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.170527808255763, 1: -5.036870124599813, 2: -5.207809614991362, 3: -5.018366314725132, 4: -5.002672879805659}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1889707563257845, 1: -5.036870124599826, 2: -5.207809614991362, 3: -5.018366314725132, 4: -5.45243232062315}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.322328522509144, 2: -6.09963994872803, 3: -5.605405512402973, 4: -5.813079487106919}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.452494565374148, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.2877381452894765, 4: -4.485721605319233}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375258588495, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -5.2691179973319295, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375258588495, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -5.26911800533402, 4: -5.609871858760523}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.647306996861665, 2: -6.09963994872803, 3: -5.682023112938662, 4: -5.863072471456456}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875490236690119, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.287738186655349, 4: -4.485721605319233}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822842142589488, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.2877381839084325, 4: -4.485721605319233}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843192931647457, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.287738184970236, 4: -4.982006660840502}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.851526579766696, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.287738185405044, 4: -5.6368547916008165}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.146180416589862, 1: -6.379707611457967, 2: -5.322675089073155, 3: -4.509688110694631, 4: -6.400073261971953}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.067677839651196, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.158197546071083, 4: -4.095970824515132}, Best action: 0, Actual action: 0\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.197096169561709, 1: -5.036870124599832, 2: -5.207809614991362, 3: -5.868693094391637, 4: -6.090917602587001}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.386632584890983, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.158197547089665, 4: -4.095970824515132}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.244681549963817, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.15819754700049, 4: -4.095970824515132}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.352282481687029, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.158197547068085, 4: -4.62733345030877}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.726069711218684, 1: -3.8830189749610344, 2: -4.959212925686836, 3: -5.078025528205405, 4: -5.088380390854481}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -3.085594141785243, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3737835659771265, 1: -4.574563009438641, 2: -3.888280578259649, 3: -3.3096653903282585, 4: -4.277800856851135}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1891400385206032, 1: -3.109344215251135, 2: -3.208155054245165, 3: -3.880900679148276, 4: -2.7267977287779703}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1891400385206032, 1: -3.109344215251135, 2: -3.208155054245165, 3: -3.880900679148276, 4: -2.7267977287779703}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1891400385206032, 1: -3.109344215251135, 2: -3.208155054245165, 3: -3.880900679148276, 4: -3.381385933187953}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3107626149575893, 1: -2.2262361018801724, 2: -3.6576870989577466, 3: -3.2328333034257275, 4: -3.239519404355012}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -2.5343830797187437, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -1.7703469238224103, 2: -2.947191337511496, 3: -3.280387028090384, 4: -2.7799258251218935}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6129219708069757, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -1.6509968118717286, 4: -4.57699996860916}, Best action: 0, Actual action: 0\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -2.863338870479093, 4: -3.3820932597301887}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -2.8945627527944926, 2: -3.5530218692565554, 3: -3.221292999529855, 4: -3.3820932597301887}, Best action: 1, Actual action: 1\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -1.5084972081032915, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.43818833361511, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -1.6509968118717286, 4: -4.57699996860916}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -1.5583577870179475}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -1.5583577870179475}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.796947181034058, 4: -2.318105586186332}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.0796947181034058, 4: -2.240485028275419}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: -1.7745527216637587, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -2.365850079035598, 3: -2.6230828486771616, 4: -3.0854423103886233}, Best action: 2, Actual action: 2\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.270265440287611, 1: -4.127153678923396, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -4.001357430419479}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086395205763347, 1: -3.928714042062891, 2: -4.274337884644279, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 1, Actual action: 1\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -4.939636622161343, 2: -4.393971784795843, 3: -3.6346666944520316, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.547991741191997, 1: -4.127153678923396, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -4.001357430419479}, Best action: 4, Actual action: 4\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724146388652669, 1: -4.127153678923396, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -4.001357430419479}, Best action: 4, Actual action: 4\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.773342756026442, 1: -4.127153678923396, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -4.541235261681726}, Best action: 1, Actual action: 1\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.779734922814585, 1: -4.127153678923396, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -4.767265241082602}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -4.939636622161343, 2: -4.393971784795843, 3: -4.827242148787638, 4: -4.961905315007897}, Best action: 2, Actual action: 2\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237969075319339, 1: -5.496595934555097, 2: -5.31111679989344, 3: -4.5061025700253605, 4: -4.813638996070624}, Best action: 3, Actual action: 3\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -4.939636622161343, 2: -4.989340260200127, 3: -4.8492581623354525, 4: -4.961905315007897}, Best action: 3, Actual action: 3\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.795245325155272, 1: -5.661004234059252, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -5.315720254501215}, Best action: 2, Actual action: 2\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.79535352087858, 1: -5.6798973249629325, 2: -4.460607585543953, 3: -5.4613303512345315, 4: -5.319546105409211}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -4.939636622161343, 2: -5.411308190138203, 3: -5.2243773518823, 4: -4.961905315007897}, Best action: 1, Actual action: 1\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -4.939636622161343, 2: -5.429263516920522, 3: -5.313376958567304, 4: -4.961905315007897}, Best action: 1, Actual action: 1\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.395069326166822, 2: -5.437667531213903, 3: -5.355033341419806, 4: -4.961905315007897}, Best action: 4, Actual action: 4\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.487261647995894, 2: -5.438195492202105, 3: -5.357650298541483, 4: -4.961905315007897}, Best action: 4, Actual action: 4\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.783123758372056, 2: -5.439889816079265, 3: -5.3660485950744485, 4: -5.415333836657187}, Best action: 3, Actual action: 3\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.795632421278475, 1: -5.728598793442409, 2: -5.991972766970941, 3: -5.4613303512345315, 4: -5.329408152776304}, Best action: 0, Actual action: 0\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1693632950944166, 1: -2.8852170873120047, 2: -3.623333536736053, 3: -3.1052071838067112, 4: -3.5540930432190474}, Best action: 1, Actual action: 1\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7165876964015934, 1: -5.72833546200204, 2: -5.9777022355616936, 3: -5.4613303512345315, 4: -5.329354828159629}, Best action: 0, Actual action: 4\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895626111073244, 1: -5.7285974208407024, 2: -5.991898382553512, 3: -5.4613303512345315, 4: -5.329407874824458}, Best action: 0, Actual action: 0\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1693632950944166, 1: -5.536344647722793, 2: -3.623333536736053, 3: -3.1052071838067112, 4: -3.5540930432190474}, Best action: 3, Actual action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1693632950944166, 1: -5.333152272683937, 2: -3.623333536736053, 3: -3.1052071838067112, 4: -3.5540930432190474}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1693632950944166, 1: -5.389698192267742, 2: -3.623333536736053, 3: -3.7257385372641076, 4: -3.5540930432190474}, Best action: 0, Actual action: 0\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.055097688295845, 1: -3.250597806623883, 2: -5.030321684891242, 3: -3.849017539147606, 4: -3.8429276062657522}, Best action: 0, Actual action: 0\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.764823597216899, 1: -3.712944978627115, 2: -4.352644839696327, 3: -3.5155461832122135, 4: -3.0694077438457565}, Best action: 0, Actual action: 0\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -3.278725390939294, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -3.026047849616744, 2: -3.5530218692565554, 3: -3.662762636901368, 4: -3.3820932597301887}, Best action: 1, Actual action: 1\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -2.874516843155828, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -2.874516843155843, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -2.731796155714888, 4: -4.57699996860916}, Best action: 3, Actual action: 3\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.9181588768966218, 4: -2.7659239973232914}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -1.9181588768966198, 4: -2.7659239973232914}, Best action: 3, Actual action: 3\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.38252392621346, 2: -3.1089054697145246, 3: -2.6455245779760532, 4: -2.7659239973233056}, Best action: 1, Actual action: 1\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: 0.8378684146921831, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.25532603406197785, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.25532603406197785, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.1323466909963997, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -1.5792995232980644, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.95 -2.50 -2.78 -3.81 -4.18 -4.99 -5.42 -5.59 -5.32 -6.33 \n",
      "-1.61 -3.12 -3.06 -3.47 -4.28 -5.15 -5.41 -5.84 -6.18 -6.82 \n",
      "0.00 0.00 -1.65 -2.39 -4.24 -4.22 -5.13 -5.55 -6.87 -6.88 \n",
      "0.00 0.00 -1.64 -3.19 -3.37 -4.03 -4.67 -5.75 -6.24 -6.39 \n",
      "0.00 0.00 -2.09 -3.23 -2.11 -4.42 -5.05 -5.59 -5.62 -5.99 \n",
      "0.00 0.00 0.00 -2.78 -3.06 -3.66 -3.93 -4.50 -5.21 -5.71 \n",
      "0.00 0.00 -1.53 -3.07 -3.03 -3.07 -2.55 -5.26 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 -0.10 -1.42 -3.25 -5.02 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -4.09 -4.48 -5.47 -5.43 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -4.81 -4.83 -5.48 \n",
      "\n",
      "Action values: {0: -4.3169101867797215, 1: -3.0515136422431066, 2: -3.894716306098784, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 4, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.6144249238644377, 2: -2.9575200042455623, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: -3.825711640120336, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.3882660213028917, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -1.6509442271096433, 3: -1.8951333114341244, 4: -2.549095480023762}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.4760914260891003, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -3.0707284778431356, 3: -1.8951333114341244, 4: -2.549095480023762}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.127949405595652, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.6961733152146288, 2: -2.292711278075485, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.696854327792949, 2: -2.300184667137985, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.6971607834531932, 2: -2.30354769221611, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.6971745739579043, 2: -2.3036990283446257, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.6972366312291036, 2: -2.304380040922946, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.69726204368166, 2: -2.3046589155737682, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.587610941920972, 1: -1.6972719869390338, 2: -2.3047680322527686, 3: -1.952322246815625, 4: -3.2643291262500003}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -1.8252127604348303, 2: -2.9575200042455623, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8738582396550623, 3: -1.741683321589446, 4: -2.549095480023762}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.873960606712304, 3: -1.742188837921504, 4: -2.549095480023762}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.1216881035375175, 3: -1.4509523823895034, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.121679702261859, 3: -1.4504970980983936, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.1216822469978363, 3: -1.4506350031455033, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.121683289067219, 3: -1.4506914752622948, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.1216834014418597, 3: -1.4506975651004073, 4: -2.4118780694254633}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9229958686270763, 1: -1.6972710381098224, 2: -2.3047576198608763, 3: -1.943343444758846, 4: -3.001027569212312}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.937140935432997, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.5257607202048458, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.10032688866558459, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.61 -2.50 -2.78 -3.81 -4.18 -4.99 -5.42 -5.59 -5.32 -6.33 \n",
      "-2.68 -3.12 -3.06 -3.47 -4.28 -5.15 -5.41 -5.84 -6.18 -6.82 \n",
      "-1.82 -2.34 -1.46 -2.59 -4.24 -4.22 -5.13 -5.55 -6.87 -6.88 \n",
      "0.00 0.00 -1.64 -3.19 -3.37 -4.03 -4.67 -5.75 -6.24 -6.39 \n",
      "0.00 0.00 -2.09 -3.23 -2.11 -4.42 -5.05 -5.59 -5.62 -5.99 \n",
      "0.00 0.00 0.00 -2.78 -3.06 -3.66 -3.93 -4.50 -5.21 -5.71 \n",
      "0.00 0.00 -1.09 -3.07 -3.03 -3.07 -2.55 -5.26 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 -0.01 -1.42 -3.25 -5.02 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -4.09 -4.48 -5.47 -5.43 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -4.81 -4.83 -5.48 \n",
      "\n",
      "Action values: {0: -4.3169101867797215, 1: -2.6076908439255706, 2: -3.894716306098784, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3276514420002328, 1: -3.41024115297373, 2: -3.264949458362511, 3: -3.8033677362958076, 4: -3.1244189976992907}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3276514420002328, 1: -3.41024115297373, 2: -3.264949458362511, 3: -3.8033677362958076, 4: -3.1244189976992907}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3276514420002328, 1: -3.41024115297373, 2: -3.264949458362511, 3: -3.8033677362958076, 4: -3.7432212879063544}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.0787389880140092, 2: -3.0563655520293, 3: -3.385633982465797, 4: -3.2378682870418993}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.726069711783203, 1: -3.4738354981250934, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.589264874369777, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.589264874369777, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8739898008807843, 3: -1.4550442422268066, 4: -2.549095480023762}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -1.8185916611653363, 2: -2.3047576371440073, 3: -1.9433583483284065, 4: -3.001464613379879}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: -3.825711640120336, 3: -1.7717134215216614, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: -3.825711640120336, 3: -1.7717134215216614, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: -3.825711640120336, 3: -1.7717134215216614, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5450210187299298, 1: -1.60889021124552, 2: -3.825711640120336, 3: -1.7717134215216614, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8739898008807843, 3: -2.4550966792268207, 4: -2.549095480023762}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3418440267701395, 1: -2.621570238054151, 2: -3.1216836380977924, 3: -2.700464235155952, 4: -3.094898375268303}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -2.6838132253470066, 2: -2.9575200042455623, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -1.757387448006618, 2: -2.3047576371440073, 3: -1.9433583483284065, 4: -3.001464613379879}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6359310717044317, 1: -3.493579017492904, 2: -3.1295293055132136, 3: -2.0386262147212793, 4: -3.6524193856796687}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8739898008807843, 3: -3.5286277009851457, 4: -2.549095480023762}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8739898008807843, 3: -3.5903348146025023, 4: -2.549095480023762}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -2.8739898008807843, 3: -3.6028116793020133, 4: -3.2196768868216235}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694216, 1: -5.216117155178922, 2: -4.61612273027559, 3: -4.2435592984039445, 4: -4.979065064395894}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.697440236410895, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -2.6974335465744232, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.2151171751791523, 2: -4.427346735727129, 3: -3.6114291584703464, 4: -4.7120649706411255}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6425694893190874, 1: -3.493579017492904, 2: -3.1295293055132136, 3: -2.0386262147212793, 4: -3.6524193856796687}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546907967429306, 1: -1.60889021124552, 2: -3.825711640120336, 3: -1.7717134215216614, 4: -4.026793703822053}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.6957227331671634, 2: -4.051201967723744, 3: -2.090160388276966, 4: -2.628770293591887}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.6957227331671634, 2: -4.051201967723744, 3: -2.090160388276966, 4: -2.628770293591887}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.6957227331671634, 2: -4.051201967723744, 3: -2.802045953332039, 4: -2.628770293591887}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.6957227331671634, 2: -4.051201967723744, 3: -3.5378666940573997, 4: -2.628770293591887}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.6957227331671634, 2: -4.051201967723744, 3: -3.970742158566216, 4: -3.2921809671686173}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: -2.294393513868313, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0597460483210748, 1: -3.8396698348200093, 2: -3.5530218692565554, 3: -3.662762636901379, 4: -3.3820932597301887}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.1139620603108793, 1: -3.2164851411032553, 2: -3.3310519635354363, 3: -3.5907967498188764, 4: -2.9898254268029403}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0335006498673165, 1: -4.345131656282124, 2: -5.537184256308888, 3: -4.2816321974461236, 4: -5.5171491512334585}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.96303994997327, 1: -4.221335972421993, 2: -5.23498050721888, 3: -5.174744057257799, 4: -4.662432993262021}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.9767858152997775, 2: -5.750724764699598, 3: -6.138650502089475, 4: -6.047470664736775}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.391015795785025, 2: -6.685918379126221, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.017168140265884, 1: -5.990939315911989, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.047499746615025}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -5.912161625620553, 3: -5.977045831125718, 4: -5.708367155042535}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -5.912161625620553, 3: -5.977045831125718, 4: -5.708367155042535}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -5.912161625620553, 3: -5.977045831125718, 4: -6.094614111088707}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -5.912161625620553, 3: -5.977045831125718, 4: -6.389976525409283}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -6.280067079314703, 3: -5.977045831125718, 4: -6.630034833944716}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.83676098519225, 2: -6.052863663853859, 3: -5.211985965535397, 4: -5.8412297728931515}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.624902463522731, 4: -4.497761515782182}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.624902463522731, 4: -4.497761515782182}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.624902463522731, 4: -4.992962979361786}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.624902463522731, 4: -5.214094234702103}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -3.6615959316669433, 2: -4.59322168117289, 3: -4.045101190624952, 4: -4.880416877476394}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0280236251963504, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -3.718858729575738, 2: -4.59322168117289, 3: -4.045101190624952, 4: -4.880416877476394}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -2.552082294844605, 2: -4.85347816989545, 3: -3.566174697703242, 4: -3.333318206420599}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -3.250597806623883, 2: -5.030321684891242, 3: -3.849017539147606, 4: -3.8429276062657522}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952445451648, 1: -5.512052568029475, 2: -5.469651842600124, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.43866118009326, 2: -5.48253365672065, 3: -5.434552374379778, 4: -5.906905853665669}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.43866118009326, 2: -5.48253365672065, 3: -5.434552374379778, 4: -5.906905853665669}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952445451648, 1: -5.512052568029475, 2: -6.0338532363452515, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -4.834248832169591, 4: -5.0862420413957175}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237969075319339, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -4.813638996070624}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237969075319339, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -4.813638996070624}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.237969075319339, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -5.280411486424268}, Best action: 0, Actual action: 0\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.481307238309825, 1: -5.742945223848236, 2: -4.695674249610679, 3: -4.591224971314155, 4: -4.814566704016307}, Best action: 0, Actual action: 0\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926178560325308, 2: -5.030321684891242, 3: -3.849017539147606, 4: -3.8429276062657522}, Best action: 4, Actual action: 4\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.9261631201407186, 2: -5.030321684891242, 3: -3.849017539147606, 4: -3.8429276062657522}, Best action: 4, Actual action: 4\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926351807109278, 2: -5.030321684891242, 3: -3.849017539147606, 4: -4.397064121701834}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.4213864088234116, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.4213864088234116, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.010032688866558462, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.010032688866558462, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.9091297468685682, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.95 -2.50 -2.78 -3.81 -4.18 -4.99 -5.42 -5.59 -5.32 -6.33 \n",
      "-2.96 -3.33 -3.08 -3.57 -4.28 -5.15 -5.41 -5.84 -6.18 -6.82 \n",
      "-1.94 -2.62 -3.35 -4.16 -3.92 -4.66 -5.13 -5.55 -6.87 -6.88 \n",
      "0.00 -1.77 -3.13 -3.19 -3.37 -4.28 -4.67 -5.98 -6.24 -6.56 \n",
      "0.00 0.00 -2.37 -3.23 -2.99 -4.42 -5.05 -5.59 -5.62 -6.02 \n",
      "0.00 0.00 0.00 -2.78 -3.38 -4.05 -3.93 -4.46 -5.34 -5.78 \n",
      "0.00 0.00 -1.09 -3.07 -3.28 -3.07 -3.33 -5.26 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 1.02 -1.23 -2.65 -5.02 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -4.09 -4.59 -5.63 -5.44 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.48 \n",
      "\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -3.122337509309411, 4: -2.946022846613221}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -3.122337509309411, 4: -3.580880790418031}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -3.122337509309411, 4: -3.880016763606404}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -3.741327133471564, 4: -4.283907493372209}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -3.894716306098784, 3: -4.558083942553525, 4: -4.449300747211306}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -2.975144281066258, 2: -3.404050150065713, 3: -2.778878368012239, 4: -3.4623856966643474}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -2.504371996952083, 2: -4.038139133154586, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3276514420002328, 1: -3.41024115297373, 2: -4.154358192175799, 3: -3.8033677362958076, 4: -4.578339844848501}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -4.0044071938734405, 3: -4.561067629033098, 4: -4.4495393179974805}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8107112848519527, 1: -3.9253201391366344, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.020093984889381}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -2.975144281066258, 2: -3.404050150065713, 3: -4.068985720259258, 4: -3.4623856966643474}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.726069711783203, 1: -3.5667844299822913, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -4.157848560495833, 4: -4.676292719753342}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694216, 1: -5.216117155178922, 2: -4.61612273027559, 3: -3.91720474829419, 4: -4.979065064395894}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694216, 1: -5.216117155178922, 2: -4.61612273027559, 3: -3.91720474829419, 4: -4.979065064395894}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.235686034297412, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -4.7350739098619625, 4: -4.676292719753342}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.726069711783203, 1: -4.9127833384919235, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.70921208367714, 2: -3.404050150065713, 3: -4.096072694863244, 4: -3.4623856966643474}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.035385563363818, 2: -5.351792397077804, 3: -4.183844888469229, 4: -5.091985832961612}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.035385563363818, 2: -5.351792397077804, 3: -4.183844888469229, 4: -5.091985832961612}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.035385563363818, 2: -5.351792397077804, 3: -4.707298848506999, 4: -5.091985832961612}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.035385563363818, 2: -5.351792397077804, 3: -5.397996348776836, 4: -5.091985832961612}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.276932559852724, 4: -4.854940912523406}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -4.276932559852724, 4: -4.854940912523406}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.836790419367156, 1: -4.952388132405557, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471689287938629, 1: -3.9253201391366344, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.020093984889381}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.562914133879415, 1: -4.952414410716187, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471690564247367, 1: -4.988492462355991, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.020093984889381}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471690078641231, 1: -4.816747524544014, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.020093984889381}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471690386791191, 1: -4.925731311669405, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.558285526249336}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471690436413514, 1: -4.943281301586538, 2: -4.833841269350606, 3: -4.191419080948453, 4: -4.837544625067911}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.471690497026102, 1: -4.964718232504605, 2: -4.833841269350606, 3: -4.714191363663092, 4: -5.178653539539213}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.219645547765866, 2: -5.351792397077804, 3: -5.734086071161015, 4: -5.091985832961612}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.080639915203883, 1: -5.21998292033168, 2: -5.351792397077804, 3: -5.734336949835268, 4: -5.091985832961612}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.661721493849692, 1: -4.979753787197902, 2: -4.833841269350606, 3: -5.895667320527707, 4: -5.417902420804297}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.29771496238745, 1: -5.220040029525286, 2: -5.351792397077804, 3: -5.734379417659364, 4: -5.091985832961612}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.737533489327342, 1: -5.220060944420003, 2: -5.351792397077804, 3: -5.734394970497947, 4: -5.091985832961612}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.86723389870904, 1: -5.220067112123819, 2: -5.351792397077804, 3: -5.734399556956697, 4: -5.533707107995067}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -5.654346044629425, 4: -4.854940912523406}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -5.654348766544757, 4: -4.854940912523406}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -5.654352985341334, 4: -5.317996230396299}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.366586433407243, 1: -5.429854158473344, 2: -5.405670326271413, 3: -5.654354712938533, 4: -5.928997722329582}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.715959399151432, 1: -4.980204166040944, 2: -5.774894966577963, 3: -5.931057552906173, 4: -5.425068942860936}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.470624017833889, 1: -5.429854158473344, 2: -5.405670326271413, 3: -5.654354634812927, 4: -5.859020914290607}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.146180416589862, 1: -6.379707611457967, 2: -5.322675089083521, 3: -5.230296744352303, 4: -6.400073261971953}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.197097822251424, 1: -4.992323121302627, 2: -5.207809614991362, 3: -5.868892123336986, 4: -6.091047468973843}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.852880668317296, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.405895070579691, 4: -5.9063266710972515}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.811957659012848, 1: -6.379707611457967, 2: -5.322675089083521, 3: -5.230296744352303, 4: -6.400073261971953}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.935850867357407, 1: -5.429854158473344, 2: -5.93328920025093, 3: -5.654355021053614, 4: -6.204975230267533}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.96303994997327, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.174744057257799, 4: -4.662432993262021}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.96303994997327, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.174744057257799, 4: -4.662432993262021}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.96303994997327, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.174744057257799, 4: -5.142814023868439}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941000227529913, 1: -5.494762376106803, 2: -5.958718139374419, 3: -5.654355025328716, 4: -6.208804423225814}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694216, 1: -5.216117155178922, 2: -4.61612273027559, 3: -5.548945328761795, 4: -4.979065064395894}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.676634123963862, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.174744057257799, 4: -6.031152342492594}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -5.303473020998916, 2: -5.56052925120849, 3: -5.134460794499714, 4: -5.1714083759032}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.902982922685008, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.576387649270548, 4: -6.178844933658142}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.924278267759556, 1: -6.420528752381336, 2: -5.23498050721888, 3: -5.8100814223794455, 4: -6.192740146319284}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -5.547781991696018, 2: -6.0736080359910245, 3: -6.776066763442742, 4: -5.713453080324176}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -5.9767858152997775, 2: -6.729187199660623, 3: -6.138650502089475, 4: -6.047470664736775}, Best action: 1, Actual action: 1\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -5.804885281665515, 2: -5.619468644999817, 3: -6.3124040971027515, 4: -5.927595140848987}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.017168140265884, 1: -6.371462502320918, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.047499746615025}, Best action: 0, Actual action: 0\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.562997859351231, 2: -6.685918379126221, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.817745080101086, 1: -6.371462502320918, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.047499746615025}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.769044604705014, 1: -6.371462502320918, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.047499746615025}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.841078921822955, 1: -6.371462502320918, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.403224769419673}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.857035452070195, 1: -6.371462502320918, 2: -6.21976326981688, 3: -6.241939314982917, 4: -6.657128405726926}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.870986651987732, 1: -6.371462502320918, 2: -6.5599845755333615, 3: -6.241939314982917, 4: -6.8791228077069295}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -5.804885281665515, 2: -6.720503057380564, 3: -6.3124040971027515, 4: -5.927595140848987}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.83676098519225, 2: -6.052863663853859, 3: -5.343979415624149, 4: -5.8412297728931515}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.464700896763251, 4: -5.399344867660639}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -4.500658439941332, 2: -5.271645682276203, 3: -3.928038944811147, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.538665005074813, 2: -4.59322168117289, 3: -4.045101190624952, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -3.2608866946594257, 2: -2.947191337511496, 3: -3.280387028090384, 4: -2.7799258251218935}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -3.2608866946594257, 2: -2.947191337511496, 3: -3.280387028090384, 4: -2.7799258251218935}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -3.2608866946594257, 2: -2.947191337511496, 3: -3.280387028090384, 4: -3.429732500860923}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.8396698348200093, 2: -3.5530218692565554, 3: -3.662762636901379, 4: -3.3820932597301887}, Best action: 4, Actual action: 4\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.8396698348200093, 2: -3.5530218692565554, 3: -3.662762636901379, 4: -3.3820932597301887}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.8396698348200093, 2: -3.5530218692565554, 3: -3.662762636901379, 4: -3.9777048663544723}, Best action: 2, Actual action: 2\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.538665005074813, 2: -4.59322168117289, 3: -4.007277555272739, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.538665005074813, 2: -4.59322168117289, 3: -4.015150979385493, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.8396698348200093, 2: -4.7435833920314625, 3: -3.662762636901379, 4: -5.041665594814337}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.035192533221686, 1: -3.2608866946594257, 2: -4.346520955084626, 3: -3.280387028090384, 4: -4.633470388611138}, Best action: 0, Actual action: 0\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -3.2164851411032553, 2: -3.3310519635354363, 3: -3.5907967498188764, 4: -2.9898254268029403}, Best action: 4, Actual action: 4\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -3.2164851411032553, 2: -3.3310519635354363, 3: -3.5907967498188764, 4: -2.9898254268029403}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -3.2164851411032553, 2: -3.3310519635354363, 3: -3.5907967498188764, 4: -3.6207411383906756}, Best action: 1, Actual action: 1\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.538665005074813, 2: -4.59322168117289, 3: -4.529127760342484, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.8396698348200093, 2: -4.746117093071384, 3: -4.209194787764733, 4: -5.043318834742886}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -3.5155461832122135, 4: -3.0694077438457565}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -3.5155461832122135, 4: -3.0694077438457565}, Best action: 4, Actual action: 4\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -3.5155461832122135, 4: -3.6931610468996388}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -3.2839108826542844, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: 1.0210266814361066, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.09 -3.05 -3.46 -5.43 -5.35 -5.20 -5.42 -5.59 -5.32 -6.33 \n",
      "-2.96 -3.41 -3.08 -4.95 -5.65 -5.32 -5.56 -5.84 -6.18 -6.82 \n",
      "-1.94 -2.62 -3.35 -4.39 -4.78 -5.94 -5.17 -5.71 -6.87 -6.88 \n",
      "0.00 -1.77 -3.13 -3.19 -3.37 -4.28 -4.67 -6.05 -6.24 -6.68 \n",
      "0.00 0.00 -2.37 -3.23 -3.33 -4.42 -5.05 -5.59 -5.75 -6.20 \n",
      "0.00 0.00 0.00 -3.26 -4.07 -4.54 -4.50 -4.81 -5.21 -5.78 \n",
      "0.00 0.00 -1.09 -3.07 -0.81 -2.80 -3.33 -5.26 -5.04 -5.58 \n",
      "0.00 0.00 0.00 0.00 0.10 -1.23 -2.65 -5.02 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -4.09 -4.59 -5.63 -5.44 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.48 \n",
      "\n",
      "Action values: {0: -4.3169101867797215, 1: -4.086638129177874, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.457191767696215}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -3.288019355723, 2: -2.9575200042455623, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -3.41024115297373, 2: -4.154358192175799, 3: -3.8033677362958076, 4: -4.578339844848501}, Best action: 1, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -3.41024115297373, 2: -4.154358192175799, 3: -3.8033677362958076, 4: -4.578339844848501}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3520086587991216, 1: -3.3681683920319956, 2: -4.477822464245886, 3: -3.611619337042051, 4: -4.7450003834996135}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.0787389880140092, 2: -4.061270328019996, 3: -3.385633982465797, 4: -3.2378682870418993}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -2.621570238054151, 2: -3.1216836380977924, 3: -2.700464235155952, 4: -3.094898375268303}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -1.7717134215216614, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6431413949641023, 1: -3.493579017492904, 2: -3.1295293055132136, 3: -3.139447193809823, 4: -3.6524193856796687}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -4.345131656282124, 2: -5.537184256308888, 3: -4.2816321974461236, 4: -5.5171491512334585}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -4.671398907007443, 4: -5.429126215476942}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -4.345131656282124, 2: -5.537184256308888, 3: -5.111996334420642, 4: -5.5171491512334585}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.474545648264467, 2: -4.834267186837453, 3: -4.423316211778065, 4: -4.597261267049744}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -3.3310519635354363, 3: -3.5907967498188764, 4: -5.069945182620789}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.770802185686172, 2: -5.849695164581123, 3: -5.662186159606709, 4: -5.588798121119952}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.770802185686172, 2: -5.849695164581123, 3: -5.662186159606709, 4: -5.588798121119952}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.770802185686172, 2: -5.849695164581123, 3: -5.662186159606709, 4: -5.9858062902191564}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.770802185686172, 2: -5.849695164581123, 3: -5.662186159606709, 4: -6.129566725941237}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.770802185686172, 2: -5.849695164581123, 3: -6.052589405242106, 4: -6.384304843718334}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -4.500658439941332, 2: -5.271645682276203, 3: -4.556773442175438, 4: -5.527427675081785}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.038552660645188, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.118069858694262, 4: -5.0691375637772556}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.83676098519225, 2: -6.052863663853859, 3: -5.206690735851462, 4: -5.8412297728931515}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.811112158787283, 4: -5.399344867660639}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -4.811112158787283, 4: -5.399344867660639}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.83676098519225, 2: -6.052863663853859, 3: -5.52781987977196, 4: -5.8412297728931515}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -6.1876002691207574, 4: -5.399344867660639}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -6.30773738952326, 4: -5.399344867660639}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -5.470408936294993, 3: -6.429315452214244, 4: -5.813403829571182}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.546484321770892, 1: -5.83676098519225, 2: -6.052863663853859, 3: -6.0809033243563055, 4: -5.8412297728931515}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -5.747331948924405, 2: -6.72034728465569, 3: -6.3124040971027515, 4: -5.927595140848987}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.642550458153397, 2: -6.193269539329656, 3: -6.485372804027145, 4: -6.428573671139377}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.257639911056966, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.864227449572409}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.240294689511862, 1: -5.017137488793177, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.522640943959728}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613084296635228, 1: -5.742945223848236, 2: -4.695674249610679, 3: -4.591224971314155, 4: -4.814566704016307}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.086395205763347, 1: -4.787263913616074, 2: -4.274337884644279, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -2.6484755814436296, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.225484494310379, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.225484494310379, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: 0.10210266814361069, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.32 -3.05 -3.46 -5.43 -5.35 -5.20 -5.42 -5.59 -5.32 -6.33 \n",
      "-3.18 -3.80 -3.10 -4.95 -5.65 -5.32 -5.56 -5.84 -6.18 -6.82 \n",
      "-1.94 -2.70 -3.37 -4.39 -4.78 -5.94 -5.17 -5.71 -6.87 -6.88 \n",
      "0.00 -3.04 -3.14 -3.19 -3.37 -5.29 -5.31 -6.05 -6.24 -6.68 \n",
      "0.00 0.00 -2.37 -3.23 -3.59 -4.47 -5.05 -5.70 -5.93 -6.20 \n",
      "0.00 0.00 0.00 -3.26 -4.07 -4.54 -4.56 -5.68 -5.84 -5.78 \n",
      "0.00 0.00 -1.09 -3.07 -0.81 -2.80 -3.33 -5.43 -5.07 -5.58 \n",
      "0.00 0.00 0.00 0.00 0.01 -0.63 -2.32 -5.00 -5.28 -5.36 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -3.31 -4.32 -5.63 -5.44 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.48 \n",
      "\n",
      "Action values: {0: -4.3169101867797215, 1: -4.561875324381763, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.457191767696215}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.038139133154586, 3: -3.0517685955517386, 4: -3.642632063850307}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8036235810748806, 1: -4.561875324381763, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.457191767696215}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.038139133154586, 3: -4.286111960225827, 4: -3.642632063850307}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.038139133154586, 3: -4.253424718952084, 4: -3.642632063850307}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.038139133154586, 3: -4.369287749588413, 4: -4.214795178103779}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.096090000874176, 4: -3.4623856966643474}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.096090000874176, 4: -3.4623856966643474}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.096090000874176, 4: -4.050770983964556}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.096090000874176, 4: -4.827145370557181}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.470008169090123, 3: -4.421403786791063, 4: -5.044076428516347}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.072231714096687, 1: -4.481396100378218, 2: -4.491004463449815, 3: -4.42226476608665, 4: -5.057776510586046}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.605730859827985, 1: -4.481396100378218, 2: -4.500849023154904, 3: -4.422668454563057, 4: -5.064200085793617}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.461503110398958, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.916475048140874, 4: -5.228001117389817}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.442662641089764, 1: -4.481396100378218, 2: -4.505641909607119, 3: -4.956177565204883, 4: -5.067327444203687}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1843684963905634, 1: -3.288019355723, 2: -4.863342910967938, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5205657398271, 1: -3.9274780921141783, 2: -4.506088040002551, 3: -5.075587581542226, 4: -5.067618544286706}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0965590893935833, 1: -3.577007910226248, 2: -4.061270328019996, 3: -3.385633982465797, 4: -3.2378682870418993}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.663657810986594, 2: -5.351792397077804, 3: -5.734401180775185, 4: -6.037629661425725}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -5.420811231633453, 2: -6.09963994872803, 3: -5.682909676712728, 4: -5.863650954319036}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -5.836927459110481}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.843469068459051, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -6.2116039877905385}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.95580470931357, 1: -6.356570825035127, 2: -6.352692946591304, 3: -5.318511625443726, 4: -6.131865599436364}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.331115628045647, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.331115628045647, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.661315221521539, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.95580470931357, 1: -6.356570825035127, 2: -6.352692946591304, 3: -6.769492168413269, 4: -6.131865599436364}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.001223629187647, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.356571610573352, 1: -6.356570825035127, 2: -6.352692946591304, 3: -6.725500179859296, 4: -6.131865599436364}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4454428355324405, 1: -6.356570825035127, 2: -6.352692946591304, 3: -6.729144455527774, 4: -6.131865599436364}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.515939584982712, 1: -6.356570825035127, 2: -6.352692946591304, 3: -6.732035262859919, 4: -6.479997695487091}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -6.829655649763357, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.564714441868989, 1: -6.356570825035127, 2: -7.0672903709674495, 3: -6.734035336835112, 4: -7.256113388053359}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -6.176746356701945, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.860836188916882, 4: -6.8153185404544105}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.860836188916882, 4: -6.8153185404544105}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.860836188916882, 4: -7.101939871813514}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -7.180332366798942, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -7.165499126322158, 3: -6.556139115011176, 4: -6.311078425941315}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -7.17911332194882, 3: -6.556139115011176, 4: -6.643081367606597}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -7.183388828498706, 3: -6.556139115011176, 4: -6.979045573460614}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.922621570829952, 4: -7.237275404678034}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -6.936065286888861, 4: -7.246047429406472}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -6.997691714228703, 2: -7.3365258519645415, 3: -7.216907850218459, 4: -7.249367635951583}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -6.881676455298851, 2: -7.105223439320772, 3: -7.005902027323141, 4: -7.361193865304372}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.682674914237653, 2: -6.685918379126221, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.371462502320918, 2: -6.608161463352199, 3: -6.200252009913858, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -6.126575767403885, 2: -6.72034728465569, 3: -6.3124040971027515, 4: -5.927595140848987}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -6.126575767403885, 2: -6.72034728465569, 3: -6.3124040971027515, 4: -5.927595140848987}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -6.126575767403885, 2: -6.72034728465569, 3: -6.3124040971027515, 4: -6.294111578172578}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -6.280271164354498, 3: -5.77881026773618, 4: -6.630076161165276}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -6.280271164354498, 3: -5.77881026773618, 4: -6.630076161165276}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -5.83676098519225, 2: -6.052863663853859, 3: -6.160412280145308, 4: -5.8412297728931515}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.118069858694262, 4: -5.0691375637772556}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.118069858694262, 4: -5.0691375637772556}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.118069858694262, 4: -5.512915183037302}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.480849241323898, 2: -5.599880297314851, 3: -5.425650108606269, 4: -5.864227449572409}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -4.992248662932574, 2: -4.85347816989545, 3: -3.566174697703242, 4: -3.333318206420599}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -4.992248662932574, 2: -4.85347816989545, 3: -3.566174697703242, 4: -3.333318206420599}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -4.992248662932574, 2: -4.85347816989545, 3: -3.566174697703242, 4: -3.9333195678427453}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.480849241323898, 2: -5.599880297314851, 3: -4.462897684252711, 4: -5.864227449572409}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -4.992248662932574, 2: -4.85347816989545, 3: -4.8715645940150205, 4: -5.1455766216038565}, Best action: 2, Actual action: 2\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.439932280619105, 4: -5.844749148515993}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.447722996377673, 4: -5.849832590548458}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -5.631717427767347, 2: -5.7676064775856055, 3: -5.858958868876258, 4: -5.850831530316063}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -5.3633280347766, 2: -5.444297473888468, 3: -5.4509210807541075, 4: -5.407960992015212}, Best action: 1, Actual action: 1\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -5.43866118009326, 2: -5.48253365672065, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7487982432385785, 1: -5.787684045431547, 2: -5.752536482581051, 3: -6.116625880775895, 4: -5.4782041177694065}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7487982432385785, 1: -5.787684045431547, 2: -5.752536482581051, 3: -6.116625880775895, 4: -5.4782041177694065}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7487982432385785, 1: -5.787684045431547, 2: -5.752536482581051, 3: -6.116625880775895, 4: -5.88516574717016}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -6.116969361058331, 2: -5.48253365672065, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -6.132181207504349, 2: -5.48253365672065, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712389218402646, 1: -6.148853199385868, 2: -5.889105627615792, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.16311839590704, 2: -5.444297473888468, 3: -5.4509210807541075, 4: -5.407960992015212}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.163638910381568, 2: -5.444297473888468, 3: -5.4509210807541075, 4: -5.407960992015212}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.164333851787029, 2: -5.444297473888468, 3: -5.4509210807541075, 4: -5.821244502733843}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.164387395191362, 2: -5.444297473888468, 3: -5.4509210807541075, 4: -5.9238478097481835}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.164527007273914, 2: -5.854310701238505, 3: -5.4509210807541075, 4: -6.191381440594083}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.282442450310387, 1: -5.734783094979414, 2: -5.648121029824797, 3: -5.42510709522443, 4: -5.735025665007315}, Best action: 0, Actual action: 0\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -6.168018654900757, 2: -5.7676064775856055, 3: -6.483129203940591, 4: -5.851303280854246}, Best action: 2, Actual action: 2\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -5.582835199051851, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.17431995732119}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.779820990205644, 1: -6.164581529246932, 2: -6.370253926522313, 3: -6.1386021245155735, 4: -6.2958599437140546}, Best action: 0, Actual action: 0\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.139938521971756, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.17431995732119}, Best action: 1, Actual action: 1\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.451332301817687, 1: -6.164586928381292, 2: -6.421346112689734, 3: -6.216904325538441, 4: -6.3062061114129575}, Best action: 1, Actual action: 1\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.105424789519239, 1: -6.1563027143666345, 2: -6.474479630744668, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.105445699815857, 1: -6.156302888000837, 2: -6.474493274713211, 3: -6.114516087571635, 4: -5.906905853665669}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.105471100441205, 1: -6.1563030989216765, 2: -6.474509848621251, 3: -6.114516087571635, 4: -6.2752843268357585}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563574869524753, 1: -6.506852284026591, 2: -6.424349339721538, 3: -6.221506972330478, 4: -6.3068142648868974}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.240294689511862, 1: -4.997590565005902, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.522640943959728}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.256745703433394, 1: -6.15630316739222, 2: -6.474515228954909, 3: -6.114516087571635, 4: -6.660615385902035}, Best action: 3, Actual action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631952445451648, 1: -5.693616334972193, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 0, Actual action: 0\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.389010700549147, 1: -5.734783094979414, 2: -5.648121029824797, 3: -5.42510709522443, 4: -5.735025665007315}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -2.3194656417749315, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.6304069867368192, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: 0.01021026681436106, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.46 -4.51 -4.71 -5.43 -5.66 -5.20 -5.68 -5.59 -6.57 -7.01 \n",
      "-3.19 -3.80 -3.24 -4.95 -5.65 -5.32 -5.56 -6.43 -6.56 -7.06 \n",
      "-1.94 -2.70 -3.37 -4.39 -4.78 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "0.00 -3.04 -3.14 -3.19 -3.37 -5.29 -5.31 -6.05 -6.24 -6.69 \n",
      "0.00 0.00 -2.37 -3.23 -3.59 -4.47 -5.05 -5.70 -6.31 -6.37 \n",
      "0.00 0.00 0.00 -3.26 -4.07 -4.54 -4.56 -5.68 -5.84 -6.06 \n",
      "0.00 0.00 -1.09 -3.07 -0.81 -2.80 -4.99 -5.48 -5.84 -6.17 \n",
      "0.00 0.00 0.00 0.00 0.00 -0.96 -1.79 -5.24 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -3.31 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -4.724618039743157, 1: -4.561875324381763, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.457191767696215}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724618039743157, 1: -4.561875324381763, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.457191767696215}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724618039743157, 1: -4.561875324381763, 2: -4.719052266974317, 3: -4.656773021414975, 4: -4.956044508603555}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -4.226687439990101, 2: -4.154358192175799, 3: -3.8033677362958076, 4: -4.487530147550937}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -3.288019355723, 2: -4.863342910967938, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -3.288019355723, 2: -4.863342910967938, 3: -3.1883584756918757, 4: -3.578398740876632}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -3.288019355723, 2: -4.863342910967938, 3: -3.801406212879607, 4: -3.578398740876632}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -3.306654515756278, 2: -2.3047576371440073, 3: -1.9433583483284065, 4: -3.001464613379879}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -3.306654515756278, 2: -2.3047576371440073, 3: -1.9433583483284065, 4: -3.001464613379879}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -3.306654515756278, 2: -2.3047576371440073, 3: -2.6684560969788502, 4: -3.001464613379879}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -3.1216836380977924, 3: -2.700464235155952, 4: -3.094898375268303}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -3.1216836380977924, 3: -2.700464235155952, 4: -3.094898375268303}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9532004611667673, 1: -3.3681683920319956, 2: -4.477822464245886, 3: -3.611619337042051, 4: -4.7450003834996135}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3737835659771265, 1: -4.574563009438641, 2: -3.888280578259649, 3: -3.853849110227026, 4: -4.277800856851135}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -4.3944914985728865, 2: -4.727830764033407, 3: -4.886500478194619, 4: -4.676292719753342}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1891400385206032, 1: -3.5879079498628186, 2: -3.208155054245165, 3: -3.880900679148276, 4: -4.237864908024254}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.782267356694216, 1: -5.216117155178922, 2: -5.908807449316774, 3: -5.548945328761816, 4: -4.979065064395894}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.927036092451177, 1: -6.379707611457967, 2: -5.322675089083521, 3: -5.890416212764834, 4: -6.400073261971953}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.927036092451177, 1: -6.379707611457967, 2: -5.322675089083521, 3: -5.890416212764834, 4: -6.400073261971953}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4293646753838845, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -6.655912088147491}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -5.682909676712728, 4: -5.863650954319036}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.197097822251424, 1: -6.033737171384991, 2: -5.207809614991362, 3: -5.868892123336986, 4: -6.091047468973843}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.197097822251424, 1: -6.033737171384991, 2: -5.207809614991362, 3: -5.868892123336986, 4: -6.091047468973843}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -5.872457741893744, 4: -5.863650954319036}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -5.9905424086000805, 4: -5.863650954319036}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -6.024465641210972, 4: -6.235922368430323}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.766989024461586, 1: -6.033737171384991, 2: -5.207809614991362, 3: -5.868892123336986, 4: -6.091047468973843}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -5.715741097700565, 4: -6.27658546018272}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.663657810986594, 2: -6.266962310384902, 3: -5.734401180775185, 4: -6.037629661425725}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.019996063872231, 1: -4.952429139964312, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037439722275213, 2: -4.727830764033407, 3: -4.886500478194619, 4: -4.676292719753342}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037441171272239, 2: -4.727830764033407, 3: -4.886500478194619, 4: -4.676292719753342}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037442526015184, 2: -4.727830764033407, 3: -4.886500478194619, 4: -5.155426374975542}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057602285689185, 1: -5.216117155178922, 2: -5.908807449316774, 3: -5.548945328761816, 4: -4.979065064395894}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604202709525, 1: -5.216117155178922, 2: -5.908807449316774, 3: -5.548945328761816, 4: -4.979065064395894}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604777672445, 1: -5.216117155178922, 2: -5.908807449316774, 3: -5.548945328761816, 4: -5.430949208600264}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.086244723584473, 1: -4.574563009438641, 2: -3.888280578259649, 3: -3.853849110227026, 4: -4.277800856851135}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0862447077859, 1: -4.574563009438641, 2: -3.888280578259649, 3: -3.853849110227026, 4: -4.277800856851135}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.086244713630214, 1: -4.574563009438641, 2: -3.888280578259649, 3: -4.4070026903065935, 4: -4.277800856851135}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.138650502089475, 4: -6.047470664736775}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.138650502089475, 4: -6.047470664736775}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.138650502089475, 4: -6.4031983049104655}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.309747752301679, 4: -5.429126215476942}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.086244719271272, 1: -4.574563009438641, 2: -6.340001536355672, 3: -6.127397643780102, 4: -4.277800856851135}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.086244719234972, 1: -4.574563009438641, 2: -6.323035024787497, 3: -6.116326994981868, 4: -4.277800856851135}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.086244719255304, 1: -4.574563009438641, 2: -6.332538184896354, 3: -6.122527806952897, 4: -4.792798779734532}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.474545648264467, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -4.597261267049744}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.538665005074813, 2: -4.59322168117289, 3: -4.571837330798787, 4: -4.880416877476394}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -2.8004564131044765, 4: -3.840998797883056}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.8148752822838051, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: 0.001021026681436105, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.9589055406138657, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.60 -4.51 -4.71 -5.43 -5.72 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-3.35 -4.15 -3.24 -4.96 -5.65 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-2.92 -3.09 -3.61 -4.89 -5.03 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "0.00 -3.04 -3.14 -3.21 -4.99 -5.29 -5.22 -5.78 -6.24 -6.69 \n",
      "0.00 0.00 -2.37 -3.23 -3.59 -4.48 -5.05 -5.70 -6.31 -6.37 \n",
      "0.00 0.00 0.00 -3.26 -4.07 -3.34 -4.56 -5.68 -5.84 -6.06 \n",
      "0.00 0.00 -1.09 -3.07 -1.56 -2.18 -4.99 -5.48 -5.84 -6.17 \n",
      "0.00 0.00 0.00 0.00 -1.29 -0.10 -1.79 -5.24 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -3.31 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -4.724618039743157, 1: -4.603130202561937, 2: -4.719052266974317, 3: -4.656773021414975, 4: -5.178247801374863}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -3.3450207669087897, 2: -4.863342910967938, 3: -4.044543259167113, 4: -3.578398740876632}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -3.1216836380977924, 3: -5.132143405095109, 4: -3.094898375268303}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -3.1216836380977924, 3: -5.132143405095109, 4: -3.094898375268303}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -3.1216836380977924, 3: -5.132143405095109, 4: -3.7163575214941558}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9532004611667673, 1: -4.740189046623665, 2: -4.477822464245886, 3: -3.611619337042051, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9235528744404027, 1: -3.306654515756278, 2: -3.861331953079593, 3: -4.213723476395053, 4: -3.001464613379879}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.131300482879239, 2: -4.863342910967938, 3: -4.044543259167113, 4: -3.578398740876632}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.152840550428605, 2: -4.863342910967938, 3: -4.044543259167113, 4: -3.578398740876632}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.157639662889972, 2: -4.863342910967938, 3: -4.044543259167113, 4: -4.156342854197735}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.159266513085271, 2: -4.863342910967938, 3: -4.044543259167113, 4: -4.787631487361465}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.160167788851971, 2: -4.863342910967938, 3: -4.580534365842073, 4: -5.137365684466877}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493976405563538, 1: -3.306654515756278, 2: -3.861331953079593, 3: -4.213723476395053, 4: -3.001464613379879}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.486354195387116, 1: -3.306654515756278, 2: -3.861331953079593, 3: -4.213723476395053, 4: -3.001464613379879}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.491584473168304, 1: -3.306654515756278, 2: -3.861331953079593, 3: -4.213723476395053, 4: -3.63133279817569}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -3.038916003587199, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -3.038916003587199, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -0.7742988632043731, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -0.9848814512081642, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -1.9034482200469343, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: -2.683288353086321, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: -2.445050703115606, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: -2.498563859365606, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -1.6641434599183393, 2: -4.359432580966742, 3: -2.5204774968499812, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -2.3696458850861224, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2542460117455256}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.2608866946594257, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.560834547199276, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -1.288254641280472, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: -2.4293687952299154, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.668881804159397, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.323225, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.4052375000000001, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.4388216187500003, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8828912403563434, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8592241990547873, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8833051193672874, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8843887607813499, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8892651471446311, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6007130998087917, 1: -1.7735479502140195, 2: -1.8912620273603948, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.072302520383686, 1: -3.5817113760339887, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2542460117455256}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -3.5879079498628186, 2: -3.208155054245165, 3: -3.880900679148276, 4: -4.237864908024254}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0862447192637825, 1: -4.986489872531999, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.48488252936206, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -4.597261267049744}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -3.3411301393526243, 2: -4.59322168117289, 3: -4.571837330798787, 4: -4.880416877476394}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -2.1757762891722914, 4: -3.840998797883056}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -4.992248662932574, 2: -6.06312923738645, 3: -5.434961935994421, 4: -5.513193387245418}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.240294689511862, 1: -6.166258184659604, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.522640943959728}, Best action: 0, Actual action: 0\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.17431995732119}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.17431995732119}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.518631161162283}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.208112230514324, 4: -6.608245310584578}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8419399363520945, 1: -6.168034104989659, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -5.851303288482482}, Best action: 0, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.055737022051172, 2: -6.280271164354498, 3: -6.281784849203269, 4: -6.630076161165276}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.217069112218303, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.525976087623112, 4: -6.826184196313277}, Best action: 0, Actual action: 0\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.129777305101754, 1: -6.541399683101942, 2: -6.280271164354498, 3: -6.281784849203269, 4: -6.630076161165276}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.371462502320918, 2: -6.608161463352199, 3: -6.549612062406805, 4: -6.888878627490244}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.67386235739012, 1: -6.772967743451513, 2: -6.280271164354498, 3: -6.281784849203269, 4: -6.630076161165276}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.787578883357362, 1: -6.795995339959879, 2: -6.280271164354498, 3: -6.281784849203269, 4: -6.630076161165276}, Best action: 2, Actual action: 2\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.855370941387002, 1: -6.809723231710882, 2: -6.615046759562593, 3: -6.281784849203269, 4: -6.630076161165276}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -5.836635103054547, 2: -6.052863663853859, 3: -6.160412280145308, 4: -5.8412297728931515}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.480849241323898, 2: -5.599880297314851, 3: -5.885185014629548, 4: -5.864227449572409}, Best action: 1, Actual action: 1\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629387187004291, 1: -6.166258184659604, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.522640943959728}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629393338700669, 1: -6.166258184659604, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.522640943959728}, Best action: 4, Actual action: 4\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629395870633263, 1: -6.166258184659604, 2: -6.041622056999685, 3: -5.694912394634602, 4: -5.925603259003353}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -1.7904005726789873, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.09589055406138658, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.09589055406138658, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -1.738950192738805, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.44 -4.51 -4.71 -5.43 -5.72 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-4.12 -4.15 -3.24 -4.96 -5.65 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.62 -3.17 -3.95 -4.89 -5.03 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-1.94 -1.12 -3.14 -3.59 -5.09 -5.29 -5.22 -5.78 -6.24 -6.69 \n",
      "0.00 0.00 -3.25 -3.23 -3.59 -4.60 -5.05 -5.70 -6.31 -6.55 \n",
      "-1.77 -1.50 0.00 -2.82 -4.07 -4.57 -4.56 -5.68 -5.84 -6.38 \n",
      "0.00 -1.72 -1.09 -3.07 -2.30 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 0.00 0.00 -0.17 -2.03 -1.70 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -3.31 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -4.724618039743157, 1: -4.43664023293277, 2: -4.719052266974317, 3: -4.656773021414975, 4: -5.178247801374863}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -4.226687439990101, 2: -4.154358192175799, 3: -4.17273396679394, 4: -4.487530147550937}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -3.577007910226248, 2: -4.061270328019996, 3: -3.385633982465797, 4: -3.2378682870418993}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -3.577007910226248, 2: -4.061270328019996, 3: -3.385633982465797, 4: -3.2378682870418993}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -3.577007910226248, 2: -4.061270328019996, 3: -3.385633982465797, 4: -3.8464601412081283}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -4.121698409432168, 2: -4.863342910967938, 3: -4.768888680524646, 4: -5.1755074331900985}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9532004611667673, 1: -4.740189046623665, 2: -4.477822464245886, 3: -4.335610094098369, 4: -4.7450003834996135}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.019996063872231, 1: -5.499967429920837, 2: -4.959212925709985, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941332344707604, 1: -5.786622891566809, 2: -5.960358224202523, 3: -5.654355025604448, 4: -6.209051393862072}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.019996063872231, 1: -5.499967429920837, 2: -5.9759488633106015, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.716155103753492, 1: -6.026224295289861, 2: -5.7770426164815785, 3: -5.931185250156019, 4: -5.42509480155403}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.716155103753492, 1: -6.026224295289861, 2: -5.7770426164815785, 3: -5.931185250156019, 4: -5.42509480155403}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.716155103753492, 1: -6.026224295289861, 2: -5.7770426164815785, 3: -5.931185250156019, 4: -5.836836269414167}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -4.710149935884189, 2: -4.979883749581611, 3: -4.9885414381879984, 4: -5.281591486688611}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.998567370983932, 1: -5.499967429920837, 2: -6.118884332912348, 3: -5.07802552822051, 4: -5.08838039122283}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -3.577007910226248, 2: -4.061270328019996, 3: -5.135267715793331, 4: -5.249892780333815}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.032091683249313, 2: -5.908807449316774, 3: -5.548945328761816, 4: -5.654813469700492}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.285245478531932, 2: -5.537184256308888, 3: -5.3992533148030475, 4: -5.5171491512334585}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -5.051639408218031, 2: -5.4533802513862915, 3: -5.896994213920696, 4: -5.6684883264834705}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -4.556773442175438, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -4.556773442175438, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.571837330798787, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.071522548974169, 2: -4.7461135601408495, 3: -4.209156017607984, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -3.067026956856934, 4: -4.57699996860916}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -2.302382712313359, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.1738950192738804, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.66 -4.51 -4.98 -5.67 -5.72 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-4.70 -4.17 -4.06 -5.09 -5.79 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.62 -3.17 -4.34 -4.89 -5.55 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-1.94 -1.12 -3.14 -3.59 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "0.00 0.00 -3.25 -3.23 -3.59 -4.60 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -1.50 0.00 -2.82 -3.57 -4.43 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.72 -1.09 -2.58 -1.20 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 0.00 0.00 -0.02 -2.03 -1.70 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.13 -3.55 -3.31 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -4.724618039743157, 1: -4.8228229555913815, 2: -4.719052266974317, 3: -4.656773021414975, 4: -5.178247801374863}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724618039743157, 1: -4.8228229555913815, 2: -4.719052266974317, 3: -4.656773021414975, 4: -5.178247801374863}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724618039743157, 1: -4.8228229555913815, 2: -4.719052266974317, 3: -5.137663449487627, 4: -5.178247801374863}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -5.277908580391853, 2: -4.506604255841472, 3: -5.213756472051455, 4: -5.067955375121602}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.724225614950191, 2: -6.266962310384902, 3: -5.734401180775185, 4: -6.037629661425725}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941332344707604, 1: -5.786622891566809, 2: -5.960358224202523, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -4.886500478194619, 4: -5.880908047605686}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -4.477822464245886, 3: -4.335610094098369, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.1674860571674532, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -1.1192709623246058, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.9371409367148031, 1: -3.531256992703778, 2: -4.359432580966742, 3: -2.5350387753447365, 4: -4.086021188004767}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -3.6165913729010355, 2: -3.861331953079593, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0231531057213195, 1: -3.531256992703778, 2: -4.359432580966742, 3: -2.5350387753447365, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8874552333095567, 1: -3.531256992703778, 2: -4.359432580966742, 3: -2.5350387753447365, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.023504151628899, 1: -3.531256992703778, 2: -4.359432580966742, 3: -3.20688528556371, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0792161836806695, 1: -3.531256992703778, 2: -4.359432580966742, 3: -4.093386755797646, 4: -4.086021188004767}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5571402217973134, 1: -1.698096577596309, 2: -2.764704082824532, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.05229672680972, 1: -1.902941146665079, 2: -4.359432580966742, 3: -3.008566698385894, 4: -4.086021188004767}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.581711395735418, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2542460117455256}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.581711395735418, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2542460117455256}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.581711395735418, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.861363870688429}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: -2.294393513868313, 3: -2.666830248376459, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: -2.294393513868313, 3: -2.666830248376459, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: -2.294393513868313, 3: -2.666830248376459, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5842710462377239, 1: -1.6317307275292976, 2: -2.294393513868313, 3: -2.666830248376459, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -1.856762971460156, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2084752068916695}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5624051115064987, 1: -1.6317307275292976, 2: -2.294393513868313, 3: -2.666830248376459, 4: -3.318042608950842}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.0932084619300462, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -1.5028215525066686, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.357339585667527, 1: -3.856141471466209, 2: -3.127127523677499, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3058502686947606, 1: -4.787263913616074, 2: -4.274337884644279, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -1.7027652826354311, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -2.0250840774061247, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.01738950192738803, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.72 -5.07 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-4.70 -4.17 -4.06 -5.09 -5.36 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.68 -3.21 -3.92 -4.71 -5.55 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.01 -3.24 -3.14 -3.59 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.70 0.00 -2.68 -3.23 -3.59 -4.60 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -1.50 -2.20 -2.82 -3.57 -4.43 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.72 -1.65 -2.58 -1.20 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 -1.58 0.00 -0.00 -1.11 -2.30 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.17 -3.55 -2.88 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -4.724618039743157, 1: -4.8228229555913815, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.178247801374863}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -5.277908580391853, 2: -6.096497757529535, 3: -5.213756472051455, 4: -5.067955375121602}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -5.277908580391853, 2: -6.096497757529535, 3: -5.213756472051455, 4: -5.067955375121602}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -5.277908580391853, 2: -6.096497757529535, 3: -5.213756472051455, 4: -5.511839391360658}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.710157141383148, 1: -4.8228229555913815, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.178247801374863}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.700392885235414, 1: -5.362121910333382, 2: -4.863342910967938, 3: -4.768888680524646, 4: -5.1755074331900985}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.735595202617124, 1: -5.189600532599823, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.178247801374863}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.751538933101719, 1: -5.578412737680618, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.178247801374863}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.755142416116048, 1: -5.666289171500561, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.612205499251125}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.756618042410415, 1: -5.702274571149828, 2: -5.737706749688652, 3: -5.945211585438715, 4: -6.184812681598854}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -4.061270328019996, 3: -5.135329685292181, 4: -5.249933215431817}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -5.499967429920837, 2: -6.125992042728915, 3: -5.2600177580969705, 4: -5.08838039122283}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -5.499967429920837, 2: -6.125992042728915, 3: -5.2600177580969705, 4: -5.08838039122283}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -5.499967429920837, 2: -6.125992042728915, 3: -5.2600177580969705, 4: -5.530426156012775}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941332344707604, 1: -5.35848419484809, 2: -5.960358224202523, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -5.548945328761816, 4: -5.654813469700492}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -4.712626074536332, 4: -5.880908047605686}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -4.477822464245886, 3: -3.9181253174254618, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -4.477822464245886, 3: -3.9181253174254618, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -3.681652697303589, 2: -3.861331953079593, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.9169702042463292, 2: -4.359432580966742, 3: -3.0139657170784897, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.9169702042463292, 2: -4.359432580966742, 3: -3.0139657170784897, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.9169702042463292, 2: -4.359432580966742, 3: -3.6427088025414256, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.9169702042463292, 2: -4.359432580966742, 3: -4.4723353038097695, 4: -4.086021188004767}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -1.698096577596309, 2: -2.764704082824532, 3: -2.0110835228535984, 4: -3.999227257106635}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.500692401212442, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.5960199013862653, 4: -2.509383734201211}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: -1.460168560950244, 4: 0.0}, Best action: 4, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.614821520717034, 2: -2.764704082824532, 3: -2.0110835228535984, 4: -3.999227257106635}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.8608237753199135, 2: -2.764704082824532, 3: -2.0110835228535984, 4: -3.999227257106635}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.9263428765781105, 2: -2.764704082824532, 3: -2.730086005796774, 4: -3.999227257106635}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.953172948543342, 2: -2.764704082824532, 3: -3.678809782040295, 4: -3.999227257106635}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: -3.115410186459024, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: -3.0502826793423328, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: -3.066890210592333, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -1.5753115805455993, 2: -4.14378685072118, 3: -3.073690994639208, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.959390627587555, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.5960199013862653, 4: -2.509383734201211}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.959977051830034, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -1.5960199013862653, 4: -2.509383734201211}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.960234596557014, 1: -1.7086262314653264, 2: -3.9262894408365767, 3: -2.3523781102615016, 4: -2.509383734201211}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.7164776114020177, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: -2.7393247115732513}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603120546676065, 1: -2.461209488382167, 2: -3.9262894408365767, 3: -3.085366760364506, 4: -2.509383734201211}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -2.5758600614352685, 4: -4.57699996860916}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -1.6514313986180886, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.51 -5.28 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-4.77 -4.17 -5.14 -5.50 -5.82 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.86 -3.21 -4.48 -4.80 -5.31 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.23 -3.24 -3.14 -3.59 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.83 -1.62 -2.68 -3.23 -3.59 -4.60 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -2.51 -2.20 -2.82 -3.57 -4.43 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.79 -0.17 -1.83 -1.20 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 -1.58 0.00 -0.00 -1.11 -2.30 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.17 -3.55 -2.88 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -5.756394263480344, 1: -5.506610898476262, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -4.226687439990101, 2: -4.407977740255146, 3: -4.17273396679394, 4: -4.487530147550937}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -4.863342910967938, 3: -4.768888680524646, 4: -5.1755074331900985}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -4.863342910967938, 3: -4.768888680524646, 4: -5.1755074331900985}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -4.863342910967938, 3: -5.239688699277428, 4: -5.1755074331900985}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -5.499967429920837, 2: -6.125992042728915, 3: -5.975706393036196, 4: -6.26309771359884}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -4.8002501104250515, 4: -5.880908047605686}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -4.477822464245886, 3: -4.529867388280193, 4: -4.7450003834996135}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -5.007061207081673, 4: -5.880908047605686}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -5.4035018241607435, 3: -4.529867388280193, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.209487394300759, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.2364091028651276, 2: -3.825711640120336, 3: -3.5328916492159, 4: -4.026819103801112}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.624000595060484, 1: -2.8462720855857144, 2: -4.14378685072118, 3: -3.0769387038574836, 4: -3.523803201410253}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -2.539081392285505, 2: -3.825711640120336, 3: -3.5328916492159, 4: -4.026819103801112}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1190559872573074, 1: -2.8462720855857144, 2: -4.14378685072118, 3: -3.0769387038574836, 4: -3.523803201410253}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -2.8240613269986947, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.2006657540372576, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.1095511560212046, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.0017389501927388036, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.43 -5.28 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-5.18 -4.23 -5.14 -5.58 -5.82 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.86 -3.58 -4.25 -4.90 -5.31 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.23 -3.53 -3.14 -3.59 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.83 -3.08 -2.68 -3.23 -3.59 -4.60 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -2.51 -2.20 -2.46 -3.57 -4.43 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.79 -0.17 -1.83 -1.87 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 -1.58 0.00 -0.00 -1.01 -2.30 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.17 -3.55 -2.88 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -5.756394263480344, 1: -5.432037597413628, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.1755074331900985}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.1755074331900985}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.362121910333382, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.60971176420299}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5799658738772875, 1: -3.8789923232726644, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.135329685292181, 4: -5.249933215431817}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -4.226687439990101, 2: -4.407977740255146, 3: -5.509316176711518, 4: -4.487530147550937}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -5.207200109964995, 3: -4.253948746248991, 4: -4.7450003834996135}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.393122838972748, 1: -3.8789923232726644, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -3.5879079498628186, 2: -5.307571413225051, 3: -3.880900679148276, 4: -4.237864908024254}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -3.5907967498188764, 4: -5.069945182620789}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3107626149575893, 1: -3.5011745148018716, 2: -3.6576870989577466, 3: -3.2328333034257275, 4: -3.239519404355012}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -2.681264823600987, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2439200520435345}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.908986224175483, 1: -2.199872248425886, 2: -2.294393513868313, 3: -2.666830248376459, 4: -3.5757689888593163}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -1.8264157225838527, 4: -4.57699996860916}, Best action: 3, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -1.8264157225838527, 4: -4.57699996860916}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -0.16514313986180884, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -1.5780549524683514, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -0.9, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.74 -5.28 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-5.17 -4.41 -5.19 -5.58 -5.82 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.86 -4.46 -4.74 -4.90 -5.31 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.23 -3.53 -3.14 -3.88 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.83 -3.08 -3.24 -3.24 -4.18 -4.60 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -2.51 -2.29 -2.46 -3.57 -4.43 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.79 -2.41 -2.23 -1.87 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 -1.44 0.00 -0.00 -1.01 -2.30 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.17 -3.55 -2.88 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -5.756394263480344, 1: -5.85296946893203, 2: -5.737706749688652, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -5.277908580391853, 2: -6.096497757529535, 3: -5.721159732377355, 4: -6.078526589422081}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -5.578963299189976, 2: -6.125992042728915, 3: -5.975706393036196, 4: -6.26309771359884}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -5.311552469400534, 4: -5.654813469700492}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -4.899055116109166, 4: -5.880908047605686}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -5.399389890988479, 4: -5.654813469700492}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -5.788350184229567, 4: -5.654813469700492}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -6.11408788717214, 4: -5.654813469700492}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.843595797268639, 2: -5.908807449316774, 3: -6.325703902680889, 4: -6.045880257427448}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0862447192637825, 1: -5.092487897086701, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 0, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.6206248872514655, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -4.597261267049744}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.6206248872514655, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -4.597261267049744}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.6206248872514655, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -5.083507753015267}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.429620394865883, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.429620394865883, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -2.4582840769225056, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.8747517172649404, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -1.0116593904301796, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.76 -5.61 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-5.17 -4.41 -5.19 -5.98 -5.82 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-3.86 -4.46 -4.74 -5.04 -5.74 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.23 -3.53 -3.14 -3.88 -5.09 -5.40 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.83 -3.08 -3.24 -3.24 -4.18 -4.83 -5.32 -5.70 -6.31 -6.55 \n",
      "-1.77 -2.51 -2.29 -2.49 -3.57 -2.71 -5.04 -5.68 -5.84 -6.38 \n",
      "0.00 -1.79 -2.41 -2.23 -1.50 -3.71 -5.36 -5.60 -5.85 -6.60 \n",
      "0.00 0.00 -1.44 0.00 -0.00 -0.10 -2.30 -2.88 -3.08 -6.10 \n",
      "0.00 0.00 0.00 -2.67 -3.17 -3.55 -2.88 -4.32 -4.80 -5.70 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.11 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -5.756394263480344, 1: -5.85296946893203, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.756394263480344, 1: -5.85296946893203, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.138318779767114, 1: -5.85296946893203, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.173487200148985, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.084322394082996, 2: -3.861331953079593, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.574282362438841, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.574282362438841, 2: -4.463375867489183, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -4.740189046623665, 2: -5.207200109964995, 3: -4.780259174100538, 4: -4.7450003834996135}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.432747262579916, 2: -5.307571413225051, 3: -3.880900679148276, 4: -4.237864908024254}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0862447192637825, 1: -5.387857717717051, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -5.742191195650749, 2: -5.908807449316774, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.639329459271583, 2: -5.537184256308888, 3: -5.3992533148030475, 4: -5.5171491512334585}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.107239739410643, 1: -5.387857717717051, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.865757110781941, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.865757110781941, 2: -4.834267186837453, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -5.316032721021996, 2: -5.4533802513862915, 3: -5.896994213920696, 4: -5.6684883264834705}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.683147987923876, 1: -5.823387572391601, 2: -6.270066412571752, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -6.608161463352199, 3: -6.549612062406805, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -5.704085254880676, 2: -5.849695164581123, 3: -6.193234601138981, 4: -6.4127854958874515}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -6.103979984222525, 2: -6.052863663853859, 3: -6.160412280145308, 4: -5.8412297728931515}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -6.103979984222525, 2: -6.052863663853859, 3: -6.160412280145308, 4: -5.8412297728931515}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -6.103979984222525, 2: -6.052863663853859, 3: -6.160412280145308, 4: -6.215519093332768}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -6.726945599602881, 3: -6.3761581149201, 4: -6.630076161165276}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -6.103979984222525, 2: -6.669974439470668, 3: -6.160412280145308, 4: -6.921019830819832}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.747783420218077, 4: -6.871100181163758}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -6.598299524222118, 3: -6.747783420218077, 4: -6.871100181163758}, Best action: 2, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.025534522798855, 3: -6.747783420218077, 4: -6.871100181163758}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.168034104989659, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -5.851303288482482}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.168034104989659, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -5.851303288482482}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.168034104989659, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.224685992519059}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -5.734783094979414, 2: -5.648121029824797, 3: -3.083198598266963, 4: -5.735025665007315}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -6.096090312404696, 4: -6.306853049733153}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -6.096090312404696, 4: -6.306853049733153}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -6.447442184288273, 4: -6.306853049733153}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -6.745929040703666, 4: -6.306853049733153}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -6.962809095358087, 4: -6.639236275257169}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.424540869826503, 3: -7.000559127619213, 4: -6.825656187657791}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.542201655532943, 2: -6.746332191542118, 3: -7.043077817196649, 4: -7.03562502507723}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.7006074147404995, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.803673168046093, 1: -5.693616334972193, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -2.8802798228138387, 4: -4.349817860389269}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -5.734783094979414, 2: -5.648121029824797, 3: -6.385723159779774, 4: -5.735025665007315}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.060811925730772, 2: -6.617077727307178, 3: -7.037777576322615, 4: -7.0094509960696545}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.520314502452142, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.515801043836669, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.926826097320939, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.170909223611088, 1: -5.693616334972193, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -6.1057903419473885, 4: -4.349817860389269}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -6.1039217134391235, 4: -4.349817860389269}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -6.105821883862272, 4: -4.858334252954235}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -6.106600003650551, 4: -5.529321632943708}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.041622056999685, 3: -6.10690446247071, 4: -6.194223273084155}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -5.734783094979414, 2: -6.412505445952383, 3: -6.3868218711440905, 4: -5.735025665007315}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.310550981022729, 1: -5.693616334972193, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.177666058152433, 2: -6.637531185002121, 3: -7.0386162959222185, 4: -7.01359282125288}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.369148419406382, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298718118519967, 1: -5.693616334972193, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.112955446809324, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -5.764897783000377}, Best action: 0, Actual action: 0\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613084296635228, 1: -5.742945223848236, 2: -4.695674249610679, 3: -4.317857392118863, 4: -4.814566704016307}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613084296635228, 1: -5.742945223848236, 2: -4.695674249610679, 3: -4.317857392118863, 4: -4.814566704016307}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.8779526959709116, 1: -4.787263913616074, 2: -4.274337884644279, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 0, Actual action: 0\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.391428674163818, 3: -6.107032603805793, 4: -6.850394517189916}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.393892834173835, 3: -6.107032981383685, 4: -6.852327974138776}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -2.29860481633929, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.00017389501927388032, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -0.00017389501927388032, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -1.4440233479424092, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -2.46570444651658, 4: -3.280349951152159}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.5707253976680087, 3: -3.3164008456844085, 4: -3.280349951152159}, Best action: 2, Actual action: 2\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.3935154350019365, 3: -1.7570987339022337, 4: -6.852031854954779}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -1.8724691258313566, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -1.8755902534934956, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -0.10116593904301796, 4: -3.310322407758678}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -2.9798485504543084, 3: -3.522032368990379, 4: -3.280349951152159}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -3.3237939197722914, 4: -3.310322407758678}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -3.675047879569249, 4: -3.310322407758678}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -3.706347382756006, 3: -3.796967253687847, 4: -3.912393391060397}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -3.0627750164020697, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -3.0639833079510836, 4: -3.7012129152079596}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -3.71866676237369, 2: -4.0323911775892585, 3: -3.845054557320837, 4: -4.6775685929022055}, Best action: 1, Actual action: 1\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.357339585667527, 1: -3.856141471466209, 2: -3.6978975622847736, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.357339585667527, 1: -3.856141471466209, 2: -3.6978975622847736, 3: -3.1744249083172025, 4: -3.703309531013778}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.357339585667527, 1: -3.856141471466209, 2: -3.6978975622847736, 3: -3.788726666568654, 4: -3.703309531013778}, Best action: 0, Actual action: 0\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1263210282568137, 1: -3.4192027294271474, 2: -4.306489804681626, 3: -3.600382224738882, 4: -3.280349951152159}, Best action: 0, Actual action: 0\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.360155967096041, 1: -6.268957713558427, 2: -6.06312923738645, 3: -5.434961935994421, 4: -5.513193387245418}, Best action: 0, Actual action: 0\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -5.042593925451163, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -5.042593925451163, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -2.7119298971100423, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.5704189870117835, 2: -4.7461135601408495, 3: -4.209156017607984, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.4971972248507168, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 1, Actual action: 1\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.584007756502745, 1: -3.4192027294271474, 2: -4.307658619248149, 3: -3.600393013623897, 4: -3.280349951152159}, Best action: 4, Actual action: 4\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.602355806502142, 1: -3.4192027294271474, 2: -4.307664982160846, 3: -3.600393072357537, 4: -3.280349951152159}, Best action: 4, Actual action: 4\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604615641665192, 1: -3.4192027294271474, 2: -4.307665765848151, 3: -3.600393079591458, 4: -3.885118455548465}, Best action: 1, Actual action: 1\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.667381240244387}, Best action: 4, Actual action: 4\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.667381240244387}, Best action: 4, Actual action: 4\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.053773198892698, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -3.327316928622392}, Best action: 0, Actual action: 0\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.67 -5.61 -4.98 -5.67 -5.73 -5.87 -6.10 -5.59 -6.57 -7.01 \n",
      "-5.17 -4.41 -5.19 -5.98 -5.82 -5.89 -5.56 -6.30 -6.56 -7.06 \n",
      "-4.08 -4.57 -4.75 -5.04 -5.91 -5.94 -5.17 -5.71 -6.87 -7.01 \n",
      "-3.23 -3.53 -3.14 -4.24 -5.48 -5.52 -5.22 -5.78 -6.24 -6.69 \n",
      "-1.83 -3.08 -3.24 -3.24 -4.18 -4.87 -5.45 -5.85 -6.31 -6.53 \n",
      "-1.77 -2.51 -2.29 -2.49 -3.61 -4.08 -3.71 -5.82 -6.16 -6.63 \n",
      "0.00 -1.79 -2.41 -2.23 -3.66 -3.71 -5.43 -5.60 -5.50 -6.27 \n",
      "0.00 0.00 -1.61 0.00 -3.53 -3.85 -3.70 -2.99 -5.74 -6.16 \n",
      "0.00 0.00 0.00 -0.31 -3.70 -3.55 -4.27 -4.61 -5.63 -6.02 \n",
      "0.00 0.00 -2.62 -1.64 -3.07 -4.24 -5.35 -5.16 -4.84 -5.75 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.673107959158827, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -5.005206920993889, 2: -4.407977740255146, 3: -5.509316176711518, 4: -4.487530147550937}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.187483561372904, 4: -5.249933215431817}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -5.005206920993889, 2: -5.5426594587375675, 3: -5.509316176711518, 4: -4.487530147550937}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -5.005206920993889, 2: -5.482433355163858, 3: -5.509316176711518, 4: -4.487530147550937}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.740009736806503, 1: -5.005206920993889, 2: -5.582898118224742, 3: -5.509316176711518, 4: -4.983652434271352}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -5.56611217489144, 2: -4.979883749581611, 3: -4.9885414381879984, 4: -5.281591486688611}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.9669246901407105, 2: -6.266962310384902, 3: -5.734401180775185, 4: -6.037629661425725}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.672019965994804, 1: -6.026224295289861, 2: -5.7770426164815785, 3: -5.931185250156019, 4: -6.209590929799614}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.033737171384991, 2: -6.06090424638421, 3: -5.868892123336986, 4: -6.091047468973843}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.9669246901407105, 2: -6.266962310384902, 3: -6.314819383261746, 4: -6.037629661425725}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.913153841390407, 1: -5.9669246901407105, 2: -6.266962310384902, 3: -6.3973688526176415, 4: -6.037629661425725}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.09963994872803, 3: -6.129768681363744, 4: -6.527075371325444}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589375258588495, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -6.03892269059355, 4: -5.609871858760523}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.005296693914983, 2: -7.139410098558595, 3: -7.033284242963803, 4: -7.195711279233019}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0623430979372745, 1: -7.240847409648259, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.2503555554523915}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.321027578720691, 2: -7.139410098558595, 3: -7.033284242963803, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.566756504694702, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.734119074173861, 4: -7.288607117515974}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.566756504694702, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.734119074173861, 4: -7.288607117515974}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8757484192721785, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.734119074173861, 4: -7.288607117515974}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3297172544026505, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -6.03892269059355, 4: -5.609871858760523}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.324596231122806, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -6.03892269059355, 4: -5.609871858760523}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.326072642226323, 1: -5.696790909443338, 2: -5.8652751611914695, 3: -6.03892269059355, 4: -6.004983391472076}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.303498725404206, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -6.655912088147491}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.435728984515047, 2: -7.139410098558595, 3: -7.064485496784279, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.922895835991132, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.436458156552324, 4: -7.288607117515974}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.327207593735872, 1: -6.952442267236499, 2: -5.8652751611914695, 3: -6.03892269059355, 4: -6.983673499702256}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.919166673686362, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.292917151161386, 4: -7.288607117515974}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.32722038484596, 1: -6.969346505787282, 2: -6.58379040855987, 3: -6.03892269059355, 4: -6.994703515356642}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.819387221176991, 3: -6.129768681363744, 4: -6.527075371325444}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.033737171384991, 2: -6.06090424638421, 3: -6.545684835178275, 4: -6.091047468973843}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.852880668317296, 1: -5.556341977230056, 2: -6.249984247654176, 3: -5.974183630768975, 4: -5.9063266710972515}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.938402779569701, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -5.965082923725352, 4: -6.201956390275406}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.852880668317296, 1: -6.265740449174464, 2: -6.249984247654176, 3: -5.974183630768975, 4: -5.9063266710972515}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.327221985764199, 1: -6.971462217686381, 2: -6.635385272735409, 3: -6.661519069189124, 4: -6.996084017370803}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.921053526100972, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.767069551700856, 4: -7.288607117515974}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221237163055, 1: -6.971644529878737, 2: -7.045924025370123, 3: -6.683474432645898, 4: -6.996202976076316}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.921055599871941, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -6.990952693906486, 4: -7.288607117515974}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.921056006831541, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -7.211981588321647, 4: -7.288607117515974}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.198161069742852, 1: -6.993790942613026, 2: -7.1170891900672375, 3: -7.268208964325575, 4: -7.288607117515974}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.318715391807063, 1: -7.240847409648259, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.2503555554523915}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.03038825403956, 2: -7.105223439320772, 3: -7.005902027323141, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.03038825403956, 2: -7.105223439320772, 3: -7.005902027323141, 4: -7.361193865304372}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.03038825403956, 2: -7.105223439320772, 3: -7.275370844864058, 4: -7.361193865304372}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.747683643075815, 2: -6.685918379126221, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.747683643075815, 2: -6.685918379126221, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.747683643075815, 2: -6.984185725004862, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -6.608161463352199, 3: -6.529248707531777, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -6.490704021186788, 2: -5.849695164581123, 3: -6.193234601138981, 4: -6.4127854958874515}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -6.3816390914713645, 2: -6.72034728465569, 3: -6.3124040971027515, 4: -6.747388026427253}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -6.490704021186788, 2: -6.598016835111341, 3: -6.193234601138981, 4: -6.4127854958874515}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -6.490704021186788, 2: -6.703927187899885, 3: -6.193234601138981, 4: -6.4127854958874515}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -5.4533802513862915, 3: -5.896994213920696, 4: -5.6684883264834705}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -6.490704021186788, 2: -6.721817936393685, 3: -5.716562841707075, 4: -6.4127854958874515}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.07575392692136, 3: -5.896994213920696, 4: -5.6684883264834705}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.0672399476021335, 3: -5.896994213920696, 4: -5.6684883264834705}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.146181747851973, 3: -5.896994213920696, 4: -6.058324377099958}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.166600434047316, 3: -5.896994213920696, 4: -6.383230769234371}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -4.865757110781941, 2: -6.71898928921594, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -3.7084645097935356, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -3.7084645097935356, 4: -5.527427675081785}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -5.823387572391601, 2: -6.270066412571752, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.882690548978812, 2: -5.599880297314851, 3: -5.885185014629548, 4: -5.864227449572409}, Best action: 2, Actual action: 2\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -5.500824756151945, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.215472728475433}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.160698266217788, 2: -6.6375332446820146, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -6.022249385463874, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -5.6340073564027655, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 1, Actual action: 1\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84479997739582, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -5.560181107973761, 4: -5.0862420413957175}, Best action: 0, Actual action: 0\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -5.954927509650284, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.156303194831096, 2: -6.474517385069047, 3: -6.230969698540284, 4: -6.815032899321402}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.333401067163432, 1: -5.0042419057000975, 2: -5.254883454333393, 3: -5.560181107973761, 4: -5.0862420413957175}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.787684045431547, 2: -5.752536482581051, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 2, Actual action: 2\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.787684045431547, 2: -5.752536482581051, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.787684045431547, 2: -6.134808199148757, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 1, Actual action: 1\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.787684045431547, 2: -6.231518410618981, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330743906476925, 1: -6.280053351395582, 2: -5.254883454333393, 3: -5.560181107973761, 4: -5.0862420413957175}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.328762497373466, 1: -6.2583094929214145, 2: -5.254883454333393, 3: -5.560181107973761, 4: -5.0862420413957175}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.329506126479385, 1: -6.26647003180666, 2: -5.254883454333393, 3: -5.560181107973761, 4: -5.528480257670103}, Best action: 2, Actual action: 2\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.739574267801937, 2: -6.392374976809007, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 1, Actual action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -5.8478769745218155, 2: -6.414306274919783, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 1, Actual action: 1\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -6.243787367638015, 2: -6.418805687386474, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -6.590911306480614, 2: -6.420079282105855, 3: -6.116625880775895, 4: -6.543637657725252}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1804452530905944, 1: -6.8231706366539395, 2: -6.420931439572788, 3: -6.466129551506064, 4: -6.543637657725252}, Best action: 0, Actual action: 0\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.139545201836753, 2: -6.474517385069047, 3: -6.526873810157478, 4: -6.815032899321402}, Best action: 1, Actual action: 1\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.491076138796829, 1: -6.89088237915011, 2: -6.421179873368426, 3: -6.794450089468872, 4: -6.543637657725252}, Best action: 2, Actual action: 2\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.750076492322449, 1: -6.925735912507901, 2: -6.421307750679868, 3: -6.963447820144339, 4: -6.543637657725252}, Best action: 2, Actual action: 2\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.815298158566309, 1: -6.934512755817716, 2: -6.743422255280621, 3: -7.006004957368457, 4: -6.543637657725252}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.82725981591888, 1: -6.936122429387181, 2: -6.933764547016077, 3: -7.01380993879101, 4: -6.543637657725252}, Best action: 4, Actual action: 4\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.840015737165691, 1: -6.937838986606633, 2: -7.136745723599704, 3: -7.022133177404554, 4: -6.8547102685299794}, Best action: 0, Actual action: 0\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.926106960939083, 2: -6.474517385069047, 3: -6.526883935117238, 4: -6.815032899321402}, Best action: 2, Actual action: 2\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.92580878508571, 2: -6.474517385069047, 3: -6.526883933073013, 4: -6.815032899321402}, Best action: 2, Actual action: 2\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493404200802753, 1: -6.928443552195596, 2: -6.791810820412833, 3: -6.526883951136367, 4: -6.815032899321402}, Best action: 0, Actual action: 0\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.49913690809361, 2: -6.6375332446820146, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 1, Actual action: 1\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8136413156361, 1: -6.929157772908032, 2: -7.068955651045679, 3: -6.526883956032899, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018895151, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 4, Actual action: 4\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018800613, 2: -6.071430732168992, 3: -5.94152447585509, 4: -5.8715911490719}, Best action: 4, Actual action: 4\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018873053, 2: -6.071430732168992, 3: -5.94152447585509, 4: -6.243147945655429}, Best action: 3, Actual action: 3\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018881283, 2: -6.071430732168992, 3: -5.94152447585509, 4: -6.379160373466898}, Best action: 3, Actual action: 3\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.613084296635228, 1: -5.742945223848236, 2: -4.695674249610679, 3: -5.011965319427587, 4: -4.814566704016307}, Best action: 0, Actual action: 0\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.277403638725437, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -5.735025665007315}, Best action: 4, Actual action: 4\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.277403638725437, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -5.735025665007315}, Best action: 4, Actual action: 4\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.277403638725437, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -6.118873355156657}, Best action: 4, Actual action: 4\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.277403638725437, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -6.625360382308713}, Best action: 1, Actual action: 1\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890339, 2: -6.071430732168992, 3: -5.868979507378825, 4: -6.528838276078324}, Best action: 3, Actual action: 3\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.252309994448072, 1: -5.742945223848236, 2: -4.695674249610679, 3: -5.011965319427587, 4: -4.814566704016307}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.241631595465252, 1: -5.742945223848236, 2: -4.695674249610679, 3: -5.011965319427587, 4: -4.814566704016307}, Best action: 2, Actual action: 2\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963266247518938, 1: -6.9294093726201575, 2: -7.166585919099229, 3: -6.51565520587114, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890333, 2: -6.071430732168992, 3: -5.812749743056232, 4: -6.528725348090418}, Best action: 3, Actual action: 3\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250852461228629, 1: -5.742945223848236, 2: -7.212906063328131, 3: -5.011965319427587, 4: -4.814566704016307}, Best action: 4, Actual action: 4\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250541889506479, 1: -5.742945223848236, 2: -7.092390727287078, 3: -5.011965319427587, 4: -4.814566704016307}, Best action: 4, Actual action: 4\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250700800044917, 1: -5.742945223848236, 2: -7.1540549277741725, 3: -5.011965319427587, 4: -5.281255700654839}, Best action: 3, Actual action: 3\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -4.274337884644279, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 2, Actual action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890328, 2: -6.071430732168992, 3: -5.609872441538971, 4: -6.528651291180086}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250771763412602, 1: -5.742945223848236, 2: -7.181591800880405, 3: -5.582101880164647, 4: -5.952784384848907}, Best action: 3, Actual action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -6.011483761827422, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -5.91548705965841, 3: -4.626017743475508, 4: -4.575994430153568}, Best action: 4, Actual action: 4\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -5.959970685338114, 3: -4.626017743475508, 4: -5.064154931439747}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.153018920857214, 1: -5.412524920721961, 2: -3.623333536736053, 3: -4.532902232033064, 4: -3.5540930432190474}, Best action: 4, Actual action: 4\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.153018920857214, 1: -5.412524920721961, 2: -3.623333536736053, 3: -4.532902232033064, 4: -3.5540930432190474}, Best action: 4, Actual action: 4\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.153018920857214, 1: -5.412524920721961, 2: -3.623333536736053, 3: -4.532902232033064, 4: -4.134224669329333}, Best action: 2, Actual action: 2\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250774566855206, 1: -5.742945223848236, 2: -7.182679658542288, 3: -5.3773119401126666, 4: -5.979313454487872}, Best action: 3, Actual action: 3\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250774670924714, 1: -5.742945223848236, 2: -7.182720042037652, 3: -5.395384109993179, 4: -5.980298267665496}, Best action: 3, Actual action: 3\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250774680654677, 1: -5.742945223848236, 2: -7.182723817686761, 3: -5.81148919502539, 4: -5.980390342632325}, Best action: 1, Actual action: 1\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.1644039156759725, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -5.764897783000377}, Best action: 0, Actual action: 0\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2507746836444635, 1: -5.657461694082361, 2: -7.182724977853842, 3: -6.2223261484882055, 4: -5.980418635077524}, Best action: 1, Actual action: 1\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330011758639013, 1: -6.272018807220975, 2: -6.337995956249374, 3: -5.560181107973761, 4: -6.497405046025366}, Best action: 3, Actual action: 3\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.889707824977602, 2: -5.440500194774749, 3: -5.347507256555888, 4: -5.9416749063142165}, Best action: 3, Actual action: 3\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.889707824977602, 2: -5.440500194774749, 3: -5.347507256555888, 4: -5.9416749063142165}, Best action: 3, Actual action: 3\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.436043806299544, 1: -5.889707824977602, 2: -5.440500194774749, 3: -5.766231603465858, 4: -5.9416749063142165}, Best action: 0, Actual action: 0\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.25077468559513, 1: -6.239205273548112, 2: -7.1827257347971445, 3: -6.490373989084306, 4: -5.9804370942954135}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250774685628755, 1: -6.281203334803348, 2: -7.182725747845324, 3: -6.494994594503989, 4: -5.980437412495188}, Best action: 4, Actual action: 4\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.250774685635182, 1: -6.289230624910167, 2: -7.1827257503392845, 3: -6.495877752894266, 4: -6.342198106189664}, Best action: 0, Actual action: 0\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.393515757319005, 3: -2.989788014983063, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.244172915731569, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -6.636793662858732}, Best action: 1, Actual action: 1\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890328, 2: -6.071430732168992, 3: -5.891388179418559, 4: -6.528658225140746}, Best action: 3, Actual action: 3\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890328, 2: -6.071430732168992, 3: -5.891388182198098, 4: -6.5286582251407514}, Best action: 3, Actual action: 3\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.056034018890328, 2: -6.071430732168992, 3: -6.261163254648985, 4: -6.528658225140767}, Best action: 1, Actual action: 1\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330011758639013, 1: -6.272018807220975, 2: -6.337995956249374, 3: -6.0895832308951805, 4: -6.497405046025366}, Best action: 3, Actual action: 3\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.09451189178143, 1: -5.496595934555097, 2: -5.31111679989344, 3: -5.508680202413409, 4: -5.764897783000377}, Best action: 2, Actual action: 2\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.025470216554724, 1: -6.9387123413510015, 2: -7.240019049753839, 3: -7.026367897837564, 4: -7.364686178767792}, Best action: 1, Actual action: 1\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.025470216554724, 1: -6.9387123413510015, 2: -7.240019049753839, 3: -7.026367897837564, 4: -7.364686178767792}, Best action: 1, Actual action: 1\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.025470216554724, 1: -7.214228230629411, 2: -7.240019049753839, 3: -7.026367897837564, 4: -7.364686178767792}, Best action: 0, Actual action: 0\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -6.213640578766585, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -6.2136405787663005, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.47990515934119, 1: -6.2883145546517385, 2: -7.182725750054673, 3: -6.49577696730859, 4: -6.209172073043684}, Best action: 0, Actual action: 0\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -4.930004258380096, 4: -3.7012129152079596}, Best action: 4, Actual action: 4\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -4.930004258380096, 4: -3.7012129152079596}, Best action: 4, Actual action: 4\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.080549830136146, 1: -5.926278273474477, 2: -5.030321684891242, 3: -4.930004258380096, 4: -4.2681037528392425}, Best action: 0, Actual action: 0\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.472664082772328, 1: -6.268957713558427, 2: -6.06312923738645, 3: -5.434961935994421, 4: -5.513193387245418}, Best action: 3, Actual action: 3\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -3.712944978627115, 2: -4.352644839696327, 3: -5.735818118674249, 4: -3.840998797883056}, Best action: 1, Actual action: 1\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -4.3010959840934815, 2: -4.204119850375878, 3: -3.852096506209293, 4: -4.7896215518954754}, Best action: 3, Actual action: 3\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -4.3010959840934815, 2: -4.204119850375878, 3: -3.852096506209293, 4: -4.7896215518954754}, Best action: 3, Actual action: 3\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -3.5257642015435273, 2: -4.307665894661952, 3: -3.6003930807804894, 4: -4.205423837325841}, Best action: 1, Actual action: 1\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883453718441717, 1: -3.856141471466209, 2: -3.6978975622847736, 3: -5.08842318169823, 4: -3.703309531013778}, Best action: 2, Actual action: 2\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -5.965608691816427, 3: -4.733032099378251, 4: -5.263517452849398}, Best action: 3, Actual action: 3\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -5.96560869181643, 3: -4.733032099378458, 4: -5.263517452849533}, Best action: 3, Actual action: 3\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.901694718098138, 1: -6.288314300462087, 2: -7.182725750054594, 3: -6.495776939342772, 4: -6.209135161201204}, Best action: 0, Actual action: 0\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.554819572321734, 2: -6.4126252679704585, 3: -6.386821889504156, 4: -6.636793662958748}, Best action: 3, Actual action: 3\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.166258184659604, 2: -6.393515757319005, 3: -6.396549866546752, 4: -6.852032107854823}, Best action: 1, Actual action: 1\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -4.787263913616074, 2: -5.965608691816431, 3: -6.601220347624678, 4: -5.263517452849572}, Best action: 1, Actual action: 1\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.242422226506176, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -5.4613303512345315, 4: -5.123241110237471}, Best action: 0, Actual action: 0\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.475760710034278, 1: -6.288314300481149, 2: -7.182725750054594, 3: -6.49577693934487, 4: -6.209135163969329}, Best action: 4, Actual action: 4\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.56233987341877, 1: -6.288314300481981, 2: -7.182725750054594, 3: -6.495776939344961, 4: -6.209135164090187}, Best action: 4, Actual action: 4\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.568635998158685, 1: -6.288314300482042, 2: -7.182725750054594, 3: -6.495776939344967, 4: -6.550312999330859}, Best action: 1, Actual action: 1\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0945196087971345, 1: -5.496595934555097, 2: -7.158569157046236, 3: -5.508680202413409, 4: -5.764897783000377}, Best action: 1, Actual action: 1\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330011758639013, 1: -6.272018807220975, 2: -6.337995956249374, 3: -6.642360455468325, 4: -6.497405046025366}, Best action: 1, Actual action: 1\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330011758639013, 1: -6.272018807220975, 2: -6.337995956249374, 3: -6.642360455916076, 4: -6.497405046025366}, Best action: 1, Actual action: 1\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.330011758639013, 1: -6.607537114571087, 2: -6.337995956249374, 3: -6.6423604559814935, 4: -6.497405046025366}, Best action: 0, Actual action: 0\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -5.36490073209081, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -5.364900728978597, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.686872072325726, 2: -6.071430732168992, 3: -6.919778997276592, 4: -6.528658225140776}, Best action: 2, Actual action: 2\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -6.672367198066926, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57031326915391, 1: -6.5188085032285406, 2: -7.182725750054594, 3: -6.495776939344969, 4: -6.843177148414667}, Best action: 3, Actual action: 3\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -5.85260742955199, 2: -5.965608691816431, 3: -6.562566141375704, 4: -5.263517452849571}, Best action: 4, Actual action: 4\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -5.852586244747664, 2: -5.965608691816431, 3: -6.5625648817471, 4: -5.263517452849571}, Best action: 4, Actual action: 4\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6361614273001726, 1: -5.852592196894599, 2: -5.965608691816431, 3: -6.5625652356561766, 4: -5.68980088209311}, Best action: 0, Actual action: 0\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -5.873708289953769, 2: -6.393515757319005, 3: -6.396549866578593, 4: -6.852032107854823}, Best action: 1, Actual action: 1\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5703101111701985, 1: -6.51796343389208, 2: -7.182725750054594, 3: -6.127932103214078, 4: -6.842625740672622}, Best action: 3, Actual action: 3\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.481098950245398, 1: -5.852596750349949, 2: -5.965608691816431, 3: -6.562565506400363, 4: -6.7406040610474145}, Best action: 1, Actual action: 1\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -5.889707824977602, 2: -5.440500194774749, 3: -6.580773207317697, 4: -5.9416749063142165}, Best action: 2, Actual action: 2\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.247073422311412, 1: -6.6701827261235795, 2: -6.337995956249374, 3: -6.642360455985284, 4: -6.497405046025366}, Best action: 0, Actual action: 0\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.68687207232894, 2: -6.691660355109687, 3: -6.919778997278689, 4: -6.528658225140776}, Best action: 0, Actual action: 4\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431471466281061, 1: -6.68687207232894, 2: -6.691853007123417, 3: -6.919778997278689, 4: -6.528658225140776}, Best action: 0, Actual action: 0\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.388953588602762, 1: -6.554819589949886, 2: -6.4126252679704585, 3: -6.401704395887898, 4: -6.636793662958748}, Best action: 0, Actual action: 0\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.049895251598431, 3: -6.271774952456184, 4: -6.871100181163758}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.049895251598431, 3: -6.271774952456184, 4: -6.871100181163758}, Best action: 3, Actual action: 3\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.049895251598431, 3: -6.6073152067351275, 4: -6.871100181163758}, Best action: 3, Actual action: 3\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.215472728475433}, Best action: 4, Actual action: 4\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.215472728475433}, Best action: 4, Actual action: 4\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.556080182912644}, Best action: 2, Actual action: 2\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -6.4097133592020095, 3: -6.483139296814383, 4: -6.833603884594404}, Best action: 2, Actual action: 2\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.049895251598431, 3: -6.737662401391626, 4: -6.871100181163758}, Best action: 3, Actual action: 3\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -7.164868547587947, 3: -6.483139296814383, 4: -7.131929419194876}, Best action: 3, Actual action: 3\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.761184113607379, 2: -7.049895251598431, 3: -6.829240514095857, 4: -6.871100181163758}, Best action: 1, Actual action: 1\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5707331131562245, 1: -6.831679761805403, 2: -6.6375332446820146, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 0, Actual action: 0\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816508183171856, 1: -6.89841223301728, 2: -7.049895251598431, 3: -7.109090426634769, 4: -6.871100181163758}, Best action: 0, Actual action: 0\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -6.726945599602881, 3: -6.911256016474799, 4: -6.630076161165276}, Best action: 4, Actual action: 4\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -6.726945599602881, 3: -6.911256016474799, 4: -6.630076161165276}, Best action: 4, Actual action: 4\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -6.726945599602881, 3: -6.911256016474799, 4: -6.933369306660401}, Best action: 2, Actual action: 2\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -6.726945599602881, 3: -6.911256016474799, 4: -7.091119968202162}, Best action: 2, Actual action: 2\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.81114726503104, 2: -7.0215204956386215, 3: -6.911256016474799, 4: -7.283330087865483}, Best action: 1, Actual action: 1\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.592545460187336, 2: -7.426149946951219, 3: -7.21904066331106, 4: -7.184838902565938}, Best action: 1, Actual action: 1\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.816417890428412, 1: -6.554819589949886, 2: -6.4126252679704585, 3: -6.401704396912906, 4: -6.636793662958748}, Best action: 3, Actual action: 3\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475179532501034, 1: -5.926278273474477, 2: -5.030321684891242, 3: -4.930004258380096, 4: -5.705830011672023}, Best action: 3, Actual action: 3\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.11482791506714, 1: -4.3010959840934815, 2: -4.204119850375878, 3: -5.104488427592336, 4: -4.7896215518954754}, Best action: 0, Actual action: 0\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.472664082772328, 1: -6.268957713558427, 2: -6.06312923738645, 3: -4.912307227843173, 4: -5.513193387245418}, Best action: 3, Actual action: 3\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.834838877199498, 1: -5.882690548978812, 2: -6.406930399030484, 3: -5.885185014629548, 4: -5.864227449572409}, Best action: 0, Actual action: 0\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -6.381414343836224, 2: -6.270066412571752, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 2, Actual action: 2\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -6.381414343836224, 2: -6.270066412571752, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 2, Actual action: 2\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -7.058238690361506, 2: -6.910768495170282, 3: -6.160412280145308, 4: -7.0781379521638295}, Best action: 3, Actual action: 3\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -6.381414343836224, 2: -6.525647290221374, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 1, Actual action: 1\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -6.486055561580825, 2: -7.426180562826213, 3: -7.219144931935988, 4: -7.184845102280624}, Best action: 1, Actual action: 1\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150157587901, 1: -6.831679761805403, 2: -6.6375332446820146, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 2, Actual action: 2\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150715740638, 1: -6.831679761805403, 2: -6.6375332446820146, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 2, Actual action: 2\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150889011587, 1: -6.831679761805403, 2: -6.940155252660634, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 1, Actual action: 1\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -6.58870731325094, 4: -6.815032899321402}, Best action: 3, Actual action: 3\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.910558461914772, 1: -6.68687207232894, 2: -6.691921850645765, 3: -6.919778997278689, 4: -6.9779468582369075}, Best action: 1, Actual action: 1\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6228219163133275, 1: -7.093347143094038, 2: -7.240019049753839, 3: -7.026367897837564, 4: -7.364686178767792}, Best action: 0, Actual action: 0\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -7.086072509114523, 4: -6.815032899321402}, Best action: 4, Actual action: 4\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -7.179148986177612, 4: -6.815032899321402}, Best action: 4, Actual action: 4\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -6.929409405161572, 2: -7.1665985464070285, 3: -7.205269697612053, 4: -7.101679938382476}, Best action: 1, Actual action: 1\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.236015216570572, 1: -7.093347143094038, 2: -7.240019049753839, 3: -7.026367897837564, 4: -7.364686178767792}, Best action: 3, Actual action: 3\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.094519608797137, 1: -6.689735704106776, 2: -7.158569157537623, 3: -5.508680202413409, 4: -5.764897783000377}, Best action: 3, Actual action: 3\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -5.889707824977602, 2: -6.849761922714015, 3: -6.580773207317697, 4: -5.9416749063142165}, Best action: 1, Actual action: 1\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.015131552606785, 1: -6.670246130953081, 2: -6.337995956249374, 3: -6.642360455985288, 4: -6.497405046025366}, Best action: 2, Actual action: 2\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.248159907132078, 1: -7.093347143094038, 2: -7.240019049753839, 3: -6.53389130958716, 4: -7.364686178767792}, Best action: 3, Actual action: 3\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -6.826251556390537, 3: -6.642360455985288, 4: -6.497405046025366}, Best action: 4, Actual action: 4\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -6.935310337201024, 3: -6.642360455985288, 4: -6.497405046025366}, Best action: 4, Actual action: 4\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -6.999145130237212, 3: -6.642360455985288, 4: -6.812638591883084}, Best action: 3, Actual action: 3\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -7.012717035927245, 3: -6.642360455985288, 4: -7.028597585030381}, Best action: 3, Actual action: 3\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.25072743724458, 1: -7.093347143094038, 2: -7.240019049753839, 3: -7.038409024185933, 4: -7.364686178767792}, Best action: 3, Actual action: 3\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.094519608797137, 1: -6.689735704106776, 2: -7.158569157537623, 3: -6.6918511761095525, 4: -5.764897783000377}, Best action: 4, Actual action: 4\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.094519608797137, 1: -6.689735704106776, 2: -7.158569157537623, 3: -6.690542141000754, 4: -5.764897783000377}, Best action: 4, Actual action: 4\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.094519608797137, 1: -6.689735704106776, 2: -7.158569157537623, 3: -6.690830556788779, 4: -6.146056982530343}, Best action: 0, Actual action: 0\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.570310199360194, 1: -6.5179870333361, 2: -7.182725750054594, 3: -6.566415674606222, 4: -6.842641139309846}, Best action: 1, Actual action: 1\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.789021457881955, 1: -6.689735704106776, 2: -7.158569157537623, 3: -6.691040865537421, 4: -7.041628357388327}, Best action: 1, Actual action: 1\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -7.027738430214852, 3: -7.151195796255087, 4: -7.267621142967613}, Best action: 1, Actual action: 1\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.670246130953081, 2: -7.027781661490765, 3: -7.154592858360104, 4: -7.268309048043879}, Best action: 1, Actual action: 1\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -6.969923979167303, 2: -7.027802325034653, 3: -7.156216574996114, 4: -7.268637850662671}, Best action: 1, Actual action: 1\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0151315526067854, 1: -7.36534889988597, 2: -7.027810786755875, 3: -7.156881486958561, 4: -7.2687724953350665}, Best action: 0, Actual action: 0\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.910558461917019, 1: -7.215734986509143, 2: -6.691921850645765, 3: -6.919778997278689, 4: -6.977946858237919}, Best action: 2, Actual action: 2\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.963285599714796, 1: -7.090971167550081, 2: -7.1665985464070285, 3: -7.213225421325138, 4: -7.382998015114114}, Best action: 0, Actual action: 0\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049045461, 2: -7.45307725060309, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 4, Actual action: 4\n",
      "Step: 242\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049181525, 2: -7.453077250691871, 3: -7.038616380381967, 4: -7.013593238338058}, Best action: 4, Actual action: 4\n",
      "Step: 243\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049233926, 2: -7.453077250726063, 3: -7.038616380381967, 4: -7.282369846887632}, Best action: 3, Actual action: 3\n",
      "Step: 244\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -6.554819589949886, 2: -6.4126252679704585, 3: -5.8282625127609835, 4: -6.636793662958748}, Best action: 3, Actual action: 3\n",
      "Step: 245\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -6.393515757319005, 3: -6.396549866578594, 4: -6.852032107854823}, Best action: 2, Actual action: 2\n",
      "Step: 246\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -6.393515757319005, 3: -6.396549866578594, 4: -6.852032107854823}, Best action: 2, Actual action: 2\n",
      "Step: 247\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049227279, 2: -7.4530772507217256, 3: -6.765472624572035, 4: -7.172505834791912}, Best action: 3, Actual action: 3\n",
      "Step: 248\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.20105404922848, 2: -7.453077250722509, 3: -6.795884993779594, 4: -7.192349905699844}, Best action: 3, Actual action: 3\n",
      "Step: 249\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228947, 2: -7.453077250722814, 3: -7.096080331027075, 4: -7.200065709513532}, Best action: 3, Actual action: 3\n",
      "Step: 250\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.4669286600084535, 3: -6.396549866578594, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 251\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475179532501034, 1: -5.926278273474477, 2: -5.030321684891242, 3: -5.58509008900635, 4: -5.705830011672023}, Best action: 2, Actual action: 2\n",
      "Step: 252\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -6.554819589949886, 2: -6.4126252679704585, 3: -6.89371145240379, 4: -6.636793662958748}, Best action: 2, Actual action: 2\n",
      "Step: 253\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228913, 2: -7.4530772507227905, 3: -6.341519073890234, 4: -7.199498778283316}, Best action: 3, Actual action: 3\n",
      "Step: 254\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.379557414695661, 3: -6.373053890221274, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 255\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.475179532501034, 1: -5.926278273474477, 2: -6.7811608433104915, 3: -5.58509008900635, 4: -5.705830011672023}, Best action: 0, Actual action: 0\n",
      "Step: 256\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.472664082772328, 1: -6.268957713558427, 2: -6.06312923738645, 3: -6.542175736570636, 4: -5.513193387245418}, Best action: 0, Actual action: 0\n",
      "Step: 257\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -7.204896847448358, 4: -5.527427675081785}, Best action: 2, Actual action: 2\n",
      "Step: 258\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -5.271645682276203, 3: -7.204896847448358, 4: -5.527427675081785}, Best action: 2, Actual action: 2\n",
      "Step: 259\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.280647029121623, 1: -7.058238690361506, 2: -6.910768495170282, 3: -7.000594406184895, 4: -7.0781379521638295}, Best action: 0, Actual action: 0\n",
      "Step: 260\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.317806219000864, 1: -6.3816390914713645, 2: -6.72034728465569, 3: -6.652690002948506, 4: -6.747388026427253}, Best action: 0, Actual action: 0\n",
      "Step: 261\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -6.239076618444486, 2: -6.528138887728478, 3: -6.282467574969518, 4: -6.588015558081064}, Best action: 1, Actual action: 1\n",
      "Step: 262\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5854326828401195, 1: -6.3816390914713645, 2: -6.72034728465569, 3: -6.652690002948506, 4: -6.747388026427253}, Best action: 1, Actual action: 1\n",
      "Step: 263\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.85784628729761, 1: -7.058238690361506, 2: -6.910768495170282, 3: -7.000594406184895, 4: -7.0781379521638295}, Best action: 0, Actual action: 0\n",
      "Step: 264\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -6.608161463352199, 3: -6.696830601736252, 4: -6.888878627490244}, Best action: 2, Actual action: 2\n",
      "Step: 265\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -6.608161463352199, 3: -6.696830601736252, 4: -6.888878627490244}, Best action: 2, Actual action: 2\n",
      "Step: 266\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -6.913426931650501, 3: -6.696830601736252, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 267\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -7.061832327585825, 3: -6.696830601736252, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 268\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.371943381804916, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.389503595242064, 4: -6.4127854958874515}, Best action: 0, Actual action: 0\n",
      "Step: 269\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -5.776347261534426, 4: -6.325466667244228}, Best action: 3, Actual action: 3\n",
      "Step: 270\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -5.224384489993054, 4: -5.429126215476942}, Best action: 3, Actual action: 3\n",
      "Step: 271\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -5.762037644602957, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 4, Actual action: 4\n",
      "Step: 272\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -5.762037644602957, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.484802904935068}, Best action: 4, Actual action: 4\n",
      "Step: 273\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -5.762037644602957, 2: -6.336501109080629, 3: -6.125113614983136, 4: -5.891170643490912}, Best action: 1, Actual action: 1\n",
      "Step: 274\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -5.05445591968576, 2: -6.71898928921594, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 1, Actual action: 1\n",
      "Step: 275\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 4, Actual action: 4\n",
      "Step: 276\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.489939074113051, 4: -6.478683630929845}, Best action: 4, Actual action: 4\n",
      "Step: 277\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.489939074113051, 4: -6.795602104146159}, Best action: 3, Actual action: 3\n",
      "Step: 278\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -7.368189474852819, 3: -7.204896847448358, 4: -5.527427675081785}, Best action: 4, Actual action: 4\n",
      "Step: 279\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -7.368189301604199, 3: -7.204896847448358, 4: -5.527427675081785}, Best action: 4, Actual action: 4\n",
      "Step: 280\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.631016808528666, 1: -5.792817773184844, 2: -7.368189369277624, 3: -7.204896847448358, 4: -5.929959184324424}, Best action: 0, Actual action: 0\n",
      "Step: 281\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.951799026280492, 1: -7.182058474528537, 2: -6.72034728465569, 3: -6.652690002948506, 4: -6.747388026427253}, Best action: 3, Actual action: 3\n",
      "Step: 282\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9517991678213775, 1: -7.182059173495873, 2: -6.72034728465569, 3: -6.652690002948506, 4: -6.747388026427253}, Best action: 3, Actual action: 3\n",
      "Step: 283\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.951799183539521, 1: -7.182059251116332, 2: -6.72034728465569, 3: -6.95394790268314, 4: -6.747388026427253}, Best action: 2, Actual action: 2\n",
      "Step: 284\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -7.187601121757457, 3: -6.6572771871286, 4: -6.888878627490244}, Best action: 3, Actual action: 3\n",
      "Step: 285\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.951799188112365, 1: -7.182059273698277, 2: -6.964429250039735, 3: -7.23635725792284, 4: -6.747388026427253}, Best action: 4, Actual action: 4\n",
      "Step: 286\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.95179918988974, 1: -7.1820592824754375, 2: -7.132654519601872, 3: -7.346124246312135, 4: -6.747388026427253}, Best action: 4, Actual action: 4\n",
      "Step: 287\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.951799190516048, 1: -7.182059285568314, 2: -7.191933372820236, 3: -7.384803698037117, 4: -7.0401231040488}, Best action: 0, Actual action: 0\n",
      "Step: 288\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.860239993682824, 1: -6.938871669800335, 2: -7.22472798010381, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 0, Actual action: 0\n",
      "Step: 289\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.18644598825023, 2: -7.105223439320772, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 2, Actual action: 2\n",
      "Step: 290\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.18644598825023, 2: -7.105223439320772, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 2, Actual action: 2\n",
      "Step: 291\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.144079099720245, 1: -7.18644598825023, 2: -7.365753329781903, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 0, Actual action: 0\n",
      "Step: 292\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.318715394479122, 1: -7.443820208912295, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.2503555554523915}, Best action: 4, Actual action: 4\n",
      "Step: 293\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.318715394479122, 1: -7.443820208912295, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.2503555554523915}, Best action: 4, Actual action: 4\n",
      "Step: 294\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.318715394479122, 1: -7.443820208912295, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.497823555461676}, Best action: 0, Actual action: 0\n",
      "Step: 295\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.139410098558595, 3: -6.9149844642082305, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 296\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.139410098558595, 3: -6.9149844642082305, 4: -7.195711279233019}, Best action: 3, Actual action: 3\n",
      "Step: 297\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.1170891900672375, 3: -7.29921139702996, 4: -7.288607117515974}, Best action: 2, Actual action: 2\n",
      "Step: 298\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.139410098558595, 3: -7.4702673156929755, 4: -7.195711279233019}, Best action: 2, Actual action: 2\n",
      "Step: 299\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.139410098558595, 3: -7.651363411166671, 4: -7.195711279233019}, Best action: 2, Actual action: 2\n",
      "Step: 300\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.396863189688322, 3: -7.726958075049637, 4: -7.195711279233019}, Best action: 4, Actual action: 4\n",
      "Step: 301\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.500319624604243, 3: -7.736385542681351, 4: -7.195711279233019}, Best action: 4, Actual action: 4\n",
      "Step: 302\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.665001479731284, 3: -7.751392176729802, 4: -7.4480972641020475}, Best action: 0, Actual action: 0\n",
      "Step: 303\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.272545481468842, 1: -7.436395112164522, 2: -7.690686121743511, 3: -7.753732689733167, 4: -7.574935002434031}, Best action: 0, Actual action: 0\n",
      "Step: 304\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.518016388136647, 1: -7.436395112164522, 2: -7.723120499480161, 3: -7.7566882724044195, 4: -7.735104769034773}, Best action: 1, Actual action: 1\n",
      "Step: 305\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -6.564711870710831, 2: -7.187789270437362, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 1, Actual action: 1\n",
      "Step: 306\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625530172332142, 1: -7.18644598825023, 2: -7.76331296191721, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 1, Actual action: 1\n",
      "Step: 307\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015729052213, 1: -6.938871669800335, 2: -7.22472798010381, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 3, Actual action: 3\n",
      "Step: 308\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015758943064, 1: -6.938871669800335, 2: -7.22472798010381, 3: -6.938279630223781, 4: -7.111078648156045}, Best action: 3, Actual action: 3\n",
      "Step: 309\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015829941012, 1: -6.938871669800335, 2: -7.22472798010381, 3: -7.213834463503641, 4: -7.111078648156045}, Best action: 1, Actual action: 1\n",
      "Step: 310\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -6.7904421630016065, 2: -7.187601544849178, 3: -7.247350273896927, 4: -6.888878627490244}, Best action: 1, Actual action: 1\n",
      "Step: 311\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.862403204696428, 1: -6.873394909012967, 2: -7.203745299307384, 3: -6.911256016474799, 4: -7.320230610608408}, Best action: 0, Actual action: 0\n",
      "Step: 312\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.871599754799979, 1: -7.137590812104268, 2: -7.187601544849178, 3: -7.247350274563363, 4: -6.888878627490244}, Best action: 0, Actual action: 0\n",
      "Step: 313\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015852505765, 1: -7.309053376832675, 2: -7.22472798010381, 3: -7.496028828650484, 4: -7.111078648156045}, Best action: 4, Actual action: 4\n",
      "Step: 314\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015854766668, 1: -7.35238640581085, 2: -7.22472798010381, 3: -7.524303630058743, 4: -7.111078648156045}, Best action: 4, Actual action: 4\n",
      "Step: 315\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015855322945, 1: -7.363048150617415, 2: -7.22472798010381, 3: -7.531260418545026, 4: -7.371081569822001}, Best action: 2, Actual action: 2\n",
      "Step: 316\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5140158554366066, 1: -7.365226620482388, 2: -7.22472798010381, 3: -7.5326818701319205, 4: -7.542263133836214}, Best action: 2, Actual action: 2\n",
      "Step: 317\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015855544821, 1: -7.3673006892382835, 2: -7.474502461894467, 3: -7.5340351999951425, 4: -7.705240983204618}, Best action: 1, Actual action: 1\n",
      "Step: 318\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.516561878654805, 1: -7.398620454907409, 2: -7.187601544849178, 3: -7.247350274814677, 4: -6.888878627490244}, Best action: 4, Actual action: 4\n",
      "Step: 319\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.513774557207656, 1: -7.398056022314361, 2: -7.187601544849178, 3: -7.247350274814133, 4: -6.888878627490244}, Best action: 4, Actual action: 4\n",
      "Step: 320\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.516099619251398, 1: -7.3985268473782195, 2: -7.187601544849178, 3: -7.247350274814586, 4: -7.168879551016122}, Best action: 4, Actual action: 4\n",
      "Step: 321\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.51705173215831, 1: -7.398719650241869, 2: -7.187601544849178, 3: -7.247350274814772, 4: -7.538340769608519}, Best action: 2, Actual action: 2\n",
      "Step: 322\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5169465544884195, 1: -7.398698351763716, 2: -7.187601544849178, 3: -7.247350274814751, 4: -7.4349778178274954}, Best action: 2, Actual action: 2\n",
      "Step: 323\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5171380823607405, 1: -7.3987371361578615, 2: -7.440717405812752, 3: -7.247350274814789, 4: -7.623201099936533}, Best action: 3, Actual action: 3\n",
      "Step: 324\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019147, 1: -7.182059287552418, 2: -7.2299611992946975, 3: -7.409616854811703, 4: -7.645229807894827}, Best action: 1, Actual action: 1\n",
      "Step: 325\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.058238690361506, 2: -6.910768495170282, 3: -7.000594406184895, 4: -7.0781379521638295}, Best action: 2, Actual action: 2\n",
      "Step: 326\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442754149888914, 1: -6.873394909012967, 2: -7.203745299307384, 3: -6.911256016474799, 4: -7.320230610608408}, Best action: 1, Actual action: 1\n",
      "Step: 327\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142521606436949, 1: -7.1929002731663285, 2: -7.049895251598431, 3: -7.17054268534566, 4: -6.871100181163758}, Best action: 4, Actual action: 4\n",
      "Step: 328\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142521606436949, 1: -7.1929002731663285, 2: -7.049895251598431, 3: -7.17054268534566, 4: -6.871100181163758}, Best action: 4, Actual action: 4\n",
      "Step: 329\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142521606436949, 1: -7.1929002731663285, 2: -7.049895251598431, 3: -7.17054268534566, 4: -7.15270116485902}, Best action: 2, Actual action: 2\n",
      "Step: 330\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142521606436949, 1: -7.1929002731663285, 2: -7.049895251598431, 3: -7.17054268534566, 4: -7.403528117720357}, Best action: 2, Actual action: 2\n",
      "Step: 331\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142521606436949, 1: -7.1929002731663285, 2: -7.315404678954573, 3: -7.17054268534566, 4: -7.576773019070239}, Best action: 0, Actual action: 0\n",
      "Step: 332\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760560230832, 1: -7.343040252983173, 2: -7.203745299307384, 3: -6.911256016474799, 4: -7.320230610608408}, Best action: 3, Actual action: 3\n",
      "Step: 333\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760568329318, 1: -7.344329143693792, 2: -7.203745299307384, 3: -6.911256016474799, 4: -7.320230610608408}, Best action: 3, Actual action: 3\n",
      "Step: 334\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.3618864082226105, 4: -6.77122043628769}, Best action: 3, Actual action: 3\n",
      "Step: 335\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -5.792817773184844, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 336\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.142160416560202, 1: -6.268957713558427, 2: -6.06312923738645, 3: -6.542175736570636, 4: -5.513193387245418}, Best action: 4, Actual action: 4\n",
      "Step: 337\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.142160416560202, 1: -6.268957713558427, 2: -6.06312923738645, 3: -6.542175736570636, 4: -5.513193387245418}, Best action: 4, Actual action: 4\n",
      "Step: 338\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.142160416560202, 1: -6.268957713558427, 2: -6.06312923738645, 3: -6.542175736570636, 4: -5.917005982393331}, Best action: 4, Actual action: 4\n",
      "Step: 339\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.142160416560202, 1: -6.268957713558427, 2: -6.06312923738645, 3: -6.542175736570636, 4: -6.449836701691001}, Best action: 2, Actual action: 2\n",
      "Step: 340\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -5.882690548978812, 2: -6.406930399030484, 3: -5.885185014629548, 4: -5.864227449572409}, Best action: 4, Actual action: 4\n",
      "Step: 341\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -5.882690548978812, 2: -6.406930399030484, 3: -5.885185014629548, 4: -5.864227449572409}, Best action: 4, Actual action: 4\n",
      "Step: 342\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -5.882690548978812, 2: -6.406930399030484, 3: -5.885185014629548, 4: -6.236446979110893}, Best action: 1, Actual action: 1\n",
      "Step: 343\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.288543251725082, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 344\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.288543251725082, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 345\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -5.926278273474477, 2: -6.771221194485513, 3: -5.58509008900635, 4: -5.705830011672023}, Best action: 3, Actual action: 3\n",
      "Step: 346\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -5.844803130021662, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 347\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -4.3010959840934815, 2: -4.204119850375878, 3: -5.104488427592336, 4: -4.7896215518954754}, Best action: 2, Actual action: 2\n",
      "Step: 348\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -4.544274626385894, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 349\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -5.926278273474477, 2: -6.771221194485513, 3: -5.763884944975442, 4: -5.705830011672023}, Best action: 4, Actual action: 4\n",
      "Step: 350\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -5.926278273474477, 2: -6.771221194485513, 3: -5.856306782371386, 4: -5.705830011672023}, Best action: 4, Actual action: 4\n",
      "Step: 351\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -5.926278273474477, 2: -6.771221194485513, 3: -5.872154685098935, 4: -6.092305310621541}, Best action: 3, Actual action: 3\n",
      "Step: 352\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.552018208716814, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 353\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -5.926278273474477, 2: -6.771221194485513, 3: -6.802303921824805, 4: -6.943546428142502}, Best action: 1, Actual action: 1\n",
      "Step: 354\n",
      "---------------------------------\n",
      "State: (8, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.153018920857214, 1: -5.412524920721961, 2: -5.899886523249604, 3: -4.532902232033064, 4: -5.785117538451144}, Best action: 0, Actual action: 0\n",
      "Step: 355\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -4.856573153241791, 2: -6.771221194485513, 3: -6.451545387416853, 4: -6.716561315616097}, Best action: 1, Actual action: 1\n",
      "Step: 356\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.56357627986519, 1: -6.526232789904323, 2: -5.965608691816431, 3: -6.562565520266416, 4: -6.79442051862433}, Best action: 2, Actual action: 2\n",
      "Step: 357\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.910558461917019, 1: -7.215734989947958, 2: -7.400008828693702, 3: -6.919778997278689, 4: -6.977946858237919}, Best action: 0, Actual action: 0\n",
      "Step: 358\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -6.66961547074168, 4: -7.199689647729596}, Best action: 3, Actual action: 3\n",
      "Step: 359\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -6.554819589949886, 2: -6.799208732282278, 3: -6.900216662080747, 4: -6.636793662958748}, Best action: 1, Actual action: 1\n",
      "Step: 360\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.086481852378816, 1: -7.215734989947958, 2: -7.400008828693702, 3: -6.919778997278689, 4: -6.977946858237919}, Best action: 3, Actual action: 3\n",
      "Step: 361\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.570310199360194, 1: -7.187078381137176, 2: -7.182725750054594, 3: -6.566415674606222, 4: -6.842641139309846}, Best action: 3, Actual action: 3\n",
      "Step: 362\n",
      "---------------------------------\n",
      "State: (8, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.56357627986519, 1: -6.526232789904323, 2: -7.22810240821094, 3: -6.562565520266416, 4: -6.79442051862433}, Best action: 1, Actual action: 1\n",
      "Step: 363\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -5.4613303512345315, 4: -5.123241110237471}, Best action: 4, Actual action: 4\n",
      "Step: 364\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -5.4613303512345315, 4: -5.123241110237471}, Best action: 4, Actual action: 4\n",
      "Step: 365\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -5.4613303512345315, 4: -5.562149410316098}, Best action: 3, Actual action: 3\n",
      "Step: 366\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -5.4613303512345315, 4: -6.022876927378547}, Best action: 3, Actual action: 3\n",
      "Step: 367\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.333193852195059, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -3.081244103506604}, Best action: 1, Actual action: 1\n",
      "Step: 368\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.333193852195059, 1: -3.0712664353383463, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -3.081244103506604}, Best action: 1, Actual action: 1\n",
      "Step: 369\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.333193852195059, 1: -3.6948524561578955, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -3.081244103506604}, Best action: 4, Actual action: 4\n",
      "Step: 370\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.333193852195059, 1: -3.796991200440348, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -3.081244103506604}, Best action: 4, Actual action: 4\n",
      "Step: 371\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.333193852195059, 1: -4.203295140461923, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -3.70393213419101}, Best action: 0, Actual action: 0\n",
      "Step: 372\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883453718441717, 1: -3.856141471466209, 2: -5.506161424107597, 3: -5.08842318169823, 4: -3.703309531013778}, Best action: 4, Actual action: 4\n",
      "Step: 373\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883453718441717, 1: -3.856141471466209, 2: -5.506161424107597, 3: -5.08842318169823, 4: -3.703309531013778}, Best action: 4, Actual action: 4\n",
      "Step: 374\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883453718441717, 1: -3.856141471466209, 2: -5.506161424107597, 3: -5.08842318169823, 4: -4.2700116732225375}, Best action: 1, Actual action: 1\n",
      "Step: 375\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.524560046747045, 1: -4.438918305673295, 2: -3.4408574194138493, 3: -4.455254978136371, 4: -4.867503320420009}, Best action: 2, Actual action: 2\n",
      "Step: 376\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -3.680001435066191, 4: -5.845973942629461}, Best action: 3, Actual action: 3\n",
      "Step: 377\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.576444840583591, 1: -4.44577390833891, 2: -4.2248869043449995, 3: -4.455254978136371, 4: -4.901358148398355}, Best action: 2, Actual action: 2\n",
      "Step: 378\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.690742925492109, 4: -5.8462490578497635}, Best action: 3, Actual action: 3\n",
      "Step: 379\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.910587984082863, 4: -5.8462710273664555}, Best action: 3, Actual action: 3\n",
      "Step: 380\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600837133615204, 1: -4.448996892507544, 2: -5.514154872594471, 3: -4.455254978136371, 4: -4.917274119601482}, Best action: 1, Actual action: 1\n",
      "Step: 381\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.827083087391841, 4: -5.846276551034103}, Best action: 3, Actual action: 3\n",
      "Step: 382\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600754841582404, 1: -5.254908422053657, 2: -5.502237849172716, 3: -4.455254978136371, 4: -4.91722042405008}, Best action: 3, Actual action: 3\n",
      "Step: 383\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -1.641694893386122, 4: -3.7235654418916977}, Best action: 3, Actual action: 3\n",
      "Step: 384\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -4.471915128541488, 3: -2.6230828486771616, 4: -3.0854423103886233}, Best action: 3, Actual action: 3\n",
      "Step: 385\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4407399979726616, 1: -2.0972733863607456, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 386\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4407399979726616, 1: -2.0972733863607456, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 387\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -2.6145387959007156, 2: -2.4276456642156568, 3: -2.7137680430528626, 4: -3.7235654418916977}, Best action: 2, Actual action: 2\n",
      "Step: 388\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.225348243554059, 4: -5.846278223181004}, Best action: 3, Actual action: 3\n",
      "Step: 389\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459676153766, 1: -4.864790156817364, 2: -5.459493816649746, 3: -3.281501916486079, 4: -4.917027828607893}, Best action: 3, Actual action: 3\n",
      "Step: 390\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -2.6145387959007156, 2: -4.445705495036727, 3: -2.983909920023307, 4: -3.7235654418916977}, Best action: 1, Actual action: 1\n",
      "Step: 391\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459376036203, 1: -4.864393493348352, 2: -5.459450355479811, 3: -3.3459540939478156, 4: -4.917027632781183}, Best action: 3, Actual action: 3\n",
      "Step: 392\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7737354828479597, 1: -3.8716766956878024, 2: -4.5737103759049305, 3: -2.989158920169409, 4: -3.7235654418916977}, Best action: 0, Actual action: 0\n",
      "Step: 393\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.30537731988926975, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.0834966478199073}, Best action: 0, Actual action: 0\n",
      "Step: 394\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -3.6003930807804894, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 395\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -3.6003930807804894, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 396\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.60 -5.61 -4.99 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-5.17 -5.01 -5.25 -5.98 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-4.08 -4.57 -4.75 -5.04 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-3.23 -3.53 -3.14 -4.24 -6.13 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-1.83 -3.08 -3.24 -3.24 -4.18 -5.24 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.77 -2.51 -2.29 -2.49 -3.61 -4.08 -6.22 -6.42 -7.00 -6.62 \n",
      "0.00 -1.79 -2.41 -2.23 -3.66 -3.84 -6.14 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -1.61 0.00 1.27 -4.30 -6.18 -6.22 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.57 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.600735973095083, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.44603385399239, 4: -5.249933215431817}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.44603385399239, 4: -5.249933215431817}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.44603385399239, 4: -5.677439226042953}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.005206920993889, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.574282362438841, 2: -5.812391125311882, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.432747262579916, 2: -5.307571413225051, 3: -5.919630515698002, 4: -4.237864908024254}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.432747262579916, 2: -5.307571413225051, 3: -5.919630515698002, 4: -4.237864908024254}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.432747262579916, 2: -5.307571413225051, 3: -5.919630515698002, 4: -4.7564570663020715}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -4.180599194797421, 4: -5.069945182620789}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3107626149575893, 1: -3.5011745148018716, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -3.239519404355012}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3107626149575893, 1: -3.5011745148018716, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -3.239519404355012}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3107626149575893, 1: -3.5011745148018716, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -3.8479626579630613}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.756234971471072, 2: -5.307571413225051, 3: -5.919630515698002, 4: -5.271617984729458}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.083626588387327, 1: -3.5011745148018716, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -5.176655823251859}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -2.4944777770904514, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -2.2271575178901233, 4: -3.0174305400416586}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: -2.7393247115732513}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -1.7894898903291185, 3: -1.830250681582517, 4: -2.7393247115732513}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -2.904728222397269, 4: -3.0174305400416586}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -2.4112542561810826, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6134850742187528, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -2.398948213811125, 4: -3.37986488759892}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.6599105328144135, 4: -3.6683785041078747}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -3.7200051862309444, 4: -3.0174305400416586}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -3.724996436479309, 4: -3.0174305400416586}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -3.1852957390260914, 2: -4.276406050471545, 3: -3.7531143011022357, 4: -3.6458617914379094}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.95 -5.61 -4.99 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-5.17 -5.34 -5.65 -5.98 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-4.08 -4.71 -4.75 -5.04 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-3.23 -3.53 -3.14 -4.28 -6.13 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-1.83 -3.08 -3.24 -3.66 -4.38 -5.24 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.77 -2.51 -2.29 -3.28 -3.61 -4.08 -6.22 -6.42 -7.00 -6.62 \n",
      "0.00 -1.83 -2.74 -0.32 -3.67 -3.84 -6.14 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -2.40 0.00 1.27 -4.30 -6.18 -6.22 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.57 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.9643721240009455, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -5.9643721240009455, 2: -6.138808199095796, 3: -5.945211585438715, 4: -5.964894796152934}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -5.9643721240009455, 2: -6.138808199095796, 3: -6.31014254274923, 4: -5.964894796152934}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.650725359746915, 4: -6.103309005075792}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.342772183977509, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.101132980889187, 2: -5.812391125311882, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.101132980889187, 2: -5.812391125311882, 3: -5.132143405095109, 4: -4.713382568568022}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.101132980889187, 2: -5.812391125311882, 3: -5.132143405095109, 4: -5.1891781373969}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.2270096519543916, 2: -4.359432580966742, 3: -4.0379952501594145, 4: -4.086021188004767}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.9422174746557506, 2: -1.8265182550168009, 3: -2.6977170299600495, 4: -3.999227257106635}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.8165784222457027, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2439200520435345}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.8165784222457027, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.2439200520435345}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -3.8165784222457027, 2: -4.051201967723744, 3: -3.963060330093041, 4: -3.8519672473596165}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -3.6066894905936655, 2: -4.7461135601408495, 3: -4.209156017607984, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.771929609150816, 4: -3.6683785041078747}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.771929609150816, 4: -3.6683785041078747}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.771929609150816, 4: -4.238224438738166}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.771929609150816, 4: -4.442472872132493}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -0.3185295739026093, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -2.06357707635451}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -4.3010959840934815, 2: -5.581764831599653, 3: -5.104488427592336, 4: -4.7896215518954754}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.570310199360194, 1: -7.187078381137176, 2: -7.182725750054594, 3: -6.578922191127805, 4: -6.842641139309846}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.220509870685617, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.220509870685617, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.181649210500232, 1: -7.136170988844245, 2: -6.771221194485513, 3: -6.613679400037213, 4: -6.821482517779028}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.142160416560202, 1: -6.268957713558427, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -6.219763336440218, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552224344172597, 1: -6.268957713558427, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.754807546789555, 1: -7.136170988844245, 2: -6.771221194485513, 3: -6.613679400037213, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.2737890995706245, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.96 -5.61 -4.99 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-5.17 -5.46 -5.70 -5.98 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-4.08 -4.26 -4.75 -5.04 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-3.75 -3.53 -3.14 -4.28 -6.13 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-2.70 -3.08 -3.96 -3.66 -4.38 -5.24 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.77 -2.51 -2.29 -3.28 -4.21 -4.08 -5.75 -6.42 -7.00 -6.62 \n",
      "0.00 -1.83 -2.74 -2.06 -3.75 -3.84 -4.38 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -2.40 0.00 0.13 -4.79 -1.05 -6.63 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.58 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -6.1617511966571445, 2: -6.138808199095796, 3: -6.514351429008765, 4: -5.964894796152934}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -6.1617511966571445, 2: -6.138808199095796, 3: -6.514351429008765, 4: -5.964894796152934}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -6.1617511966571445, 2: -6.138808199095796, 3: -6.514351429008765, 4: -6.32805426449917}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.610707128714951, 1: -6.144423189301917, 2: -6.096497757529535, 3: -5.721159732377355, 4: -6.078526589422081}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -5.56611217489144, 2: -6.365714263453464, 3: -4.9885414381879984, 4: -5.281591486688611}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -5.56611217489144, 2: -6.365714263453464, 3: -4.9885414381879984, 4: -5.281591486688611}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.704753349557159, 1: -6.144423189301917, 2: -6.096497757529535, 3: -5.721159732377355, 4: -6.078526589422081}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.831363391548389, 1: -6.144423189301917, 2: -6.096497757529535, 3: -5.721159732377355, 4: -6.078526589422081}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.143329483527573, 1: -6.144423189301917, 2: -6.096497757529535, 3: -5.721159732377355, 4: -6.078526589422081}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -6.1617511966571445, 2: -6.176679202305753, 3: -6.514351429008765, 4: -6.609684508760261}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.167456933804426, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.084322394082996, 2: -5.2445082459574985, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -3.7540740814969795, 2: -4.359432580966742, 3: -4.0379952501594145, 4: -4.086021188004767}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.354122472999571, 1: -3.307517120893229, 2: -4.14378685072118, 3: -3.0769387038574836, 4: -3.523803201410253}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.9422174746557506, 2: -4.164058987767759, 3: -2.6977170299600495, 4: -3.999227257106635}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.9422174746557506, 2: -4.164058987767759, 3: -2.6977170299600495, 4: -3.999227257106635}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.354122472999571, 1: -3.307517120893229, 2: -4.14378685072118, 3: -3.6885871249400064, 4: -3.523803201410253}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.908986224175483, 1: -4.125550956560632, 2: -2.294393513868313, 3: -2.666830248376459, 4: -3.5757689888593163}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.079554095802396, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.079554095802396, 4: -4.880416877476394}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -4.209156017607984, 4: -5.043316529505712}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.371023926888088, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.371023926888088, 2: -4.351058077657067, 3: -3.280387028090384, 4: -4.6364308610896545}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -4.250173419876349, 4: -5.043316529505712}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.908986224175483, 1: -4.125550956560632, 2: -4.725053050623901, 3: -2.666830248376459, 4: -3.5757689888593163}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.908986224175483, 1: -4.125550956560632, 2: -4.717420165210284, 3: -2.666830248376459, 4: -3.5757689888593163}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.908986224175483, 1: -4.125550956560632, 2: -4.71988632858797, 3: -3.326815526022578, 4: -3.5757689888593163}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -4.628292412270566, 2: -4.051201967723744, 3: -3.963060330093041, 4: -5.142364724974118}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.354122472999571, 1: -4.181388617303107, 2: -4.14378685072118, 3: -3.8815495356785688, 4: -3.523803201410253}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.840006205674237, 2: -3.825711640120336, 3: -3.5328916492159, 4: -4.026819103801112}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -4.129805047920856, 2: -4.359432580966742, 3: -4.0379952501594145, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -4.129806309058503, 2: -4.359432580966742, 3: -4.0379952501594145, 4: -4.086021188004767}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.052430701702466, 1: -4.129806616285994, 2: -4.359432580966742, 3: -4.5745756776450675, 4: -4.086021188004767}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.5183118936529745, 2: -5.2445082459574985, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.518311928397814, 2: -5.2445082459574985, 3: -4.213723476395053, 4: -4.283343024599117}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.5183119406247325, 2: -5.2445082459574985, 3: -4.734488363519499, 4: -4.283343024599117}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.518311941770748, 2: -5.2445082459574985, 3: -4.891767431518216, 4: -4.283343024599117}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.493264723545814, 1: -4.518311944216909, 2: -5.2445082459574985, 3: -5.227478112398632, 4: -4.797842152385196}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.462919109902182, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.261170109466141, 2: -5.812391125311882, 3: -5.132143405095109, 4: -5.165505580544758}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6431413949641023, 1: -3.493579017492904, 2: -5.1840045132933, 3: -3.139447193809823, 4: -3.6524193856796687}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.546942124402327, 1: -3.840006205674237, 2: -3.825711640120336, 3: -4.869491795037854, 4: -4.026819103801112}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.037443162621844, 2: -5.640437445437223, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -4.282710034953819, 2: -5.307571413225051, 3: -5.919630515698002, 4: -5.312596137832592}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.2407521703635895, 4: -5.341402841260826}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -4.37943622731973, 4: -5.069945182620789}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -3.6650902183323897, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -5.019176894870568}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -3.6650902183323897, 2: -3.6576870989577466, 3: -3.9059989568494937, 4: -5.019176894870568}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -4.557533845379959, 4: -5.069945182620789}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -3.6650902183323897, 2: -5.36813244708304, 3: -3.9059989568494937, 4: -5.019176894870568}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -3.978156138193497, 4: -5.043316529505712}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.371023926888088, 2: -4.351058077657067, 3: -4.846741188933365, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -2.06357707635451}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -2.06357707635451}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -2.777855139482604}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.562666872859275, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -3.7203450437801244}, Best action: 0, Actual action: 0\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.40151114034285, 2: -4.351058077657067, 3: -4.846741188941494, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -2.737351363134398, 4: -2.7659239973233065}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -4.321292062001962, 3: -1.830250681582517, 4: -2.7393247115732513}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -4.321292062001962, 3: -1.830250681582517, 4: -2.7393247115732513}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6203208949139567, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3041881472519172, 1: -1.7735479502140195, 2: -1.8919580239211344, 3: -1.94204585541234, 4: -3.1358073965764572}, Best action: 1, Actual action: 1\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4986059291647513, 1: -2.0672237368500377, 2: -1.9412176671422658, 3: -1.9545384433499235, 4: -3.2920459969594513}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -4.321292062001962, 3: -1.328055354053556, 4: -2.7393247115732513}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.939190208613386, 1: -2.0672237368500377, 2: -2.1698466034976067, 3: -1.9807351715581774, 4: -3.619675481764442}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -1.993215957853462, 2: -4.321292062001962, 3: -2.638692595584275, 4: -2.7393247115732513}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.076284623352932, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -2.398948213811125, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.076284623352932, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -1.5631198213811124, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.59 -6.08 -5.03 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-4.92 -5.09 -5.70 -5.98 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-4.52 -4.70 -4.75 -5.20 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-4.09 -3.83 -3.49 -5.31 -6.13 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-2.94 -3.52 -4.05 -3.91 -4.73 -4.94 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.89 -2.51 -3.58 -3.50 -4.05 -4.59 -5.75 -6.42 -7.00 -6.62 \n",
      "-2.07 -2.73 -2.77 -3.73 -3.75 -3.84 -4.38 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -0.11 0.00 0.13 -4.79 -1.05 -6.63 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.58 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.5906135747153005, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -4.9203421308444355, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -4.518311945764697, 2: -5.2445082459574985, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -3.840006205674237, 2: -3.825711640120336, 3: -4.869774453803711, 4: -4.026819103801112}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6431413949641023, 1: -3.493579017492904, 2: -5.1840045132933, 3: -4.984143197336508, 4: -3.6524193856796687}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -4.628292412270566, 2: -4.051201967723744, 3: -4.61818340864236, 4: -5.142364724974118}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -4.521578003268824, 2: -5.374084235078326, 3: -3.9059989568494937, 4: -5.019176894870568}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -4.726642785371683, 4: -5.069945182620789}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -4.521578003268824, 2: -5.374084235078326, 3: -5.1191805518360125, 4: -5.019176894870568}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -3.4953957572201713, 2: -4.351058077657067, 3: -4.846741188942627, 4: -4.6364308610896545}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -3.7499134666925413, 4: -4.690251454114083}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -4.738112982084367, 2: -4.352644839696327, 3: -5.735818118674249, 4: -3.840998797883056}, Best action: 4, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -5.104488427592336, 4: -4.7896215518954754}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -5.104488427592336, 4: -4.7896215518954754}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -5.104488427592336, 4: -5.258555612224883}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.12737890995706236, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.58 -6.08 -5.03 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-5.22 -5.09 -5.70 -5.98 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-4.89 -4.70 -4.75 -5.20 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-4.09 -3.84 -3.64 -5.31 -6.13 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-2.94 -3.52 -4.62 -4.84 -4.89 -4.94 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.89 -2.51 -3.58 -4.11 -4.05 -4.59 -5.75 -6.42 -7.00 -6.62 \n",
      "-2.07 -2.73 -2.77 -3.73 -4.02 -3.84 -4.38 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -0.11 0.00 0.01 -1.36 -1.05 -6.63 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.58 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.578178948158913, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.217320941296416, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -4.885987617192627, 2: -5.2445082459574985, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -3.840006205674237, 2: -4.793111627050746, 3: -4.869774453803711, 4: -4.026819103801112}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -4.628292412270566, 2: -5.107882677446121, 3: -4.61818340864236, 4: -5.142364724974118}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84227957171102, 1: -4.856287726501118, 2: -5.374084235078326, 3: -5.325784124906506, 4: -5.019176894870568}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6431413949641023, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -3.6524193856796687}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -5.207200109964995, 3: -4.780259174100538, 4: -4.7450003834996135}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -5.207200109964995, 3: -4.780259174100538, 4: -4.7450003834996135}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -5.207200109964995, 3: -4.780259174100538, 4: -5.217950348984648}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -5.207200109964995, 3: -4.780259174100538, 4: -5.327939543540764}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -5.207200109964995, 3: -5.250035848431489, 4: -5.63446882354171}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.202509420302865, 1: -5.494425309767142, 2: -5.640437445437223, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -6.018234541231866, 2: -6.125992042728915, 3: -5.975706393036196, 4: -6.26309771359884}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -5.698871905763266, 2: -5.728957116545332, 3: -5.846784121662576, 4: -6.103309005075792}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -5.434976881219846, 2: -6.138816280692826, 3: -6.427475146782192, 4: -5.872900281457728}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.66423417982574, 2: -5.307571413225051, 3: -5.919630515698002, 4: -5.312596137832592}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -6.352382324520431, 2: -6.336501109080629, 3: -6.125113614983136, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -6.352382324520431, 2: -6.336501109080629, 3: -6.125113614983136, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.66423417982574, 2: -6.549032068052028, 3: -5.919630515698002, 4: -5.312596137832592}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.66423417982574, 2: -6.422820869299104, 3: -5.919630515698002, 4: -5.312596137832592}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.66423417982574, 2: -6.461263440223704, 3: -5.919630515698002, 4: -5.734462485427659}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.889296530534938, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.069945182620789}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -4.050961715262501, 4: -5.043316529505712}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -4.050961715262501, 4: -5.043316529505712}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.277290807646646, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -4.586375160888876, 4: -5.043316529505712}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.959110444600232, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.069945182620789}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.344608540890853, 1: -4.551614118738391, 2: -4.7461135601408495, 3: -5.626258450451724, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -4.023681313213845, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.012737890995706228, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.82 -6.08 -5.03 -5.78 -5.97 -6.06 -6.40 -6.97 -7.29 -7.37 \n",
      "-5.52 -5.09 -5.73 -6.02 -5.82 -5.89 -5.91 -6.50 -6.83 -7.34 \n",
      "-5.19 -4.70 -5.84 -5.49 -5.91 -5.97 -5.17 -5.71 -6.87 -7.36 \n",
      "-4.09 -4.03 -3.65 -5.49 -5.92 -5.52 -5.43 -6.13 -6.28 -7.40 \n",
      "-2.94 -3.52 -4.63 -4.86 -4.55 -4.94 -5.23 -6.37 -7.23 -7.40 \n",
      "-1.89 -2.51 -3.58 -4.11 -3.39 -4.59 -5.75 -6.42 -7.00 -6.62 \n",
      "-2.07 -2.73 -2.77 -3.73 -1.30 -3.84 -4.38 -5.89 -6.73 -7.17 \n",
      "0.00 0.00 -0.11 0.00 0.00 -1.36 -1.05 -6.63 -6.64 -7.15 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -6.58 -6.92 -7.09 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -5.94 -6.69 -7.03 -6.59 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.819013087336132, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.517688119230064, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.193334406469056, 2: -5.2445082459574985, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.12980674892774, 2: -4.359432580966742, 3: -5.321042436323845, 4: -4.086021188004767}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.12980674892774, 2: -4.359432580966742, 3: -5.321042436323845, 4: -4.086021188004767}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.12980674892774, 2: -4.359432580966742, 3: -5.321042436323845, 4: -4.618279281084338}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -4.14378685072118, 3: -3.8815586830874445, 4: -3.523803201410253}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -4.14378685072118, 3: -3.8815586830874445, 4: -3.523803201410253}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -4.14378685072118, 3: -3.8815586830874445, 4: -4.1066609132833305}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -2.9422174746557506, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -3.999227257106635}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603523387991997, 1: -2.9333039447790137, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -2.509383734201211}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603523387991997, 1: -2.9333039447790137, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -2.509383734201211}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603523387991997, 1: -2.9333039447790137, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -3.183539198123102}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -2.725933925835684, 2: -4.321292062001962, 3: -3.114046782915332, 4: -2.7393247115732513}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.076284623352932, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -0.11107816136230286, 4: -3.37986488759892}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.076284623352932, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -0.11107816136230286, 4: -3.37986488759892}, Best action: 3, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -3.108385793147445, 2: -4.321292062001962, 3: -3.114046782915332, 4: -2.7393247115732513}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -2.9970506563571755, 2: -4.321292062001962, 3: -3.114046782915332, 4: -2.7393247115732513}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0147664602222424, 1: -3.0565972695663852, 2: -4.321292062001962, 3: -3.114046782915332, 4: -3.392785487531659}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603523387991997, 1: -3.5554581647045262, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -4.1851416562168025}, Best action: 0, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.9603523387991997, 1: -3.568550503767935, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -4.1936844074556765}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.5001422446252004, 1: -3.671102306699505, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -3.999227257106635}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.510771429793366, 2: -4.359432580966742, 3: -5.321042436323845, 4: -4.995462300149729}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.510775051835885, 2: -4.359432580966742, 3: -5.321042436323845, 4: -4.995464663532472}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -4.793111627050746, 3: -4.869774453803711, 4: -4.026819103801112}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -4.793111627050746, 3: -4.869774453803711, 4: -4.026819103801112}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -4.793111627050746, 3: -4.869774453803711, 4: -4.564405384459012}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -4.793111627050746, 3: -4.869774453803711, 4: -5.273750481787111}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -4.793111627050746, 3: -4.869774453803711, 4: -5.33331481834733}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -6.352382324520431, 2: -6.336501109080629, 3: -5.918772039560672, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -3.6524193856796687}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -3.6524193856796687}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -4.223701640968499}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -4.97750857682211}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -4.984143197336508, 4: -5.7244786137342425}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -5.95117673665813, 3: -4.869774453803711, 4: -5.84090260329864}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.510775785732752, 2: -5.089884244778991, 3: -5.321042436323845, 4: -4.995465142400179}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715237873914, 1: -3.671372609166499, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -3.999227257106635}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3041881472519172, 1: -3.1137782556140023, 2: -1.8919580239211344, 3: -1.94204585541234, 4: -3.1358073965764572}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.111578759906753, 1: -4.9906387857221635, 2: -4.351058077657067, 3: -4.846741188942627, 4: -4.6364308610896545}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.131599719604112, 1: -4.856287726501118, 2: -5.374084235078326, 3: -5.325784124906506, 4: -5.019176894870568}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.24475093445658, 1: -4.9906387857221635, 2: -4.351058077657067, 3: -4.846741188942627, 4: -4.6364308610896545}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -4.59322168117289, 3: -4.956262155392515, 4: -4.880416877476394}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.420496540566905, 4: -6.77122043628769}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -5.749030649763432, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3403946351680425, 1: -4.378287864974168, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -7.158983535882446, 2: -6.799208732282278, 3: -6.900216662080747, 4: -6.636793662958748}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -7.158983535882446, 2: -6.799208732282278, 3: -6.900216662080747, 4: -6.636793662958748}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -7.158983535882446, 2: -6.799208732282278, 3: -6.900216662080747, 4: -6.939482233292461}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -7.1482391906032285, 4: -7.199689647729596}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -7.1482391906032285, 4: -7.199689647729596}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8164178297598195, 1: -7.158983535882446, 2: -7.485490930397412, 3: -6.900216662080747, 4: -7.621927709181461}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258323399547336, 1: -7.1929002731663285, 2: -7.53825386968358, 3: -7.17054268534566, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7292755908376005, 1: -7.13307078666456, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.39106020705794, 4: -6.77122043628769}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -6.1763699312675, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -6.650687673753603, 2: -6.406930399030484, 3: -5.885185014629548, 4: -6.813221845062342}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3403946351680425, 1: -6.945224887662312, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 0, Actual action: 0\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.598510631440701, 2: -6.546705225525891, 3: -4.956262155392515, 4: -4.880416877476394}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -5.184246680948153, 2: -4.352644839696327, 3: -5.735818118674249, 4: -3.840998797883056}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -5.184246680948153, 2: -4.352644839696327, 3: -5.735818118674249, 4: -3.840998797883056}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.177119036241064, 1: -5.184246680948153, 2: -4.352644839696327, 3: -5.735818118674249, 4: -4.395308906073581}, Best action: 0, Actual action: 0\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -6.415399324226507, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.514185356247577, 1: -5.184246680948153, 2: -4.352644839696327, 3: -5.735818118674249, 4: -6.395392865516936}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.414222320118693, 1: -6.945274269253132, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 0, Actual action: 0\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -5.681983035563911, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.869433786481046, 1: -7.13307078666456, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -6.657402992998215, 4: -6.77122043628769}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -7.2121786554292955, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -7.346540328083964, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.036519737470167}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050983164194867, 1: -7.37306757170063, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.303232961097852}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.168577479814788, 3: -5.2317469553494425, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -4.548558778833656, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.069945182620789}, Best action: 1, Actual action: 1\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.786905508220879, 1: -7.349326347477112, 2: -7.368189427012465, 3: -7.204896847448358, 4: -6.534083002688999}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.229961199294701, 3: -7.409616854811705, 4: -7.645229807894893}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.517209647688404, 1: -7.398751628136715, 2: -7.745468678885597, 3: -7.5506063512722985, 4: -7.693531651279605}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.203745299307384, 3: -6.622559590439526, 4: -7.320230610608408}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.058238690361506, 2: -7.370828721553068, 3: -7.000594406184895, 4: -7.0781379521638295}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.764337059648138, 1: -7.082764476420722, 2: -7.073866127462204, 3: -7.317345309811505, 4: -6.77122043628769}, Best action: 0, Actual action: 0\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.3744523596630875, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.389503595242064, 4: -6.4127854958874515}, Best action: 0, Actual action: 0\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.128384460733787, 4: -6.325466667244228}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.128384460733787, 4: -6.325466667244228}, Best action: 3, Actual action: 3\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.639329459271583, 2: -5.537184256308888, 3: -5.972471049929773, 4: -5.5171491512334585}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.639329459271583, 2: -5.537184256308888, 3: -5.972471049929773, 4: -5.5171491512334585}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.639329459271583, 2: -5.537184256308888, 3: -5.972471049929773, 4: -5.920605727622448}, Best action: 2, Actual action: 2\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -6.155491818184102, 4: -5.429126215476942}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -6.155491818184102, 4: -5.429126215476942}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.547280087377587, 1: -5.578581891666773, 2: -6.247826568036474, 3: -6.155491818184102, 4: -5.840504856084017}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -5.303473020998916, 2: -5.56052925120849, 3: -5.998228071065946, 4: -5.1714083759032}, Best action: 4, Actual action: 4\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -5.303473020998916, 2: -5.56052925120849, 3: -5.998228071065946, 4: -5.1714083759032}, Best action: 4, Actual action: 4\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -5.303473020998916, 2: -5.56052925120849, 3: -5.998228071065946, 4: -5.605981622071911}, Best action: 1, Actual action: 1\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -6.528138887728478, 3: -6.282467574969518, 4: -6.588015558081064}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.164167660223484, 4: -6.325466667244228}, Best action: 3, Actual action: 3\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -5.639329459271583, 2: -6.104498851321783, 3: -5.972471049929773, 4: -6.372810935355858}, Best action: 1, Actual action: 1\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.007569875063912, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.069242415464287, 4: -6.414689933709904}, Best action: 0, Actual action: 0\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.994416890940914, 1: -5.578581891666773, 2: -6.247826568036474, 3: -6.155491818184102, 4: -6.330683245844422}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.019408319756478, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.069242431806974, 4: -6.414689933709904}, Best action: 0, Actual action: 0\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.995730664576289, 1: -6.333578928169424, 2: -6.247826568036474, 3: -6.155491818184102, 4: -6.331540483141505}, Best action: 0, Actual action: 0\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -6.688022780301115, 2: -5.56052925120849, 3: -5.998228071065946, 4: -6.727523386375978}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.40742167023673, 2: -7.763321272952369, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 4, Actual action: 4\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.40742167023673, 2: -7.763321272952369, 3: -7.445030568258385, 4: -7.361193865304372}, Best action: 4, Actual action: 4\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.40742167023673, 2: -7.763321272952369, 3: -7.445030568258385, 4: -7.598686417426979}, Best action: 1, Actual action: 1\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -6.528138887728478, 3: -6.665203164559709, 4: -6.588015558081064}, Best action: 2, Actual action: 2\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015855575285, 1: -7.402988659805543, 2: -7.701076821800475, 3: -7.534416187622355, 4: -7.7511222910855855}, Best action: 1, Actual action: 1\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.517209647688404, 1: -7.30224661306105, 2: -7.745468678885597, 3: -7.5506063512722985, 4: -7.693531651279605}, Best action: 1, Actual action: 1\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.203745299307384, 3: -7.284999994930686, 4: -7.320230610608408}, Best action: 2, Actual action: 2\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.203745299307384, 3: -7.284999994962467, 4: -7.320230610608408}, Best action: 2, Actual action: 2\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.455408222369719, 3: -7.284999994984546, 4: -7.320230610608408}, Best action: 3, Actual action: 3\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.587332986286585, 3: -7.284999994988138, 4: -7.320230610608408}, Best action: 3, Actual action: 3\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.746771361580906, 3: -7.529349995443547, 4: -7.320230610608408}, Best action: 4, Actual action: 4\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.76232520597232, 3: -7.606159103549717, 4: -7.320230610608408}, Best action: 4, Actual action: 4\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.345177121758602, 2: -7.794192521094204, 3: -7.763528560942606, 4: -7.561409855653651}, Best action: 1, Actual action: 1\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258323399547336, 1: -7.1929002731663285, 2: -7.53825386968358, 3: -7.130882753922408, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.13307078666456, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 1, Actual action: 1\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629392797868668, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.825912840858677, 4: -6.852032107854823}, Best action: 0, Actual action: 0\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -6.650687673753603, 2: -6.406930399030484, 3: -6.214689116430419, 4: -6.813221845062342}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -6.650687673753603, 2: -6.406930399030484, 3: -6.214689116430419, 4: -6.813221845062342}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -6.504385539533006, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 2, Actual action: 2\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -6.650687673753603, 2: -6.406930399030484, 3: -6.945013851916253, 4: -6.813221845062342}, Best action: 2, Actual action: 2\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.0716037238528475, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 1, Actual action: 1\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -7.414863508582687, 4: -7.199689647729596}, Best action: 4, Actual action: 4\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -7.414863508582687, 4: -7.199689647729596}, Best action: 4, Actual action: 4\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.201054049228923, 2: -7.453077250722798, 3: -7.414863508582687, 4: -7.451717579433932}, Best action: 1, Actual action: 1\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.090971249648895, 2: -7.1665985464070285, 3: -7.213225422840093, 4: -7.382998068683592}, Best action: 1, Actual action: 1\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.027812181751465, 3: -7.1569911040484095, 4: -7.26879469279576}, Best action: 2, Actual action: 2\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.027812181751465, 3: -7.1569911040484095, 4: -7.26879469279576}, Best action: 2, Actual action: 2\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.093347143094038, 2: -7.240019049753839, 3: -6.590206378613573, 4: -7.364686178767792}, Best action: 3, Actual action: 3\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.093347143094038, 2: -7.240019049753839, 3: -6.590206378613573, 4: -7.364686178767792}, Best action: 3, Actual action: 3\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.02036825105244, 3: -7.1569911040484095, 4: -7.26879469279576}, Best action: 2, Actual action: 2\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.093347143094038, 2: -7.240019049753839, 3: -7.4468107304768925, 4: -7.364686178767792}, Best action: 1, Actual action: 1\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.093347143094038, 2: -7.240019049753839, 3: -7.594988754227998, 4: -7.364686178767792}, Best action: 1, Actual action: 1\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.354945900215574, 2: -7.240019049753839, 3: -7.671800689287809, 4: -7.364686178767792}, Best action: 2, Actual action: 2\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.565143874370134, 2: -7.240019049753839, 3: -7.690954979682643, 4: -7.364686178767792}, Best action: 2, Actual action: 2\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250737539649478, 1: -7.727223755673339, 2: -7.488417335275993, 3: -7.705724508866398, 4: -7.364686178767792}, Best action: 0, Actual action: 0\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406495439918848, 2: -7.1665985464070285, 3: -7.213225422840093, 4: -7.382998068683592}, Best action: 2, Actual action: 2\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406556486239441, 2: -7.1665985464070285, 3: -7.213225422840093, 4: -7.382998068683592}, Best action: 2, Actual action: 2\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406595560275535, 2: -7.421604677230396, 3: -7.213225422840093, 4: -7.382998068683592}, Best action: 3, Actual action: 3\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.208825051430158, 1: -7.215734989947958, 2: -7.400008828693702, 3: -6.916402528593621, 4: -6.977946858237919}, Best action: 3, Actual action: 3\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785756740499835, 1: -7.187078381137176, 2: -7.182725750054594, 3: -6.578922191127805, 4: -6.842641139309846}, Best action: 3, Actual action: 3\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785756740499835, 1: -7.187078381137176, 2: -7.182725750054594, 3: -6.578922191127805, 4: -6.842641139309846}, Best action: 3, Actual action: 3\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.785756740499835, 1: -7.187078381137176, 2: -7.182725750054594, 3: -6.886819193926302, 4: -6.842641139309846}, Best action: 0, Actual action: 0\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.870588763553916, 1: -6.634279297239232, 2: -7.3810181122177, 3: -6.825912840858677, 4: -6.852032107854823}, Best action: 1, Actual action: 1\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.952341904813761, 1: -7.187078381137176, 2: -7.182725750054594, 3: -7.283088257284371, 4: -6.842641139309846}, Best action: 4, Actual action: 4\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.164601484710311, 1: -7.187078381137176, 2: -7.182725750054594, 3: -7.42158763316687, 4: -6.842641139309846}, Best action: 4, Actual action: 4\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.222144349946389, 1: -7.187078381137176, 2: -7.182725750054594, 3: -7.459134352733411, 4: -7.12680343677196}, Best action: 4, Actual action: 4\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.245708153260563, 1: -7.187078381137176, 2: -7.182725750054594, 3: -7.47450973439591, 4: -7.50175558827322}, Best action: 2, Actual action: 2\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.208825051430158, 1: -7.215734989947958, 2: -7.400008828693702, 3: -7.141069453736298, 4: -6.977946858237919}, Best action: 4, Actual action: 4\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.208825051430158, 1: -7.215734989947958, 2: -7.400008828693702, 3: -7.1412168951120485, 4: -6.977946858237919}, Best action: 4, Actual action: 4\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.208825051430158, 1: -7.215734989947958, 2: -7.400008828693702, 3: -7.141422700732238, 4: -7.249931640996507}, Best action: 3, Actual action: 3\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.248804423057235, 1: -7.187078381137176, 2: -7.4251244993355305, 3: -7.476530050438239, 4: -7.626531344139736}, Best action: 1, Actual action: 1\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.567760659806362, 1: -7.778955256919655, 2: -7.743881538961501, 3: -7.710438541917467, 4: -7.364686178767792}, Best action: 4, Actual action: 4\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.567761782389104, 1: -7.778955405247916, 2: -7.74388227144674, 3: -7.71043855543388, 4: -7.364686178767792}, Best action: 4, Actual action: 4\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.567762084167109, 1: -7.778955445122221, 2: -7.7438824683568885, 3: -7.710438559067426, 4: -7.601864422678691}, Best action: 0, Actual action: 0\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406603388806765, 2: -7.586230563309328, 3: -7.324929224738802, 4: -7.382998068683592}, Best action: 3, Actual action: 3\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.208825051430158, 1: -7.215734989947958, 2: -7.400008828693702, 3: -7.680514925523911, 4: -7.833040139732658}, Best action: 0, Actual action: 0\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3719343889655, 1: -7.158983535882446, 2: -7.486882712217814, 3: -6.900216662080747, 4: -7.6228358468192745}, Best action: 3, Actual action: 3\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.505826579763032, 2: -7.453077250722798, 3: -7.414863508582687, 4: -7.688728195265529}, Best action: 0, Actual action: 2\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.225150980154119, 1: -7.505826579765647, 2: -7.453077250722798, 3: -7.414863508582687, 4: -7.6887281952672355}, Best action: 0, Actual action: 0\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258323399547336, 1: -7.1929002731663285, 2: -7.53825386968358, 3: -7.372237801956234, 4: -7.621899980192864}, Best action: 1, Actual action: 1\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.448764319280138, 1: -7.505826579765881, 2: -7.598306021603825, 3: -7.414863508582687, 4: -7.688728195267389}, Best action: 3, Actual action: 3\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6433574575261645, 1: -7.5058265797660235, 2: -7.6858729338145375, 3: -7.414863508582687, 4: -7.6887281952674815}, Best action: 3, Actual action: 3\n",
      "Step: 160\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690471570082245, 1: -7.505826579766058, 2: -7.707074284464774, 3: -7.647525792810245, 4: -7.688728195267504}, Best action: 1, Actual action: 1\n",
      "Step: 161\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406603388821267, 2: -7.586230868248535, 3: -7.642880700315575, 4: -7.382998068683592}, Best action: 4, Actual action: 4\n",
      "Step: 162\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406603388821275, 2: -7.586230868423017, 3: -7.6430908636101975, 4: -7.382998068683592}, Best action: 4, Actual action: 4\n",
      "Step: 163\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.38674183940399, 1: -7.406603388821282, 2: -7.586230868570979, 3: -7.643269084960232, 4: -7.618528242502069}, Best action: 0, Actual action: 0\n",
      "Step: 164\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3719343889655, 1: -7.158983535882446, 2: -7.486882712217814, 3: -7.745064486896775, 4: -7.6228358468192745}, Best action: 1, Actual action: 1\n",
      "Step: 165\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5902567893319794, 1: -7.215734989947958, 2: -7.400008828693702, 3: -7.68639039321363, 4: -7.8368732950541276}, Best action: 1, Actual action: 1\n",
      "Step: 166\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733238590692866, 1: -7.778955464994483, 2: -7.743882566491521, 3: -7.710438560878286, 4: -7.982741241310691}, Best action: 3, Actual action: 3\n",
      "Step: 167\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247684635513, 1: -7.778955464994793, 2: -7.74388256649305, 3: -7.710438560878314, 4: -7.98274717510674}, Best action: 3, Actual action: 3\n",
      "Step: 168\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496996, 3: -7.1569911040484095, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 169\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -6.69108700107434, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 170\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -5.9416749063142165}, Best action: 4, Actual action: 4\n",
      "Step: 171\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -5.9416749063142165}, Best action: 4, Actual action: 4\n",
      "Step: 172\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -6.306924164745937}, Best action: 4, Actual action: 4\n",
      "Step: 173\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431967784653517, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -6.788870561246593}, Best action: 0, Actual action: 0\n",
      "Step: 174\n",
      "---------------------------------\n",
      "State: (8, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.24972056256284, 1: -7.744026088787789, 2: -7.474772188846604, 3: -7.477127831465647, 4: -7.663450607252407}, Best action: 0, Actual action: 0\n",
      "Step: 175\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3719343889655, 1: -7.750810456236321, 2: -7.486882712217814, 3: -7.745304378210462, 4: -7.6228358468192745}, Best action: 0, Actual action: 0\n",
      "Step: 176\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258323399547336, 1: -7.773830118953626, 2: -7.53825386968358, 3: -7.372237801956234, 4: -7.621899980192864}, Best action: 0, Actual action: 0\n",
      "Step: 177\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442760573657417, 1: -7.519142514468234, 2: -7.801482738789935, 3: -7.799529635983455, 4: -7.739192942274146}, Best action: 0, Actual action: 0\n",
      "Step: 178\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.517209647688404, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.5506063512722985, 4: -7.693531651279605}, Best action: 0, Actual action: 0\n",
      "Step: 179\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.514015855575285, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.534416187622355, 4: -7.7511222910855855}, Best action: 0, Actual action: 0\n",
      "Step: 180\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0469770513958, 1: -6.8664299448918396, 2: -7.160263106593032, 3: -7.064657811412096, 4: -7.334344899790631}, Best action: 1, Actual action: 1\n",
      "Step: 181\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -6.6652171221845755, 4: -6.588015558081064}, Best action: 4, Actual action: 4\n",
      "Step: 182\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -6.6652171221845755, 4: -6.588015558081064}, Best action: 4, Actual action: 4\n",
      "Step: 183\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -6.6652171221845755, 4: -6.895094157853769}, Best action: 3, Actual action: 3\n",
      "Step: 184\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -6.6652171221845755, 4: -7.030293791860386}, Best action: 3, Actual action: 3\n",
      "Step: 185\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.20374415623201, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.48434454763764, 4: -6.325466667244228}, Best action: 0, Actual action: 0\n",
      "Step: 186\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -6.551600699998761, 2: -6.0736080359910245, 3: -6.776066763442742, 4: -5.713453080324176}, Best action: 4, Actual action: 4\n",
      "Step: 187\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -6.551600699998761, 2: -6.0736080359910245, 3: -6.776066763442742, 4: -5.713453080324176}, Best action: 4, Actual action: 4\n",
      "Step: 188\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -6.551600699998761, 2: -6.0736080359910245, 3: -6.776066763442742, 4: -6.099242303095}, Best action: 2, Actual action: 2\n",
      "Step: 189\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.448412469263404, 2: -7.763321272952369, 3: -7.445030568258385, 4: -7.714163890742718}, Best action: 3, Actual action: 3\n",
      "Step: 190\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0469770513958, 1: -7.099130790607335, 2: -7.160263106593032, 3: -7.064657811412096, 4: -7.334344899790631}, Best action: 0, Actual action: 0\n",
      "Step: 191\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.83390874042281, 1: -7.476931494447693, 2: -7.187789270437362, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 0, Actual action: 0\n",
      "Step: 192\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.703742859724118, 1: -7.371554957173813, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 1, Actual action: 1\n",
      "Step: 193\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.436821842342896, 1: -7.443820208912295, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.691059503631032}, Best action: 2, Actual action: 2\n",
      "Step: 194\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.436821842342896, 1: -7.443820208912295, 2: -7.3365258519645415, 3: -7.4828051681810415, 4: -7.691059503631032}, Best action: 2, Actual action: 2\n",
      "Step: 195\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.436821842342896, 1: -7.443820208912295, 2: -7.5762385252877325, 3: -7.4828051681810415, 4: -7.691059503631032}, Best action: 0, Actual action: 0\n",
      "Step: 196\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.557112116967058, 3: -7.29921139702996, 4: -7.288607117515974}, Best action: 4, Actual action: 4\n",
      "Step: 197\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.557112116967058, 3: -7.29921139702996, 4: -7.288607117515974}, Best action: 4, Actual action: 4\n",
      "Step: 198\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.557112116967058, 3: -7.29921139702996, 4: -7.532632476939536}, Best action: 3, Actual action: 3\n",
      "Step: 199\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.557112116967058, 3: -7.29921139702996, 4: -7.580470880345129}, Best action: 3, Actual action: 3\n",
      "Step: 200\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.703742859724118, 1: -7.731632485547062, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 0, Actual action: 0\n",
      "Step: 201\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.555803255745208, 2: -7.557112116967058, 3: -8.052649865500312, 4: -7.842424108630662}, Best action: 1, Actual action: 1\n",
      "Step: 202\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.495468771115458, 4: -6.655912088147491}, Best action: 3, Actual action: 3\n",
      "Step: 203\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.249984247654176, 3: -5.974183630768975, 4: -5.9063266710972515}, Best action: 4, Actual action: 4\n",
      "Step: 204\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.249984247654176, 3: -5.974183630768975, 4: -5.9063266710972515}, Best action: 4, Actual action: 4\n",
      "Step: 205\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.249984247654176, 3: -5.974183630768975, 4: -6.274757270698499}, Best action: 3, Actual action: 3\n",
      "Step: 206\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.249984247654176, 3: -5.974183630768975, 4: -6.4078777067751185}, Best action: 3, Actual action: 3\n",
      "Step: 207\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.927036092451177, 1: -6.379707611457967, 2: -7.022352807901501, 3: -5.890416212764834, 4: -6.400073261971953}, Best action: 3, Actual action: 3\n",
      "Step: 208\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941332344707604, 1: -5.823667349069302, 2: -5.960358224202523, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 1, Actual action: 1\n",
      "Step: 209\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -5.965082923725352, 4: -6.201956390275406}, Best action: 3, Actual action: 3\n",
      "Step: 210\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -5.965082923725352, 4: -6.201956390275406}, Best action: 3, Actual action: 3\n",
      "Step: 211\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -6.105562285362571, 2: -5.908807449316774, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 2, Actual action: 2\n",
      "Step: 212\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -6.31478558374258, 4: -6.201956390275406}, Best action: 4, Actual action: 4\n",
      "Step: 213\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -6.709977410301613, 4: -6.201956390275406}, Best action: 4, Actual action: 4\n",
      "Step: 214\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.420528752381336, 2: -6.7483928166359135, 3: -6.810345460243098, 4: -6.54378031515062}, Best action: 1, Actual action: 1\n",
      "Step: 215\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.712268953630249, 1: -6.528191762448822, 2: -6.105036915006317, 3: -5.972471049929773, 4: -6.373162021910017}, Best action: 0, Actual action: 0\n",
      "Step: 216\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.1689907276786355, 2: -6.7483928166359135, 3: -6.823298801289153, 4: -6.685929462432428}, Best action: 1, Actual action: 1\n",
      "Step: 217\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -6.247826568036474, 3: -6.155491818184102, 4: -6.331756740136294}, Best action: 3, Actual action: 3\n",
      "Step: 218\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48059298922344, 1: -6.528191762448822, 2: -6.105036915006317, 3: -5.972471049929773, 4: -6.373162021910017}, Best action: 3, Actual action: 3\n",
      "Step: 219\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.520639169324118, 1: -6.528191762448822, 2: -6.105036915006317, 3: -5.972471049929773, 4: -6.373162021910017}, Best action: 3, Actual action: 3\n",
      "Step: 220\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.492935140520707, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 1, Actual action: 1\n",
      "Step: 221\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.131599719604112, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.325784124906506, 4: -5.019176894870568}, Best action: 4, Actual action: 4\n",
      "Step: 222\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.131599719604112, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.325784124906506, 4: -5.019176894870568}, Best action: 4, Actual action: 4\n",
      "Step: 223\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.131599719604112, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.325784124906506, 4: -5.467450974332217}, Best action: 0, Actual action: 0\n",
      "Step: 224\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.666452441993637, 1: -5.744067838590991, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 0, Actual action: 0\n",
      "Step: 225\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.057604866070359, 1: -6.105562285362571, 2: -6.72229867282136, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 0, Actual action: 0\n",
      "Step: 226\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -6.018234541231866, 2: -6.125992042728915, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 1, Actual action: 1\n",
      "Step: 227\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.494425309767142, 2: -5.640437445437223, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 1, Actual action: 1\n",
      "Step: 228\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -6.352382324520431, 2: -6.336501109080629, 3: -4.8533619035605655, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 229\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4949052246188295, 1: -5.8574446963135856, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 1, Actual action: 1\n",
      "Step: 230\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.39934530018091, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.325784124906506, 4: -6.491695314830063}, Best action: 3, Actual action: 3\n",
      "Step: 231\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -4.14378685072118, 3: -3.9994718333230654, 4: -4.688297425263532}, Best action: 3, Actual action: 3\n",
      "Step: 232\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.23634973489685, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -3.999227257106635}, Best action: 4, Actual action: 4\n",
      "Step: 233\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.23634973489685, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -3.999227257106635}, Best action: 4, Actual action: 4\n",
      "Step: 234\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.23634973489685, 2: -4.164058987767759, 3: -4.7366941481959115, 4: -4.539296803967038}, Best action: 2, Actual action: 2\n",
      "Step: 235\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -4.14378685072118, 3: -4.820325490621476, 4: -4.688297425263532}, Best action: 2, Actual action: 2\n",
      "Step: 236\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397864987338347, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.062399308019564, 4: -6.4907294107002915}, Best action: 3, Actual action: 3\n",
      "Step: 237\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.069945182620789}, Best action: 4, Actual action: 4\n",
      "Step: 238\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.069945182620789}, Best action: 4, Actual action: 4\n",
      "Step: 239\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.133977469116936, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.185761836639449, 4: -5.513650116184918}, Best action: 0, Actual action: 0\n",
      "Step: 240\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -6.247826568036474, 3: -6.478450080731877, 4: -6.331756740136294}, Best action: 2, Actual action: 2\n",
      "Step: 241\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.317968891622436, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.534416187622355, 4: -7.7511222910855855}, Best action: 0, Actual action: 0\n",
      "Step: 242\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.448412469263404, 2: -7.763321272952369, 3: -7.57328115255863, 4: -7.714163890742718}, Best action: 1, Actual action: 1\n",
      "Step: 243\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6650109892656015, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.534416187622355, 4: -7.7511222910855855}, Best action: 3, Actual action: 3\n",
      "Step: 244\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.527450018299129, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.48434454763764, 4: -6.325466667244228}, Best action: 4, Actual action: 4\n",
      "Step: 245\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.527450018299129, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.48434454763764, 4: -6.325466667244228}, Best action: 4, Actual action: 4\n",
      "Step: 246\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.527450018299129, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -6.48434454763764, 4: -6.656174667192248}, Best action: 3, Actual action: 3\n",
      "Step: 247\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -6.6780845742309625, 4: -7.167958157451303}, Best action: 3, Actual action: 3\n",
      "Step: 248\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.691839399187873, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.001777963353719, 4: -7.7511222910855855}, Best action: 3, Actual action: 3\n",
      "Step: 249\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.053224414172727, 2: -7.683422894794398, 3: -7.239248607739609, 4: -7.167958157451303}, Best action: 1, Actual action: 1\n",
      "Step: 250\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.389503595242064, 4: -6.4127854958874515}, Best action: 3, Actual action: 3\n",
      "Step: 251\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.069242436333679, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 252\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -6.792387619940581, 2: -6.71898928921594, 3: -4.9401775752362225, 4: -5.341402841260826}, Best action: 3, Actual action: 3\n",
      "Step: 253\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297538278, 1: -5.622615856626698, 2: -5.374084235078326, 3: -5.919772371460359, 4: -6.490803345605741}, Best action: 2, Actual action: 2\n",
      "Step: 254\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.272273335967422, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.747025987937067, 4: -5.341402841260826}, Best action: 0, Actual action: 0\n",
      "Step: 255\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.5459920467031925, 1: -6.528191762448822, 2: -6.105036915006317, 3: -6.063454751143463, 4: -6.373162021910017}, Best action: 3, Actual action: 3\n",
      "Step: 256\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.223316330773805, 1: -6.352382324520431, 2: -6.336501109080629, 3: -6.055785408627561, 4: -6.660906070967596}, Best action: 3, Actual action: 0\n",
      "Step: 257\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.717238701607059, 2: -6.7483928166359135, 3: -6.845606378363578, 4: -6.930731405635981}, Best action: 1, Actual action: 1\n",
      "Step: 258\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703235, 1: -6.528191762448822, 2: -6.105036915006317, 3: -6.880222095814012, 4: -6.373162021910017}, Best action: 2, Actual action: 2\n",
      "Step: 259\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.528191762448822, 2: -6.105036915006317, 3: -6.839634022430015, 4: -6.373162021910017}, Best action: 2, Actual action: 2\n",
      "Step: 260\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.527450018299129, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -7.246962672267269, 4: -7.388337724027607}, Best action: 0, Actual action: 0\n",
      "Step: 261\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -6.551600699998761, 2: -7.595548326823504, 3: -6.776066763442742, 4: -7.5712497755956765}, Best action: 1, Actual action: 1\n",
      "Step: 262\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.859541568828909, 1: -6.5448435718249725, 2: -6.729187199660623, 3: -7.2469790135130765, 4: -7.388348386690495}, Best action: 1, Actual action: 1\n",
      "Step: 263\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.455583050740693, 4: -6.4127854958874515}, Best action: 4, Actual action: 4\n",
      "Step: 264\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.455597116851194, 4: -6.4127854958874515}, Best action: 4, Actual action: 4\n",
      "Step: 265\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.4556071344246435, 4: -6.735634801257581}, Best action: 3, Actual action: 3\n",
      "Step: 266\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.070512073158179, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 267\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713749598924761, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.189164446939332, 4: -5.341402841260826}, Best action: 4, Actual action: 4\n",
      "Step: 268\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7137332623720285, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.189161138787403, 4: -5.341402841260826}, Best action: 4, Actual action: 4\n",
      "Step: 269\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713746271864257, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.18916377320958, 4: -5.760676585547351}, Best action: 4, Actual action: 4\n",
      "Step: 270\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713751599251324, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.189164852005461, 4: -6.313908291133422}, Best action: 3, Actual action: 3\n",
      "Step: 271\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.622615856626698, 2: -6.3566156964370135, 3: -5.919775932277943, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 272\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -4.846741188942627, 4: -4.6364308610896545}, Best action: 4, Actual action: 4\n",
      "Step: 273\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -4.846741188942627, 4: -4.6364308610896545}, Best action: 4, Actual action: 4\n",
      "Step: 274\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -4.846741188942627, 4: -5.119152083591586}, Best action: 3, Actual action: 3\n",
      "Step: 275\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.125550956560632, 2: -4.721679162908845, 3: -4.872810399611633, 4: -3.5757689888593163}, Best action: 4, Actual action: 4\n",
      "Step: 276\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.125550956560632, 2: -4.721679162908845, 3: -4.872810399611633, 4: -3.5757689888593163}, Best action: 4, Actual action: 4\n",
      "Step: 277\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.125550956560632, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.153949779861978}, Best action: 1, Actual action: 1\n",
      "Step: 278\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -2.8146446912010314, 4: -2.7659239973233065}, Best action: 4, Actual action: 4\n",
      "Step: 279\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -2.8146446912010314, 4: -2.7659239973233065}, Best action: 4, Actual action: 4\n",
      "Step: 280\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.784319004563606, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -2.8146446912010314, 4: -3.416990837564209}, Best action: 0, Actual action: 0\n",
      "Step: 281\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -3.862134956173816, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.71162597537016}, Best action: 1, Actual action: 1\n",
      "Step: 282\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.7311431047175256, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 283\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.451411538075339, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -2.8146446912010314, 4: -4.620778343519277}, Best action: 3, Actual action: 3\n",
      "Step: 284\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.1001553400374804, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 285\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 286\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -2.4293687952299154, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 287\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.0012737890995706217, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 288\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.98 -6.08 -5.03 -5.78 -5.97 -6.06 -6.40 -6.97 -6.95 -7.52 \n",
      "-5.58 -5.09 -5.73 -6.03 -5.94 -5.93 -6.25 -6.56 -7.19 -7.44 \n",
      "-5.02 -4.70 -5.84 -5.64 -6.11 -6.75 -6.00 -6.65 -7.06 -7.52 \n",
      "-4.58 -5.07 -5.01 -5.69 -6.06 -6.37 -6.33 -6.73 -6.81 -7.21 \n",
      "-4.24 -4.18 -4.63 -5.46 -5.19 -6.00 -6.11 -6.48 -7.41 -7.55 \n",
      "-1.94 -3.47 -4.44 -4.63 -3.39 -4.63 -6.82 -6.77 -7.06 -7.52 \n",
      "-2.07 -3.10 -3.11 -3.95 -1.30 -5.18 -6.54 -6.65 -7.18 -7.37 \n",
      "0.00 0.00 -0.36 0.00 0.00 -1.36 -1.05 -6.83 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.979678717885339, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.580910413842003, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.021202701311409, 2: -5.2445082459574985, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -4.5791290985653585, 2: -5.089904410015853, 3: -5.321042436323845, 4: -4.995465142405375}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -4.628292412270566, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.437055746349858, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.9479457748368856, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -3.556308132845678, 2: -3.1089054697145246, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.8130080079524538, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.2972092854681234, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.07 -6.08 -5.03 -5.78 -5.97 -6.06 -6.40 -6.97 -6.95 -7.52 \n",
      "-5.70 -5.09 -5.73 -6.03 -5.94 -5.93 -6.25 -6.56 -7.19 -7.44 \n",
      "-5.24 -4.70 -5.84 -5.64 -6.11 -6.75 -6.00 -6.65 -7.06 -7.52 \n",
      "-5.00 -5.07 -5.01 -5.69 -6.06 -6.37 -6.33 -6.73 -6.81 -7.21 \n",
      "-4.24 -4.18 -4.75 -5.46 -5.19 -6.00 -6.11 -6.48 -7.41 -7.55 \n",
      "-1.94 -3.47 -4.50 -4.63 -3.39 -4.63 -6.82 -6.77 -7.06 -7.52 \n",
      "-2.07 -3.10 -3.18 -1.36 -0.13 -5.18 -6.54 -6.65 -7.18 -7.37 \n",
      "0.00 0.00 -0.36 0.00 0.00 -1.36 -1.05 -6.83 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -6.074323580916404, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.094945248181841, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.6991824395195785, 2: -5.812391125311882, 3: -5.132143405095109, 4: -5.165505580544758}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -5.956589514636005, 3: -5.07146482259499, 4: -5.842151765133615}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -5.2664393736344675, 2: -5.089904410015853, 3: -5.321042436323845, 4: -4.995465142405375}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -5.2664393736344675, 2: -5.089904410015853, 3: -5.321042436323845, 4: -4.995465142405375}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.051217152056557, 1: -5.2664393736344675, 2: -5.089904410015853, 3: -5.321042436323845, 4: -5.445873279588891}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.837333118600283, 1: -6.266403835764696, 2: -6.188706187400157, 3: -6.460028310908727, 4: -5.87949229719335}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.941332344707604, 1: -6.549752965988854, 2: -5.960358224202523, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.5014224446188305, 2: -6.06090424638421, 3: -6.545684890946863, 4: -6.091047468973843}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.400646727309056, 2: -6.819389049228685, 3: -6.610762349913443, 4: -6.527075371325444}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.249984247654176, 3: -6.7099129291610735, 4: -6.7199084526533746}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.561632915586996, 4: -6.655912088147491}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -6.561632915586996, 4: -6.655912088147491}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.661701368172249, 2: -6.979174953309611, 3: -6.7099129291610735, 4: -6.7199084526533746}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -6.691383334071977, 2: -7.541618630918383, 3: -5.998228071065946, 4: -6.729716147711469}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -6.691383334071977, 2: -7.541618630918383, 3: -5.998228071065946, 4: -6.729716147711469}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.800437898252437, 2: -6.7483928166359135, 3: -6.845606378363578, 4: -6.9307314056359814}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.646112089437674, 1: -7.020831609002569, 2: -7.595548326823504, 3: -6.776066763442742, 4: -7.5712497755956765}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -7.082138776309993, 4: -6.655912088147491}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -7.090427640750318, 4: -6.655912088147491}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -7.094051432903867, 4: -6.956880000214217}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -6.971904609757015, 2: -7.0676763859157035, 3: -7.095535375790745, 4: -7.354007160186262}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.099227835341874, 2: -7.160263106593032, 3: -7.064657811412096, 4: -7.334344899790631}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.613982784697881, 1: -6.691383334071977, 2: -7.541618630918383, 3: -7.577861831666671, 4: -6.729716147711469}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.757036205976652, 2: -7.010542492351176, 3: -6.7099129291610735, 4: -6.7199084526533746}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.757166430892966, 2: -7.010554359096675, 3: -6.7099129291610735, 4: -6.7199084526533746}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.927036092451177, 1: -6.379707611457967, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.400073261971953}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -5.9669246901407105, 2: -6.266962310384902, 3: -6.451869918702749, 4: -6.037629661425725}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028071338543, 1: -6.549752965988854, 2: -5.960358224202523, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.486858681473925, 1: -6.379707611457967, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.400073261971953}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.800437898252437, 2: -7.187858053180749, 3: -6.845606378363578, 4: -6.9307314056359814}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -7.622981458529929, 3: -6.478450126726301, 4: -6.331756740136294}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -7.622981458529929, 3: -6.478450126726301, 4: -6.331756740136294}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -7.622981458529929, 3: -6.478450126726301, 4: -6.661898633524028}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -7.622981458529929, 3: -6.478450126726301, 4: -6.882060590615212}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.070695477880624, 1: -6.910061895879341, 2: -6.729187199660623, 3: -7.246981961831042, 4: -7.388350310467967}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -6.810567440764014, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.167958157451303}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.5506063512722985, 4: -7.693531651279605}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.5506063512722985, 4: -7.693531651279605}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.572557681962325, 3: -7.409616854811705, 4: -7.645229807894893}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.481699667393255, 4: -6.8497666256358585}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.999976322626044, 4: -6.554464610781809}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.459818240018966, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -3.38743086309148, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -5.184246680948153, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.3588603842266234, 4: -3.252339898182482}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.91 -6.08 -5.03 -5.78 -6.04 -6.09 -6.53 -6.97 -6.95 -7.52 \n",
      "-5.70 -5.51 -5.73 -6.03 -5.99 -6.40 -6.63 -7.07 -7.19 -7.44 \n",
      "-5.24 -5.13 -5.88 -5.64 -6.11 -6.82 -6.69 -6.78 -7.10 -7.52 \n",
      "-5.09 -5.38 -5.01 -5.69 -6.06 -6.37 -6.53 -6.91 -7.07 -7.21 \n",
      "-4.24 -4.18 -4.75 -4.46 -5.19 -5.47 -6.11 -6.17 -6.75 -7.21 \n",
      "-1.94 -3.47 -4.50 -4.63 -3.99 -4.63 -6.82 -6.77 -7.06 -7.52 \n",
      "-2.07 -3.10 -3.18 -1.36 -0.13 -1.97 -6.54 -6.65 -7.18 -7.37 \n",
      "0.00 0.00 -0.36 0.00 0.00 -0.14 -1.05 -6.83 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -5.91349213849822, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -6.246360593909585, 2: -5.728957116545332, 3: -5.846784121662576, 4: -6.103309005075792}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.033667172547222, 1: -6.144606878275907, 2: -6.125992042728915, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -6.026224295289861, 2: -5.7770426164815785, 3: -5.931185250156019, 4: -6.209590929799614}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -6.266962310384902, 3: -6.451869918702749, 4: -6.037629661425725}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -6.266962310384902, 3: -6.451869918702749, 4: -6.037629661425725}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -6.266962310384902, 3: -6.451869918702749, 4: -6.394242991897409}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -6.971660951564784, 2: -7.2844838121390225, 3: -7.369087136106113, 4: -6.996213691226458}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -7.367997663476205, 2: -7.0676763859157035, 3: -7.095795965401255, 4: -7.530623326046187}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.476931494447693, 2: -7.187789270437362, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.476931494447693, 2: -7.187789270437362, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697073676276251, 1: -7.443820208912295, 2: -7.898608825260489, 3: -7.4828051681810415, 4: -7.691059503631032}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.51989422517787, 2: -7.763321272952369, 3: -7.57328115255863, 4: -7.714163890742718}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697177779427114, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.209746195949004, 4: -7.7511222910855855}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0733927870484505, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.167958157451303}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.156535695455583, 1: -7.020831609002569, 2: -7.595548326823504, 3: -6.776066763442742, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0773114950989955, 1: -6.691383334071977, 2: -7.541618630918383, 3: -7.578445003832143, 4: -6.729716147711469}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.528191762448822, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.373162021910017}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.528191762448822, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.373162021910017}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.528191762448822, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.699577439938115}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.473168416957592, 4: -6.554464610781809}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.185761836639449, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.185761836639449, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -5.998315205140056, 3: -5.619043271341898, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.922603511369609, 4: -6.554464610781809}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.934051229118228, 4: -6.554464610781809}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.461413818418134, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -4.633318423138047, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -4.633318423138047, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.9906387857221635, 2: -5.934680391155646, 3: -5.116319765055623, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -1.3563230491085672, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -3.556308132845678, 2: -3.179602627484725, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -1.968763123706598, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.0454833546776188, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.13588603842266234, 4: -3.252339898182482}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.00012737890995706221, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.18 -6.08 -5.03 -5.93 -6.45 -6.09 -6.53 -7.00 -6.95 -7.52 \n",
      "-5.70 -5.51 -5.85 -6.13 -5.99 -6.40 -6.63 -7.10 -7.32 -7.48 \n",
      "-5.24 -5.13 -5.88 -5.64 -6.11 -6.82 -6.73 -7.02 -7.10 -7.57 \n",
      "-5.09 -5.38 -5.01 -5.69 -6.06 -6.19 -6.53 -6.91 -7.17 -7.42 \n",
      "-4.24 -4.18 -4.75 -5.24 -6.00 -5.11 -6.11 -6.17 -6.75 -7.21 \n",
      "-1.94 -3.47 -4.50 -3.45 -3.99 -4.63 -6.82 -6.77 -7.06 -7.52 \n",
      "-2.07 -3.10 -2.89 -3.48 -0.13 -2.13 -6.54 -6.65 -7.18 -7.37 \n",
      "0.00 0.00 -0.36 0.00 0.00 -0.91 -1.46 -6.83 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -6.528385311404883, 2: -6.177828250144976, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -5.56611217489144, 2: -6.365714263453464, 3: -6.66407852017572, 4: -5.281591486688611}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.033812987368518, 1: -5.56611217489144, 2: -6.365714263453464, 3: -6.66407852017572, 4: -5.281591486688611}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.480769818505352, 1: -5.56611217489144, 2: -6.365714263453464, 3: -6.66407852017572, 4: -5.281591486688611}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.836594406471642, 1: -5.56611217489144, 2: -6.365714263453464, 3: -6.66407852017572, 4: -5.281591486688611}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.113682946415853, 1: -5.56611217489144, 2: -6.365714263453464, 3: -6.66407852017572, 4: -5.7062482528866365}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.144606878275907, 2: -6.125992042728915, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -6.549752965988854, 2: -6.991993573545696, 3: -5.987784313200699, 4: -6.209051393862072}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.144606878275907, 2: -6.362704497965457, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.9217562503034475, 2: -5.640437445437223, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.9217562503034475, 2: -5.640437445437223, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.818315932898109, 1: -6.9407665628053, 2: -7.187880696816165, 3: -6.845606378363578, 4: -6.9307314056359814}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.695764839715919, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.400073261971953}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.695764839715919, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.400073261971953}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.695764839715919, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.724066668394478}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.695764839715919, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.532950701636416, 4: -6.927110265211655}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -6.549752965988854, 2: -6.991993573545696, 3: -6.624410354446775, 4: -6.209051393862072}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -6.549752965988854, 2: -6.991993573545696, 3: -6.624021664423187, 4: -6.209051393862072}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -6.549752965988854, 2: -6.991993573545696, 3: -6.6242798327916415, 4: -6.550236768414486}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.967870113362933, 1: -6.9407665628053, 2: -7.187880696816165, 3: -6.845606378363578, 4: -6.9307314056359814}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.969925906293782, 1: -6.9407665628053, 2: -7.187880696816165, 3: -6.845606378363578, 4: -6.9307314056359814}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.970403280012295, 1: -6.9407665628053, 2: -7.187880696816165, 3: -7.1295018043108564, 4: -6.9307314056359814}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9704769359225, 1: -6.9407665628053, 2: -7.187880696816165, 3: -7.270645985604649, 4: -6.9307314056359814}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.970570995395855, 1: -6.9407665628053, 2: -7.187880696816165, 3: -7.450888783808676, 4: -7.2069655791287435}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.530680250225989, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.112787809119467, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.11490227249002, 4: -6.554464610781809}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -5.998315205140056, 3: -6.396997984966571, 4: -6.9314273748951365}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.168577479814788, 3: -6.174200093543956, 4: -6.414689933709904}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.171087230515618, 4: -6.8497666256358585}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.51543840469913, 3: -6.306665770313887, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.719927749619717, 3: -6.325299861869776, 4: -6.414689933709904}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.619464516887242, 4: -6.554464610781809}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.623398716577952, 4: -6.554464610781809}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.625973699227177, 4: -6.864562795811447}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.244747003641773, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.495135831603334, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.4791021206907304, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.4791021206907304, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -3.556308132845678, 2: -2.886250821967496, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.454776796803112, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -3.556308132845678, 2: -3.9869942876072697, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.3554806582352142, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.92 -6.08 -6.34 -5.93 -6.45 -6.09 -6.53 -7.00 -6.95 -7.52 \n",
      "-5.70 -5.51 -5.85 -6.26 -6.62 -6.70 -6.63 -7.10 -7.32 -7.48 \n",
      "-5.24 -5.13 -5.88 -5.88 -6.11 -6.92 -6.73 -7.02 -7.10 -7.57 \n",
      "-5.09 -5.38 -5.01 -5.69 -6.06 -6.19 -6.60 -6.91 -7.17 -7.42 \n",
      "-4.24 -4.18 -4.75 -5.03 -6.40 -5.71 -6.41 -6.49 -6.75 -7.21 \n",
      "-1.94 -3.47 -4.41 -3.45 -3.99 -4.63 -6.82 -6.77 -7.06 -7.52 \n",
      "-2.07 -3.10 -1.40 -2.95 -0.13 -2.13 -6.54 -6.65 -7.18 -7.37 \n",
      "0.00 0.00 -0.04 0.00 0.00 -0.91 -1.46 -6.83 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -6.528385311404883, 2: -5.915960037669366, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.189765778304688, 1: -6.528385311404883, 2: -5.915960037669366, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.33758104007796, 1: -6.654119560237748, 2: -6.365714263453464, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.33758104007796, 1: -6.654119560237748, 2: -6.365714263453464, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -6.026224295289861, 2: -6.680671785086011, 3: -5.931185250156019, 4: -6.209590929799614}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -7.44308073324557, 3: -6.451869918702749, 4: -7.482720391934942}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.751817469262854, 1: -6.654119560237748, 2: -6.365714263453464, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -7.44308073324557, 3: -6.70141554526758, 4: -7.482720391934942}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -6.026224295289861, 2: -6.680671785086011, 3: -6.952726951417124, 4: -6.209590929799614}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -7.2735777816417775, 2: -6.991993573545696, 3: -6.624496329406822, 4: -7.472158336401026}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -7.2735777816417775, 2: -6.991993573545696, 3: -6.624496329406822, 4: -7.472158336401026}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.695764839715919, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.91912296926454, 4: -7.145725645990073}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.944809592850413, 2: -6.819389049228685, 3: -6.610762349913443, 4: -6.527075371325444}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.944809592850413, 2: -6.819389049228685, 3: -6.610762349913443, 4: -6.527075371325444}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.944809592850413, 2: -6.819389049228685, 3: -6.610762349913443, 4: -6.839638587906155}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -7.5701923547639005, 2: -7.2844838121390225, 3: -7.369087136106113, 4: -6.996213691226458}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -7.5701923547639005, 2: -7.2844838121390225, 3: -7.369087136106113, 4: -6.996213691226458}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -7.5701923547639005, 2: -7.2844838121390225, 3: -7.369087136106113, 4: -7.266554459016077}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -7.5701923547639005, 2: -7.2844838121390225, 3: -7.369087136106113, 4: -7.623269102114479}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -6.946683895190232, 2: -7.557112116967058, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697073676276251, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.4828051681810415, 4: -7.691059503631032}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.476931494447693, 2: -7.988516338723585, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.476931494447693, 2: -7.988516338723585, 3: -7.574929800776152, 4: -7.32482705317007}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.476931494447693, 2: -7.988516338723585, 3: -7.574929800776152, 4: -7.565592618384764}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.587673663875509, 2: -7.763321272952369, 3: -7.57328115255863, 4: -7.714163890742718}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.099227835341874, 2: -7.160263106593032, 3: -7.172289756426994, 4: -7.334344899790631}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.070695477880624, 1: -6.910061895879341, 2: -7.497644416221306, 3: -7.246981961831042, 4: -7.388350310467967}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.572557681962325, 3: -6.751362819474771, 4: -7.645229807894893}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.572557681962325, 3: -6.751362819474771, 4: -7.645229807894893}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.572557681962325, 3: -7.043740165722042, 4: -7.645229807894893}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.422955511715427, 2: -7.572557681962325, 3: -7.429532074095317, 4: -7.645229807894893}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.058238690361506, 2: -7.370828721553068, 3: -7.116733443829903, 4: -7.0781379521638295}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.53825386968358, 3: -7.372237801956234, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.184845126157536}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.438209064803358}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -7.219145333504944, 4: -7.515232429436533}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -6.650687673753603, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -6.825912840858677, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.4645589662226006, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.2737890995706221e-05, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.19 -6.08 -6.65 -6.21 -6.79 -6.09 -6.73 -7.33 -7.56 -7.52 \n",
      "-5.70 -5.51 -5.85 -6.26 -6.80 -6.92 -6.63 -7.10 -7.57 -7.69 \n",
      "-5.24 -5.13 -5.88 -5.88 -6.11 -6.92 -6.73 -7.02 -7.16 -7.53 \n",
      "-5.09 -5.38 -5.01 -5.69 -6.06 -6.19 -6.60 -7.07 -7.17 -7.42 \n",
      "-4.24 -4.18 -4.75 -5.03 -6.40 -5.71 -6.41 -6.49 -7.45 -7.21 \n",
      "-1.94 -3.47 -4.41 -3.45 -3.99 -4.63 -6.82 -6.77 -7.08 -7.52 \n",
      "-2.07 -3.10 -1.40 -2.95 -0.13 -2.13 -6.54 -5.18 -5.88 -7.54 \n",
      "0.00 0.00 -0.04 0.00 0.00 -0.91 -1.05 -2.58 -7.49 -7.69 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.189765778304688, 1: -6.528385311404883, 2: -7.094754025434982, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.144423189301917, 2: -6.096497757529535, 3: -6.306901598435431, 4: -6.078526589422081}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.144423189301917, 2: -6.096497757529535, 3: -6.306901598435431, 4: -6.078526589422081}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.144423189301917, 2: -6.096497757529535, 3: -6.306901598435431, 4: -6.431459196374094}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -7.0589267228586605, 2: -6.680671785086011, 3: -6.95018340300774, 4: -6.209590929799614}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -7.0589267228586605, 2: -6.680671785086011, 3: -6.95018340300774, 4: -6.209590929799614}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -7.0589267228586605, 2: -6.680671785086011, 3: -6.95018340300774, 4: -6.550727746117648}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.525561361926881, 1: -7.0589267228586605, 2: -6.680671785086011, 3: -6.95018340300774, 4: -6.9712998570172395}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.838260839353462, 1: -7.0589267228586605, 2: -6.680671785086011, 3: -6.95018340300774, 4: -7.175336266038084}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.5014224446188305, 2: -6.935487563252365, 3: -6.545684890946863, 4: -6.091047468973843}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.5014224446188305, 2: -6.935487563252365, 3: -6.545684890946863, 4: -6.091047468973843}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.5014224446188305, 2: -6.935487563252365, 3: -6.545684890946863, 4: -6.4428531967661975}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -6.5014224446188305, 2: -6.935487563252365, 3: -6.545684890946863, 4: -6.9070608545882095}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.089868488637929, 1: -7.109473357779059, 2: -7.022352807901501, 3: -6.91912296926454, 4: -7.145725645990073}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.797028166632642, 1: -7.2735777816417775, 2: -6.991993573545696, 3: -7.313199478941094, 4: -7.472158336401026}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.111316145650543, 1: -7.0589267228586605, 2: -6.750459815844368, 3: -6.95018340300774, 4: -7.230629965563241}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1126736617238935, 1: -7.0589267228586605, 2: -6.752540300247971, 3: -6.95018340300774, 4: -7.230904862568095}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -6.788818537822541, 2: -7.44308073324557, 3: -6.937402165274015, 4: -7.482720391934942}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.190767378076846, 1: -7.2735777816417775, 2: -6.991993573545696, 3: -7.313199478941094, 4: -7.472158336401026}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.089868488637929, 1: -7.109473357779059, 2: -7.022352807901501, 3: -7.293287294443778, 4: -7.145725645990073}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.76255987531029, 2: -7.988516338723585, 3: -7.574929800776152, 4: -7.965522810134306}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -7.367997663476205, 2: -7.619250579283936, 3: -7.095795965401255, 4: -7.530623326046187}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.76255987531029, 2: -7.988516338723585, 3: -7.405087712052632, 4: -7.965522810134306}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.183827376610967, 1: -7.367997663476205, 2: -7.619250579283936, 3: -7.607700643302757, 4: -7.530623326046187}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.773992514415831, 2: -7.557112116967058, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.516471210876292, 1: -7.732632818627878, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.516471210876292, 1: -7.732632818627878, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739988801897425, 1: -7.732632818627878, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.024053370785175, 1: -7.732632818627878, 2: -7.730736445605696, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.15731587301698, 1: -7.732632818627878, 2: -7.934970165501183, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697073676276251, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.745587254114735, 4: -7.691059503631032}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697073676276251, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.745587254114735, 4: -7.691059503631032}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697073676276251, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.745587254114735, 4: -7.898864148304239}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.199319606260026, 1: -8.001728088629632, 2: -8.142396008676727, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.202403328659587, 1: -8.025066416236164, 2: -8.157624267439989, 3: -7.757382275495107, 4: -7.772714379531234}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.773992514415831, 2: -7.909367114015501, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.690481427228027, 1: -7.773992514415831, 2: -7.909355534715191, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3272221361422805, 1: -7.5701923547639005, 2: -7.627551214969507, 3: -7.369087136106113, 4: -7.778389322067925}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203507046076961, 1: -8.033419606093771, 2: -8.163074723822076, 3: -7.965242427850566, 4: -7.772714379531234}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203640665058359, 1: -8.034430865590654, 2: -8.163734570643792, 3: -8.044705993118985, 4: -7.772714379531234}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203660706852189, 1: -8.034582546542959, 2: -8.16383354246517, 3: -8.056624901461138, 4: -7.973170085373423}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203668913966762, 1: -8.034644659892928, 2: -8.163874071426024, 3: -8.061505694427249, 4: -8.237671389232192}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05828822875579, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.745587254114735, 4: -8.171751963046564}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058244905979887, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -7.745587254114735, 4: -8.171723694935286}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7168354270074, 1: -7.76255987531029, 2: -7.988516338723585, 3: -7.838010301453792, 4: -7.965522810134306}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203669100375771, 1: -8.068088723257107, 2: -8.163874991964342, 3: -8.061616552363047, 4: -8.252886151502732}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.203669502831216, 1: -8.112265298426589, 2: -8.16387697939864, 3: -8.061855893691783, 4: -8.285734692223361}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979124199364999, 1: -7.773992514415831, 2: -7.909391225800917, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.23639620006405, 1: -7.76255987531029, 2: -7.988516338723585, 3: -7.83801031593449, 4: -7.965522810134306}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.160263106593032, 3: -7.172289756426994, 4: -7.334344899790631}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.587673663875509, 2: -7.763321272952369, 3: -7.529967802098699, 4: -7.714163890742718}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.156535695455583, 1: -7.020831609002569, 2: -7.595548326823504, 3: -7.082424466434209, 4: -7.5712497755956765}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.233814323439625, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.167958157451303}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.233814323439625, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.167958157451303}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.233814323439625, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.422841923280686}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.734643050598713, 3: -7.172289756426994, 4: -7.334344899790631}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.738317408053017, 3: -7.172289756426994, 4: -7.334344899790631}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.156535695455583, 1: -7.567371233412091, 2: -7.595548326823504, 3: -7.082424466434209, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.156535695455583, 1: -7.566497649723791, 2: -7.595548326823504, 3: -7.082424466434209, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0773114950989955, 1: -6.879821755164495, 2: -7.541618630918383, 3: -7.578445003832143, 4: -6.729716147711469}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0773114950989955, 1: -6.879821755164495, 2: -7.541618630918383, 3: -7.578445003832143, 4: -6.729716147711469}, Best action: 4, Actual action: 4\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0773114950989955, 1: -6.879821755164495, 2: -7.541618630918383, 3: -7.578445003832143, 4: -7.024041694417437}, Best action: 1, Actual action: 1\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.070695477880624, 1: -7.274184624182326, 2: -7.497644416221306, 3: -7.246981961831042, 4: -7.388350310467967}, Best action: 0, Actual action: 0\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.740652373399525, 3: -7.512815817942141, 4: -7.334344899790631}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.740667180060846, 3: -7.518561446528088, 4: -7.334344899790631}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.370928146932798, 2: -7.740670529882296, 3: -7.519861322946076, 4: -7.574253858809475}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.560475433498447, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.750294510592611}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.560505489348225, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.320971245209181, 4: -7.750314122034592}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.694468088941052, 1: -7.274184624182326, 2: -7.497644416221306, 3: -7.246981961831042, 4: -7.388350310467967}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.560521003222012, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.5101447450627505, 4: -7.750324244837238}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.560527439183626, 1: -7.717603150178214, 2: -7.683422894794398, 3: -7.810903839361761, 4: -7.750328444302191}, Best action: 0, Actual action: 0\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.7100919171695015, 2: -7.740671825793946, 3: -7.520364193030541, 4: -7.873312041715129}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.587673663875509, 2: -7.763321272952369, 3: -7.586349146970901, 4: -7.714163890742718}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.537480793845121, 1: -7.715839886447031, 2: -7.74067184204624, 3: -7.796982127142855, 4: -7.877062591668718}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058350488249575, 1: -7.7659970906992415, 2: -7.898608825260489, 3: -8.293833198324627, 4: -8.171792587366262}, Best action: 1, Actual action: 1\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.587673663875509, 2: -7.763321272952369, 3: -7.94702058567558, 4: -7.714163890742718}, Best action: 1, Actual action: 1\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697177779427114, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.4226124684801755, 4: -7.7511222910855855}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6982660569242745, 1: -7.274184624182326, 2: -7.497644416221306, 3: -7.783961092652001, 4: -7.388350310467967}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -6.490704021186788, 2: -6.75114549274193, 3: -6.832550216787178, 4: -6.8497666256358585}, Best action: 1, Actual action: 1\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805914973522, 1: -7.082764476420722, 2: -7.073866127462204, 3: -7.317384857111487, 4: -6.77122043628769}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805914973522, 1: -7.082764476420722, 2: -7.073866127462204, 3: -7.317384857111487, 4: -6.77122043628769}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.847805914973522, 1: -7.082764476420722, 2: -7.073866127462204, 3: -7.317384857111487, 4: -7.061810597021798}, Best action: 0, Actual action: 0\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.2079134451233715, 4: -7.693531651279605}, Best action: 3, Actual action: 3\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.2079134451233715, 4: -7.693531651279605}, Best action: 3, Actual action: 3\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -7.4592012350622685, 4: -7.693531651279605}, Best action: 3, Actual action: 3\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446173452019247, 1: -7.631003888279422, 2: -7.572557681962325, 3: -7.9577319972383505, 4: -7.645229807894893}, Best action: 0, Actual action: 0\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.94966957052285, 1: -7.717603150178214, 2: -7.683422894794398, 3: -8.029949803978228, 4: -7.750329138518927}, Best action: 2, Actual action: 2\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.949672222185688, 1: -7.717603150178214, 2: -7.683422894794398, 3: -8.029951347589666, 4: -7.750329138523819}, Best action: 2, Actual action: 2\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697177779427114, 1: -7.70118464109234, 2: -7.701076821800475, 3: -7.513165559491395, 4: -7.7511222910855855}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.949672662752205, 1: -7.717603150178214, 2: -7.722178925172459, 3: -8.029951604056478, 4: -7.7503291385246325}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.973793181204618, 1: -7.631003888279422, 2: -7.572557681962325, 3: -7.9577319972383505, 4: -7.645229807894893}, Best action: 2, Actual action: 2\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.626837765413266, 2: -7.745468678885597, 3: -8.053116430860907, 4: -7.693531651279605}, Best action: 1, Actual action: 1\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.792905233836281, 1: -7.519142514468234, 2: -7.801482738789935, 3: -7.799529635983455, 4: -7.739192942274146}, Best action: 1, Actual action: 1\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.53825386968358, 3: -7.559600709108936, 4: -7.621899980192864}, Best action: 2, Actual action: 2\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.53825386968358, 3: -7.559600709108936, 4: -7.621899980192864}, Best action: 2, Actual action: 2\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.759811021412059, 3: -7.559600709108936, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -5.880867890775302, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -5.880867890775302, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -6.251589780605524, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -6.740757314236503, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.243938699579077, 3: -6.681332553187571, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.23882658786079, 3: -6.673497899213183, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.242431323301168, 3: -6.978407587043198, 4: -7.621899980192864}, Best action: 3, Actual action: 3\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.243904768504962, 3: -7.374983550503092, 4: -7.621899980192864}, Best action: 2, Actual action: 2\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.244221922985813, 3: -7.590422955787525, 4: -7.621899980192864}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.492514074249448, 3: -7.775273897099519, 4: -7.621899980192864}, Best action: 2, Actual action: 2\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.81985241038186, 3: -7.850962143517277, 4: -7.621899980192864}, Best action: 4, Actual action: 4\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -7.87913855404155, 3: -7.85637608166936, 4: -7.621899980192864}, Best action: 4, Actual action: 4\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -7.7738303443558365, 2: -8.038317269359858, 3: -7.870912087330449, 4: -7.835928981975506}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.710182851315418, 1: -7.771080002848285, 2: -7.7159443610197025, 3: -7.961175809689256, 4: -7.688728195267513}, Best action: 4, Actual action: 4\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.710182851315418, 1: -7.771080002848285, 2: -7.7159443610197025, 3: -7.961175809689256, 4: -7.688728195267513}, Best action: 4, Actual action: 4\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.710182851315418, 1: -7.771080002848285, 2: -7.7159443610197025, 3: -7.961175809689256, 4: -7.896742657693436}, Best action: 0, Actual action: 0\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.812033501697731, 1: -8.006590773516317, 2: -8.121721496505426, 3: -7.878528459378197, 4: -8.197281579970614}, Best action: 0, Actual action: 0\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.792905233836281, 1: -7.785655225800167, 2: -7.801482738789935, 3: -7.799529635983455, 4: -7.739192942274146}, Best action: 4, Actual action: 4\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.792905233836281, 1: -7.7856552417907885, 2: -7.801482738789935, 3: -7.799529635983455, 4: -7.739192942274146}, Best action: 4, Actual action: 4\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.792905233836281, 1: -7.785655252406982, 2: -7.801482738789935, 3: -7.799529635983455, 4: -7.942665577469473}, Best action: 1, Actual action: 1\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.053253620531972, 1: -8.042779392722943, 2: -8.127171658483295, 3: -7.879026161506311, 4: -8.220894654002938}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.07830583879578, 1: -8.043806690248124, 2: -8.127326373916889, 3: -7.8790402899305425, 4: -8.221564965638118}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -7.27163314388949, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -5.1837282948509085, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 1, Actual action: 1\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -2.5807353439253866, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.0464507377764067, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.0464507377764067, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.9135370153837337, 4: -3.252339898182482}, Best action: 3, Actual action: 3\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.9135370153837337, 4: -3.252339898182482}, Best action: 3, Actual action: 3\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.2737890995706215e-06, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.51 -6.14 -6.65 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.70 -5.51 -5.85 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.24 -5.13 -5.88 -5.88 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.09 -5.38 -5.01 -5.69 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.18 -4.75 -5.03 -6.40 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -4.41 -3.45 -3.99 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -1.40 -2.95 -0.13 -2.13 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.04 0.00 0.00 -0.78 -2.15 -2.41 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.528385311404883, 2: -7.094754025434982, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 3, Actual action: 3\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.528385311404883, 2: -7.094754025434982, 3: -6.514351429008765, 4: -6.610434262475354}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.528385311404883, 2: -7.094754025434982, 3: -6.828059800397976, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -5.704951022543889, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.420504463750181, 2: -5.2445082459574985, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.9217562503034475, 2: -7.572457577691253, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.9217562503034475, 2: -7.572457577691253, 3: -5.977839666152929, 4: -5.880908047605686}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -5.9217562503034475, 2: -7.572457577691253, 3: -5.977839666152929, 4: -6.251626323321174}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.694842174556702, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.750573207517903, 1: -4.9829804341345065, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.317448515545172, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -6.396997984966571, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.026257676006865, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -3.9910152971184525, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -2.1323018548547727, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.776947053347596, 4: -3.252339898182482}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.1533491058629943, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -2.410364607617353, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.0677302427563555, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.3795244960156463, 4: -3.252339898182482}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.4051440248094473, 4: -3.252339898182482}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.430046686143961, 4: -3.8596293073460584}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.273789099570622e-07, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.035548065823521435, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.41 -6.14 -6.65 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.77 -5.51 -5.85 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.42 -5.13 -5.88 -5.98 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.09 -5.38 -5.01 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.18 -4.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -4.41 -3.45 -3.39 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -1.40 -2.95 -0.13 -2.93 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.00 0.00 -0.91 -1.64 -4.14 -3.82 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.412132593339446, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -6.246360593909585, 2: -6.61024785688609, 3: -5.846784121662576, 4: -6.103309005075792}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.7152877579136, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.7152877579136, 2: -5.659007090416334, 3: -5.509316176711518, 4: -6.194714268870099}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.7152877579136, 2: -5.659007090416334, 3: -5.913477720807482, 4: -6.194714268870099}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.956434211560574, 1: -6.246360593909585, 2: -6.61024785688609, 3: -6.1618345335341465, 4: -6.103309005075792}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.654119560237748, 2: -6.952157285126243, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885480264948634, 1: -6.246360593909585, 2: -6.61024785688609, 3: -6.257486263956172, 4: -6.103309005075792}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.820217975402472, 1: -6.246360593909585, 2: -6.61024785688609, 3: -6.254810102195469, 4: -6.103309005075792}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.891235168784966, 1: -6.246360593909585, 2: -6.61024785688609, 3: -6.25772225098161, 4: -6.45401119461897}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.266403835764696, 2: -6.188706187400157, 3: -6.460028310908727, 4: -5.87949229719335}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.266403835764696, 2: -6.188706187400157, 3: -6.460028310908727, 4: -5.87949229719335}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.266403835764696, 2: -6.188706187400157, 3: -6.460028310908727, 4: -6.250337990445948}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.163056736332673, 2: -7.572457577691253, 3: -5.977839666152929, 4: -6.510805254502509}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.266403835764696, 2: -6.360920748323888, 3: -6.460028310908727, 4: -6.779652331018204}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.006337814980593, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -4.9829804341345065, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -3.3859071043755935, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -2.9315042375911764, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -4.136323063299435, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.9143969539206351, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.9143969539206351, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.46 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.77 -5.72 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.42 -5.13 -5.65 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.09 -5.38 -5.17 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.18 -4.38 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -4.41 -3.45 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -1.40 -2.95 -0.13 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.00 0.00 0.53 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.462507285489033, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.7152877579136, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.420504463750181, 2: -6.391005245548477, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.2664393736344675, 2: -5.089904410015853, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.382963134904596, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.181489000390897, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.407853502812194, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -2.949734787294413, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -2.949734787294413, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.3996004798698294, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.32 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.77 -6.03 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.44 -5.13 -5.65 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.27 -4.99 -5.17 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.55 -4.38 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -3.66 -3.45 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -0.14 -1.03 -0.13 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.00 0.00 0.53 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.316814786538148, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -6.234470431295902, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -6.234470431295902, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -5.768765947209327}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.827541435800304, 1: -6.234470431295902, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -6.149577011960488}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.393098948608738, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -6.0290232558674415, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -5.654333069188183, 2: -6.505055551436441, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.167580160485999, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -4.384607605998925, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -3.6594098633237846, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -1.0337164915899928, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.13996004798698292, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.0035548065823521394, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.40 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.88 -5.98 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.44 -5.13 -5.42 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.27 -4.99 -4.66 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.55 -3.69 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -2.30 -3.45 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -0.92 -1.47 -0.13 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.00 0.00 0.53 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.4048433563849265, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.234470431295902, 2: -5.8768560505037835, 3: -6.080208519199367, 4: -6.799651671662251}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -5.977818597326366, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.8090834552630355, 2: -5.812391125311882, 3: -5.132143405095109, 4: -5.165505580544758}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.7913619402800345, 2: -6.391005245548477, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.7913619402800345, 2: -6.391005245548477, 3: -5.439896298632867, 4: -5.846820849838211}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608702713601196, 1: -5.7913619402800345, 2: -6.391005245548477, 3: -5.850305631755909, 4: -5.846820849838211}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.03133054208409, 1: -6.063449697150166, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.527990615815144, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.234470431295902, 2: -6.388168950536889, 3: -6.080208519199367, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.234470431295902, 2: -6.387971739806075, 3: -6.080208519199367, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.838494098672047, 1: -6.10858810174555, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -5.420791926293057, 2: -6.505055551436441, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -4.655621692442843, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.68978875163251, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.45293613056213, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -1.4657033320933612, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.1297209285468124, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.5282908745606725, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.5282908745606725, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.61 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-6.23 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.79 -5.17 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-5.27 -4.99 -4.32 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.24 -4.55 -3.61 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-1.94 -3.47 -2.30 -2.43 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -3.10 -0.92 -1.47 -0.84 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 0.00 -0.00 0.00 0.13 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 0.00 0.00 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -2.79 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.615122568941738, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.615122568941738, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.610434262475354}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -6.615122568941738, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.915495178852572}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.234470431295902, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.8090834552630355, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.165505580544758}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.8090834552630355, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.165505580544758}, Best action: 4, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.2664393736344675, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.23634973489685, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3041881472519172, 1: -3.1137782556140023, 2: -5.0846835228144345, 3: -1.94204585541234, 4: -3.1358073965764572}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3041881472519172, 1: -3.1137782556140023, 2: -5.0846835228144345, 3: -1.94204585541234, 4: -3.1358073965764572}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.3041881472519172, 1: -3.1137782556140023, 2: -5.0846835228144345, 3: -2.6672617284252294, 4: -3.1358073965764572}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.2971252700769784, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -3.5697365107956136, 2: -3.9262894408365767, 3: -3.466576823599344, 4: -4.51185297381412}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.0790776924067185, 1: -3.1137782556140023, 2: -5.0846835228144345, 3: -4.3558695799911895, 4: -3.1358073965764572}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.099630614037746, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -1.3050000000000002, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: -2.0875500000000002}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.7925139407280803, 1: -3.706424999899108, 2: -4.5586518151261854, 3: -2.9885414250614755, 4: -3.7235654418916977}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -2.4359681459948725, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.4872500000000002, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.5618813750000002, 4: -2.0875500000000002}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -2.7546267326238136, 2: -1.496939222265469, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -2.754210986551574, 2: -1.4923768511023445, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -2.754891999129894, 2: -1.4998502401648446, 3: -1.3050000000000002, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -2.7551984547901385, 2: -1.5032132652429695, 3: -1.4872500000000002, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5067887832630025, 1: -2.2703957767723537, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: -2.934758822002341}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -1.4690392110507138, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.915435701464551, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.53 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-6.06 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.79 -5.41 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.51 -4.99 -4.32 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.23 -4.55 -3.61 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.14 -3.57 -2.30 -2.43 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.83 -0.09 -1.42 -0.84 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -0.00 0.00 0.13 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.53130518850773, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.056407947437847, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.7913619402800345, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.51086149934693, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.225756111111575, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -3.5697365107956136, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.8275308832030597, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.00035548065823521376, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.1278728677656853, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.39 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.91 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.16 -5.41 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.57 -4.99 -4.32 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.77 -4.55 -3.61 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.14 -2.57 -2.30 -2.43 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.46 -0.09 -1.42 -0.84 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -0.85 0.00 0.01 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.393714758277179, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.911727507441737, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.406714194740835, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -4.317190194467001, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.6073423880778077, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -2.434014457582644, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.835042985698945, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.012787286776568527, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.18 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.59 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.16 -4.78 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.57 -4.99 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.77 -4.55 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.14 -2.57 -2.30 -1.88 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.46 -0.09 -1.42 -0.98 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -0.85 0.00 0.00 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.183059178207552, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.589923999335133, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.15821425377142, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.567039822174494, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.7659588271991877, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.1496337440563655, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.1358073965764572}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.1496337440563655, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.1358073965764572}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.1496337440563655, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.753584730884576}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.464592227836595, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.848247036620721, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.848247036620721, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.0012787286776568523, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.06 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.61 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.10 -4.78 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.54 -4.99 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.06 -4.55 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-2.63 -2.57 -2.30 -1.88 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.98 -0.09 -1.42 -0.98 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -0.79 0.00 0.00 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.056252021056426, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.612385474388939, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.103190984661589, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.991902123427416, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.5517105995471825, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.2976454227467884, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -1.4176553801982146, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.981625795321673, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.794318101569965, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.00012787286776568528, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.00012787286776568528, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.08 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.67 -5.74 -6.26 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.27 -4.78 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.54 -4.59 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.06 -3.45 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-2.63 -2.57 -2.82 -1.88 -3.93 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.93 -0.09 -2.63 -0.98 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -1.22 0.00 0.27 -1.64 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.078229733823961, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.540961151508584, 2: -6.61024785688609, 3: -6.2587816496812465, 4: -6.865103967021368}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.671435024307333, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.782964752187238, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.591190044865457, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.451964481523843, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.821424598622847, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -2.625120265504022, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -2.625120265504022, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -3.2888594416086603, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.044841314003701, 1: -5.51730282319569, 2: -4.276406050471545, 3: -4.16466328447873, 4: -4.801787522208119}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -3.92751778891169, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.9783254474253842, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.6400888405576495, 4: -2.995629848893583}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.27446450888555174, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.27446450888555174, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.47 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.44 -5.74 -6.02 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.27 -5.00 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.54 -4.38 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-4.06 -3.95 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-2.63 -2.57 -3.76 -1.88 -2.59 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.07 -1.93 -0.09 -3.88 -2.10 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "0.00 -1.98 -1.22 0.00 0.20 -1.14 -2.11 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.468037192230316, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.440173712539402, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.2734393830894835, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.540522718448067, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.062385685419801, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -2.633948184321564, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.5229166617474474}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.933265424818664, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.217477915393754, 1: -2.2704463630369713, 2: -3.0101019533708544, 3: -1.9786616187918464, 4: -2.9347964392133674}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -1.4531212548534043, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.217477915393754, 1: -2.2704463630369713, 2: -3.0101019533708544, 3: -1.6403457410032625, 4: -2.9347964392133674}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.217477915393754, 1: -2.2704463630369713, 2: -3.0101019533708544, 3: -1.647992437300834, 4: -2.9347964392133674}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6291444027112794, 1: -2.5938305263334187, 2: -2.7122484819872996, 3: -1.9592882021721885, 4: -3.3514488744300954}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -2.0672237368500377, 2: -2.972411334269742, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.217477915393754, 1: -2.2704463630369713, 2: -3.0101019533708544, 3: -3.2097225341053632, 4: -2.9347964392133674}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8840600834532926, 1: -5.51730282319569, 2: -4.276406050471545, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -1.8842633719513078, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -2.10095074104087, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.1393026971057294, 4: -2.995629848893583}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.1065853135565193, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -2.7202643736913537, 4: -2.995629848893583}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.19832237555881516, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.19832237555881516, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.7195266382414782, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.03 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.62 -5.74 -6.02 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-5.06 -5.00 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.44 -4.38 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.61 -3.95 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.57 -3.76 -3.12 -2.59 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.55 -0.09 -3.37 -2.83 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.27 -1.22 0.00 0.94 -1.13 -2.52 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -1.58 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.033992431095697, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.619391500796622, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.059857670289932, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.439834562977066, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.607385431958066, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -2.5739512715591304, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -2.549179505902361, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -2.2704463630369713, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -2.9347964392133674}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.5762696986280011, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.9406986937231074, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.51 -5.74 -6.02 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -5.00 -5.06 -6.16 -6.11 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.38 -3.97 -5.92 -6.06 -6.19 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.95 -2.98 -4.36 -5.31 -5.71 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -3.37 -3.76 -3.12 -2.59 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.87 -0.09 -3.37 -2.83 -3.63 -6.54 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -1.22 0.00 0.09 -1.13 -2.52 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.0049704314644075, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.540961151508584, 2: -6.61024785688609, 3: -6.015672944361495, 4: -6.865103967021368}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.540961151508584, 2: -6.61024785688609, 3: -6.015672944361495, 4: -6.865103967021368}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.540961151508584, 2: -6.61024785688609, 3: -6.374262379368961, 4: -6.865103967021368}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.540961151508584, 2: -6.61024785688609, 3: -6.847421138861312, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.437398016674666, 1: -6.105562285362571, 2: -6.722325908506042, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -6.352382324520431, 2: -6.336501109080629, 3: -6.055785408988724, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.254408793283606, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.254408793283606, 2: -6.471512086403765, 3: -5.919630515698002, 4: -6.096859363003361}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -6.352382324520431, 2: -6.336501109080629, 3: -6.465734222728486, 4: -6.660906070967596}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.193449161522554, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.7110189936938855, 4: -6.3972922329699085}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -5.312524824048686, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.363049471532346, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -2.5903767734326983, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -6.542175736570636, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.630190117647348, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.130304384743253, 4: -2.995629848893583}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.5157373846271915, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.5157373846271915, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.1893210200107447, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -4.0781146268993425, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.09406986937231077, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -1.2203296193806876, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.61 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.51 -5.74 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -5.00 -5.06 -6.16 -6.26 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.38 -3.97 -6.10 -6.35 -6.16 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.95 -2.98 -5.01 -5.26 -5.75 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -3.37 -3.76 -3.12 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.87 -0.09 -3.37 -2.83 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -0.12 0.00 -1.38 -3.00 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.612083864015857, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.739451885195903, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -5.060838589418879, 2: -6.505055551436441, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.254408793283606, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.096859363003361}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.254408793283606, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.096859363003361}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.254408793283606, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.448142020333059}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -5.255725911336752, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.748687496128453, 4: -6.3972922329699085}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.748687496128453, 4: -6.3972922329699085}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -6.2541876194045205, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.008390264844974, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.1170159423966255, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.09154357014645509, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -1.3848265089119476, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.43 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.51 -6.19 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -5.00 -6.46 -6.16 -6.26 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.38 -3.97 -6.21 -6.35 -6.16 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.95 -2.98 -3.38 -4.72 -5.81 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -3.37 -3.76 -1.91 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.87 -1.47 -3.37 -2.83 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -0.12 0.00 -0.14 -3.00 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.4332085218412205, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.235105459486911, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.235105459486911, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.194714268870099}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.235105459486911, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.53718998467179}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.002584220713915, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.381020731874725, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.9537655867546584, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -3.3674209221400515, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -2.8718248285761963, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.67 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.51 -5.55 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.95 -6.46 -6.16 -6.26 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.38 -3.97 -6.21 -6.35 -6.16 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -2.98 -3.38 -4.72 -5.81 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -3.76 -1.91 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -0.29 -1.47 -3.37 -2.83 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -0.12 0.00 -0.14 -3.00 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.666319558266937, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -5.50797832904012, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.505055551436441, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 3, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.437398016674666, 1: -6.642528175792666, 2: -6.722325908506042, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.437398016674666, 1: -6.642528175792666, 2: -6.722325908506042, 3: -6.361350367044498, 4: -6.2581432828209715}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.437398016674666, 1: -6.642528175792666, 2: -6.722325908506042, 3: -6.361350367044498, 4: -6.594910387367085}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.163056736332673, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -6.162221127139858, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -5.810871696452014, 4: -6.3972922329699085}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -3.3807373828764633, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -1.9061613713981793, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -2.82721630761507, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.4046433798710907, 4: -2.995629848893583}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.4046433798710907, 4: -2.995629848893583}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.4046433798710907, 4: -3.6260231624931607}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.13848265089119471, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.3526352852089771, 4: -2.8588813033311538}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.0094828461083907, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.64 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-6.28 -5.55 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.95 -6.46 -6.24 -6.44 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.38 -3.97 -6.21 -6.35 -5.56 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -2.98 -3.65 -4.72 -4.34 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -3.76 -3.84 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -0.29 -1.47 -3.37 -3.86 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -0.12 0.00 0.19 -1.76 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.635847272143306, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.388483402812573, 3: -6.276731707135872, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.5503952032604715, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.1875149746547295}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.946565195232824, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.375865132636738, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -2.984897960915621, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.8435089112708987, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.4700090931239842, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.12203296193806867, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.50 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.95 -5.39 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.79 -6.46 -6.24 -6.44 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.04 -3.97 -6.21 -6.35 -5.56 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -3.62 -3.65 -4.72 -4.34 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -3.76 -2.31 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -0.29 -1.10 -3.37 -3.86 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -2.00 -0.01 0.00 0.19 -1.76 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.68 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.501431061527342, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.388483402812573, 3: -5.951606488320217, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.388483402812573, 3: -5.951606488320217, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.388483402812573, 3: -6.315961904371397, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.388483402812573, 3: -6.796728875850929, 4: -6.799651671662251}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.390646765406355, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.1875149746547295}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.788541721769979, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.041275009994378, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -3.6538708420628954, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -3.7619028513289985, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -0.2871824828576197, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -1.9989915273170014, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -2.9347964392133674}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.6766439989049415, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.58 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-5.87 -5.31 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.76 -6.46 -6.24 -6.44 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.28 -3.97 -6.21 -6.35 -5.56 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -3.62 -3.70 -4.72 -4.34 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -2.40 -2.31 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.27 -1.10 -3.37 -3.86 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -1.37 -0.01 0.00 0.19 -1.76 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.07 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.576801023402638, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -5.8670363443651485, 3: -6.33892753315337, 4: -6.799651671662251}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.305678152305787, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.1875149746547295}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.237701332497967, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -6.352382324520431, 2: -6.536291316269119, 3: -6.5597537778232615, 4: -6.660906070967596}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -4.723424417249677, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.620278290669068, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.399558662503951, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.0964242588973163, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.012203296193806862, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.50 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-6.28 -6.19 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.76 -6.46 -6.08 -6.44 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.28 -3.97 -6.21 -5.05 -5.56 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -3.02 -3.70 -4.04 -4.34 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -1.99 -2.31 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.27 -1.01 -3.37 -3.86 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -1.37 -0.00 0.00 0.19 -1.76 0.23 -3.82 -7.49 -7.72 \n",
      "0.00 -1.51 -0.07 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.497160756577866, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.413881847388549, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.1875149746547295}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.413881847388549, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.1875149746547295}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.413881847388549, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.530638626935804}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.761641013173241, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -3.973566361566741, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.0219232313941373, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -1.9912317418351297, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.369397996326282, 1: -5.51730282319569, 2: -4.276406050471545, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -2.3069450811555168, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.105565315368597, 1: -5.51730282319569, 2: -4.276406050471545, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.646202413564115, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.328740296666948, 1: -5.51730282319569, 2: -4.276406050471545, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -3.8557664519770136, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.759293241356553, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.759293241356553, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: 0.2260931294875611, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -3.8210923573233124, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.9724754964831264, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.215517564947505, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.18573137899586545, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.66 -6.14 -6.66 -6.95 -6.94 -6.55 -6.73 -7.37 -7.82 -8.04 \n",
      "-6.28 -5.34 -6.61 -6.26 -7.26 -7.09 -6.63 -7.37 -7.74 -7.88 \n",
      "-4.94 -4.64 -6.46 -6.08 -6.44 -6.92 -7.08 -7.16 -7.72 -7.63 \n",
      "-4.31 -4.28 -4.07 -6.21 -5.05 -5.56 -6.60 -7.23 -7.75 -7.70 \n",
      "-3.70 -3.59 -3.75 -3.70 -4.04 -4.34 -6.41 -6.61 -7.63 -7.65 \n",
      "-3.01 -2.40 -4.06 -4.60 -4.75 -4.63 -6.82 -7.07 -7.08 -7.79 \n",
      "-2.97 -2.27 -1.01 -4.12 -3.12 -3.20 -3.20 -3.43 -5.04 -5.93 \n",
      "-1.97 -1.37 -0.00 0.00 0.02 -1.02 -2.76 -3.93 -7.49 -7.72 \n",
      "0.00 -1.51 -0.07 -2.08 -4.69 -4.53 -5.94 -7.47 -7.40 -7.41 \n",
      "0.00 0.00 -2.18 -1.89 -3.47 -4.23 -6.58 -6.66 -7.02 -7.21 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -6.662500283145017, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -6.282994600591445, 3: -6.33892753315337, 4: -6.799651671662251}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.741236216988083, 2: -6.61024785688609, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.258199444988159, 1: -7.2735777816417775, 2: -7.62847609972422, 3: -7.313199478941094, 4: -7.472158336401026}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.944809592850413, 2: -6.819389049228685, 3: -7.408033621603437, 4: -7.503470115439683}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.734975860156954, 1: -6.944809592850413, 2: -6.819389049228685, 3: -7.408033621603437, 4: -7.503470115439683}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -7.909391222633645, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -7.909391222633645, 3: -7.9304551146271045, 4: -7.817679671578839}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -7.909391222633645, 3: -7.9304551146271045, 4: -8.014088501136742}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -7.909391222633645, 3: -7.9304551146271045, 4: -8.15028299813651}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.116929187712884, 2: -8.163877189219649, 3: -8.040709930537991, 4: -8.289202637770286}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.116929187712884, 2: -8.163877189219649, 3: -8.040709930537991, 4: -8.289202637770286}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -8.39412158890406, 3: -7.9304551146271045, 4: -8.333110552789606}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -8.373076665863186, 3: -7.9304551146271045, 4: -8.328848955873829}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -7.953684673045082, 2: -8.397687305600375, 3: -8.116714154310664, 4: -8.33383261042061}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.252770648019142, 1: -7.737253036648432, 2: -7.988516338723585, 3: -7.838010316396794, 4: -7.965522810134306}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.625542909550774, 1: -7.711839941696963, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -7.714163890742718}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.252770648019142, 1: -7.8504150604009695, 2: -7.988516338723585, 3: -7.838010316396794, 4: -7.965522810134306}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -7.367997663476205, 2: -7.619250579283936, 3: -7.6835047802506296, 4: -7.530623326046187}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.156535695455583, 1: -7.568562246567318, 2: -7.595548326823504, 3: -7.30006273152483, 4: -7.5712497755956765}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -7.433593679666643, 2: -7.619250579283936, 3: -7.6835047802506296, 4: -7.530623326046187}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -7.717272726713662, 2: -7.740671846097571, 3: -7.969536771100095, 4: -7.877997519942693}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.697177779427114, 1: -7.70118464109234, 2: -7.701076821800475, 3: -8.017761995870512, 4: -7.7511222910855855}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -7.906441274007329, 2: -7.740671846097571, 3: -7.969536771100095, 4: -7.877997519942693}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.001057817524375, 1: -7.711839941696963, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -7.714163890742718}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.94967295165793, 1: -7.9735006833227065, 2: -8.05141710182597, 3: -8.029951772237052, 4: -7.750329138525165}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.94967295165793, 1: -7.9735006833227065, 2: -8.05141710182597, 3: -8.029951772237052, 4: -7.750329138525165}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.94967295165793, 1: -7.9735006833227065, 2: -8.05141710182597, 3: -8.029951772237052, 4: -7.9527995160579}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002344154306643, 1: -8.07685966035895, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -7.714163890742718}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002343199252136, 1: -8.076291686891688, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -7.714163890742718}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.00235738452727, 1: -8.084727707917658, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -7.919889140575873}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002359258346717, 1: -8.08584207334892, 2: -7.763321272952369, 3: -7.9698004412141445, 4: -8.007454647206917}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002362069090829, 1: -8.087513630382423, 2: -7.964622358386656, 3: -7.9698004412141445, 4: -8.13880360545279}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002363220090542, 1: -8.088198132987642, 2: -8.230239140617199, 3: -7.9698004412141445, 4: -8.192591003854474}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8313918080874725, 1: -7.568562246567318, 2: -7.595548326823504, 3: -7.30006273152483, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83138678466577, 1: -7.568562246567318, 2: -7.595548326823504, 3: -7.30006273152483, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831388311471882, 1: -7.568562246567318, 2: -7.595548326823504, 3: -7.543057085687595, 4: -7.5712497755956765}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831388936698985, 1: -7.568562246567318, 2: -7.595548326823504, 3: -7.863688136005363, 4: -7.5712497755956765}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.698267321542112, 1: -7.227143784974837, 2: -7.497644416221306, 3: -7.784113387152386, 4: -7.388350310467967}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649852674006039, 1: -7.873119946238002, 2: -7.745468678885597, 3: -8.058238344578514, 4: -7.693531651279605}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096819619187546, 1: -7.70118464109234, 2: -7.701076821800475, 3: -8.017761995870512, 4: -7.7511222910855855}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096819941102778, 1: -7.70118464109234, 2: -7.701076821800475, 3: -8.017761995870512, 4: -7.7511222910855855}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.096820059568367, 1: -7.70118464109234, 2: -7.907979907838433, 3: -8.017761995870512, 4: -7.7511222910855855}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.000171354327687, 1: -7.873119946238002, 2: -7.745468678885597, 3: -8.058238344578514, 4: -7.693531651279605}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.018459637045613, 1: -7.873119946238002, 2: -7.745468678885597, 3: -8.058238344578514, 4: -7.693531651279605}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.026971802640837, 1: -7.873119946238002, 2: -7.745468678885597, 3: -8.058238344578514, 4: -7.90111380266444}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02813114132072, 1: -7.873119946238002, 2: -7.745468678885597, 3: -8.058238344578514, 4: -7.9922132535384804}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.02981604029235, 1: -7.873119946238002, 2: -7.948376497785894, 3: -8.058238344578514, 4: -8.124610605370924}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.792905233836281, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.799529635983455, 4: -8.066862993217743}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.030490845055027, 1: -7.999565234031189, 2: -8.21023009531689, 3: -8.058238344578514, 4: -8.17763595887095}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.158938362948891, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.799529635983455, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.661649796839417, 2: -7.370828721553068, 3: -7.116733443829903, 4: -7.0781379521638295}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.661649796839417, 2: -7.370828721553068, 3: -7.116733443829903, 4: -7.0781379521638295}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.661649796839417, 2: -7.370828721553068, 3: -7.116733443829903, 4: -7.341105536469085}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.082764476420722, 2: -7.073866127462204, 3: -7.317384857111487, 4: -7.682956980897023}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128650990319311, 1: -7.661649796839417, 2: -7.370828721553068, 3: -7.3415049076273755, 4: -7.571229621283002}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.631003888279422, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.645229807894893}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.057623053212565, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.58861405826054, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.874471498021064, 1: -7.661649796839417, 2: -7.370828721553068, 3: -7.631011064786176, 4: -7.76013238882912}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.057953555688893, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.629527987122064, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923083473252285, 1: -7.661649796839417, 2: -7.817000541724179, 3: -7.6408549897704985, 4: -7.76655554988139}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.92477057481921, 1: -7.661649796839417, 2: -7.835514687863276, 3: -7.641196627837801, 4: -7.766778468720305}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.928687964890789, 1: -7.661649796839417, 2: -7.878503879320933, 3: -7.854282202821894, 4: -7.7672960783672}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -5.037750181771357, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -5.037750181771357, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -3.4321016267260385, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.771080002848285, 2: -7.7159443610197025, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.771080002848285, 2: -7.7159443610197025, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.771080002848285, 2: -7.921509368527929, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 1, Actual action: 1\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.406603388821284, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.208972795942777, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.023073811802746, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.651121977360823, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -7.695316034537921}, Best action: 3, Actual action: 3\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.651121977360823, 1: -6.933164808535694, 2: -6.849761922714016, 3: -6.580773207317697, 4: -7.695316034537921}, Best action: 3, Actual action: 3\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.2337998287906755, 4: -5.846278255827798}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459657365617, 1: -4.864765324640269, 2: -5.459491095866127, 3: -3.4719129154488013, 4: -4.917027816348625}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8891807636494926, 1: -3.706424999899108, 2: -4.5586518151261854, 3: -2.9885414250614755, 4: -3.7235654418916977}, Best action: 0, Actual action: 0\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (8, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.883453718441717, 1: -4.689059009118557, 2: -5.506161424107597, 3: -5.08842318169823, 4: -5.075163291222344}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.887055873750981, 1: -3.706424999899108, 2: -4.5586518151261854, 3: -2.9885414250614755, 4: -3.7235654418916977}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -4.471915128541488, 3: -2.1779158004424115, 4: -3.0854423103886233}, Best action: 3, Actual action: 3\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -4.471915128541488, 3: -2.1779158004424115, 4: -3.0854423103886233}, Best action: 3, Actual action: 3\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -4.471915128541488, 3: -2.8819033784025945, 4: -3.0854423103886233}, Best action: 1, Actual action: 1\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.7698946378178118, 2: -4.471915128541488, 3: -3.679260721704229, 4: -3.0854423103886233}, Best action: 1, Actual action: 1\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (9, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4407399979726616, 1: -2.0972733863607456, 2: -5.272251346090409, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -0.2617157432736663, 2: -4.471915128541488, 3: -3.464173762727418, 4: -3.0854423103886233}, Best action: 1, Actual action: 1\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -0.9872890564873807, 2: -4.471915128541488, 3: -3.611102358653195, 4: -3.0854423103886233}, Best action: 1, Actual action: 1\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -2.036605193974517, 2: -4.471915128541488, 3: -3.6593322195488227, 4: -3.0854423103886233}, Best action: 1, Actual action: 1\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.842900727196163, 1: -3.170527414057572, 2: -4.471915128541488, 3: -3.67850880712291, 4: -3.0854423103886233}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.06766439989049411, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.0012203296193806865, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.67 -6.14 -6.66 -6.95 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.34 -5.34 -6.74 -6.26 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.64 -6.46 -6.08 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.28 -4.07 -6.21 -5.05 -5.56 -6.60 -7.39 -7.97 -7.75 \n",
      "-3.70 -3.59 -3.75 -3.70 -4.04 -4.34 -6.41 -6.61 -7.65 -7.89 \n",
      "-3.01 -2.40 -4.06 -4.60 -4.75 -4.63 -6.82 -7.08 -6.07 -7.80 \n",
      "-2.97 -2.27 -1.01 -4.12 -3.12 -3.20 -3.20 -6.78 -6.38 -5.93 \n",
      "-1.97 -1.37 -0.00 0.00 0.02 -1.02 -2.76 -3.93 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -6.674506209959979, 1: -7.108456016835572, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 0, Actual action: 0\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.674506209959979, 1: -7.108456016835572, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.9738006510635815, 1: -7.108456016835572, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.18123982115881, 1: -7.108456016835572, 2: -7.094754025434982, 3: -6.814175410585953, 4: -6.910544586938847}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.36832737017215, 1: -7.108456016835572, 2: -7.094754025434982, 3: -7.100899623633218, 4: -6.910544586938847}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.39966639339711, 1: -7.108456016835572, 2: -7.094754025434982, 3: -7.255660232151543, 4: -6.910544586938847}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.436405617896344, 1: -7.108456016835572, 2: -7.094754025434982, 3: -7.437088501283559, 4: -7.18859557411435}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.724319467437519, 2: -6.952157285126243, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.724319467437519, 2: -6.952157285126243, 3: -6.66407852017572, 4: -6.811917851218038}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.144423189301917, 2: -6.787952522189248, 3: -6.306901598435431, 4: -6.954915795264801}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.342972154456409, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.638651566611528, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.2842840831072575, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.5875721071501983, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.060760339734522, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -2.2666281856495734, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.0001220329619380687, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.018573137899586534, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.03 -5.83 -6.19 -6.95 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.34 -5.31 -6.74 -6.26 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.89 -6.46 -6.08 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -4.07 -6.21 -5.05 -5.56 -6.60 -7.39 -7.97 -7.75 \n",
      "-3.70 -3.99 -3.75 -3.70 -4.04 -4.34 -6.41 -6.61 -7.65 -7.89 \n",
      "-3.01 -2.40 -2.81 -4.60 -4.75 -4.63 -6.82 -7.08 -6.07 -7.80 \n",
      "-2.97 -1.53 -1.01 -4.12 -3.12 -3.20 -3.20 -6.78 -6.38 -5.93 \n",
      "-1.97 -1.37 -0.89 0.00 0.00 -1.02 -2.76 -3.93 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -7.034262438371769, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -5.825469700167753, 2: -6.787952522189248, 3: -6.306901598435431, 4: -6.954915795264801}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.741236216988083, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.083870116574891, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.211749021370665, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -3.699473508811507, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -4.602676742996795, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.809809460196853, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -4.12013406264438, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -3.120927855301114, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.0018573137899586534, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.0018573137899586534, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.8983098444511377, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.77 -6.31 -6.19 -6.95 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.34 -5.31 -6.47 -6.26 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.89 -6.46 -6.00 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -4.07 -5.02 -5.05 -5.56 -6.60 -7.39 -7.97 -7.75 \n",
      "-3.70 -3.99 -3.75 -4.82 -4.04 -4.34 -6.41 -6.61 -7.65 -7.89 \n",
      "-3.01 -2.40 -4.09 -4.21 -4.75 -4.63 -6.82 -7.08 -6.07 -7.80 \n",
      "-2.97 -1.53 -1.01 -3.16 -1.61 -3.20 -3.20 -6.78 -6.38 -5.93 \n",
      "-1.97 -1.37 -0.89 0.00 1.02 -1.02 -2.76 -3.93 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -6.769288347891399, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.8193178044307325, 2: -6.787952522189248, 3: -6.306901598435431, 4: -6.954915795264801}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -6.685519129521839, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.724319467437519, 2: -6.952157285126243, 3: -6.1893928909002875, 4: -6.811917851218038}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -6.537336288833908, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.362988566960968, 1: -6.8193178044307325, 2: -6.787952522189248, 3: -6.909410333427981, 4: -6.954915795264801}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.724319467437519, 2: -6.952157285126243, 3: -6.753943840489456, 4: -6.811917851218038}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.46650176955166, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.004855346413088, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.02275263791591, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -4.342394506409033, 4: -6.3972922329699085}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.813096748521333, 3: -7.081374395974738, 4: -6.414689933709904}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.813096748521333, 3: -7.081374395974738, 4: -6.414689933709904}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -6.521488224596457, 2: -6.813096748521333, 3: -7.081374395974738, 4: -6.737367839676013}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.204896847448358, 4: -6.816472480218652}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.204896847448358, 4: -6.816472480218652}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.102989956998973}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.204896847448358, 4: -7.481049767610607}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -6.0878881761243715, 2: -4.7461135601408495, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.6259042308857, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -4.956262155392515, 4: -4.880416877476394}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -7.191073280853673, 2: -6.813096748521333, 3: -7.081374395974738, 4: -7.346494977895188}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.917847167239407, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.645229807894893}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.917847167239407, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.645229807894893}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.917847167239407, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.857159125184353}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.917847167239407, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -8.136799859347796}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923057724070258, 1: -6.0725009011569515, 2: -7.816717971825389, 3: -6.869991836328255, 4: -7.766552147609786}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -6.377890329954809, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -3.1989951832940635, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.2020181112142962, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.0164426796508161, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.0164426796508161, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.02496283848224279, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -1.2832948119396899, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.8924900824468612, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.07 -6.79 -6.79 -6.95 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.34 -5.31 -6.41 -6.26 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.89 -6.46 -6.01 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -4.07 -6.01 -5.05 -5.56 -6.60 -7.39 -7.97 -7.75 \n",
      "-3.70 -3.99 -3.75 -4.82 -4.04 -6.40 -6.89 -6.61 -6.39 -7.89 \n",
      "-3.01 -2.40 -4.09 -4.21 -5.04 -4.88 -6.18 -7.08 -5.59 -7.80 \n",
      "-2.97 -1.53 -1.01 -3.16 -1.61 -1.05 -2.85 -6.78 -3.97 -5.93 \n",
      "-1.97 -1.37 -0.09 0.00 -0.73 -1.02 -2.76 -3.93 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -7.071617598169683, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -6.8193178044307325, 2: -6.787952522189248, 3: -6.9237874539372015, 4: -6.954915795264801}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.113814867131551, 1: -7.0589267228586605, 2: -7.61297045687715, 3: -6.95018340300774, 4: -7.231135956663147}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.786696797585001, 2: -6.952157285126243, 3: -6.885179809016949, 4: -6.811917851218038}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.414053808450333, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -6.460028310908727, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.012568237303235, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.008648340027109, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -4.035508080493194, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.821705050237113, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -4.210653493060256, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -4.210653493060256, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -4.731694678684834, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.086343140199357, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.5283272875323424, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.08924900824468607, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.08924900824468607, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.9812165975026643, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -2.1581678315285666, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.11 -6.82 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.34 -5.31 -6.86 -6.26 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.89 -6.33 -6.06 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -4.07 -5.33 -5.05 -5.56 -6.60 -7.39 -7.97 -7.75 \n",
      "-3.70 -3.99 -3.75 -5.00 -5.29 -6.40 -6.89 -6.61 -6.39 -7.89 \n",
      "-3.01 -2.40 -2.59 -3.21 -5.04 -4.88 -6.18 -7.08 -5.59 -7.80 \n",
      "-2.97 -1.63 -1.01 -3.16 -1.61 -1.05 -2.85 -6.78 -3.97 -5.93 \n",
      "-1.97 -1.37 1.89 0.00 -0.73 -1.02 -2.76 -3.93 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.108456016835572, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -7.289617627351447, 3: -6.33892753315337, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -7.289617627351447, 3: -6.33892753315337, 4: -6.799651671662251}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.633403878655081, 1: -6.858540261915929, 2: -7.289617627351447, 3: -6.6684240551695675, 4: -6.799651671662251}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -6.8193178044307325, 2: -7.31001025140471, 3: -6.9237874539372015, 4: -6.954915795264801}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.474798715349835, 2: -6.649224905258213, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.474798715349835, 2: -6.649224905258213, 3: -6.3600267926377105, 4: -6.26309771359884}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.474798715349835, 2: -6.649224905258213, 3: -6.3600267926377105, 4: -6.599418919374944}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.855206660869734, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.0647222559611915, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -5.562213451320775, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.885855519011603, 1: -7.213656530114431, 2: -7.844974468079526, 3: -7.081374395974738, 4: -7.361230548037831}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.698267321542112, 1: -7.990472523733364, 2: -7.497644416221306, 3: -7.784113387152386, 4: -7.388350310467967}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.698267321542112, 1: -7.990472523733364, 2: -7.497644416221306, 3: -7.784113387152386, 4: -7.388350310467967}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.698267321542112, 1: -7.990472523733364, 2: -7.497644416221306, 3: -7.784113387152386, 4: -7.62339878252585}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.071501337703333, 1: -7.9735006833227065, 2: -8.05141710182597, 3: -8.029951772237052, 4: -8.295780051219207}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -6.393391330644166, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -6.987207176573777}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923057724070258, 1: -5.590013976674938, 2: -7.816717971825389, 3: -6.869991836328255, 4: -7.766552147609786}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -3.9704963728344715, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.778673373321112, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -6.184534774051752, 4: -6.727276306632993}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -4.956262155392515, 4: -4.880416877476394}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -4.956262155392515, 4: -4.880416877476394}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -4.956262155392515, 4: -5.341179358503519}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -4.956262155392515, 4: -5.497070197164936}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -4.9795163724988205, 2: -6.54669950703933, 3: -5.410198561407189, 4: -5.793263702089511}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -2.846820164118063, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -1.0537647238922436, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -3.93363145192582, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.764933786925716, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.764933786925716, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.0211761881007435, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.0211761881007435, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.8292703311716767, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.7309915962216261, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.99 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.80 -5.31 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.89 -6.33 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -4.07 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.70 -3.99 -3.75 -5.00 -5.29 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -2.40 -2.59 -3.21 -5.04 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -1.63 -1.01 -3.16 -1.61 -4.06 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -1.37 1.89 0.00 -0.07 -0.57 -2.02 -3.63 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.993067170477619, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.305683123629451, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -6.333311034194249, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.8921585426748, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -4.071119055844831, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.746377903080595, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.5934568219661354, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.0145847608482232, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.27 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.80 -6.13 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.64 -5.38 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.41 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.70 -3.99 -2.91 -5.00 -5.29 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -2.40 -1.57 -3.21 -5.04 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -1.63 -0.10 -3.16 -1.61 -4.06 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -1.37 1.89 0.00 -0.07 -0.57 -2.02 -3.63 -7.49 -7.70 \n",
      "0.00 -1.51 -0.91 -2.08 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.2690807830402555, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.858540261915929, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.799651671662251}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.858540261915929, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.799651671662251}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.858540261915929, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -7.087683021212649}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.382597596953572, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.640198707047151, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.413224702433411, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.985045190108032, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -2.3998311477873644, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.6324992987434586, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -1.3739399722882015, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -2.9347964392133674}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -1.5058240472922688, 3: -1.6287342344113764, 4: -3.151326638095971}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3448990161847716, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.0834966478199073}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3448990161847716, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.0834966478199073}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3448990161847716, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -2.795981949516116}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (8, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3448990161847716, 1: -4.114993774403113, 2: -3.362046412878114, 3: -4.50239762076636, 4: -3.736106305104263}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.5656182562395505, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.07309915962216262, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.09 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.92 -6.13 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -4.92 -5.32 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.36 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.70 -3.53 -2.91 -5.00 -5.29 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -3.04 -1.57 -3.21 -5.04 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -2.91 -0.10 -3.16 -1.61 -4.06 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.93 1.89 0.00 -0.01 -0.99 -2.02 -3.63 -7.49 -7.70 \n",
      "0.00 -1.63 -0.91 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.09403494153839, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.132729203301982, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.321151900206051, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.321151900206051, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.916490235497154, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.363798826480911, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -2.914895875868933, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.483025877953281, 4: -5.043316529505712}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.125095019820443, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.483025877953281, 4: -5.489418041850198}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -5.289928619654282, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.001253318932446, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -3.206265510450668, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -1.570252510340144, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.160253181394877, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -4.055398019684083, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -3.630920499114584, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.0193695835338183, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.0193695835338183, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.7376263210157745, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.9861669852709308, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.007309915962216265, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.0045377304564882, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.5964733654965997, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -1.9833649520059997, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.183576273825093, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.9511588542651266, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.51 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.92 -5.98 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.94 -5.16 -5.49 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.31 -4.88 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.70 -3.53 -5.11 -4.21 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -3.04 -4.22 -3.69 -5.48 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -2.91 -0.10 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.93 1.89 0.00 1.96 -3.09 -2.88 -3.25 -7.49 -7.70 \n",
      "0.00 -1.63 -0.91 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.506907788670456, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.918107516187602, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -4.943312039235735, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.308857398966662, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.7027004159201162, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -3.035853868159335, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -2.9070466796287846, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: 1.8924814851605758, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.13 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.45 -5.98 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.85 -5.16 -5.49 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.22 -4.88 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.46 -3.53 -5.11 -4.21 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -2.44 -4.22 -3.69 -5.48 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -0.42 -0.10 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.93 0.19 0.00 1.96 -3.09 -2.88 -3.25 -7.49 -7.70 \n",
      "0.00 -1.63 -0.91 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.134501694007405, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.97715951406201, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.159098031549376, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.881069845481181, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.4616429777571565, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -2.4410345413950765, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -0.4242496664728451, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.17 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.45 -5.56 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.85 -4.91 -5.49 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.22 -3.86 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-2.72 -3.53 -5.11 -4.21 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.01 -1.32 -4.22 -3.69 -5.48 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.97 -0.04 -0.10 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.93 0.19 0.00 1.96 -3.09 -2.88 -3.25 -7.49 -7.70 \n",
      "0.00 -1.63 -0.91 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.168994023664978, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.451760465139604, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -4.845238620879955, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.221597229618628, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -2.7171027887553976, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.006501149022938, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.5229166617474474}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -2.972411334269742, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -0.04242496664728451, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -2.9981741327348588, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -2.9347964392133674}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -2.9981741327348588, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -2.9347964392133674}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -2.9981741327348588, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -3.5706647596841643}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -1.6287342344113764, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: 0.0, 4: 0.0}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: -0.9, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: -1.0305, 4: 0.0}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: -1.61775, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -1.619409409803058, 3: -1.858228875, 4: -2.0875500000000002}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -1.6078384747220638, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -1.6140237894377611, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -2.371581873218431, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9072606734848986, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.87 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.31 -5.56 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.72 -4.91 -5.49 -6.30 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.03 -3.86 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -3.53 -5.11 -4.21 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-3.52 -1.32 -4.22 -3.69 -5.48 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-2.81 -3.11 -0.10 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.51 0.19 0.00 1.96 -3.09 -2.88 -3.25 -7.49 -7.70 \n",
      "-1.63 -0.45 -0.09 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -5.870180558597916, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -5.563925398226476, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.298139228625266, 4: -6.510805254502509}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.486333658613291, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -4.717972895147298, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -3.8569947114806236, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.5285779728859548, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.534554052667388, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.5229166617474474}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.534554052667388, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.5229166617474474}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.534554052667388, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -4.105854162190177}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -2.8085241276177486, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.10145847608482228, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.36 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.31 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-4.78 -4.91 -5.30 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.03 -4.50 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.32 -5.11 -4.21 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.81 -1.32 -4.22 -3.69 -5.48 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-1.22 -3.11 -0.01 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.51 0.19 0.00 1.96 -3.09 -2.88 -3.25 -7.49 -7.70 \n",
      "-1.63 -0.45 -0.09 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.358428553552922, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.312549752847028, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -4.784668117472893, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.498561626278083, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.107882677446121, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.213397423948625, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.483025877953281, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -4.223968659988917, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.010145847608482222, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.9635563861544743, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.0943268913214697, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -3.2100491433549427, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: 0.18924814851605753, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.98 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.62 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.49 -4.91 -5.30 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.03 -5.53 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.32 -5.14 -5.04 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.81 -1.32 -2.03 -3.69 -3.88 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-1.22 -3.11 -1.57 -4.51 -1.61 -4.07 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.51 0.02 0.00 -0.70 -2.75 -2.88 -3.25 -7.49 -7.70 \n",
      "-1.63 -0.45 -0.09 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -5.978299163478035, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.622085326884031, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.485221842909082, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.527272990448186, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.042735608765536, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -3.8833478895722044, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -3.686703351762532, 4: -5.296897786230195}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.274564503884871, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.744528408087081, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.313301821121857, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.844014534975932, 2: -5.934680391155646, 3: -5.029329257105527, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -4.074401932351397, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -2.749658605807936, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.6995842161144875, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.6995842161144875, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.27 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.10 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.85 -4.91 -5.30 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.03 -5.51 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.32 -5.14 -4.98 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.81 -1.32 -2.03 -4.26 -4.60 -3.95 -5.73 -7.08 -5.86 -7.80 \n",
      "-1.22 -3.11 -1.57 -4.51 -1.61 -3.12 -3.39 -6.38 -6.61 -5.93 \n",
      "-1.97 -2.51 0.02 0.00 0.47 -1.84 -2.88 -3.25 -7.49 -7.70 \n",
      "-1.63 -0.45 -0.09 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.46 \n",
      "0.00 0.00 -1.62 -3.39 -3.98 -4.36 -4.26 -6.66 -6.70 -7.17 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.266777645421375, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.099993358656271, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.300204260977156, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.300204260977156, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -4.908742567694443, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.030386734214661, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.196842364310608, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.196842364310608, 3: -5.414258860502052, 4: -5.142364724974118}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.196842364310608, 3: -5.414258860502052, 4: -5.5795518997264475}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.982815376696841, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.595979410023118, 4: -5.975260759927502}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -3.9478417879742675, 2: -6.54669950703933, 3: -4.830163751868403, 4: -5.675806653157907}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.380849869709404, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.830299985001545, 4: -8.066862993217743}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.801482738789935, 3: -7.830299985001545, 4: -8.066862993217743}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.999349292298841, 3: -7.830299985001545, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923057724070258, 1: -5.862319613759631, 2: -7.816717971825389, 3: -6.869991836328255, 4: -7.766552147609786}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -6.608754493048281, 4: -7.35685586127683}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.591159286926061, 2: -7.4261806807368975, 3: -6.608754493048281, 4: -7.35685586127683}, Best action: 3, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.765604938497569, 1: -7.750988769197469, 2: -7.486882712217814, 3: -7.745304438927149, 4: -7.6228358468192745}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.700789175457144, 2: -7.970208341071571, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.460675455992562, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.166188690157848, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.166188690157848, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -6.704410751810183, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -6.663518624469203, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -6.663518624469203, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -6.963801948266975, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.651121977360823, 1: -6.933164808535694, 2: -6.849761922714016, 3: -4.262022937268813, 4: -7.695316034537921}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -3.605901683972402, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -3.5947173561111554, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.36470962502852, 4: -5.846278255827798}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (9, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.547996868109964, 1: -5.728588145168766, 2: -5.9913957127335316, 3: -4.36470962502852, 4: -5.846278255827798}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459657365617, 1: -4.864765324640269, 2: -5.459491095866127, 3: -3.9809799835286275, 4: -4.917027816348625}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (9, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.563741371266511, 1: -3.706424999899108, 2: -4.5586518151261854, 3: -3.3906700511041357, 4: -3.7235654418916977}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6169165597483985, 1: -2.8239961547785666, 2: -4.471915128541488, 3: -3.676071601752969, 4: -3.0854423103886233}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -0.45193345247967565, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -0.45193345247967565, 4: -3.151326638095971}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.6331149812200758, 1: -3.7640678362964843, 2: -2.6822074002148346, 3: -1.965411857852041, 4: -3.4280343983765955}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -2.513660402725105, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -3.4211575583620575}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.09072606734848987, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.42 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.98 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.85 -5.42 -5.66 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.32 -5.51 -3.97 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.32 -5.41 -5.75 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.81 -1.32 -2.03 -4.26 -5.62 -4.83 -5.73 -7.08 -6.87 -7.12 \n",
      "-1.22 -3.11 -1.57 -4.51 -1.61 -3.12 -3.39 -6.81 -7.28 -5.93 \n",
      "-1.97 -1.19 0.02 0.00 0.47 -1.84 -2.88 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.415837847518257, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.984805497466355, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -5.660882297386838, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.918011027823551, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.918011027823551, 2: -6.391005245548477, 3: -6.82344642452269, 4: -5.846820849838211}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.918011027823551, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.220606973352772}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.593213125109577, 3: -5.321042436323845, 4: -6.530565028964405}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.593213125109577, 3: -5.742148617054699, 4: -6.530565028964405}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -3.9675110948345176, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -5.750594984173317, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.25722387111456, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -4.509449474783885, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.610457216048973, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.4686695991825762, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.58 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.42 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-6.02 -5.42 -6.40 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.38 -5.51 -5.18 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.32 -5.41 -4.81 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.81 -1.32 -2.03 -3.99 -5.62 -4.83 -5.73 -7.08 -6.87 -7.12 \n",
      "-1.22 -3.11 -1.57 -2.32 -0.87 -3.12 -3.39 -6.81 -7.28 -5.93 \n",
      "-1.97 -1.19 0.02 0.00 0.05 -1.84 -2.88 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.583327942046589, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.416031507126384, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -6.024701473426507, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.375797690322992, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.51037903771399, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.31683129975795, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -2.814398484218386, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.7341467069768695}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -1.221943095576128, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.5688610724384713, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: 0.018924814851605742, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.73 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.37 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.90 -5.42 -6.40 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.48 -4.58 -5.18 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -3.49 -5.41 -4.81 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.55 -1.32 -2.03 -3.99 -5.62 -4.83 -5.73 -7.08 -6.87 -7.12 \n",
      "-2.06 -3.11 -1.05 -2.32 -0.87 -3.12 -3.39 -6.81 -7.28 -5.93 \n",
      "-1.97 -1.19 0.00 0.00 0.05 -1.84 -2.88 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.7333952166574615, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.3673135108606775, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.904039621587768, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.480627346064091, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.576246941010569, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.491443931836243, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.9943684865208944, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -2.3227650855271977, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.1245282710454765, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.876092907423521, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.8382466215988442, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.6765890542374158, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.251861796092191, 4: -3.3604236371264746}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.500515488250229, 4: -3.3604236371264746}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -4.067469234243533, 4: -3.3604236371264746}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -4.390824902585927, 4: -3.9579855097850913}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -4.523239048772138, 4: -4.746468400758137}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.04686695991825762, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.69 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.27 -6.15 -6.85 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.79 -5.42 -6.40 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.17 -4.62 -5.18 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.45 -5.41 -4.81 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.55 -1.32 -2.03 -3.92 -5.62 -4.83 -5.73 -7.08 -6.87 -7.12 \n",
      "-2.06 -3.11 -1.05 -3.98 -0.87 -3.82 -3.39 -6.81 -7.28 -5.93 \n",
      "-1.97 -1.19 0.00 0.00 0.00 -1.18 -4.38 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.686366882413053, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.847111803952494, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.42389328687287, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.6185139264240656, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.805125910952975, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.9247740499404737, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.9758706011079843, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.8712345339359538, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.177828653348145, 4: -2.835500853790975}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.177828653348145, 4: -2.835500853790975}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.72 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.27 -6.15 -5.97 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.79 -5.41 -6.40 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.17 -5.13 -5.18 -5.33 -5.05 -6.55 -6.60 -7.57 -6.78 -7.75 \n",
      "-3.84 -4.45 -5.41 -4.52 -5.13 -6.40 -7.08 -6.61 -6.19 -7.89 \n",
      "-2.55 -1.32 -2.03 -3.84 -5.62 -4.83 -5.73 -7.08 -6.87 -7.12 \n",
      "-2.06 -3.11 -1.05 -2.48 -1.94 -3.82 -3.39 -6.81 -7.28 -5.93 \n",
      "-1.97 -1.19 0.00 0.00 0.00 0.60 -4.38 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.7213268950666585, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.268432215194357, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -5.41204550000586, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.529271963714685, 2: -5.1840045132933, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -5.051649658883863, 2: -6.536291316269119, 3: -6.5597537778232615, 4: -6.660906070967596}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.708492239913104, 1: -7.213656530114431, 2: -7.844974468079526, 3: -7.081374395974738, 4: -7.361230548037831}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.762469008729482, 4: -6.3972922329699085}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.762469008729482, 4: -6.3972922329699085}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.713752513918323, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.762469008729482, 4: -6.721535932002617}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.603877085408216, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.708492239913104, 1: -7.213656530114431, 2: -7.844974468079526, 3: -7.013168439828405, 4: -7.361230548037831}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -5.125472897557991, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -5.125472897557991, 4: -6.9314273748951365}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.987266454495191, 1: -6.792387619940581, 2: -6.71898928921594, 3: -6.762469008729482, 4: -7.318701714562679}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.614598576733324, 1: -7.251270833176353, 2: -6.75114549274193, 3: -6.832550216787178, 4: -6.8497666256358585}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.071501337703333, 1: -6.784375543250824, 2: -8.05141710182597, 3: -8.029951772237052, 4: -8.295780051219207}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -6.189787990859228, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -6.987207176573777}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.600539173270871, 3: -7.123255349043999, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923057724070258, 1: -7.399533976867498, 2: -7.816717971825389, 3: -6.869991836328255, 4: -7.766552147609786}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.082764476420722, 2: -7.739076945092791, 3: -7.317384857111487, 4: -7.682956980897023}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.276440170371557, 1: -7.911055018888699, 2: -7.4261806807368975, 3: -7.853667551098125, 4: -7.35685586127683}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.923057724070258, 1: -7.399533976867498, 2: -7.816717971825389, 3: -7.51278123868365, 4: -7.766552147609786}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.621266538299829, 1: -7.911055018888699, 2: -7.4261806807368975, 3: -7.853667551098125, 4: -7.35685586127683}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.711029239103897, 1: -7.911055018888699, 2: -7.4261806807368975, 3: -7.853667551098125, 4: -7.35685586127683}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (6, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7592005410321265, 1: -7.911055018888699, 2: -7.4261806807368975, 3: -7.853667551098125, 4: -7.594738833761916}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -5.926581096067806, 4: -8.221044584762112}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8906300585365745, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8906300585365745, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -6.813221845062342}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8906300585365745, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -7.100031879006732}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8906300585365745, 1: -7.592430411884222, 2: -7.493469691975829, 3: -7.417821432864158, 4: -7.478477718796353}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -3.3889664258708505, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.8194753666197627, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -4.380376810992194, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: 0.601406342736778, 4: -2.835500853790975}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.004686695991825758, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.65 -6.90 -6.81 -7.06 -6.94 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.27 -6.15 -5.97 -6.47 -7.27 -7.09 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.79 -5.44 -6.40 -5.89 -6.44 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.17 -5.13 -5.41 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-3.84 -4.45 -5.41 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-2.55 -1.32 -2.03 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-2.06 -3.11 -1.05 -2.48 -1.94 -3.53 -4.20 -4.75 -6.97 -7.10 \n",
      "-1.97 -1.19 0.00 0.00 0.00 -0.84 -1.50 -3.25 -7.62 -7.74 \n",
      "-1.97 -2.53 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.649117685291237, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.374216342959108, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.374216342959108, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.147490873904209}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.374216342959108, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.49421669525283}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.791659111859321, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -5.173842900261045, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4129796894354065, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.437398016674666, 1: -6.642528175792666, 2: -6.722325908506042, 3: -6.561801061408299, 4: -6.895752416019183}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.089868488637929, 1: -7.109473357779059, 2: -7.780510514500251, 3: -7.305032187158878, 4: -7.145725645990073}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -7.528813785134602, 2: -7.44308073324557, 3: -6.937402165274015, 4: -7.482720391934942}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.113814867131551, 1: -7.0589267228586605, 2: -7.61297045687715, 3: -7.175886609117772, 4: -7.231135956663147}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.474798715349835, 2: -6.649224905258213, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.840646946043317, 2: -7.572457577691253, 3: -5.889985957403033, 4: -6.510805254502509}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -6.399185178489972, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.4410828767107215, 1: -6.205030012987199, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.578899301915484, 2: -6.649224905258213, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.433517300210286, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.738659905305958, 4: -6.510805254502509}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.589404362476798, 1: -6.7844937772763085, 2: -6.649224905258213, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -6.885179809016949, 4: -6.811917851218038}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -6.885179809016949, 4: -6.811917851218038}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -6.885179809016949, 4: -7.098845244608414}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -6.885179809016949, 4: -7.226495886084841}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -6.751925526726269, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.2674431073657875, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -6.293363131887598, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.126647017346466, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -5.414258860502052, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.8446000162241223, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -2.547949661204065, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.7341467069768695}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -2.0591339963884887, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.546688902661672, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.546688902661672, 2: -4.321292062001962, 3: -3.114046782915332, 4: -4.933019041760279}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.546688902661672, 2: -4.321292062001962, 3: -3.7337825724529523, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.481709776274882, 1: -2.5938305263334187, 2: -2.892681582564352, 3: -1.9700165851764682, 4: -3.4856234388467064}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.481709776274882, 1: -2.5938305263334187, 2: -2.892681582564352, 3: -1.9700165851764682, 4: -3.4856234388467064}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.481709776274882, 1: -2.5938305263334187, 2: -2.892681582564352, 3: -2.6927150925105865, 4: -3.4856234388467064}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.502878786999937, 1: -3.7640678362964843, 2: -2.6822074002148346, 3: -1.965411857852041, 4: -3.4280343983765955}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.502878786999937, 1: -3.7640678362964843, 2: -2.6822074002148346, 3: -1.965411857852041, 4: -3.4280343983765955}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (8, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.502878786999937, 1: -3.7640678362964843, 2: -2.6822074002148346, 3: -2.6885247906453573, 4: -3.4280343983765955}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (7, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.481709776274882, 1: -3.1795685271930356, 2: -2.892681582564352, 3: -3.9123698955237716, 4: -3.4856234388467064}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (7, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.036238519929389, 1: -1.188110097548649, 2: -3.0101019533708544, 3: -3.695970296107961, 4: -3.4211575583620575}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (8, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.5303090239018706, 1: -2.755436362304381, 2: -3.152629952179603, 3: -3.3906802989786047, 4: -3.151326638095971}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.71 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.41 -6.45 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.81 -5.81 -6.53 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-5.74 -5.41 -5.43 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-3.86 -4.45 -4.56 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -1.32 -2.03 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -3.35 -1.05 -2.48 -1.94 -3.53 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 0.00 0.00 0.00 -0.84 -1.50 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.714879794982737, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.4075727221002365, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.811594889180853, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.7379551239692255, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.8594958805991095, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -1.31592456906101, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.0492215572289467, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: 0.0018924814851605729, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.00046866959918257563, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.60 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.05 -6.45 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.38 -5.81 -6.53 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -5.41 -5.43 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.45 -4.56 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -2.04 -2.03 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -3.35 -1.41 -2.48 -1.94 -3.53 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.90 0.00 0.00 -0.84 -1.50 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.602039748739802, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.052945753967652, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.37780960367227, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -5.414812658687605, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.453265370804359, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -2.043393846067651, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -3.352821915635471, 2: -4.321292062001962, 3: -4.205284222543387, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.899620940663815, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.39 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.90 -6.45 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.45 -5.81 -6.53 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.59 -5.43 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-2.68 -3.44 -4.56 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.03 -2.03 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.94 -3.53 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 0.00 -0.84 -1.50 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.392452833355366, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.895974193451178, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.454818134960878, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.594899149924696, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -4.562255038160488, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.44498300125859, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.0320368537352573, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -2.4838254413792185, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.533259471495007, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.8379612538496328, 4: -2.835500853790975}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.8379612538496328, 4: -2.835500853790975}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.4986139619463141, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.4986139619463141, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.2637387053711464, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.273320804320212, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.341722630164544, 4: -2.835500853790975}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.3030970801820314, 4: -2.835500853790975}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.320349853483915, 4: -3.480305776949787}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.325854850383206, 4: -4.143257640947173}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.6866959918257574e-05, 4: -4.205423837325841}, Best action: 3, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.6866959918257574e-05, 4: -4.205423837325841}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.29 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.84 -6.45 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.30 -5.81 -6.53 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.90 -5.43 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-2.68 -3.60 -4.21 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.03 -3.60 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -3.56 -1.94 -2.54 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 0.00 -3.16 -3.87 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.289848369364798, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.8401163919707475, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.303965431199373, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.433692293270733, 4: -5.702547875017606}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.8984887194008735, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.5960408283926566, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -3.0311881768751108, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.561421634570789, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -2.5357015126548097, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.8660705680708483, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.1620002371700044, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.686695991825759e-06, 4: -1.320523402613817}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.33 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.99 -6.45 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.76 -5.81 -6.53 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.60 -5.28 -5.33 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.26 -4.21 -4.52 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.78 -3.60 -3.84 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -3.92 -1.94 -3.88 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 0.00 -1.22 -2.97 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.325196099063503, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.454432340161945, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -5.812391125311882, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.531685286170052, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.334115621824688, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.522111770579975, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.84151227001357, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.916278508598649, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.9390976645588367, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.6866959918257605e-07, 4: -1.320523402613817}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.79 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.99 -6.53 -5.97 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.76 -5.94 -5.75 -6.51 -6.56 -6.92 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.60 -5.28 -5.06 -6.54 -6.55 -6.89 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.26 -4.21 -4.45 -6.69 -6.76 -6.25 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.78 -3.60 -3.81 -5.62 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.09 -3.88 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 0.00 -1.22 -2.97 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.793452458493463, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -5.97273323867212, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.7764723104682325, 4: -6.510805254502509}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.7764723104682325, 4: -6.510805254502509}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.7764723104682325, 4: -6.824832781597284}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.7764723104682325, 4: -7.182392730257768}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.415517348540832, 1: -6.642528175792666, 2: -6.722325908506042, 3: -6.561801061408299, 4: -6.895752416019183}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -6.840646946043317, 2: -7.572457577691253, 3: -6.856525456853589, 4: -7.329156363826839}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.545992046703234, 1: -7.403950839937151, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.970574825593164, 1: -6.9168662347955845, 2: -7.187880696816165, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.157260854854747, 1: -7.403950839937151, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.206932998412559, 1: -7.403950839937151, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -6.710570558710628}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.266882849980058, 1: -7.403950839937151, 2: -7.357004713109247, 3: -6.8970699331347065, 4: -7.006619208426671}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -6.536291316269119, 3: -6.5597537778232615, 4: -6.660906070967596}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.893790327248361, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.708492239913104, 1: -7.213656530114431, 2: -7.844974468079526, 3: -6.253359322360569, 4: -7.361230548037831}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -6.792387619940581, 2: -7.205770026229213, 3: -6.762469008729482, 4: -7.360272616738428}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -4.450058134523685, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.623346608958681, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.99502413087847, 4: -5.975260759927502}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -6.792387619940581, 2: -7.205770026229213, 3: -5.8332302843204795, 4: -7.360272616738428}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.685747956485818, 2: -6.78641295008193, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6205008316340495, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.99502413087847, 4: -5.975260759927502}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.564365412711617, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.99502413087847, 4: -5.975260759927502}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.597373305404262, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -5.99502413087847, 4: -6.337487291534027}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.810894533912892, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.882852890190753, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.2161981256051237, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.2161981256051237, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.6866959918257594e-08, 4: -1.320523402613817}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.88 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-5.99 -6.53 -6.87 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.76 -5.94 -5.75 -7.18 -6.64 -6.97 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.60 -5.28 -5.06 -6.56 -7.14 -6.84 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.26 -4.21 -5.92 -6.45 -6.79 -6.67 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.78 -3.60 -3.78 -4.57 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.09 -2.45 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 0.00 -0.69 -2.97 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.877648037214206, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.98615413559456, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -6.421137721091359, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -6.421137721091359, 3: -6.140118687504241, 4: -5.940841989582545}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -6.421137721091359, 3: -6.140118687504241, 4: -6.306166210520116}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.761588758146027, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.277917754330277, 4: -5.702547875017606}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.602427968930866, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.26223199726538, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -4.247555935002388, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -4.247555935002388, 2: -3.9262894408365767, 3: -3.7849530392063397, 4: -4.51185297381412}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -4.247555935002388, 2: -3.9262894408365767, 3: -4.344307265677769, 4: -4.51185297381412}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -3.6000205798268996, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.093909576644696, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.686695991825758e-09, 4: -1.320523402613817}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 4.686695991825758e-09, 4: -1.320523402613817}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.6929441827156757, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -1.8443629439003537, 4: -1.320523402613817}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.722611103967041, 4: -1.320523402613817}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.9519771223987177, 4: -2.1016762963785736}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -3.045902506946489, 4: -3.1324075397011693}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.68 -6.90 -6.90 -6.96 -7.02 -6.55 -6.82 -7.37 -7.98 -8.12 \n",
      "-6.52 -6.53 -6.87 -6.65 -7.27 -7.11 -6.63 -7.53 -7.82 -7.88 \n",
      "-5.77 -6.19 -5.75 -7.18 -6.64 -6.97 -7.08 -7.57 -7.88 -7.77 \n",
      "-4.07 -4.99 -5.33 -5.06 -6.56 -7.14 -6.84 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.66 -4.21 -5.92 -6.45 -6.79 -6.67 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.68 -2.42 -3.78 -4.57 -4.83 -5.73 -7.32 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.71 -2.45 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 -0.23 -2.47 -2.97 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.6765248136322395, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -6.527416013619584, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -7.222690587776356, 2: -7.572457577691253, 3: -7.317988275002972, 4: -7.422602584502091}, Best action: 0, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.175842925413627, 1: -7.222690587776356, 2: -7.572457577691253, 3: -7.317988275002972, 4: -7.422602584502091}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3764997576971325, 1: -7.109473357779059, 2: -7.780510514500251, 3: -7.305032187158878, 4: -7.145725645990073}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.970574825593164, 1: -7.219589057878173, 2: -7.187880696816165, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3764997576971325, 1: -7.257112944508369, 2: -7.780510514500251, 3: -7.305032187158878, 4: -7.145725645990073}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3764997576971325, 1: -7.443647138106519, 2: -7.780510514500251, 3: -7.305032187158878, 4: -7.145725645990073}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3764997576971325, 1: -7.49566628820835, 2: -7.780510514500251, 3: -7.305032187158878, 4: -7.402610337850966}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.423898642791873, 1: -7.2735777816417775, 2: -7.62847609972422, 3: -7.313199478941094, 4: -7.472158336401026}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.551805953359913, 1: -7.219589057878173, 2: -7.187880696816165, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0773114950989955, 1: -7.5976528422474265, 2: -7.541618630918383, 3: -7.578445003832143, 4: -7.711402718964993}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.149863587437586, 1: -6.757193972316492, 2: -7.010556868808893, 3: -6.631063064685494, 4: -6.7199084526533746}, Best action: 3, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536217771796188, 1: -6.944809592850413, 2: -6.819389049228685, 3: -7.408033621603437, 4: -7.503470115439683}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.979057594904405, 1: -8.089772369910037, 2: -8.403554803771879, 3: -8.25980205363108, 4: -8.335020778800342}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.116929187712884, 2: -8.163877189219649, 3: -8.263629813914628, 4: -8.289202637770286}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058350488249577, 1: -7.878490201828744, 2: -7.898608825260489, 3: -8.293833198350809, 4: -8.171792587366264}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002362821805885, 1: -8.087961272037333, 2: -7.997464949946235, 3: -7.771611617056542, 4: -8.1739787528523}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002362821805885, 1: -8.087961272037333, 2: -7.997464949946235, 3: -7.771611617056542, 4: -8.1739787528523}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831389040799513, 1: -7.854340622927685, 2: -7.595548326823504, 3: -7.998889681938889, 4: -7.5712497755956765}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831389040799513, 1: -7.854340622927685, 2: -7.595548326823504, 3: -7.998889681938889, 4: -7.5712497755956765}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831389040799513, 1: -7.854340622927685, 2: -7.595548326823504, 3: -7.998889681938889, 4: -7.789837295792066}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -8.086280319954742, 2: -8.089912136037466, 3: -7.969536771100095, 4: -7.877997519942693}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -8.086280319954742, 2: -8.089912136037466, 3: -7.969536771100095, 4: -7.877997519942693}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -8.086280319954742, 2: -8.089912136037466, 3: -7.969536771100095, 4: -8.068977743147851}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.671700979961484, 1: -7.5976528422474265, 2: -7.541618630918383, 3: -7.578445003832143, 4: -7.711402718964993}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -8.086280319954742, 2: -8.089912136037466, 3: -7.8056647681539, 4: -8.097256244074574}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.831389040799513, 1: -7.854340622927685, 2: -8.14846628224337, 3: -7.998889681938889, 4: -8.21085010054909}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -7.619250579283936, 3: -7.6835047802506296, 4: -7.530623326046187}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -7.619250579283936, 3: -7.6835047802506296, 4: -7.530623326046187}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -7.619250579283936, 3: -7.6835047802506296, 4: -7.75286722670203}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058350488249577, 1: -8.07615130177441, 2: -7.898608825260489, 3: -8.293833198350809, 4: -8.171792587366264}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058350488249577, 1: -8.076157453090714, 2: -7.898608825260489, 3: -8.293833198350809, 4: -8.171792587366264}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058350488249577, 1: -8.076158641420875, 2: -8.087734030987043, 3: -8.293833198350809, 4: -8.171792587366264}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.18222096876536, 2: -8.163877189219649, 3: -8.263629813914628, 4: -8.289202637770286}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.18222111776129, 2: -8.163877189219649, 3: -8.263629813914628, 4: -8.289202637770286}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.20366954531997, 1: -8.18222116033897, 2: -8.329128242189881, 3: -8.263629813914628, 4: -8.289202637770286}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.399293749614973, 1: -8.076159494551346, 2: -8.525239247039002, 3: -8.293833198350809, 4: -8.171792587366264}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.002362821805885, 1: -8.087961272037333, 2: -7.997464949946235, 3: -7.9940443437399695, 4: -8.1739787528523}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.994827622859176, 1: -8.086280319954742, 2: -8.089912136037466, 3: -8.119286298089847, 4: -8.23796705367052}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.252770648019142, 1: -8.019984020915768, 2: -7.988516338723585, 3: -7.818055148773245, 4: -7.965522810134306}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -8.207380837920008, 3: -7.6835047802506296, 4: -8.272940294984899}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -8.207410594505188, 3: -7.6835047802506296, 4: -8.272959711156728}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -8.207442540143429, 3: -7.891989350028073, 4: -8.272980555685681}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212535355, 1: -6.757193972316492, 2: -7.010556868808893, 3: -6.631063064685494, 4: -6.7199084526533746}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.3764997576971325, 1: -7.525492941018675, 2: -7.780510514500251, 3: -7.688563383473992, 4: -7.877218256369172}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -7.328290997618614, 2: -6.935487563252365, 3: -6.545684890946863, 4: -7.438981204009778}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -7.528813785134602, 2: -7.44308073324557, 3: -7.266773620743766, 4: -7.482720391934942}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.022967559179845, 1: -7.528813785134602, 2: -7.44308073324557, 3: -7.266773620743766, 4: -7.482720391934942}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.290900478853659, 1: -7.528813785134602, 2: -7.44308073324557, 3: -7.266773620743766, 4: -7.482720391934942}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.113814867131551, 1: -6.9595995199716585, 2: -7.61297045687715, 3: -7.175886609117772, 4: -7.231135956663147}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.245123610891002, 1: -7.132238304193637, 2: -6.649224905258213, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523262, 1: -6.757193972316492, 2: -7.010556868808893, 3: -7.516476712376378, 4: -6.7199084526533746}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523272, 1: -6.757193972316492, 2: -7.010556868808893, 3: -7.517817525932107, 4: -6.7199084526533746}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523276, 1: -6.757193972316492, 2: -7.010556868808893, 3: -7.518313922288059, 4: -7.015116691914571}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.566974817838317, 1: -7.219589057878173, 2: -7.618886371897561, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -6.842691044952212, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.708492239913104, 1: -7.213656530114431, 2: -7.844974468079526, 3: -6.671339235950161, 4: -7.361230548037831}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.708492239913104, 1: -7.213656530114431, 2: -7.844974468079526, 3: -6.671339235950161, 4: -7.361230548037831}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -6.792387619940581, 2: -7.205770026229213, 3: -6.88338443019114, 4: -7.360272616738428}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -7.142673658234274, 2: -6.54669950703933, 3: -4.830163751868403, 4: -5.675806653157907}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -7.142673658234274, 2: -6.54669950703933, 3: -4.830163751868403, 4: -5.675806653157907}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -7.142673658234274, 2: -6.54669950703933, 3: -5.295449014200247, 4: -5.675806653157907}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.345543763192036, 1: -7.142673658234274, 2: -6.54669950703933, 3: -5.909392917847115, 4: -5.675806653157907}, Best action: 4, Actual action: 0\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -5.926342391188967, 2: -7.205770026229213, 3: -6.88338443019114, 4: -7.360272616738428}, Best action: 1, Actual action: 1\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -7.317384857111487, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -7.317384857111487, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -5.725666697152581, 4: -6.727276306632993}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -5.725666697152581, 4: -6.727276306632993}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.071412235435215, 1: -7.142673658234274, 2: -6.54669950703933, 3: -8.236241209077447, 4: -5.675806653157907}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.071376849659323, 1: -7.142673658234274, 2: -6.54669950703933, 3: -8.23621489532985, 4: -5.675806653157907}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.074608487585566, 1: -7.142673658234274, 2: -6.54669950703933, 3: -8.238618022082752, 4: -6.064984054373696}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.075931843316362, 1: -7.142673658234274, 2: -6.54669950703933, 3: -8.239602102488066, 4: -6.5785036352779285}, Best action: 2, Actual action: 2\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.076406321307184, 1: -7.142673658234274, 2: -6.54669950703933, 3: -8.23995493618399, 4: -7.044795061370649}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -6.058574667039148, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -6.056600806531449, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -6.515791478703473, 4: -6.727276306632993}, Best action: 3, Actual action: 3\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -7.002469790387898, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (5, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.59732494309961, 1: -7.714319293696, 2: -7.739076945092791, 3: -7.463356154637772, 4: -7.682956980897023}, Best action: 3, Actual action: 3\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.07662495780046, 1: -7.142673658234274, 2: -6.78707335801686, 3: -8.240117519746304, 4: -7.259659236775431}, Best action: 2, Actual action: 2\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.209686023105834, 4: -6.727276306632993}, Best action: 4, Actual action: 4\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.2329634042682835, 4: -6.727276306632993}, Best action: 4, Actual action: 4\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.245071044567647, 4: -7.021821439036023}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (5, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.649683243236642, 1: -7.3580428166533745, 2: -7.368189427012465, 3: -7.250029123270235, 4: -7.410473741241821}, Best action: 3, Actual action: 3\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0766225552727535, 1: -7.142673658234274, 2: -7.227883070723838, 3: -8.24011573316664, 4: -7.257298161885089}, Best action: 0, Actual action: 0\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -7.341383506770657, 2: -7.205770026229213, 3: -6.88338443019114, 4: -7.360272616738428}, Best action: 3, Actual action: 3\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.452458537107693, 2: -6.78641295008193, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 1, Actual action: 1\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57325972420998, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.5721853106824, 4: -5.484819887620951}, Best action: 3, Actual action: 3\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.779468589746471, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.708274892377988, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.23371589381042268, 4: -1.9776852269710905}, Best action: 3, Actual action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.34 -6.90 -6.90 -7.11 -7.39 -6.78 -6.94 -7.37 -8.09 -8.20 \n",
      "-6.52 -6.72 -6.87 -7.09 -7.31 -7.33 -7.01 -7.04 -7.97 -8.17 \n",
      "-5.77 -6.19 -5.75 -7.22 -6.64 -7.24 -7.58 -7.85 -8.09 -8.00 \n",
      "-4.07 -4.99 -5.33 -5.06 -6.56 -7.14 -6.90 -7.57 -7.16 -7.75 \n",
      "-2.68 -4.66 -4.21 -5.92 -4.90 -6.12 -6.58 -6.75 -6.99 -7.89 \n",
      "-3.68 -3.68 -2.42 -2.42 -3.81 -6.84 -7.25 -7.15 -7.61 -7.51 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.17 -2.45 -4.20 -4.75 -6.97 -7.10 \n",
      "-2.54 -2.04 -0.09 0.00 -0.02 -2.47 -2.97 -3.25 -7.62 -7.74 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.40 -7.52 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -6.97 -7.09 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.363615124239737, 2: -7.340329280937218, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 2, Actual action: 2\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -6.8951650032531555, 2: -7.31001025140471, 3: -6.9237874539372015, 4: -6.954915795264801}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.995819612095325, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.995819612095325, 2: -7.514730975140688, 3: -7.055013620980044, 4: -6.865103967021368}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917070223188531, 1: -6.995819612095325, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.147244609989444}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.902577753370355, 1: -6.972572048192, 2: -6.952157285126243, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.113814867131551, 1: -7.236713016747089, 2: -7.61297045687715, 3: -7.175886609117772, 4: -7.231135956663147}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.113814867131551, 1: -7.236713016747089, 2: -7.61297045687715, 3: -7.175886609117772, 4: -7.231135956663147}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7767691260757035, 1: -7.328290997618614, 2: -6.935487563252365, 3: -7.420264310579403, 4: -7.438981204009778}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.536217771796188, 1: -6.944809592850413, 2: -8.190299546793758, 3: -7.408033621603437, 4: -7.503470115439683}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523278, 1: -7.444613640886454, 2: -7.010556868808893, 3: -7.51859318356161, 4: -7.550255063193677}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523278, 1: -7.444613640886454, 2: -7.010556868808893, 3: -7.51859318356161, 4: -7.550255063193677}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -8.20743452778952, 3: -7.04367123381578, 4: -8.272975327624756}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523278, 1: -7.444613640886454, 2: -7.357511805178725, 3: -7.51859318356161, 4: -7.550255063193677}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.89816914995438, 1: -8.169554553346902, 2: -8.20743452778952, 3: -7.563951685576345, 4: -8.272975327624756}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.755601212523278, 1: -7.444613640886454, 2: -7.825717661068301, 3: -7.51859318356161, 4: -7.550255063193677}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955589339980666, 1: -7.854340622927685, 2: -8.15027444806206, 3: -7.998889681938889, 4: -8.21202992874578}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.071501337703333, 1: -7.164888077649313, 2: -8.05141710182597, 3: -8.029951772237052, 4: -8.295780051219207}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.462504103588688, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -6.987207176573777}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.462504103588688, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -6.987207176573777}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.462504103588688, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.258358530682137}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.462504103588688, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -7.616142742428118}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.600539173270871, 3: -7.509229730770941, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.600539173270871, 3: -7.509229730770941, 4: -8.066862993217743}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.600539173270871, 3: -7.7333990550015566, 4: -8.066862993217743}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.600539173270871, 3: -7.873146547231163, 4: -8.066862993217743}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -7.816490647676492, 3: -8.014054884280831, 4: -8.066862993217743}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.847147822071552, 2: -8.10143861815471, 3: -8.071756848302671, 4: -8.066862993217743}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -7.100235123813172, 4: -8.221044584762112}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -7.100235123813172, 4: -8.221044584762112}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -7.361213962669986, 4: -8.221044584762112}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -7.7055755405415525, 4: -8.221044584762112}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -8.043009171664204, 2: -8.127206264181895, 3: -8.046813818274511, 4: -8.221044584762112}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.739376520117625, 2: -7.970208341071571, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.518787640921305, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.087108016468811, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -6.966867854371195, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -6.966867854371195, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.239849747477788, 4: -7.26879469279576}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.425019353937732, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.431782765963707, 4: -7.982747119690688}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.894581130954714, 4: -7.26879469279576}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.855283129942723, 4: -7.26879469279576}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.340608994405317, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.892297969103957, 4: -7.5146031704441425}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.551887559472117, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (9, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.733247599706681, 1: -7.77895546499479, 2: -7.743882566493035, 3: -7.741915731218495, 4: -7.982747119690688}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.919275321534509, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -7.95750420801022, 2: -7.586230868618835, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -8.001510129622202, 2: -7.80347009044314, 3: -7.643326727840026, 4: -7.863992341161256}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.590347501009301, 1: -7.860946264951024, 2: -7.400008828693702, 3: -7.686391146577557, 4: -7.83687378654878}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -8.00832198823666, 2: -7.911824909524237, 3: -7.6583398240259015, 4: -7.863992341161256}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (8, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.590347501009301, 1: -7.860946264951024, 2: -7.84325614033035, 3: -7.686391146577557, 4: -7.83687378654878}, Best action: 0, Actual action: 0\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.765604938497569, 1: -7.750988769197469, 2: -7.903691808439285, 3: -7.745304438927149, 4: -7.6228358468192745}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.765604938497569, 1: -7.750988769197469, 2: -7.903691808439285, 3: -7.745304438927149, 4: -7.6228358468192745}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (7, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.765604938497569, 1: -7.750988769197469, 2: -7.903691808439285, 3: -7.745304438927149, 4: -7.83678062060554}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -3.2482905571149714, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.9722162987105927, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.9722162987105927, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -3.916949497569298, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -4.806018551188016, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -5.303099619213504, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -5.408348503333998, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (7, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.87058876400061, 1: -7.295120758908242, 2: -7.3810181122177, 3: -5.912905586132675, 4: -6.852032107854823}, Best action: 3, Actual action: 3\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -6.148835711389104, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -6.15425782839149, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -2.4707084403037736, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.02337158938104225, 4: -1.9776852269710905}, Best action: 3, Actual action: 3\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.1660018314290215, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.9865440052855776, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -2.8538002803135463, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -3.844987114183707, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.352061899502633, 4: -1.9776852269710905}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.2781329146135283, 4: -1.9776852269710905}, Best action: 4, Actual action: 4\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.2914559989425696, 4: -2.6996935565436924}, Best action: 3, Actual action: 3\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.36 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.52 -6.72 -7.00 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.77 -6.19 -5.75 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-4.07 -4.99 -5.33 -5.06 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.66 -4.21 -5.92 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.68 -2.42 -2.42 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -2.48 -1.17 -2.45 -4.20 -4.75 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 -0.22 -1.96 -1.96 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.363615124239737, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.519432269103947, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.774725398154948, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.068858378056145, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -4.2146377570458355, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.655699554439359, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -4.247555935002388, 2: -3.678776296036535, 3: -4.429910905248812, 4: -4.51185297381412}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -2.4173929120346815, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -2.4819623195911595, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.16548242623102, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.67 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-5.97 -6.72 -7.00 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.20 -6.19 -5.75 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.03 -4.99 -5.33 -5.06 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.21 -4.89 -5.92 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -2.42 -2.76 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -1.62 -0.12 -2.45 -4.20 -4.75 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 -0.22 -1.96 -1.96 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.671033974443058, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.995819612095325, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -5.752204234531005, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.33003584618099, 4: -5.702547875017606}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.025941437124322, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.211871505659096, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.422533207144874, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -1.620216614582679, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -4.203874536742954, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8906300585365745, 1: -7.592430411884222, 2: -7.493469691975829, 3: -4.753553598134252, 4: -5.791084996339947}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -2.445671324192246, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.9579411677052885, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.9579411677052885, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.963728156432192, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.963728156432192, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.22170125985910483, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.7458553798867638, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.91 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-5.97 -6.72 -6.28 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.20 -6.19 -5.80 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-4.68 -4.99 -5.35 -5.06 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -3.92 -4.89 -5.92 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -3.83 -2.76 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -4.68 -0.12 -3.09 -4.67 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 -0.88 0.26 -2.96 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.911992507794685, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -7.657984173274361, 2: -6.722898625638278, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.280875666657915, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -5.801111513371601, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.349062633985211, 4: -5.702547875017606}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.0638979601269165, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -6.327377468571985, 2: -6.356615455719349, 3: -5.919775932277635, 4: -6.49080334567724}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -4.892857792849346, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -3.9171831279752487, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -2.764343202818491, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -4.678493515818623, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -3.094958399844995, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: 0.26234602543306496, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.8794815991700808, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.02 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-5.97 -6.69 -6.35 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.20 -6.19 -6.08 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-4.68 -4.99 -5.53 -5.95 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.23 -4.70 -5.37 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -3.83 -4.32 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -3.23 -0.12 -1.67 -4.67 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 -0.09 -1.23 -2.96 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.022623746803329, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.972615211425921, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.203935202621652, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.681600293338568, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.228850128071389, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.3154850272426835, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.2328734250358457, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -3.2328734250358457, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.6887847664637645, 1: -6.945275376860845, 2: -7.228994858993396, 3: -4.673504491406423, 4: -6.788346347257492}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (6, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.29135588229, 1: -1.6685312211328553, 2: -6.287109161867499, 3: -5.735818118674249, 4: -6.249996633759616}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.959235259505637, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -2.959235259505637, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -3.5929040861501296, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -4.429030102907537, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.2299554451205763, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -1.2299554451205763, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.0879481599170081, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.36 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-5.80 -6.69 -6.35 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.39 -6.19 -6.08 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -4.99 -5.53 -5.95 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.69 -4.70 -5.37 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -3.83 -4.38 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -4.75 -0.12 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 -0.01 -0.74 -0.62 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.360346292700739, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.351351578477904, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.077475259996302, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.529271963714685, 2: -6.439075196002278, 3: -5.937114578721035, 4: -5.702547875017606}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -6.327377468571985, 2: -6.356615455719349, 3: -5.369510816998196, 4: -6.49080334567724}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -6.327377468571985, 2: -6.356615455719349, 3: -5.369510816998196, 4: -6.49080334567724}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -4.702454262988149, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.848477834630117, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.848477834630117, 2: -5.787095951858818, 3: -4.934077133900989, 4: -4.688297425263532}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.698651745229348, 1: -4.848477834630117, 2: -5.787095951858818, 3: -4.934077133900989, 4: -5.166350656989815}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -4.989711115406334, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -6.327377468571985, 2: -6.356615455719349, 3: -5.557021220075017, 4: -6.49080334567724}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -5.496564403480468, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -5.502634892794888, 4: -6.101314133238816}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -5.545172105600611, 2: -5.801265514919915, 3: -5.910758808363574, 4: -6.101314133238816}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -3.8308533840826327, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -0.11654824262310193, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.008794815991700802, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.008794815991700802, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.9080032825524477, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.75 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-5.80 -6.69 -6.50 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.39 -6.19 -6.18 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -5.54 -5.70 -5.95 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.85 -3.70 -5.94 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -1.92 -4.38 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -1.41 -4.75 -1.32 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 1.02 -0.74 -0.62 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.749550722644671, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -5.7954276486823915, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.388332121324449, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.961754862023823, 2: -6.439075196002278, 3: -5.937114578721035, 4: -5.702547875017606}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.961754862023823, 2: -6.439075196002278, 3: -5.937114578721035, 4: -5.702547875017606}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.961754862023823, 2: -6.439075196002278, 3: -5.937114578721035, 4: -6.089318566266022}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.961754862023823, 2: -6.439075196002278, 3: -5.937114578721035, 4: -6.420898909996718}, Best action: 3, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.961754862023823, 2: -6.439075196002278, 3: -6.694639574969445, 4: -6.915183970048806}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.397978297647855, 1: -6.327377468571985, 2: -6.356615455719349, 3: -5.942914949883877, 4: -6.49080334567724}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -3.696656650426324, 2: -5.801265514919915, 3: -4.806027257602416, 4: -6.101314133238816}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -1.9178493813255892, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.4090702856869537, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.48 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.26 -6.69 -6.50 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-6.32 -6.19 -6.18 -7.22 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -5.54 -5.46 -5.95 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.85 -2.71 -4.04 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -1.66 -4.38 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.60 -0.14 -4.75 -1.32 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.09 0.00 1.02 -0.74 -0.62 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.479337524854918, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.504510055827894, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5634665248002335, 1: -7.222690587776356, 2: -7.572457577691253, 3: -7.317988275002972, 4: -7.629123647759221}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -5.45532445739372, 2: -6.439075196002278, 3: -6.3694975573697645, 4: -5.980490986676841}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -2.708197724045943, 2: -5.801265514919915, 3: -4.806027257602416, 4: -6.101314133238816}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -1.6624584038357755, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (6, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.734269001105633, 1: -1.599628672532392, 2: -4.321292062001962, 3: -4.205284222543387, 4: -4.933019041760279}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.08996209406638145, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.7407734231180471, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 1.0205494391988896, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.82 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.26 -6.69 -6.52 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-6.32 -6.19 -6.18 -5.25 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -5.54 -3.71 -5.95 -6.56 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.85 -2.86 -4.04 -4.90 -6.12 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -2.42 -4.38 -3.81 -6.84 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.73 -0.14 -4.75 -1.32 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -1.43 0.00 0.10 -0.56 -0.62 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.821366215997352, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -7.657984173274361, 2: -6.691513312875731, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.51513076314182, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.181075120847638, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -6.5597537778232615, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -6.5597537778232615, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -5.953788999281828, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -7.341383478681239, 2: -7.205770026229213, 3: -6.117923112721276, 4: -7.360272616738428}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -4.903776880763093, 2: -6.78641295008193, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (5, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.838746039941536, 1: -7.142673658234274, 2: -7.227850753139072, 3: -8.240115733099497, 4: -7.257298073152613}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -7.341383478681239, 2: -7.205770026229213, 3: -6.39554487953987, 4: -7.360272616738428}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -6.896245942844914, 2: -6.78641295008193, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -7.028798006718322, 2: -6.78641295008193, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -7.055153437511462, 2: -7.0756357845745566, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -7.061156095080726, 2: -7.287892537519098, 3: -7.817002348368063, 4: -6.9314273748951365}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.092956967743292, 1: -7.066252236657158, 2: -7.468094464928381, 3: -7.817002348368063, 4: -7.207598911154574}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57325972420998, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -3.8056540337925773, 4: -5.484819887620951}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57325972420998, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -3.8056540337925773, 4: -5.484819887620951}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -4.382262693368031, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.3173481679400212, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -0.6214274909688833, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -0.6214274909688833, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -0.5607548194362544, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.582520256837315, 1: -7.136170988844245, 2: -6.771221194485513, 3: -1.516629335309467, 4: -6.821482517779028}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (7, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.023892474987045, 1: -6.7490118034039455, 2: -5.581764831599653, 3: -2.184545243544294, 4: -4.379981905511814}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.1020549439198889, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.15 -6.92 -6.95 -7.18 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.26 -6.83 -6.90 -7.09 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-6.32 -6.19 -6.63 -5.25 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -5.54 -3.71 -6.47 -6.63 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.85 -2.86 -4.04 -4.89 -7.05 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -2.42 -2.74 -4.05 -7.13 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.73 -0.14 -4.75 -2.06 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -1.43 0.00 0.01 -0.84 -2.30 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.149547239438719, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.828674088753977, 1: -7.657984173274361, 2: -7.018812944897155, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -6.972572048192, 2: -6.952157285126243, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445278784132711, 1: -7.236713016747089, 2: -7.61297045687715, 3: -7.175886609117772, 4: -7.231135956663147}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -6.972572048192, 2: -7.40768388189802, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.245123610891002, 1: -7.132238304193637, 2: -7.215626886348815, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.245123610891002, 1: -7.132238304193637, 2: -7.215626886348815, 3: -7.085077388955497, 4: -7.235124211640989}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.374232042523378, 1: -6.89825453084117, 2: -7.514730975140688, 3: -7.055013620980044, 4: -7.547487458204135}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.936787580048533, 2: -6.813160956655106, 3: -6.630593445492312, 4: -6.873700290049144}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -6.421137721091359, 3: -6.186810250852721, 4: -6.6236549493499774}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -6.317651610960593, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.540665140379312, 1: -6.060912718000043, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -6.205030012987199, 2: -6.421137721091359, 3: -6.501902371192572, 4: -6.6236549493499774}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.480140824557562, 1: -6.060912718000043, 2: -5.956589514636005, 3: -5.807639722615289, 4: -5.842151765133615}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -3.707296332897893, 2: -6.439075196002278, 3: -6.3694975573697645, 4: -5.980490986676841}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -2.859583792226626, 2: -5.801265514919915, 3: -4.806027257602416, 4: -6.101314133238816}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57325972420998, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.049687838765208, 4: -5.484819887620951}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (5, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.57325972420998, 1: -6.0878881761243715, 2: -6.345431572569353, 3: -4.049687838765208, 4: -5.484819887620951}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -2.7400858082854014, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -4.973402375370687, 3: -4.7525780918964955, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -0.1409070285686953, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -1.4280143104754497, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.41 -6.92 -7.03 -7.23 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.26 -6.84 -7.03 -7.13 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-6.35 -5.76 -6.68 -5.25 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.07 -4.78 -4.37 -6.47 -6.63 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.85 -4.60 -4.04 -4.89 -7.05 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.38 -2.42 -3.83 -3.84 -7.13 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.73 -1.49 -2.10 -2.06 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.14 0.00 0.01 -0.84 -2.30 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.439229950535863, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 4, Actual action: 4\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -7.439229950535863, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.405796192209762}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -7.439229950535863, 2: -7.4161918233802355, 3: -7.481071626447881, 4: -7.639274534910884}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.02548253847245, 4: -7.381057406534395}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -7.333109986923071, 2: -7.31001025140471, 3: -6.9237874539372015, 4: -6.954915795264801}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.212565686096215, 4: -7.381057406534395}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -7.333109986923071, 2: -7.31001025140471, 3: -7.434556951131655, 4: -6.954915795264801}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -7.333109986923071, 2: -7.31001025140471, 3: -7.318557431384359, 4: -6.954915795264801}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -7.333109986923071, 2: -7.31001025140471, 3: -7.374054091015657, 4: -7.22897337369097}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0110674238868524, 1: -7.333109986923071, 2: -7.31001025140471, 3: -7.380696062597195, 4: -7.334661810379362}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.422718297845281, 4: -7.381057406534395}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.440042943815533, 4: -7.381057406534395}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.653877047071971, 1: -7.440851793596398, 2: -7.542778965215694, 3: -7.4456694585067265, 4: -7.6167622399463}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479894565867911, 1: -7.657984173274361, 2: -7.018812944897155, 3: -6.842082349580022, 4: -6.863121940928212}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.26228555347731, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -6.353030448425893, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.072361101023111, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.893571899169234, 1: -4.848477834630117, 2: -5.787095951858818, 3: -4.934077133900989, 4: -6.027514924835754}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (5, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.724408492256181, 1: -4.247555935002388, 2: -3.3820935192044606, 3: -4.429910905248812, 4: -4.51185297381412}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (5, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.589598593013091, 1: -3.828848037641133, 2: -5.934680391155646, 3: -4.955752975595133, 4: -5.296897786230195}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -2.061364885533757, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.010205494391988881, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.44 -7.31 -7.12 -7.23 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.36 -6.70 -7.03 -7.13 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.65 -5.76 -6.68 -5.25 -6.64 -7.24 -7.58 -7.63 -8.09 -8.00 \n",
      "-5.08 -4.78 -4.37 -6.47 -6.63 -7.14 -6.90 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.29 -4.60 -4.04 -4.89 -7.05 -6.58 -6.75 -7.87 -7.89 \n",
      "-3.68 -3.75 -2.42 -2.52 -3.84 -7.13 -7.25 -7.15 -7.61 -7.63 \n",
      "-3.05 -1.73 -1.49 -2.10 -1.10 -3.80 -3.68 -3.65 -6.97 -7.99 \n",
      "-2.54 -2.04 -0.14 0.00 0.00 -0.84 -2.30 -5.76 -4.74 -7.78 \n",
      "-2.68 -0.25 -0.01 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.70 \n",
      "0.00 0.00 -2.10 -2.77 -3.76 -4.35 -4.64 -5.43 -7.53 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.439229950535863, 2: -7.484812616964413, 3: -7.481071626447881, 4: -7.73011363122594}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -6.3553055803738925, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.681275630939455, 1: -6.936787580048533, 2: -6.813160956655106, 3: -6.783665722926443, 4: -6.873700290049144}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.245123610891002, 1: -7.132238304193637, 2: -7.215626886348815, 3: -7.251666992172299, 4: -7.235124211640989}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5634665248002335, 1: -5.254469213243426, 2: -7.572457577691253, 3: -7.317988275002972, 4: -7.629123647759221}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -6.625557800025169, 4: -6.660906070967596}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.602053032084143, 2: -6.471512086403765, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -6.8044805699895665, 4: -6.660906070967596}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -7.016418437863731, 4: -6.660906070967596}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -7.077273424720347, 4: -6.961424524580512}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.000734619869512, 1: -7.115735261055018, 2: -7.114604619664816, 3: -7.102193541838131, 4: -7.357958624122755}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.415517348540832, 1: -6.642528175792666, 2: -6.722325908506042, 3: -7.2690237712157835, 4: -6.895752416019183}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.2934861252419125, 1: -7.403950839937151, 2: -7.357004713109247, 3: -7.144343946019521, 4: -7.4299360713039215}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.299410741507096, 1: -7.115735261055018, 2: -7.114604619664816, 3: -7.105590357506426, 4: -7.494845998409776}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.34509851573503, 1: -7.115735261055018, 2: -7.114604619664816, 3: -7.106433425437796, 4: -7.528820569520024}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.544212103488294, 1: -6.602053032084143, 2: -7.143491545539821, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5634665248002335, 1: -7.008593493289243, 2: -7.572457577691253, 3: -7.317988275002972, 4: -7.629123647759221}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.231381939913116, 1: -6.602053032084143, 2: -7.1432888814827455, 3: -6.960090213173707, 4: -6.656284310336818}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.050976649400552, 1: -7.341383478681239, 2: -7.205770026229213, 3: -7.258913603999776, 4: -7.360272616738428}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895400731056538, 1: -7.068862844108082, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.671702586622904, 1: -7.5976528422474265, 2: -8.02084520884936, 3: -7.578445003832143, 4: -7.711402718964993}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.566974817838317, 1: -7.266315961819248, 2: -7.618886371897561, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.566974817838317, 1: -7.266315961819248, 2: -7.618886371897561, 3: -7.458228453661836, 4: -7.24321086235422}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.566974817838317, 1: -7.266315961819248, 2: -7.618886371897561, 3: -7.458228453661836, 4: -7.491321884742341}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.758169468983779, 1: -7.068862844108082, 2: -7.622981458529929, 3: -7.637254867134362, 4: -7.259341320415428}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 5)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.580206875531763, 1: -7.341383478681239, 2: -7.205770026229213, 3: -7.258913603999776, 4: -7.360272616738428}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.228034688185821, 1: -7.251270833176353, 2: -6.75114549274193, 3: -6.832550216787178, 4: -6.8497666256358585}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.984286579423124, 1: -7.8743751107343565, 2: -7.945821339552107, 3: -7.9577319972383505, 4: -8.071310331696646}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (5, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058105383782884, 1: -7.626379662639625, 2: -7.879258849284878, 3: -8.053991710278174, 4: -8.066862993217743}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (6, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.058857130759398, 1: -7.991144147127822, 2: -8.127206264181895, 3: -8.307251641965072, 4: -8.221044584762112}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.779261517153455, 2: -7.970208341071571, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7038532029969415, 1: -8.016640998927052, 2: -8.044153683403762, 3: -7.877643423369876, 4: -7.863992341161256}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (7, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.109836054584456, 1: -7.9180472461428675, 2: -7.970208341071571, 3: -7.961175809689256, 4: -8.212876963406508}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.084003589675417, 1: -8.016640998927052, 2: -8.044153683403762, 3: -7.877643423369876, 4: -7.863992341161256}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.079337255368682, 1: -8.016640998927052, 2: -8.044153683403762, 3: -7.877643423369876, 4: -7.863992341161256}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.118265994951017, 1: -8.016640998927052, 2: -8.044153683403762, 3: -7.877643423369876, 4: -8.056233030456744}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.121025391673893, 1: -8.016640998927052, 2: -8.044153683403762, 3: -7.877643423369876, 4: -8.100141126458613}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (8, 9)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.128858081267232, 1: -8.016640998927052, 2: -8.044153683403762, 3: -8.068655515266588, 4: -8.224776516421217}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (9, 8)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.960017957720099, 1: -7.530445872640992, 2: -7.589099105496989, 3: -7.91679317881357, 4: -8.038755645506473}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (9, 7)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.090112564392439, 1: -7.17105516516695, 2: -7.158569157537623, 3: -5.426177007840167, 4: -7.2380903043864215}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (9, 6)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.651121977360823, 1: -6.933164808535694, 2: -6.849761922714016, 3: -4.640766740267604, 4: -7.695316034537921}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459657365617, 1: -4.864765324640269, 2: -5.459491095866127, 3: -3.764493257743092, 4: -4.917027816348625}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (9, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.600459657365617, 1: -4.864765324640269, 2: -5.459491095866127, 3: -3.764493257743092, 4: -4.917027816348625}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (9, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.10485632599414, 1: -2.8239961547785666, 2: -4.471915128541488, 3: -3.676071601752969, 4: -3.0854423103886233}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.009072606734848984, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.15 -7.31 -7.12 -7.23 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.58 -6.70 -7.03 -6.66 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.65 -5.76 -6.78 -7.32 -6.72 -7.46 -7.60 -7.63 -8.09 -8.00 \n",
      "-5.08 -4.78 -4.37 -6.66 -7.11 -7.29 -7.26 -7.57 -7.47 -7.75 \n",
      "-2.68 -4.29 -4.60 -4.04 -4.89 -7.26 -6.58 -6.83 -7.95 -7.89 \n",
      "-3.68 -3.75 -2.42 -2.52 -3.84 -7.13 -7.25 -7.15 -7.61 -7.88 \n",
      "-3.05 -1.73 -1.49 -2.10 -1.10 -3.80 -3.68 -3.65 -6.97 -8.06 \n",
      "-2.54 -2.04 -0.14 0.00 0.00 -0.84 -2.30 -5.76 -4.74 -7.96 \n",
      "-2.68 -0.25 -0.00 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.06 \n",
      "0.00 0.00 -1.11 -2.77 -1.81 -4.35 -4.31 -5.05 -5.88 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -7.149453737411389, 2: -7.484812616964413, 3: -7.481071626447881, 4: -7.73011363122594}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -7.150268296495996, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -7.150268296495996, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.584979849562667}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -7.150268296495996, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -6.892331663102027}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.121119048924489, 1: -7.150268296495996, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -7.297882381067213}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.445312200742118, 1: -7.15283824304223, 2: -7.484812616964413, 3: -7.481071626447881, 4: -7.73011363122594}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.405910881756656, 1: -7.150268296495996, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -7.674931011476471}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.648857919095201, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -5.083344173076206, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -2.6792096636523173, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -3.683942224318297, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.7341467069768695}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -3.973020043328965, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -3.973020043328965, 3: -3.0455833236487044, 4: -3.7405289393433288}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.101709566594744, 1: -3.721321757194979, 2: -3.973020043328965, 3: -3.671480824520321, 4: -3.7405289393433288}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -4.0388511213713825, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.7341467069768695}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -4.1421067016663775, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -3.7341467069768695}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.143548876067134, 1: -4.16523122486011, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -4.298073503348951}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -4.371716149424921, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.422842209869229, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (6, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.321967186322518, 1: -1.1020032633246202, 2: -5.49548806348214, 3: -5.313623026646295, 4: -4.690251454114083}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: 0.0010205494391988881, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.14280143104754495, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.89 -7.31 -7.12 -7.23 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.01 -6.70 -7.03 -6.66 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.25 -5.76 -6.78 -7.32 -6.72 -7.46 -7.60 -7.63 -8.09 -8.00 \n",
      "-4.34 -4.78 -4.37 -6.66 -7.11 -7.29 -7.26 -7.57 -7.47 -7.75 \n",
      "-3.19 -4.29 -4.60 -4.04 -4.89 -7.26 -6.58 -6.83 -7.95 -7.89 \n",
      "-4.17 -3.75 -2.19 -2.52 -3.84 -7.13 -7.25 -7.15 -7.61 -7.88 \n",
      "-3.72 -1.73 -1.49 -2.10 -1.44 -3.80 -3.68 -3.65 -6.97 -8.06 \n",
      "-2.54 -2.04 -0.01 0.00 -0.96 -0.84 -2.30 -5.76 -4.74 -7.96 \n",
      "-2.68 -0.25 -0.00 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.06 \n",
      "0.00 0.00 -1.11 -2.77 -1.81 -4.35 -4.31 -5.05 -5.88 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.890191425886485, 2: -7.484812616964413, 3: -7.481071626447881, 4: -7.73011363122594}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479894565867911, 1: -7.657984173274361, 2: -7.018812944897155, 3: -6.698518545378086, 4: -6.863121940928212}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.28470126212799, 1: -6.010252316220205, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -7.584796508080107}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.959744648949899, 1: -5.763363177147086, 2: -6.421137721091359, 3: -6.651899306822736, 4: -6.6236549493499774}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.281390748429512, 1: -6.060912718000043, 2: -5.956589514636005, 3: -4.782466390459694, 4: -5.842151765133615}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.513135671824511, 1: -4.340426040981247, 2: -6.559141806028258, 3: -5.981009916041268, 4: -6.530565028964405}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.040715667358197, 1: -3.1919929418933117, 2: -5.412362343372869, 3: -4.7366941481959115, 4: -5.625719695455619}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (5, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.324265647734098, 1: -4.173891701505545, 2: -5.0846835228144345, 3: -4.397937027329612, 4: -4.9786034299321145}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.583636371907892, 1: -3.721321757194979, 2: -3.973020043328965, 3: -4.795113474953659, 4: -3.7405289393433288}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -0.014280143104754478, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -0.9577325246303358, 4: -1.825659566789901}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -1.6771913592610475, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.3542982534644823, 4: -1.825659566789901}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.4909645609786537, 4: -1.825659566789901}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.6399419153739077, 4: -2.5613502057788096}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (7, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.604987088227803, 1: -5.061592183425292, 2: -4.307665894661952, 3: -2.700948141998764, 4: -3.5320940039246755}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (7, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.035640410464218, 1: -2.7107010704490886, 2: -3.221987114065282, 3: -4.194608465252183, 4: -3.37986488759892}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (8, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.0009072606734848981, 1: -2.146452587018015, 2: -3.6898198115520486, 3: -1.794290841749125, 4: -2.721829773942098}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.90 -7.31 -7.12 -7.23 -7.39 -6.94 -7.41 -7.37 -8.09 -8.20 \n",
      "-6.02 -6.44 -7.03 -6.66 -7.31 -7.33 -7.52 -7.90 -7.97 -8.17 \n",
      "-5.25 -5.43 -6.78 -7.32 -6.72 -7.46 -7.60 -7.63 -8.09 -8.00 \n",
      "-4.46 -4.95 -4.37 -6.66 -7.11 -7.29 -7.26 -7.57 -7.47 -7.75 \n",
      "-4.40 -4.29 -4.60 -4.04 -4.89 -7.26 -6.58 -6.83 -7.95 -7.89 \n",
      "-3.73 -3.75 -2.19 -2.52 -3.84 -7.13 -7.25 -7.15 -7.61 -7.88 \n",
      "-2.38 -1.73 -1.49 -2.10 -1.44 -3.80 -3.68 -3.65 -6.97 -8.06 \n",
      "-2.54 -2.04 -1.17 0.00 -2.67 -0.84 -2.30 -5.76 -4.74 -7.96 \n",
      "-2.68 -0.25 -0.00 -1.88 -3.97 -4.53 -5.94 -7.47 -7.68 -7.06 \n",
      "0.00 0.00 -1.11 -2.77 -1.81 -4.35 -4.31 -5.05 -5.88 -7.74 \n",
      "\n",
      "Action values: {0: -7.445312200742118, 1: -6.899058068902446, 2: -7.484812616964413, 3: -7.481071626447881, 4: -7.73011363122594}, Best action: 1, Actual action: 1\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.479894565867911, 1: -7.657984173274361, 2: -7.018812944897155, 3: -6.441271666617082, 4: -6.863121940928212}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.28470126212799, 1: -6.017175507199993, 2: -7.289617627351447, 3: -7.3802976672544665, 4: -7.584796508080107}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.705052606449681, 1: -5.248081412658515, 2: -6.391005245548477, 3: -6.82344642452269, 4: -6.4280343410620935}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.095744061789795, 1: -4.371279418566495, 2: -6.439075196002278, 3: -6.3694975573697645, 4: -5.980490986676841}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.875936646859086, 1: -4.602443600166932, 2: -5.801265514919915, 3: -4.806027257602416, 4: -6.101314133238816}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (5, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.695782875140106, 1: -2.1873710498618872, 2: -4.721679162908845, 3: -4.872810399611633, 4: -4.8133601384248585}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (6, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.763262521117499, 1: -5.51730282319569, 2: -4.973402375370687, 3: -2.097580763844122, 4: -4.801787522208119}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (6, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.495314078774509, 1: -1.4924364985994267, 2: -3.561465479508019, 3: -3.6923541678505822, 4: -4.649424751325486}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (7, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0}, Best action: 0, Actual action: 0\n",
      "[864, 88, 548, 78, 241, 214, 131, 33, 73, 93, 39, 95, 51, 79, 25, 43, 41, 18, 21, 17, 96, 396, 25, 28, 76, 15, 29, 288, 9, 46, 35, 42, 40, 125, 23, 21, 9, 12, 19, 34, 8, 7, 11, 10, 15, 27, 9, 24, 13, 8, 17, 8, 12, 9, 20, 89, 17, 12, 33, 19, 34, 7, 17, 26, 7, 6, 21, 11, 12, 14, 40, 14, 9, 17, 9, 34, 41, 8, 7, 20, 11, 9, 28, 20, 90, 74, 9, 16, 13, 16, 19, 11, 9, 25, 21, 22, 44, 21, 17, 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TDlambda import TDlambda\n",
    "from SingleAgentTests.Environments.RandomGrid import RandomGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 10\n",
    "terminal = (7,3)\n",
    "environment = RandomGrid()\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TDlambda(0.9, 0.01, 0.9, 0.5, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, RandomGrid)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 2, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 0, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 5), -1, None)\n",
      "((8, 5), 0, (7, 5), -1, None)\n",
      "((7, 5), 0, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 6), -1, None)\n",
      "((0, 6), 2, (0, 6), -1, None)\n",
      "((0, 6), 2, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 1, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 2, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 7), -1, None)\n",
      "((2, 7), 2, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 0, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 7), -1, None)\n",
      "((0, 7), 1, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 2, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), -1, None)\n",
      "((4, 4), 0, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 6), -1, None)\n",
      "((7, 6), 1, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 2, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 6), -1, None)\n",
      "((9, 6), 1, (9, 7), -1, None)\n",
      "((9, 7), 2, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 6), -1, None)\n",
      "((9, 6), 2, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 2, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 6), -1, None)\n",
      "((6, 6), 2, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 6), -1, None)\n",
      "((7, 6), 2, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 1, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 5), -1, None)\n",
      "((8, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 2, (9, 5), -1, None)\n",
      "((9, 5), 2, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 0, (8, 4), -1, None)\n",
      "((8, 4), 0, (7, 4), -1, None)\n",
      "((7, 4), 0, (6, 5), -1, None)\n",
      "((6, 5), 0, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 0, (5, 4), -1, None)\n",
      "((5, 4), 2, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 3), -1, None)\n",
      "((8, 3), 0, (7, 4), -1, None)\n",
      "((7, 4), 2, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 5), -1, None)\n",
      "((7, 5), 2, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 3), -1, None)\n",
      "((9, 3), 0, (8, 3), -1, None)\n",
      "((8, 3), 1, (9, 4), -1, None)\n",
      "((9, 4), 2, (9, 6), -1, None)\n",
      "((9, 6), 0, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 0, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 2), -1, None)\n",
      "((5, 2), 0, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 0, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 864)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 6), -1, None)\n",
      "((3, 6), 2, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 88)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 7), -1, None)\n",
      "((2, 7), 2, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 2, (5, 4), -1, None)\n",
      "((5, 4), 2, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 2, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 2, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 4), -1, None)\n",
      "((6, 4), 2, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 2, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 4), -1, None)\n",
      "((8, 4), 1, (9, 3), -1, None)\n",
      "((9, 3), 1, (9, 3), -1, None)\n",
      "((9, 3), 1, (9, 3), -1, None)\n",
      "((9, 3), 2, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 4, (9, 4), -1, None)\n",
      "((9, 4), 4, (9, 4), -1, None)\n",
      "((9, 4), 4, (9, 4), -1, None)\n",
      "((9, 4), 0, (8, 4), -1, None)\n",
      "((8, 4), 2, (8, 5), -1, None)\n",
      "((8, 5), 2, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 5), -1, None)\n",
      "((7, 5), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 2, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 5), -1, None)\n",
      "((7, 5), 0, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 2), -1, None)\n",
      "((6, 2), 0, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 5), -1, None)\n",
      "((6, 5), 0, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 0, (6, 2), -1, None)\n",
      "((6, 2), 2, (6, 2), -1, None)\n",
      "((6, 2), 2, (6, 3), -1, None)\n",
      "((6, 3), 1, (7, 5), -1, None)\n",
      "((7, 5), 2, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 5), -1, None)\n",
      "((6, 5), 2, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 2, (5, 6), -1, None)\n",
      "((5, 6), 2, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 0, (6, 6), -1, None)\n",
      "((6, 6), 2, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 4, (6, 4), -1, None)\n",
      "((6, 4), 4, (6, 4), -1, None)\n",
      "((6, 4), 4, (6, 4), -1, None)\n",
      "((6, 4), 0, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 5), -1, None)\n",
      "((8, 5), 3, (8, 3), -1, None)\n",
      "((8, 3), 2, (8, 4), -1, None)\n",
      "((8, 4), 3, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 2), -1, None)\n",
      "((7, 2), 1, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 2, (8, 5), -1, None)\n",
      "((8, 5), 4, (8, 5), -1, None)\n",
      "((8, 5), 4, (8, 5), -1, None)\n",
      "((8, 5), 4, (8, 5), -1, None)\n",
      "((8, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 0, (8, 3), -1, None)\n",
      "((8, 3), 0, (7, 4), -1, None)\n",
      "((7, 4), 0, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 4), -1, None)\n",
      "((8, 4), 4, (8, 4), -1, None)\n",
      "((8, 4), 4, (8, 4), -1, None)\n",
      "((8, 4), 4, (8, 4), -1, None)\n",
      "((8, 4), 3, (8, 3), -1, None)\n",
      "((8, 3), 2, (8, 4), -1, None)\n",
      "((8, 4), 1, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 1, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 4, (9, 3), -1, None)\n",
      "((9, 3), 4, (9, 3), -1, None)\n",
      "((9, 3), 4, (9, 3), -1, None)\n",
      "((9, 3), 0, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 2), -1, None)\n",
      "((8, 2), 1, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 2, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 3, (9, 2), -1, None)\n",
      "((9, 2), 3, (9, 1), -1, None)\n",
      "((9, 1), 0, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 4), -1, None)\n",
      "((8, 4), 0, (7, 3), 0, 548)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 0, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 1), -1, None)\n",
      "((6, 1), 0, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 4), -1, None)\n",
      "((8, 4), 0, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 78)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 5), -1, None)\n",
      "((0, 5), 2, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 6), -1, None)\n",
      "((7, 6), 2, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 6), -1, None)\n",
      "((9, 6), 2, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 4, (9, 2), -1, None)\n",
      "((9, 2), 4, (9, 2), -1, None)\n",
      "((9, 2), 4, (9, 2), -1, None)\n",
      "((9, 2), 2, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 1), -1, None)\n",
      "((9, 1), 1, (9, 1), -1, None)\n",
      "((9, 1), 1, (9, 0), -1, None)\n",
      "((9, 0), 0, (8, 0), -1, None)\n",
      "((8, 0), 0, (7, 0), -1, None)\n",
      "((7, 0), 0, (6, 0), -1, None)\n",
      "((6, 0), 0, (5, 0), -1, None)\n",
      "((5, 0), 0, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 2, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 0, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 6), -1, None)\n",
      "((3, 6), 2, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 2, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 0, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 241)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 6), -1, None)\n",
      "((0, 6), 2, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 2, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 0, (8, 4), -1, None)\n",
      "((8, 4), 0, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 4), -1, None)\n",
      "((8, 4), 2, (8, 5), -1, None)\n",
      "((8, 5), 3, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 3), -1, None)\n",
      "((8, 3), 3, (8, 3), -1, None)\n",
      "((8, 3), 1, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 6), -1, None)\n",
      "((9, 6), 0, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 5), -1, None)\n",
      "((8, 5), 0, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 214)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 1), -1, None)\n",
      "((6, 1), 2, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 0), -1, None)\n",
      "((6, 0), 1, (7, 0), -1, None)\n",
      "((7, 0), 1, (8, 0), -1, None)\n",
      "((8, 0), 1, (9, 2), -1, None)\n",
      "((9, 2), 2, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 1, (9, 6), -1, None)\n",
      "((9, 6), 2, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 2, (9, 5), -1, None)\n",
      "((9, 5), 2, (9, 6), -1, None)\n",
      "((9, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 5), -1, None)\n",
      "((8, 5), 1, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 5), -1, None)\n",
      "((8, 5), 3, (8, 5), -1, None)\n",
      "((8, 5), 3, (8, 5), -1, None)\n",
      "((8, 5), 0, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 5), -1, None)\n",
      "((6, 5), 0, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 131)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 3, (5, 1), -1, None)\n",
      "((5, 1), 2, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 4), -1, None)\n",
      "((4, 4), 0, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 4), -1, None)\n",
      "((6, 4), 0, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 6), -1, None)\n",
      "((7, 6), 1, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 73)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 2, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 2, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 0, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 93)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 39)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 2, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 95)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 5), -1, None)\n",
      "((0, 5), 2, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 51)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 1), -1, None)\n",
      "((7, 1), 0, (6, 1), -1, None)\n",
      "((6, 1), 4, (6, 1), -1, None)\n",
      "((6, 1), 4, (6, 1), -1, None)\n",
      "((6, 1), 4, (6, 1), -1, None)\n",
      "((6, 1), 0, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 0), -1, None)\n",
      "((5, 0), 2, (5, 0), -1, None)\n",
      "((5, 0), 2, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 0), -1, None)\n",
      "((5, 0), 3, (5, 0), -1, None)\n",
      "((5, 0), 3, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 0, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 5), -1, None)\n",
      "((6, 5), 3, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 79)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 4, (5, 2), -1, None)\n",
      "((5, 2), 4, (5, 2), -1, None)\n",
      "((5, 2), 4, (5, 2), -1, None)\n",
      "((5, 2), 0, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 4, (7, 2), -1, None)\n",
      "((7, 2), 4, (7, 2), -1, None)\n",
      "((7, 2), 4, (7, 2), -1, None)\n",
      "((7, 2), 1, (8, 2), -1, None)\n",
      "((8, 2), 2, (8, 4), -1, None)\n",
      "((8, 4), 2, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 43)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 0, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 0, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 1), -1, None)\n",
      "((8, 1), 0, (7, 1), -1, None)\n",
      "((7, 1), 2, (7, 3), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 4, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 1), -1, None)\n",
      "((7, 1), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 2, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 2, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 2, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 1, (8, 4), -1, None)\n",
      "((8, 4), 3, (8, 4), -1, None)\n",
      "((8, 4), 3, (8, 4), -1, None)\n",
      "((8, 4), 0, (7, 4), -1, None)\n",
      "((7, 4), 0, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 0, (7, 3), 0, 96)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 6), -1, None)\n",
      "((0, 6), 2, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 1, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 7), -1, None)\n",
      "((0, 7), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 2, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 5), -1, None)\n",
      "((8, 5), 4, (8, 5), -1, None)\n",
      "((8, 5), 4, (8, 5), -1, None)\n",
      "((8, 5), 2, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 0, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 2, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 1, (8, 4), -1, None)\n",
      "((8, 4), 2, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 6), -1, None)\n",
      "((8, 6), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 5), -1, None)\n",
      "((9, 5), 0, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 4, (8, 6), -1, None)\n",
      "((8, 6), 0, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 6), -1, None)\n",
      "((9, 6), 2, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 0, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 1, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 4, (9, 7), -1, None)\n",
      "((9, 7), 0, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 7), -1, None)\n",
      "((9, 7), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 7), -1, None)\n",
      "((7, 7), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 2, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 6), -1, None)\n",
      "((5, 6), 2, (5, 6), -1, None)\n",
      "((5, 6), 2, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 4, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 4, (6, 6), -1, None)\n",
      "((6, 6), 2, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 5), -1, None)\n",
      "((7, 5), 2, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 4, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 1, (8, 5), -1, None)\n",
      "((8, 5), 0, (7, 6), -1, None)\n",
      "((7, 6), 1, (8, 6), -1, None)\n",
      "((8, 6), 2, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 6), -1, None)\n",
      "((8, 6), 1, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 4, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 4), -1, None)\n",
      "((9, 4), 4, (9, 4), -1, None)\n",
      "((9, 4), 4, (9, 4), -1, None)\n",
      "((9, 4), 0, (8, 4), -1, None)\n",
      "((8, 4), 4, (8, 4), -1, None)\n",
      "((8, 4), 4, (8, 4), -1, None)\n",
      "((8, 4), 1, (9, 4), -1, None)\n",
      "((9, 4), 2, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 2, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 1, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 3, (9, 1), -1, None)\n",
      "((9, 1), 2, (9, 1), -1, None)\n",
      "((9, 1), 2, (9, 3), -1, None)\n",
      "((9, 3), 2, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 1, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 0, (8, 3), -1, None)\n",
      "((8, 3), 0, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 396)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 1), -1, None)\n",
      "((6, 1), 2, (6, 1), -1, None)\n",
      "((6, 1), 2, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 0, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 1, (7, 3), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 4, (6, 4), -1, None)\n",
      "((6, 4), 4, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 3), -1, None)\n",
      "((6, 3), 1, (7, 5), -1, None)\n",
      "((7, 5), 1, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 0, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 2, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 2), -1, None)\n",
      "((5, 2), 3, (5, 2), -1, None)\n",
      "((5, 2), 3, (5, 2), -1, None)\n",
      "((5, 2), 0, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 4, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 0), -1, None)\n",
      "((6, 0), 3, (6, 0), -1, None)\n",
      "((6, 0), 3, (6, 0), -1, None)\n",
      "((6, 0), 4, (6, 0), -1, None)\n",
      "((6, 0), 4, (6, 0), -1, None)\n",
      "((6, 0), 4, (6, 0), -1, None)\n",
      "((6, 0), 0, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 0), -1, None)\n",
      "((6, 0), 3, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 1), -1, None)\n",
      "((7, 1), 3, (7, 1), -1, None)\n",
      "((7, 1), 3, (7, 0), -1, None)\n",
      "((7, 0), 2, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 3), 0, 76)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 3, (7, 2), -1, None)\n",
      "((7, 2), 0, (6, 1), -1, None)\n",
      "((6, 1), 4, (6, 1), -1, None)\n",
      "((6, 1), 4, (6, 1), -1, None)\n",
      "((6, 1), 0, (5, 1), -1, None)\n",
      "((5, 1), 4, (5, 1), -1, None)\n",
      "((5, 1), 0, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 2, (5, 3), -1, None)\n",
      "((5, 3), 0, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 2, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 6), -1, None)\n",
      "((6, 6), 1, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 4, (6, 5), -1, None)\n",
      "((6, 5), 0, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 5), -1, None)\n",
      "((6, 5), 2, (6, 6), -1, None)\n",
      "((6, 6), 0, (5, 6), -1, None)\n",
      "((5, 6), 1, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 6), -1, None)\n",
      "((5, 6), 0, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 7), -1, None)\n",
      "((7, 7), 0, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 2, (6, 7), -1, None)\n",
      "((6, 7), 2, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 2, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 2, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 3, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 7), -1, None)\n",
      "((7, 7), 1, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 4, (8, 7), -1, None)\n",
      "((8, 7), 2, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 4, (8, 8), -1, None)\n",
      "((8, 8), 3, (8, 7), -1, None)\n",
      "((8, 7), 1, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 4, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 3, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 8), -1, None)\n",
      "((7, 8), 1, (8, 8), -1, None)\n",
      "((8, 8), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 4, (9, 6), -1, None)\n",
      "((9, 6), 0, (8, 7), -1, None)\n",
      "((8, 7), 0, (7, 8), -1, None)\n",
      "((7, 8), 0, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 0, (3, 6), -1, None)\n",
      "((3, 6), 2, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 5), -1, None)\n",
      "((4, 5), 0, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 5), -1, None)\n",
      "((3, 5), 2, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 4, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 4, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 4, (5, 2), -1, None)\n",
      "((5, 2), 4, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 4, (6, 2), -1, None)\n",
      "((6, 2), 0, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 3, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 288)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 2, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 5), -1, None)\n",
      "((0, 5), 2, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 4, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 6), -1, None)\n",
      "((3, 6), 3, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 46)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 7), -1, None)\n",
      "((0, 7), 1, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 8), -1, None)\n",
      "((1, 8), 2, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 35)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 5), -1, None)\n",
      "((2, 5), 3, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 7), -1, None)\n",
      "((4, 7), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 2, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 4, (0, 6), -1, None)\n",
      "((0, 6), 3, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 4, (0, 7), -1, None)\n",
      "((0, 7), 2, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 4, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 3, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 4, (0, 5), -1, None)\n",
      "((0, 5), 1, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 5), -1, None)\n",
      "((1, 5), 2, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 0, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 4, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 7), -1, None)\n",
      "((0, 7), 0, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 4, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 9), -1, None)\n",
      "((1, 9), 3, (1, 8), -1, None)\n",
      "((1, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 4, (2, 6), -1, None)\n",
      "((2, 6), 1, (3, 7), -1, None)\n",
      "((3, 7), 0, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 7), -1, None)\n",
      "((3, 7), 3, (3, 8), -1, None)\n",
      "((3, 8), 3, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 7), -1, None)\n",
      "((4, 7), 1, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 4, (5, 7), -1, None)\n",
      "((5, 7), 0, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 9), -1, None)\n",
      "((4, 9), 3, (4, 8), -1, None)\n",
      "((4, 8), 0, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 8), -1, None)\n",
      "((3, 8), 2, (3, 9), -1, None)\n",
      "((3, 9), 3, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 2, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 4, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 4, (7, 9), -1, None)\n",
      "((7, 9), 0, (6, 9), -1, None)\n",
      "((6, 9), 0, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 4, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 125)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 3, (5, 0), -1, None)\n",
      "((5, 0), 3, (5, 0), -1, None)\n",
      "((5, 0), 0, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 4, (7, 1), -1, None)\n",
      "((7, 1), 4, (7, 1), -1, None)\n",
      "((7, 1), 4, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 1), -1, None)\n",
      "((8, 1), 1, (9, 3), -1, None)\n",
      "((9, 3), 0, (8, 2), -1, None)\n",
      "((8, 2), 3, (8, 1), -1, None)\n",
      "((8, 1), 2, (8, 2), -1, None)\n",
      "((8, 2), 4, (8, 2), -1, None)\n",
      "((8, 2), 4, (8, 2), -1, None)\n",
      "((8, 2), 4, (8, 2), -1, None)\n",
      "((8, 2), 3, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 0), -1, None)\n",
      "((8, 0), 2, (8, 1), -1, None)\n",
      "((8, 1), 4, (8, 1), -1, None)\n",
      "((8, 1), 4, (8, 1), -1, None)\n",
      "((8, 1), 0, (7, 1), -1, None)\n",
      "((7, 1), 0, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 3, (7, 0), -1, None)\n",
      "((7, 0), 3, (7, 0), -1, None)\n",
      "((7, 0), 3, (7, 0), -1, None)\n",
      "((7, 0), 4, (7, 0), -1, None)\n",
      "((7, 0), 4, (7, 0), -1, None)\n",
      "((7, 0), 4, (7, 0), -1, None)\n",
      "((7, 0), 2, (7, 1), -1, None)\n",
      "((7, 1), 3, (7, 1), -1, None)\n",
      "((7, 1), 3, (7, 0), -1, None)\n",
      "((7, 0), 0, (6, 0), -1, None)\n",
      "((6, 0), 1, (7, 1), -1, None)\n",
      "((7, 1), 0, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 1, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 3), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 3), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 0, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 6), -1, None)\n",
      "((0, 6), 0, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 4, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 8), -1, None)\n",
      "((0, 8), 2, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 9), -1, None)\n",
      "((0, 9), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 8), -1, None)\n",
      "((0, 8), 3, (0, 8), -1, None)\n",
      "((0, 8), 1, (1, 8), -1, None)\n",
      "((1, 8), 1, (2, 9), -1, None)\n",
      "((2, 9), 0, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 7), -1, None)\n",
      "((1, 7), 1, (2, 8), -1, None)\n",
      "((2, 8), 1, (3, 9), -1, None)\n",
      "((3, 9), 0, (2, 8), -1, None)\n",
      "((2, 8), 2, (2, 9), -1, None)\n",
      "((2, 9), 1, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 4, (3, 8), -1, None)\n",
      "((3, 8), 0, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 4, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 2, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 3, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 7), -1, None)\n",
      "((3, 7), 1, (4, 9), -1, None)\n",
      "((4, 9), 0, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 2, (3, 9), -1, None)\n",
      "((3, 9), 1, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 4, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 2, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 0, (4, 9), -1, None)\n",
      "((4, 9), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 4, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 2, (5, 8), -1, None)\n",
      "((5, 8), 0, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 1, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 0, (8, 4), -1, None)\n",
      "((8, 4), 1, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 3, (9, 2), -1, None)\n",
      "((9, 2), 3, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 1), -1, None)\n",
      "((9, 1), 3, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 2), -1, None)\n",
      "((9, 2), 1, (9, 2), -1, None)\n",
      "((9, 2), 0, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 89)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 4, (4, 6), -1, None)\n",
      "((4, 6), 1, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 4), -1, None)\n",
      "((5, 4), 2, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 6), -1, None)\n",
      "((4, 6), 2, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 5), -1, None)\n",
      "((3, 5), 1, (4, 6), -1, None)\n",
      "((4, 6), 0, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 4, (3, 7), -1, None)\n",
      "((3, 7), 2, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 1), -1, None)\n",
      "((8, 1), 2, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 4, (8, 3), -1, None)\n",
      "((8, 3), 0, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 3), 0, 6)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 1), -1, None)\n",
      "((7, 1), 4, (7, 1), -1, None)\n",
      "((7, 1), 4, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 0), -1, None)\n",
      "((8, 0), 3, (8, 0), -1, None)\n",
      "((8, 0), 3, (8, 0), -1, None)\n",
      "((8, 0), 4, (8, 0), -1, None)\n",
      "((8, 0), 4, (8, 0), -1, None)\n",
      "((8, 0), 4, (8, 0), -1, None)\n",
      "((8, 0), 2, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 3), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 12)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 5), -1, None)\n",
      "((5, 5), 1, (6, 7), -1, None)\n",
      "((6, 7), 0, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 3, (6, 8), -1, None)\n",
      "((6, 8), 1, (7, 8), -1, None)\n",
      "((7, 8), 2, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 5), -1, None)\n",
      "((9, 5), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 3), -1, None)\n",
      "((9, 3), 3, (9, 2), -1, None)\n",
      "((9, 2), 0, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 1), -1, None)\n",
      "((8, 1), 3, (8, 0), -1, None)\n",
      "((8, 0), 0, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 3), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 4, (4, 5), -1, None)\n",
      "((4, 5), 0, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 4), -1, None)\n",
      "((4, 4), 3, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 7), -1, None)\n",
      "((4, 7), 0, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 8), -1, None)\n",
      "((5, 8), 3, (5, 7), -1, None)\n",
      "((5, 7), 1, (6, 8), -1, None)\n",
      "((6, 8), 0, (5, 8), -1, None)\n",
      "((5, 8), 1, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 4, (6, 8), -1, None)\n",
      "((6, 8), 2, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 4, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 2, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 1), -1, None)\n",
      "((6, 1), 3, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 0), -1, None)\n",
      "((7, 0), 3, (7, 0), -1, None)\n",
      "((7, 0), 3, (7, 0), -1, None)\n",
      "((7, 0), 1, (8, 0), -1, None)\n",
      "((8, 0), 3, (8, 0), -1, None)\n",
      "((8, 0), 3, (8, 0), -1, None)\n",
      "((8, 0), 0, (7, 0), -1, None)\n",
      "((7, 0), 2, (7, 1), -1, None)\n",
      "((7, 1), 1, (8, 1), -1, None)\n",
      "((8, 1), 0, (7, 3), 0, 41)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 8)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 4, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 5), -1, None)\n",
      "((3, 5), 0, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 4, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 3), -1, None)\n",
      "((4, 3), 1, (5, 4), -1, None)\n",
      "((5, 4), 0, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 4, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 1), -1, None)\n",
      "((5, 1), 3, (5, 1), -1, None)\n",
      "((5, 1), 2, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 5), -1, None)\n",
      "((1, 5), 1, (2, 5), -1, None)\n",
      "((2, 5), 0, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 4, (1, 5), -1, None)\n",
      "((1, 5), 3, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 5), -1, None)\n",
      "((2, 5), 2, (2, 6), -1, None)\n",
      "((2, 6), 0, (1, 6), -1, None)\n",
      "((1, 6), 0, (0, 6), -1, None)\n",
      "((0, 6), 2, (0, 8), -1, None)\n",
      "((0, 8), 0, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 4, (2, 7), -1, None)\n",
      "((2, 7), 2, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 4, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 6), -1, None)\n",
      "((2, 6), 2, (2, 8), -1, None)\n",
      "((2, 8), 3, (2, 7), -1, None)\n",
      "((2, 7), 0, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 4, (1, 7), -1, None)\n",
      "((1, 7), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 2, (1, 9), -1, None)\n",
      "((1, 9), 0, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 2, (0, 9), -1, None)\n",
      "((0, 9), 1, (1, 9), -1, None)\n",
      "((1, 9), 1, (2, 9), -1, None)\n",
      "((2, 9), 3, (2, 8), -1, None)\n",
      "((2, 8), 0, (1, 8), -1, None)\n",
      "((1, 8), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 3, (1, 5), -1, None)\n",
      "((1, 5), 0, (0, 5), -1, None)\n",
      "((0, 5), 3, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 4, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 6), -1, None)\n",
      "((4, 6), 3, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 3, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 1, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 4, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 7), -1, None)\n",
      "((5, 7), 3, (5, 5), -1, None)\n",
      "((5, 5), 2, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 4, (5, 6), -1, None)\n",
      "((5, 6), 3, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 90)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 5), -1, None)\n",
      "((0, 5), 0, (0, 6), -1, None)\n",
      "((0, 6), 1, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 2, (1, 7), -1, None)\n",
      "((1, 7), 3, (1, 6), -1, None)\n",
      "((1, 6), 1, (2, 7), -1, None)\n",
      "((2, 7), 1, (3, 8), -1, None)\n",
      "((3, 8), 1, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 4, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 3, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 2, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 3, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 8), -1, None)\n",
      "((9, 8), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 9), -1, None)\n",
      "((9, 9), 3, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 4, (9, 8), -1, None)\n",
      "((9, 8), 0, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 9), -1, None)\n",
      "((9, 9), 0, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 2, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 8), -1, None)\n",
      "((8, 8), 0, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 4, (7, 8), -1, None)\n",
      "((7, 8), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 7), -1, None)\n",
      "((7, 7), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 74)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 2, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 7), -1, None)\n",
      "((6, 7), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 3), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 3), -1, None)\n",
      "((6, 3), 2, (6, 6), -1, None)\n",
      "((6, 6), 3, (6, 5), -1, None)\n",
      "((6, 5), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 1), -1, None)\n",
      "((6, 1), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 5), -1, None)\n",
      "((5, 5), 0, (4, 5), -1, None)\n",
      "((4, 5), 3, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 4), -1, None)\n",
      "((4, 4), 2, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 4, (4, 4), -1, None)\n",
      "((4, 4), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 6), -1, None)\n",
      "((7, 6), 3, (7, 5), -1, None)\n",
      "((7, 5), 3, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 4), -1, None)\n",
      "((5, 4), 3, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (5, 1), -1, None)\n",
      "((5, 1), 2, (5, 3), -1, None)\n",
      "((5, 3), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 3), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 5), -1, None)\n",
      "((3, 5), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 5), -1, None)\n",
      "((4, 5), 0, (3, 6), -1, None)\n",
      "((3, 6), 0, (2, 6), -1, None)\n",
      "((2, 6), 3, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 4, (2, 5), -1, None)\n",
      "((2, 5), 1, (3, 6), -1, None)\n",
      "((3, 6), 1, (4, 5), -1, None)\n",
      "((4, 5), 2, (4, 7), -1, None)\n",
      "((4, 7), 2, (4, 8), -1, None)\n",
      "((4, 8), 1, (5, 9), -1, None)\n",
      "((5, 9), 1, (6, 9), -1, None)\n",
      "((6, 9), 1, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 0, (7, 9), -1, None)\n",
      "((7, 9), 1, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 4, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 3, (8, 9), -1, None)\n",
      "((8, 9), 1, (9, 8), -1, None)\n",
      "((9, 8), 1, (9, 7), -1, None)\n",
      "((9, 7), 3, (9, 6), -1, None)\n",
      "((9, 6), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 4), -1, None)\n",
      "((9, 4), 3, (9, 2), -1, None)\n",
      "((9, 2), 0, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 3), 0, 44)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 3, (6, 0), -1, None)\n",
      "((6, 0), 3, (6, 0), -1, None)\n",
      "((6, 0), 0, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 4, (5, 0), -1, None)\n",
      "((5, 0), 0, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 4), -1, None)\n",
      "((6, 4), 1, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 3), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (5, 0), -1, None)\n",
      "((5, 0), 1, (6, 0), -1, None)\n",
      "((6, 0), 1, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 2, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 4, (7, 4), -1, None)\n",
      "((7, 4), 3, (7, 2), -1, None)\n",
      "((7, 2), 1, (8, 2), -1, None)\n",
      "((8, 2), 0, (7, 3), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (5, 2), -1, None)\n",
      "((5, 2), 1, (6, 3), -1, None)\n",
      "((6, 3), 3, (6, 2), -1, None)\n",
      "((6, 2), 1, (7, 3), 0, 8)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "            font = pygame.font.Font('freesansbold.ttf', 20)\n",
    "            text = font.render(f\"{w},{h}\", True, black)\n",
    " \n",
    "            textRect = text.get_rect()\n",
    "            \n",
    "            textRect.center = (squareSize*(w+0.5), squareSize*(h+0.5) + topMargin)\n",
    "            gameDisplay.blit(text, textRect)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
