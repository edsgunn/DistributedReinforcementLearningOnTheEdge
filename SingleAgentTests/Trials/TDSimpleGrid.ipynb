{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 78\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 79\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 80\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 81\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 82\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 83\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 1, Actual action: 1\n",
      "Step: 84\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 85\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 86\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 87\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 88\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 89\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 90\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 3, Actual action: 3\n",
      "Step: 91\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 92\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 93\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 94\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 95\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 96\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 97\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 98\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 99\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 100\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 101\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 102\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 103\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 104\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 105\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 106\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 107\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 108\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 109\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 110\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 111\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 112\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 113\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 114\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 115\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 116\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 117\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 118\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 119\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 120\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 121\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 122\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 123\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 124\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 125\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 126\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 127\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 128\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 129\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 130\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 131\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 132\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 133\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 134\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 135\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 136\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 137\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 138\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 139\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.99, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 140\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 141\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 142\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 143\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 144\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 145\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 146\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 147\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 148\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 149\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 150\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 151\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 152\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 153\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 154\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 155\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 156\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "Step: 157\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 158\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 159\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-0.99 -0.9 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.9 -0.9 -0.9 -0.9 -0.9 \n",
      "0 0 0 0 0.0 \n",
      "0 0 0 0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -0.9}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-1.719 -0.99 -0.99 -0.99 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.99 -0.99 \n",
      "-0.99 -0.99 -0.9 -0.9 -0.9 \n",
      "-0.9 -0.9 0 0 0.0 \n",
      "0 0 0 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.7280000000000002, 2: -1.8009, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.99, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.99, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.9, 2: -0.9, 3: -0.9, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-1.8009 -1.7919 -0.99 -0.99 -0.99 \n",
      "-1.719 -1.719 -1.719 -0.99 -0.99 \n",
      "-0.99 -1.719 -0.99 -0.9 -0.9 \n",
      "-0.99 -0.99 -0.9 -0.9 0.0 \n",
      "-0.99 -0.9 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -1.8009, 2: -1.8009, 3: -1.7919, 4: -1.8738000000000001}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -1.8009, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -1.8009, 2: -1.8009, 3: -2.537919, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -1.8009, 2: -1.8009, 3: -2.537919, 4: -1.8738000000000001}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.538819, 1: -1.8009, 2: -1.8009, 3: -2.537919, 4: -1.8738000000000001}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.8009, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -0.99, 4: -1.719}, Best action: 3, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.99, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8009, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.351439, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-1.88199 -1.8009 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.7919 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -0.99 -0.9 0.0 \n",
      "-1.719 -0.99 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.46519, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.46519, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.46519, 2: -1.719, 3: -2.39868, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.538819, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.538819, 3: -3.1499568000000004, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -1.8009, 3: -2.537919, 4: -1.8738000000000001}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.537919, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.537919, 4: -1.8738000000000001}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.537919, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.598687, 2: -2.4724800000000005, 3: -2.537919, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.46429, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -3.0679749000000003, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.719, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -0.99, 3: -1.719, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.589678, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -1.8009, 3: -2.5306290000000002, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -3.0679749000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.589678, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.589678, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.589678, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.46429, 3: -3.0679749000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.351439, 3: -2.4244119, 4: 0}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-2.5389090000000003 -2.537919 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.46519 -2.46519 -2.46519 -1.8738000000000001 -1.719 \n",
      "-1.719 -1.719 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -0.99 -0.9 0.0 \n",
      "-1.719 -0.99 -0.9 0.0 0 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -2.5389090000000003, 2: -2.6126109, 3: -3.27143907, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.46519, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -1.719, 3: -2.39868, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.719, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: 0.0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -1.7019, 1: -1.7019, 2: -2.351439, 3: -2.4244119, 4: -2.95651629}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.546109 -2.537919 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.4724800000000005 -2.46519 -2.46519 -1.8738000000000001 -1.719 \n",
      "-1.719 -1.7919 -1.719 -1.719 -0.99 \n",
      "-1.719 -1.719 -0.99 -0.9 0.0 \n",
      "-1.719 -0.99 -0.9 0 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1506948, 2: -2.6126109, 3: -3.27143907, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1506948, 2: -2.6126109, 3: -3.27143907, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1506948, 2: -2.6126109, 3: -3.27143907, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.598687, 2: -2.5396380000000005, 3: -2.537919, 4: -3.1632246000000004}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.1506948, 2: -3.2169754800000003, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5389090000000003, 2: -2.664207, 3: -3.1499568000000004, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.46429, 3: -2.39868, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.46429, 3: -2.39868, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.46429, 3: -2.39868, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.46429, 3: -2.39868, 4: -3.0893598000000004}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.46429, 3: -3.0827988, 4: -3.0893598000000004}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.46519, 2: -2.597868, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.46429, 3: -2.4724800000000005, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.719, 3: -2.4724800000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.70919, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.70919, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -0.99, 2: -1.378539, 3: -1.70919, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.9, 3: -0.9, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: 0.0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.1325382900000003, 1: -1.7019, 2: -2.351439, 3: -2.4244119, 4: -2.95651629}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-3.15806499 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.546109 -2.46519 -2.46519 -1.8738000000000001 -1.719 \n",
      "-2.5389090000000003 -2.46429 -1.719 -1.719 -0.99 \n",
      "-1.8738000000000001 -1.7919 -0.99 -0.9 0 \n",
      "-1.719 -1.7919 -0.9999 -0.99 -1.7019 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5462809, 2: -2.664207, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5462809, 2: -2.664207, 3: -3.27151197, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -2.5462809, 2: -2.664207, 3: -3.27151197, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.5389090000000003, 2: -2.597868, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.6716689000000002, 2: -2.597868, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -2.46519, 2: -2.538819, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.46519, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -2.46429, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -0.9, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.46519, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.46519, 2: -2.46429, 3: -2.4724800000000005, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.7280000000000002, 2: -1.7280000000000002, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -0.9999, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.378539, 3: -1.70919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -1.378539, 3: -1.70919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.8009, 2: -1.378539, 3: -1.70919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.1325382900000003, 1: -3.1325382900000003, 2: -2.351439, 3: -2.4244119, 4: -2.95651629}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-3.15806499 -2.5396380000000005 -2.4724800000000005 -1.8009 -1.719 \n",
      "-2.664207 -2.538819 -2.46519 -1.8738000000000001 -1.719 \n",
      "-2.6716689000000002 -2.538819 -1.8747 -1.719 -0.99 \n",
      "-2.46519 -2.46429 -1.7280000000000002 -0.99 0 \n",
      "-1.719 -1.7919 -1.719 -1.70919 -2.351439 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.598687, 2: -2.5396380000000005, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.4724800000000005, 3: -2.589678, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -1.8009, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -1.8009, 2: -2.4724800000000005, 3: -2.46429, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -1.719, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -1.8738000000000001, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.7280000000000002, 2: -2.4724800000000005, 3: -2.589678, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -0.99, 3: -1.7919, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.999, 2: -1.8009, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.9, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.99, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.1967065900000002, 2: -2.04251949, 3: -1.70919, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.88199, 2: -1.80189, 3: -2.3823900000000005, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.882719, 2: -1.7280000000000002, 3: -1.7919, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.3834439, 2: -0.99, 3: -2.3823900000000005, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: 0}, Best action: 4, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.99, 3: -1.7019, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.999, 3: -1.7019, 4: 0}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -0.9, 1: -1.378539, 2: -0.999, 3: -1.7019, 4: -0.9}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -0.9999, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -0.999, 3: -1.7019, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -0.999, 3: -1.7019, 4: -1.719}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -1.378539, 2: -1.8090899999999999, 3: -1.7019, 4: -1.719}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.1325382900000003, 1: -3.1325382900000003, 2: -3.1922506800000003, 3: -2.4244119, 4: -2.95651629}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-3.15806499 -2.598687 -2.589678 -2.4724800000000005 -1.88199 \n",
      "-2.664207 -2.538819 -2.46519 -2.46519 -1.8738000000000001 \n",
      "-2.6716689000000002 -2.538819 -1.8747 -1.719 -1.719 \n",
      "-2.46519 -2.46429 -1.7919 -1.719 -1.7019 \n",
      "-1.719 -1.7919 -1.719 -1.719 -2.4244119 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.2177782800000005, 2: -3.2169754800000003, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15806499, 1: -3.2177782800000005, 2: -3.2169754800000003, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7738391409000003, 1: -3.2177782800000005, 2: -3.2169754800000003, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.598687, 2: -3.1566726000000007, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1425939, 2: -2.538819, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.538819, 3: -3.0679749000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.8747, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.882719, 2: -1.8747, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.5979579999999998, 2: -2.538819, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.538909, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.665026, 2: -2.538819, 3: -3.0679749000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.46519, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.7280000000000002, 2: -1.8738000000000001, 3: -1.7919, 4: -2.46429}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.3834439, 2: -1.8009, 3: -2.3823900000000005, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.538909, 2: -2.46429, 3: -3.0759939000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -1.8738000000000001, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -1.80918, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.8747, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.88199, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -2.46429, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -2.4724800000000005, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.4724800000000005, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -1.8747, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80918, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80918, 2: -1.88928, 3: -1.7919, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80918, 2: -1.88928, 3: -1.7919, 4: -2.46429}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -2.4797700000000003, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -2.4724800000000005, 3: -2.589678, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.4798600000000004, 2: -3.1499568000000004, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -1.80918, 2: -1.88928, 3: -3.0752649, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.101627539, 2: -2.19752559, 3: -1.7019, 4: -1.719}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.3834439, 2: -1.8009, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.3834439, 2: -1.8009, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.3834439, 2: -1.8009, 3: -2.3823900000000005, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.101627539, 2: -2.19752559, 3: -2.4625800000000004, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.101627539, 2: -2.19752559, 3: -2.4625800000000004, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.799919, 1: -2.101627539, 2: -2.19752559, 3: -2.4625800000000004, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.459457, 2: -1.88928, 3: -3.0752649, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.459457, 2: -1.88928, 3: -3.0752649, 4: -2.597868}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.459457, 2: -2.6192448, 3: -3.0752649, 4: -2.597868}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.101627539, 2: -2.19752559, 3: -2.4625800000000004, 4: -2.60436339}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.1325382900000003, 1: -3.1325382900000003, 2: -3.1922506800000003, 3: -3.7004738319, 4: -2.95651629}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-3.2177782800000005 -2.6126109 -2.589678 -2.5306290000000002 -2.4724800000000005 \n",
      "-2.664207 -2.546109 -2.546109 -2.5389090000000003 -2.546109 \n",
      "-2.6716689000000002 -2.546109 -2.538909 -2.46519 -2.589678 \n",
      "-2.46519 -2.46519 -1.8747 -2.3823900000000005 -2.19752559 \n",
      "-1.719 -1.7919 -1.719 -1.719 -2.95651629 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.2177782800000005, 2: -3.326634018, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.2111443800000004, 2: -2.664207, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1425939, 2: -3.1506858, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1425939, 2: -3.1506858, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1425939, 2: -3.1506858, 3: -3.0752649, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1491378000000005, 1: -3.2111443800000004, 2: -3.2287689900000003, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.326634018, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.326634018, 3: -3.27143907, 4: -3.3379107479999996}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.326634018, 3: -3.8770095537, 4: -3.3379107479999996}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -3.21631209, 2: -3.1566726000000007, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6126109, 1: -3.21631209, 2: -3.1566726000000007, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.277475919, 1: -3.21631209, 2: -3.1566726000000007, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -2.589678, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.21631209, 2: -3.3133064400000003, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.21631209, 2: -3.3133064400000003, 3: -3.705854688, 4: -3.1632246000000004}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.21631209, 2: -3.3133064400000003, 3: -3.705854688, 4: -3.7785343860000005}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0900888000000006, 1: -3.1425939, 2: -3.1506858, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.724603137000001, 2: -3.3133064400000003, 3: -3.705854688, 4: -3.8830662315000004}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.721179726000001, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.721179726000001, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -2.605977, 3: -3.721179726000001, 4: -3.27069378}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -2.5306290000000002, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.1433229000000003, 2: -3.2104071900000006, 3: -3.721179726000001, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.665026, 2: -3.1506858, 3: -3.0679749000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.665026, 2: -3.1506858, 3: -3.0679749000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.665026, 2: -3.1506858, 3: -3.0679749000000003, 4: -3.21695919}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.721179726000001, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.721179726000001, 4: -3.337910748}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2766805800000003, 2: -3.2104071900000006, 3: -3.721179726000001, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -2.665026, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.5389090000000003, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.3834439, 2: -2.4724800000000005, 3: -2.3823900000000005, 4: -2.6051580000000003}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.882719, 2: -1.8747, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.3834439, 2: -2.4724800000000005, 3: -2.656746, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.719, 1: -2.1967065900000002, 2: -2.04251949, 3: -2.463309, 4: -1.719}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.53073439, 2: -2.4724800000000005, 3: -2.656746, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -2.19752559, 3: -2.4625800000000004, 4: -2.60436339}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -2.19752559, 3: -2.4625800000000004, 4: -2.60436339}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -2.8997482869, 3: -2.4625800000000004, 4: -2.60436339}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.53073439, 2: -2.9272437279, 3: -2.656746, 4: -2.6051580000000003}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.0762549000000003, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.589678, 1: -2.84826400659, 2: -3.15408465, 3: -3.0752649, 4: -2.597868}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6134218000000002, 2: -3.2236822800000002, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6134218000000002, 2: -3.2236822800000002, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6134218000000002, 2: -3.2236822800000002, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1506948, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1506948, 2: -3.1506858000000006, 3: -2.589678, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1506948, 2: -3.1506858000000006, 3: -2.589678, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -2.665026, 2: -3.1506858, 3: -3.0679749000000003, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.538909, 2: -2.664207, 3: -3.0759939000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -1.882719, 2: -3.018059559, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -1.80189, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -1.80189, 3: -2.3823900000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -1.80189, 3: -2.3823900000000005, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.1967065900000002, 2: -2.04251949, 3: -2.463309, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.1967065900000002, 2: -2.04251949, 3: -2.463309, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.1967065900000002, 2: -2.04251949, 3: -2.463309, 4: -2.46429}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.1325382900000003, 1: -3.1325382900000003, 2: -3.1922506800000003, 3: -3.7004738319, 4: -3.8020520358000005}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.3379107479999996 -3.3415086240000003 -3.2766805800000003 -3.1499568000000004 -2.4724800000000005 \n",
      "-3.2111443800000004 -3.1425939 -3.0679749000000003 -2.6117919 -2.6117919 \n",
      "-2.6716689000000002 -2.546109 -2.546109 -2.546109 -2.597868 \n",
      "-2.46519 -2.46519 -2.4806619000000003 -2.53073439 -2.60436339 \n",
      "-1.719 -1.7919 -1.88199 -2.1967065900000002 -3.1325382900000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.3488782308, 3: -3.98227450995, 4: -3.3379107479999996}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.3488782308, 3: -3.98227450995, 4: -3.3379107479999996}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.3488782308, 3: -3.98227450995, 4: -3.93749878068}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.724603137000001, 2: -3.3415086240000003, 3: -3.705854688, 4: -3.8830662315000004}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.2766805800000003, 2: -3.3312186990000003, 3: -3.721179726000001, 4: -3.337910748}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2230188899999996, 2: -3.1506858, 3: -3.0679749000000003, 4: -3.337247358}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.1425939, 2: -3.1506858, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.5979579999999998, 2: -3.1499568, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.5979579999999998, 2: -3.1499568, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -2.5979579999999998, 2: -3.1499568, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.46519, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8747, 3: -1.7919, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -1.719}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1.8738000000000001, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.46429}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.46519, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -1.88199, 2: -1.8738000000000001, 3: -2.4724800000000005, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -1.8747, 3: -2.4715800000000003, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -2.4725790000000005, 3: -2.3823900000000005, 4: -2.6059598999999998}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -1.88199, 2: -2.4725790000000005, 3: -2.3823900000000005, 4: -2.6059598999999998}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -2.6126109, 2: -2.4725790000000005, 3: -2.3823900000000005, 4: -2.6059598999999998}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.6118819, 3: -2.4715800000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -1.88199, 2: -2.6118819, 3: -2.4715800000000003, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.46429, 1: -2.6126109, 2: -2.6118819, 3: -2.4715800000000003, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.5979579999999998, 2: -2.4797700000000003, 3: -3.0752649, 4: -2.546109}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -2.4806619000000003, 2: -3.018059559, 3: -3.0752649, 4: -2.546109}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.4715800000000003, 1: -3.0909969900000003, 2: -2.4725790000000005, 3: -2.6626509, 4: -2.6059598999999998}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.523339, 1: -3.1500459900000006, 2: -3.018059559, 3: -3.0752649, 4: -2.546109}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.67889329, 2: -2.664207, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.67889329, 2: -2.664207, 3: -3.0759939000000003, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.67889329, 2: -2.664207, 3: -3.0759939000000003, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.0762549000000003, 2: -3.2456161800000003, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.0762549000000003, 2: -3.2456161800000003, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.0762549000000003, 2: -3.2456161800000003, 3: -3.0752649, 4: -3.21695919}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.67889329, 2: -3.2287689900000003, 3: -3.0759939000000003, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1500459900000006, 2: -3.018059559, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1500459900000006, 2: -3.018059559, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1500459900000006, 2: -3.018059559, 3: -3.0752649, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.53073439, 2: -2.9272437279, 3: -2.656746, 4: -2.6051580000000003}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.1967065900000002, 2: -2.7416079639000004, 3: -2.463309, 4: -2.8008697869000003}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.1967065900000002, 2: -2.7416079639000004, 3: -2.463309, 4: -2.8008697869000003}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -2.8990029969000006, 2: -2.7416079639000004, 3: -2.463309, 4: -2.8008697869000003}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -2.4725790000000005, 3: -2.6626509, 4: -2.6059598999999998}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -3.1851805896900003, 2: -2.7416079639000004, 3: -3.1491198900000006, 4: -2.8008697869000003}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -3.1325382900000003, 2: -3.1922506800000003, 3: -3.7004738319, 4: -3.8020520358000005}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-3.3797854980000004 -3.705854688 -3.3312186990000003 -3.1499568000000004 -2.4724800000000005 \n",
      "-3.2111443800000004 -3.1506858 -3.1506858 -2.6117919 -2.6117919 \n",
      "-2.6716689000000002 -3.0759939000000003 -3.0759939000000003 -3.0762549000000003 -2.597868 \n",
      "-2.4724800000000005 -2.546109 -3.0752649 -2.6051580000000003 -2.60436339 \n",
      "-1.88199 -2.4715800000000003 -2.6059598999999998 -2.8008697869000003 -3.1325382900000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.2111443800000004, 2: -3.2287689900000003, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -2.6716689000000002, 2: -3.1558617, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -2.664207, 3: -2.4724800000000005, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -2.664207, 3: -3.1499568000000004, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -2.664207, 3: -3.27734397, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -2.664207, 3: -3.27734397, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.5979579999999998, 2: -3.157313139, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.5979579999999998, 2: -3.157313139, 3: -3.0752649, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -2.5979579999999998, 2: -3.157313139, 3: -3.0752649, 4: -3.21695919}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -2.6118819, 3: -2.4715800000000003, 4: -2.546109}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -1.88199, 2: -2.605887, 3: -2.4724800000000005, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -1.88199, 2: -2.605887, 3: -2.4724800000000005, 4: -2.664207}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -2.6126109, 2: -2.605887, 3: -2.4724800000000005, 4: -2.664207}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -3.1639698900000006, 2: -2.605887, 3: -2.4724800000000005, 4: -2.664207}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -3.1639698900000006, 2: -2.605887, 3: -3.1499568000000004, 4: -2.664207}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -2.6118819, 3: -2.6715699, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -2.6118819, 3: -2.6715699, 4: -2.546109}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -2.6118819, 3: -2.6715699, 4: -3.21695919}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -3.3679603507590006, 3: -2.6626509, 4: -2.6059598999999998}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -3.3679603507590006, 3: -2.6626509, 4: -2.6059598999999998}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -3.3679603507590006, 3: -2.6626509, 4: -3.271423509}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -3.2720157089999997, 3: -2.6715699, 4: -3.337320258}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -3.1639698900000006, 2: -3.22293699, 3: -3.32576415, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -3.1639698900000006, 2: -3.22293699, 3: -3.32576415, 4: -2.664207}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0841839, 1: -3.1639698900000006, 2: -3.22293699, 3: -3.32576415, 4: -3.3244283700000006}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -2.664297, 2: -3.2287689900000003, 3: -3.27734397, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.1639698900000006, 2: -3.22293699, 3: -3.32576415, 4: -3.7306317960000004}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.1639698900000006, 2: -3.22293699, 3: -3.32576415, 4: -3.7306317960000004}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.779212599900001, 2: -3.22293699, 3: -3.32576415, 4: -3.7306317960000004}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.15733599, 2: -3.2720157089999997, 3: -3.3251646600000004, 4: -3.337320258}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1617756000000004, 2: -3.157313139, 3: -3.0752649, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19165308, 1: -3.7292453109000006, 2: -3.2287689900000003, 3: -3.27734397, 4: -3.3797035890000005}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0679749000000003, 1: -3.1698756900000005, 2: -3.1558617, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.2287689900000003, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.27660768, 2: -3.1506858, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2230188899999996, 2: -3.1506858, 3: -3.752298549, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -3.1506948, 2: -3.1506858000000006, 3: -3.31763886, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2230188900000005, 2: -3.1499568000000004, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -2.4724800000000005, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.1499568000000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -2.665755, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.27069378}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6117919, 1: -2.6134218000000002, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 0, Actual action: 0\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.1491378000000005, 4: -3.386330928}, Best action: 3, Actual action: 3\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2230188900000005, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1639698900000006, 1: -3.2230188900000005, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 0, Actual action: 0\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.779212599900001, 1: -3.2230188900000005, 2: -3.2177044800000005, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.15733599, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7731757509, 1: -3.2821269390000003, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -2.6134218000000002, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.84826400659, 2: -3.15408465, 3: -3.0752649, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.84826400659, 2: -3.15408465, 3: -3.0752649, 4: -2.597868}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -2.84826400659, 2: -3.15408465, 3: -3.0752649, 4: -3.26405988}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -3.18466462869, 3: -3.19016259, 4: -2.60436339}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -3.18466462869, 3: -3.19016259, 4: -2.60436339}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.6049409488000004, 2: -3.18466462869, 3: -3.19016259, 4: -3.2699706849}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -3.8142807768000004, 2: -3.1922506800000003, 3: -3.7004738319, 4: -3.8020520358000005}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-3.3797854980000004 -3.705854688 -3.3312186990000003 -3.2230188900000005 -3.3251736600000004 \n",
      "-3.27151197 -3.27660768 -3.2230188899999996 -3.1506858000000006 -3.22131609 \n",
      "-3.0893598000000004 -3.0759939000000003 -3.0759939000000003 -3.0762549000000003 -3.0752649 \n",
      "-3.2287689900000003 -3.157313139 -3.0752649 -2.6051580000000003 -2.6103087 \n",
      "-3.32576415 -3.15733599 -3.0909969900000003 -2.8008697869000003 -3.1922506800000003 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.724603137000001, 2: -3.8882621322000004, 3: -3.705854688, 4: -3.8830662315000004}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.3797854980000004, 2: -3.9415098085199998, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.774932397, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.774932397, 3: -3.27151197, 4: -3.2841834480000003}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.774932397, 3: -3.8770758927, 4: -3.2841834480000003}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.774932397, 3: -3.9478961821500005, 4: -3.2841834480000003}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.3851662470000004, 2: -3.774932397, 3: -3.9478961821500005, 4: -3.8886069376800005}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.1698756900000005, 2: -3.1558617, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.1698756900000005, 2: -3.1558617, 3: -3.20435478, 4: -3.0893598000000004}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.1698756900000005, 2: -3.1558617, 3: -3.20435478, 4: -3.7113174180000006}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -3.1565997, 2: -3.1499568, 3: -3.0759939000000003, 4: -3.326041899}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.1698756900000005, 2: -3.7071412290000003, 3: -3.20435478, 4: -3.8273797188}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.2287689900000003, 3: -3.27734397, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1617756000000004, 2: -3.157313139, 3: -3.7927654848, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1500459900000006, 2: -3.2517008118, 3: -3.0752649, 4: -3.66632416179}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.1617756000000004, 2: -3.7066958829, 3: -3.7927654848, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.15733599, 2: -3.2720157089999997, 3: -3.3251646600000004, 4: -3.337320258}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.15733599, 2: -3.2720157089999997, 3: -3.3251646600000004, 4: -3.337320258}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.7731757509, 2: -3.2720157089999997, 3: -3.3251646600000004, 4: -3.337320258}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -3.3679603507590006, 3: -3.3302367090000002, 4: -3.3838895799}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.0909969900000003, 2: -3.3679603507590006, 3: -3.3302367090000002, 4: -3.3838895799}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.19106259, 1: -3.7128072609000005, 2: -3.3679603507590006, 3: -3.3302367090000002, 4: -3.3838895799}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.1500459900000006, 2: -3.2517008118, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.3679603507590006, 3: -3.3302367090000002, 4: -3.3838895799}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.9276502993799998, 2: -3.7309091328000004, 3: -3.3251646600000004, 4: -3.337320258}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.88850022189, 2: -3.777878286, 3: -3.32576415, 4: -3.7306317960000004}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.88850022189, 2: -3.777878286, 3: -3.32576415, 4: -3.7306317960000004}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.3664989600000004, 1: -3.88850022189, 2: -3.777878286, 3: -3.9264453765, 4: -3.7306317960000004}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -3.27734397, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -3.27734397, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -3.8823830127, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -4.02579820836, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.704224977, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -4.02579820836, 4: -3.9755302659900003}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.8322904509000004, 2: -3.7071412290000003, 3: -3.20435478, 4: -3.8273797188}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.8322904509000004, 2: -3.7071412290000003, 3: -3.20435478, 4: -3.8273797188}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.8322904509000004, 2: -3.7071412290000003, 3: -3.8159628498, 4: -3.8273797188}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1432329, 1: -3.1565997, 2: -3.1499568, 3: -3.7751986989000006, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.27660768, 2: -3.767124078, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.1565997, 2: -3.1499568, 3: -3.7751986989000006, 4: -3.326041899}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.230237619, 2: -3.2287689900000003, 3: -3.0759939000000003, 4: -3.3797035890000005}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.1565997, 2: -3.7065507390000003, 3: -3.7751986989000006, 4: -3.326041899}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.7736197119, 2: -3.7066958829, 3: -3.7927654848, 4: -3.326041899}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.8099866059000003, 2: -3.7065507390000003, 3: -3.7751986989000006, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.8099866059000003, 2: -3.7065507390000003, 3: -3.7751986989000006, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.8099866059000003, 2: -3.7065507390000003, 3: -3.7751986989000006, 4: -3.92669812809}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.20287239, 1: -3.230237619, 2: -3.2287689900000003, 3: -3.764445147, 4: -3.3797035890000005}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.2230188899999996, 2: -3.330620019, 3: -3.752298549, 4: -3.337247358}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.230237619, 2: -3.2287689900000003, 3: -3.764445147, 4: -3.3797035890000005}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.0762549000000003, 2: -3.2456161800000003, 3: -3.3774300549, 4: -3.712660488}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.9324057769000005, 2: -2.9272437279, 3: -2.656746, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.9324057769000005, 2: -2.9272437279, 3: -2.656746, 4: -2.6051580000000003}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.9324057769000005, 2: -2.9272437279, 3: -2.656746, 4: -3.27069378}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.21468219, 1: -3.9124963332900005, 2: -3.2517008118, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.230237619, 2: -3.7146433680000004, 3: -3.764445147, 4: -3.3797035890000005}, Best action: 1, Actual action: 1\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -3.2517008118, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.9324057769000005, 2: -2.9272437279, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 2, Actual action: 2\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2.6103087, 1: -2.8462171456800003, 2: -3.18466462869, 3: -3.19016259, 4: -3.3369992370180004}, Best action: 0, Actual action: 0\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.294360746559, 2: -3.15408465, 3: -3.0752649, 4: -3.5334998333379}, Best action: 3, Actual action: 3\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1550427, 1: -3.3178034700000003, 2: -3.2456161800000003, 3: -3.3774300549, 4: -3.712660488}, Best action: 0, Actual action: 0\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.1506948, 2: -3.1506858000000006, 3: -3.31763886, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.26561526, 2: -3.2236822800000002, 3: -3.22131609, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.1506948, 2: -3.8243346129000004, 3: -3.31763886, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3178034700000003, 2: -3.2456161800000003, 3: -3.3774300549, 4: -3.712660488}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.294360746559, 2: -3.15408465, 3: -3.763111077, 4: -3.5334998333379}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.294360746559, 2: -3.15408465, 3: -3.763111077, 4: -3.5334998333379}, Best action: 2, Actual action: 2\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.22131609, 1: -3.294360746559, 2: -3.7702170315, 3: -3.763111077, 4: -3.5334998333379}, Best action: 0, Actual action: 0\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.26561526, 2: -3.2236822800000002, 3: -3.774194397, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.26561526, 2: -3.2236822800000002, 3: -3.774194397, 4: -3.3193350990000003}, Best action: 2, Actual action: 2\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.26561526, 2: -3.8335508748000002, 3: -3.774194397, 4: -3.3193350990000003}, Best action: 1, Actual action: 1\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.294360746559, 2: -3.8862877360500003, 3: -3.763111077, 4: -3.5334998333379}, Best action: 1, Actual action: 1\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -2.8462171456800003, 2: -3.18466462869, 3: -3.19016259, 4: -3.3369992370180004}, Best action: 1, Actual action: 1\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -3.8142807768000004, 2: -4.220967365280001, 3: -3.7004738319, 4: -3.8020520358000005}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-3.8831340528900005 -3.724603137000001 -3.3312186990000003 -3.2230188900000005 -3.3251736600000004 \n",
      "-3.740898062700001 -3.712660488 -3.330620019 -3.31763886 -3.3193350990000003 \n",
      "-3.8167327719000004 -3.7751986989000006 -3.3797035890000005 -3.3178034700000003 -3.5334998333379 \n",
      "-3.7292453109000006 -3.326041899 -3.596237500779 -2.9324057769000005 -3.18466462869 \n",
      "-3.7306317960000004 -3.337320258 -3.3679603507590006 -2.8008697869000003 -3.7004738319 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.8879032455, 2: -3.9415098085199998, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8831340528900005, 1: -3.8879032455, 2: -3.9415098085199998, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.433651988129901, 1: -3.8879032455, 2: -3.9415098085199998, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -3.740898062700001, 2: -3.774932397, 3: -3.9478961821500005, 4: -4.030845353838}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.8322904509000004, 2: -3.8167327719000004, 3: -4.28438068047, 4: -3.8273797188}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.8099866059000003, 2: -3.8649817098000003, 3: -3.7751986989000006, 4: -4.294975911399001}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8221003719000004, 1: -3.8322904509000004, 2: -4.339584223299001, 3: -4.28438068047, 4: -3.8273797188}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -4.365643351509, 2: -3.774932397, 3: -3.9478961821500005, 4: -4.030845353838}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.779125776, 2: -3.767124078, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.779125776, 2: -3.767124078, 3: -3.7583281080000006, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.779125776, 2: -3.767124078, 3: -3.7583281080000006, 4: -4.27852104408}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8647794267, 1: -4.365643351509, 2: -4.28474823498, 3: -3.9478961821500005, 4: -4.030845353838}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -3.9415098085199998, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -3.724603137000001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -3.8830662315000004}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.779125776, 2: -3.767124078, 3: -4.406304146427, 4: -4.372097871888}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8376047709, 2: -3.330620019, 3: -3.752298549, 4: -3.337247358}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.8440185858, 2: -3.8243346129000004, 3: -3.31763886, 4: -3.3193350990000003}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8376047709, 2: -3.9203494785000004, 3: -3.752298549, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8376047709, 2: -3.9203494785000004, 3: -3.752298549, 4: -3.337247358}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.723994800900001, 1: -3.8376047709, 2: -3.9203494785000004, 3: -3.752298549, 4: -3.93689509578}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.7127277270000003, 2: -3.3312186990000003, 3: -3.721179726000001, 4: -3.337910748}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.2230188900000005, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.8440185858, 2: -3.8243346129000004, 3: -3.93493424598, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.8440185858, 2: -3.8243346129000004, 3: -3.93493424598, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7126441980000005, 1: -3.8440185858, 2: -3.8243346129000004, 3: -3.93493424598, 4: -3.9205949400900004}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.385740438}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.7792125999, 3: -3.6991544490000003, 4: -3.98102379858}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.7127277270000003, 2: -3.8437671708000005, 3: -3.721179726000001, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.7127277270000003, 2: -3.8437671708000005, 3: -3.721179726000001, 4: -3.337910748}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -3.7127277270000003, 2: -3.8437671708000005, 3: -3.721179726000001, 4: -3.93749878068}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -3.8376047709, 2: -3.9203494785000004, 3: -3.752298549, 4: -4.310125298307001}, Best action: 3, Actual action: 3\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -3.779125776, 2: -3.9745146231899997, 3: -4.406304146427, 4: -4.372097871888}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.8099866059000003, 2: -3.8649817098000003, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.7736197119, 2: -3.7066958829, 3: -3.7927654848, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.7736197119, 2: -3.7066958829, 3: -3.7927654848, 4: -3.326041899}, Best action: 4, Actual action: 4\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.7736197119, 2: -3.7066958829, 3: -3.7927654848, 4: -3.92669812809}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -3.596237500779, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -2.9324057769000005, 2: -3.30707441979, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -3.1851805896900003, 2: -2.8115168112900006, 3: -3.1491198900000006, 4: -2.8008697869000003}, Best action: 4, Actual action: 4\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -3.1851805896900003, 2: -2.8115168112900006, 3: -3.1491198900000006, 4: -2.8008697869000003}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -3.1851805896900003, 2: -2.8115168112900006, 3: -3.1491198900000006, 4: -3.4487915060790004}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -3.8142807768000004, 2: -4.220967365280001, 3: -4.415385966030901, 4: -3.8020520358000005}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-3.98227450995 -3.7846523979000004 -3.721179726000001 -3.7792125999 -3.3251736600000004 \n",
      "-3.9478961821500005 -3.8927870964 -3.8376047709 -3.8243346129000004 -3.3193350990000003 \n",
      "-3.8273797188 -3.8649817098000003 -3.3797035890000005 -3.3178034700000003 -3.5334998333379 \n",
      "-3.7292453109000006 -3.7736197119 -3.634872429366901 -3.1609476 -3.18466462869 \n",
      "-3.7306317960000004 -3.337320258 -3.3679603507590006 -3.0746088000000005 -3.8020520358000005 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.311079521822001, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.311079521822001, 3: -3.98227450995, 4: -4.006341245015999}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.311079521822001, 3: -4.5238698040545, 4: -4.006341245015999}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.311079521822001, 3: -4.597523388868409, 4: -4.006341245015999}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.311079521822001, 3: -4.597523388868409, 4: -4.545770532964559}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -4.323830816880001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -3.8830662315000004}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7846523979000004, 1: -4.323830816880001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -3.8830662315000004}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.344033682089001, 1: -4.323830816880001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -3.8830662315000004}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.323830816880001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -3.8830662315000004}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.323830816880001, 2: -3.8882621322000004, 3: -4.00821172218, 4: -4.433590270665}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.31063459739, 2: -3.8437671708000005, 3: -3.721179726000001, 4: -4.301059336938001}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.323830816880001, 2: -4.302981791280001, 3: -4.00821172218, 4: -4.492851354148501}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.318917755337001, 2: -4.396676394481201, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.28474823498, 3: -3.9478961821500005, 4: -4.030845353838}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.28474823498, 3: -3.9478961821500005, 4: -4.030845353838}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.28474823498, 3: -4.492585525756501, 4: -4.030845353838}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.28474823498, 3: -4.614243289184431, 4: -4.030845353838}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.28474823498, 3: -4.614243289184431, 4: -4.568069271992581}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8927870964, 1: -4.364001728379, 2: -3.9745146231899997, 3: -4.406304146427, 4: -4.372097871888}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.323830816880001, 2: -4.302981791280001, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.31063459739, 2: -3.8437671708000005, 3: -4.5187694675658, 4: -4.301059336938001}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.7792125999, 3: -3.97362315078, 4: -4.294417483548}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3450843519000006, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3450843519000006, 2: -3.3251736600000004, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.3450843519000006, 2: -3.9259080306000005, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.89499373071279, 2: -3.9285034480800003, 3: -3.774194397, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.89499373071279, 2: -3.9285034480800003, 3: -3.774194397, 4: -3.3193350990000003}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7119808080000007, 1: -3.89499373071279, 2: -3.9285034480800003, 3: -3.774194397, 4: -3.9205949400900004}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.9231698653800007, 2: -4.002109128099001, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.9231698653800007, 2: -4.002109128099001, 3: -3.7777293909000007, 4: -3.386330928}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.9231698653800007, 2: -4.002109128099001, 3: -3.7777293909000007, 4: -3.98156114448}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.9713119245900006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8842618887900007, 1: -3.9109633191900004, 2: -3.9713119245900006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.434678318798901, 1: -3.9109633191900004, 2: -3.9713119245900006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.8440185858, 2: -3.8243346129000004, 3: -3.93493424598, 4: -4.299301294389}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01412613248, 1: -3.89499373071279, 2: -3.9285034480800003, 3: -3.774194397, 4: -4.298763948489}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.8440185858, 2: -4.33953092286, 3: -3.93493424598, 4: -4.299301294389}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.3178034700000003, 2: -3.7793701845000003, 3: -3.3774300549, 4: -3.712660488}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.1609476, 1: -3.461945105079, 2: -3.30707441979, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.792147903, 2: -3.7793701845000003, 3: -3.3774300549, 4: -3.712660488}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.856901419458, 2: -3.7146433680000004, 3: -3.764445147, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.856901419458, 2: -3.7146433680000004, 3: -3.764445147, 4: -3.3797035890000005}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.856901419458, 2: -3.7146433680000004, 3: -3.764445147, 4: -3.9755302659900003}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.792147903, 2: -3.7793701845000003, 3: -3.97530291258, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.792147903, 2: -3.7793701845000003, 3: -3.97530291258, 4: -3.712660488}, Best action: 4, Actual action: 4\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7675597680000004, 1: -3.792147903, 2: -3.7793701845000003, 3: -3.97530291258, 4: -4.27852104408}, Best action: 0, Actual action: 0\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9718226692800003, 2: -4.33953092286, 3: -3.93493424598, 4: -4.299301294389}, Best action: 3, Actual action: 3\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -3.8376047709, 2: -3.9203494785000004, 3: -4.33632173346, 4: -4.310125298307001}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.856901419458, 2: -4.2787193320800005, 3: -3.764445147, 4: -4.3064141546790005}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.97509259878, 2: -3.8649817098000003, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8309325399, 1: -3.856901419458, 2: -4.2787193320800005, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 0, Actual action: 0\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.33296104616, 2: -3.9203494785000004, 3: -4.33632173346, 4: -4.310125298307001}, Best action: 2, Actual action: 2\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -3.9718226692800003, 2: -4.33953092286, 3: -4.401953289027, 4: -4.299301294389}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -3.792147903, 2: -3.7793701845000003, 3: -3.97530291258, 4: -4.379575516488}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.5348719626567005, 2: -3.8862877360500003, 3: -3.763111077, 4: -3.5334998333379}, Best action: 4, Actual action: 4\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.5348719626567005, 2: -3.8862877360500003, 3: -3.763111077, 4: -3.5334998333379}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.5348719626567005, 2: -3.8862877360500003, 3: -3.763111077, 4: -4.115484848337489}, Best action: 1, Actual action: 1\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.2820055184070003, 2: -3.18466462869, 3: -3.19016259, 4: -3.3369992370180004}, Best action: 2, Actual action: 2\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.2820055184070003, 2: -3.18466462869, 3: -3.19016259, 4: -3.3369992370180004}, Best action: 2, Actual action: 2\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.2820055184070003, 2: -3.7980448121079005, 3: -3.19016259, 4: -3.3369992370180004}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.461945105079, 2: -3.30707441979, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 2, Actual action: 2\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.2820055184070003, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -3.3369992370180004}, Best action: 1, Actual action: 1\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -3.8142807768000004, 2: -4.220967365280001, 3: -4.415385966030901, 4: -4.5058475566395}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-4.396676394481201 -4.323830816880001 -3.8783510838900006 -3.9713119245900006 -3.9231698653800007 \n",
      "-4.365643351509 -3.9745146231899997 -3.9706866262800005 -4.01371417458 -3.89499373071279 \n",
      "-3.8273797188 -3.8683755108000004 -3.856901419458 -3.792147903 -3.763111077 \n",
      "-3.7292453109000006 -3.7736197119 -3.634872429366901 -3.379033638 -3.3369992370180004 \n",
      "-3.7306317960000004 -3.337320258 -3.3679603507590006 -3.0746088000000005 -3.8142807768000004 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.365643351509, 2: -4.481632371582, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -3.8322904509000004, 2: -4.339584223299001, 3: -4.28438068047, 4: -3.8273797188}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -3.8322904509000004, 2: -4.339584223299001, 3: -4.28438068047, 4: -3.8273797188}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -3.8322904509000004, 2: -4.339584223299001, 3: -4.28438068047, 4: -4.382915544108}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8659498695, 1: -3.7292453109000006, 2: -3.7803005415900004, 3: -4.02579820836, 4: -4.297975257969}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -3.88850022189, 2: -3.777878286, 3: -4.019508695250001, 4: -3.7306317960000004}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -3.88850022189, 2: -3.777878286, 3: -4.019508695250001, 4: -3.7306317960000004}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -3.88850022189, 2: -3.777878286, 3: -4.019508695250001, 4: -4.29487493436}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.9276502993799998, 2: -3.7309091328000004, 3: -3.9263854274999996, 4: -3.337320258}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.9276502993799998, 2: -3.7309091328000004, 3: -3.9263854274999996, 4: -3.337320258}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7064688390000002, 1: -3.9276502993799998, 2: -3.7309091328000004, 3: -3.9263854274999996, 4: -3.93696143478}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -3.7736197119, 2: -4.18362196392099, 3: -3.7927654848, 4: -4.295093477958001}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -3.9276502993799998, 2: -3.7309091328000004, 3: -3.9263854274999996, 4: -4.295935903068}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.3679603507590006, 3: -3.9264070455000004, 4: -3.3838895799}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.0746088000000005, 1: -3.1851805896900003, 2: -3.3608138301270003, 3: -3.1491198900000006, 4: -3.5222077677528008}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.461945105079, 2: -3.8891319118886702, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.461945105079, 2: -3.8891319118886702, 3: -3.7695671739000005, 4: -3.379033638}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.461945105079, 2: -3.8891319118886702, 3: -3.7695671739000005, 4: -3.9749206105800003}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -3.1851805896900003, 2: -3.3608138301270003, 3: -3.1491198900000006, 4: -3.5222077677528008}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.7272291630759007, 3: -3.9264070455000004, 4: -3.3838895799}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.7272291630759007, 3: -3.9264070455000004, 4: -3.3838895799}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.7272291630759007, 3: -3.9264070455000004, 4: -3.9793395177089996}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -3.1851805896900003, 2: -3.3608138301270003, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -3.1851805896900003, 2: -3.3608138301270003, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -3.7985143366179, 2: -3.3608138301270003, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -3.91696153488, 1: -4.817599192402291, 2: -4.220967365280001, 3: -4.415385966030901, 4: -4.5058475566395}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.396676394481201 -4.323830816880001 -3.8783510838900006 -3.9713119245900006 -3.9231698653800007 \n",
      "-4.4367419073789005 -3.9745146231899997 -3.9706866262800005 -4.01371417458 -3.89499373071279 \n",
      "-4.28438068047 -3.8683755108000004 -3.856901419458 -3.792147903 -3.763111077 \n",
      "-3.7803005415900004 -3.7927654848 -3.634872429366901 -3.7695671739000005 -3.3369992370180004 \n",
      "-3.88850022189 -3.9263854274999996 -3.7706435109000007 -3.5088202262654997 -3.91696153488 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.529687683075201, 2: -4.396676394481201, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.323830816880001, 2: -4.443749587476001, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.364001728379, 2: -3.9745146231899997, 3: -4.406304146427, 4: -4.372097871888}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9706866262800005, 1: -4.33296104616, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.310125298307001}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.31063459739, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.301059336938001}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8783510838900006, 1: -4.31063459739, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.301059336938001}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.429299486339901, 1: -4.31063459739, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.301059336938001}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.31063459739, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.301059336938001}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.31063459739, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.81396399661358}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.33296104616, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.310125298307001}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.33296104616, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.310125298307001}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.33296104616, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.82221402145937}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -3.856901419458, 2: -4.2787193320800005, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -3.634872429366901, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.7969816214079004, 2: -3.8891319118886702, 3: -3.7695671739000005, 4: -4.10166759617199}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -4.316836653795691, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -4.316836653795691, 3: -3.7685647260000006, 4: -3.66632416179}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -4.316836653795691, 3: -3.7685647260000006, 4: -4.2363549872289}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -4.299398368758, 2: -4.18362196392099, 3: -3.7927654848, 4: -4.295093477958001}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8659498695, 1: -4.29473628585, 2: -3.7803005415900004, 3: -4.02579820836, 4: -4.297975257969}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9143811771899997, 1: -4.299398368758, 2: -4.18362196392099, 3: -4.3413199871679, 4: -4.295093477958001}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8683755108000004, 1: -3.97509259878, 2: -4.3895535282989995, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.364001728379, 2: -4.5137076296058005, 3: -4.406304146427, 4: -4.372097871888}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -3.97509259878, 2: -4.3895535282989995, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.299398368758, 2: -4.18362196392099, 3: -4.3413199871679, 4: -4.295093477958001}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.83796069039, 1: -3.9124963332900005, 2: -4.316836653795691, 3: -4.348996515288, 4: -4.376172926782891}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.2299368097329895, 2: -4.2787193320800005, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -3.9124963332900005, 2: -4.316836653795691, 3: -4.348996515288, 4: -4.376172926782891}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.7706435109000007, 1: -3.8560414239900003, 2: -3.8527191939564904, 3: -3.9264070455000004, 4: -4.31698957386238}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.345470877158001, 2: -4.316836653795691, 3: -4.348996515288, 4: -4.376172926782891}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.951813104469, 1: -3.7969816214079004, 2: -3.8891319118886702, 3: -4.2466792884399, 4: -4.10166759617199}, Best action: 1, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -3.792147903, 2: -4.1400718834536985, 3: -3.97530291258, 4: -4.379575516488}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -3.7969816214079004, 2: -3.8891319118886702, 3: -4.2466792884399, 4: -4.10166759617199}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -3.5088202262654997, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853004033017774, 1: -4.817599192402291, 2: -4.220967365280001, 3: -4.415385966030901, 4: -4.5058475566395}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-4.49256682766799 -4.443749587476001 -4.345538922999 -3.9713119245900006 -3.9231698653800007 \n",
      "-4.4367419073789005 -4.372097871888 -4.33632173346 -4.01371417458 -3.89499373071279 \n",
      "-4.28438068047 -4.294975911399001 -4.2787193320800005 -3.97530291258 -3.763111077 \n",
      "-3.8659498695 -4.295093477958001 -4.345470877158001 -3.8891319118886702 -3.3369992370180004 \n",
      "-3.88850022189 -3.9263854274999996 -3.8527191939564904 -3.5222077677528008 -4.220967365280001 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.5517399264719, 2: -4.443749587476001, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.8222649513676705, 2: -4.345538922999, 3: -4.5187694675658, 4: -4.873010423547258}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.388807368368001, 2: -3.9713119245900006, 3: -3.97362315078, 4: -4.294417483548}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -3.9231698653800007, 2: -4.002109128099001, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01412613248, 1: -3.89499373071279, 2: -3.9285034480800003, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.8330655455045703, 2: -3.8862877360500003, 3: -3.763111077, 4: -4.174794774585676}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.3547699036404, 2: -4.1400718834536985, 3: -3.97530291258, 4: -4.379575516488}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.4921157109382, 2: -4.2787193320800005, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.3547699036404, 2: -4.1400718834536985, 3: -4.7632929502428, 4: -4.379575516488}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.8330655455045703, 2: -3.8862877360500003, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.4177679810487005, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -3.3369992370180004}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.4177679810487005, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -3.3369992370180004}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.4177679810487005, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -3.93666930568638}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853004033017774, 1: -4.817599192402291, 2: -4.92153390238356, 3: -4.415385966030901, 4: -4.5058475566395}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-4.49256682766799 -4.4796870157239 -4.5187694675658 -3.97362315078 -3.9358403956800005 \n",
      "-4.4367419073789005 -4.372097871888 -4.33632173346 -4.01371417458 -3.9285034480800003 \n",
      "-4.28438068047 -4.294975911399001 -4.3064141546790005 -4.3547699036404 -3.8333142558000004 \n",
      "-3.8659498695 -4.295093477958001 -4.345470877158001 -3.8891319118886702 -3.6519954390000002 \n",
      "-3.88850022189 -3.9263854274999996 -3.8527191939564904 -3.5222077677528008 -4.415385966030901 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.529687683075201, 2: -4.841970601120921, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.49256682766799, 1: -4.529687683075201, 2: -4.841970601120921, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.988235813177871, 1: -4.529687683075201, 2: -4.841970601120921, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.4367419073789005, 2: -4.481632371582, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -4.303917746919001, 2: -4.339584223299001, 3: -4.28438068047, 4: -4.442446819639801}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -4.303917746919001, 2: -4.339584223299001, 3: -4.28438068047, 4: -4.442446819639801}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -4.303917746919001, 2: -4.339584223299001, 3: -4.7987864192277, 4: -4.442446819639801}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8659498695, 1: -4.29473628585, 2: -4.4486788076829, 3: -4.02579820836, 4: -4.297975257969}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -4.4618111689869, 2: -4.339584223299001, 3: -4.866052016927161, 4: -4.442446819639801}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.686243050654001, 2: -4.3895535282989995, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.686243050654001, 2: -4.3895535282989995, 3: -4.373421171129, 4: -4.294975911399001}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.686243050654001, 2: -4.3895535282989995, 3: -4.373421171129, 4: -4.8084280793730905}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.33990527876, 1: -4.4618111689869, 2: -4.812888910563091, 3: -4.866052016927161, 4: -4.442446819639801}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4791008875711995, 1: -4.8140225419185905, 2: -4.481632371582, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -4.841970601120921, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -4.841970601120921, 3: -4.597523388868409, 4: -4.8465514659722775}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -4.841970601120921, 3: -5.083746283870252, 4: -4.8465514659722775}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.5517399264719, 2: -4.86426148637679, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.4796870157239, 1: -4.5517399264719, 2: -4.86426148637679, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.976515184308749, 1: -4.5517399264719, 2: -4.86426148637679, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -4.5517399264719, 2: -4.86426148637679, 3: -4.799144554040971, 4: -4.492851354148501}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -4.5517399264719, 2: -4.86426148637679, 3: -4.799144554040971, 4: -4.988494732275136}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.556225177849701, 2: -4.5137076296058005, 3: -4.406304146427, 4: -4.372097871888}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.556225177849701, 2: -4.5137076296058005, 3: -4.406304146427, 4: -4.372097871888}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.556225177849701, 2: -4.5137076296058005, 3: -4.406304146427, 4: -4.87860906341808}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.8140225419185905, 2: -4.481632371582, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.556225177849701, 2: -4.5137076296058005, 3: -4.9707526356241205, 4: -4.956967264947678}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.45738625437698, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.891919849535538}, Best action: 3, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.4921157109382, 2: -4.681330158805496, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.4921157109382, 2: -4.681330158805496, 3: -4.407079699638, 4: -4.3064141546790005}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.4921157109382, 2: -4.681330158805496, 3: -4.407079699638, 4: -4.818836880757891}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.686243050654001, 2: -4.3895535282989995, 3: -4.8526653929084995, 4: -4.9233139565518}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.458576331575, 1: -4.4921157109382, 2: -4.681330158805496, 3: -4.89624632788599, 4: -4.95161824478257}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.833934090727689, 2: -4.5092113099668, 3: -4.33632173346, 4: -4.891919849535538}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -4.556225177849701, 2: -4.961853629005935, 3: -4.9707526356241205, 4: -4.956967264947678}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.686243050654001, 2: -4.95040218140565, 3: -4.8526653929084995, 4: -4.9233139565518}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.299398368758, 2: -4.427110355607999, 3: -4.3413199871679, 4: -4.295093477958001}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.299398368758, 2: -4.427110355607999, 3: -4.3413199871679, 4: -4.295093477958001}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.299398368758, 2: -4.427110355607999, 3: -4.3413199871679, 4: -4.808535064941781}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -3.9276502993799998, 2: -4.00113879739479, 3: -3.9263854274999996, 4: -4.295935903068}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -3.88850022189, 2: -3.98101723758, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -3.88850022189, 2: -3.98101723758, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8912985117, 1: -4.438535201919899, 2: -3.98101723758, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.29473628585, 2: -4.4486788076829, 3: -4.02579820836, 4: -4.297975257969}, Best action: 3, Actual action: 3\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.29473628585, 2: -4.4486788076829, 3: -4.02579820836, 4: -4.297975257969}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.29473628585, 2: -4.4486788076829, 3: -4.5634763696076, 4: -4.297975257969}, Best action: 1, Actual action: 1\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -3.98101723758, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -3.9276502993799998, 2: -4.00113879739479, 3: -4.4423237224809, 4: -4.295935903068}, Best action: 1, Actual action: 1\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -3.9276502993799998, 2: -4.00113879739479, 3: -4.4423237224809, 4: -4.295935903068}, Best action: 1, Actual action: 1\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -4.4741617724358, 2: -4.00113879739479, 3: -4.4423237224809, 4: -4.295935903068}, Best action: 2, Actual action: 2\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -3.8560414239900003, 2: -3.8527191939564904, 3: -3.9264070455000004, 4: -4.31698957386238}, Best action: 2, Actual action: 2\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -3.7698655885033507, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -3.7698655885033507, 3: -3.955862548719, 4: -3.5222077677528008}, Best action: 4, Actual action: 4\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -3.7698655885033507, 3: -3.955862548719, 4: -4.105209068655048}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853004033017774, 1: -4.817599192402291, 2: -4.92153390238356, 3: -4.9805177270141625, 4: -4.5058475566395}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-4.8465514659722775 -4.799144554040971 -4.5187694675658 -3.97362315078 -3.9358403956800005 \n",
      "-4.614243289184431 -4.7746939605768 -4.438533040578901 -4.01371417458 -3.9285034480800003 \n",
      "-4.442446819639801 -4.821678951066991 -4.4921157109382 -4.3547699036404 -3.8333142558000004 \n",
      "-4.297975257969 -4.3413199871679 -4.345470877158001 -3.8891319118886702 -3.6519954390000002 \n",
      "-4.019508695250001 -4.295935903068 -3.8560414239900003 -3.9444781267800004 -4.5058475566395 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -5.012743542848451, 3: -5.330370815294971, 4: -4.8465514659722775}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -5.012743542848451, 3: -5.330370815294971, 4: -4.8465514659722775}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -4.946729713284429, 2: -5.012743542848451, 3: -5.330370815294971, 4: -5.310361834034772}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.8140225419185905, 2: -5.004266417138899, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.8140225419185905, 2: -5.004266417138899, 3: -4.614243289184431, 4: -4.827452997533058}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.8140225419185905, 2: -5.004266417138899, 3: -5.098961393157833, 4: -4.827452997533058}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -4.4618111689869, 2: -4.812888910563091, 3: -4.866052016927161, 4: -4.442446819639801}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -4.4618111689869, 2: -4.812888910563091, 3: -4.866052016927161, 4: -4.442446819639801}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -4.4618111689869, 2: -4.812888910563091, 3: -4.866052016927161, 4: -4.942626605872219}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.5540975910248, 2: -4.4486788076829, 3: -4.83508402849926, 4: -4.297975257969}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.5540975910248, 2: -4.4486788076829, 3: -4.83508402849926, 4: -4.297975257969}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.5540975910248, 2: -4.4486788076829, 3: -4.83508402849926, 4: -4.81115748475179}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.5103120331508, 2: -4.427110355607999, 3: -4.3413199871679, 4: -4.863366185188158}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.5540975910248, 2: -4.861337070374288, 3: -4.83508402849926, 4: -4.9845455826983285}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.479498466255801, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.479498466255801, 3: -4.019508695250001, 4: -4.3895689050960005}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.479498466255801, 3: -4.5577529126775005, 4: -4.3895689050960005}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.479498466255801, 3: -4.911326104395511, 4: -4.3895689050960005}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.479498466255801, 3: -4.911326104395511, 4: -4.894507703637361}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -4.58833860313336, 2: -4.420816426844237, 3: -4.4423237224809, 4: -4.295935903068}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -4.58833860313336, 2: -4.420816426844237, 3: -4.4423237224809, 4: -4.295935903068}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.327278850539001, 1: -4.58833860313336, 2: -4.420816426844237, 3: -4.4423237224809, 4: -4.8093016717918795}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.424822281467001, 1: -4.5103120331508, 2: -4.427110355607999, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.821678951066991, 1: -4.847650022211381, 2: -4.95040218140565, 3: -4.8526653929084995, 4: -4.9233139565518}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.7746939605768, 1: -5.151479388814711, 2: -4.961853629005935, 3: -4.9707526356241205, 4: -4.956967264947678}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -4.89657326887647, 2: -4.86426148637679, 3: -4.799144554040971, 4: -5.085758813669752}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -5.132210035567833, 2: -5.012743542848451, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -4.89657326887647, 2: -4.86426148637679, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.8222649513676705, 2: -4.5513165512178, 3: -4.5187694675658, 4: -4.873010423547258}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -4.89657326887647, 2: -5.046629417365977, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -4.961853629005935, 3: -4.9707526356241205, 4: -4.956967264947678}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -4.961853629005935, 3: -4.9707526356241205, 4: -4.956967264947678}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -4.961853629005935, 3: -4.9707526356241205, 4: -5.4108402111023866}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.438533040578901, 1: -4.833934090727689, 2: -4.5092113099668, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.8222649513676705, 2: -4.5513165512178, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.388807368368001, 2: -4.474898783416801, 3: -3.97362315078, 4: -4.294417483548}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.8222649513676705, 2: -4.573766407253579, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.388807368368001, 2: -4.474898783416801, 3: -5.002113104953399, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.388807368368001, 2: -4.474898783416801, 3: -5.002113104953399, 4: -4.294417483548}, Best action: 4, Actual action: 4\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.388807368368001, 2: -4.474898783416801, 3: -5.002113104953399, 4: -4.80791991002868}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01371417458, 1: -4.358472116373, 2: -4.33953092286, 3: -4.401953289027, 4: -4.299301294389}, Best action: 0, Actual action: 0\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.5899892182466, 2: -4.474898783416801, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -4.447261908415361, 2: -4.002109128099001, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9358403956800005, 1: -4.447261908415361, 2: -4.002109128099001, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 0, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01412613248, 1: -4.337619345441279, 2: -3.9285034480800003, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01412613248, 1: -4.337619345441279, 2: -3.9285034480800003, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.01412613248, 1: -4.337619345441279, 2: -4.474938137752801, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 0, Actual action: 0\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.002109128099001, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.002109128099001, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.54191930657009, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.884266636729379, 3: -4.4240250690099, 4: -4.358116921077}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.884266636729379, 3: -4.4240250690099, 4: -4.86588639818007}, Best action: 3, Actual action: 3\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.5899892182466, 2: -4.5355205988424805, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 0, Actual action: 0\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.511348120423791, 1: -4.5899892182466, 2: -4.5355205988424805, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.00532678958565, 1: -4.5899892182466, 2: -4.5355205988424805, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 2, Actual action: 2\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.526813983786337, 2: -4.884266636729379, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.337619345441279, 2: -4.598935981084081, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.337619345441279, 2: -4.598935981084081, 3: -4.3910744941980004, 4: -4.298763948489}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.337619345441279, 2: -4.598935981084081, 3: -4.3910744941980004, 4: -4.81187519312499}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.8333142558000004, 1: -3.986275936535037, 2: -3.8862877360500003, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 0, Actual action: 0\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.438746481742129, 2: -4.598935981084081, 3: -4.3910744941980004, 4: -4.894659189119936}, Best action: 3, Actual action: 3\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.358472116373, 2: -4.33953092286, 3: -4.401953289027, 4: -4.299301294389}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.358472116373, 2: -4.33953092286, 3: -4.401953289027, 4: -4.299301294389}, Best action: 4, Actual action: 4\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.358472116373, 2: -4.33953092286, 3: -4.401953289027, 4: -4.812364177893991}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.438746481742129, 2: -4.598935981084081, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 1, Actual action: 1\n",
      "Step: 65\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -3.986275936535037, 2: -3.8862877360500003, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 2, Actual action: 2\n",
      "Step: 66\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -3.986275936535037, 2: -3.8862877360500003, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 2, Actual action: 2\n",
      "Step: 67\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -3.986275936535037, 2: -4.436521839805501, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 1, Actual action: 1\n",
      "Step: 68\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.6519954390000002, 1: -3.9182394305899, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -4.062058995218086}, Best action: 0, Actual action: 0\n",
      "Step: 69\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.256743899243505, 2: -4.57253569257393, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 4, Actual action: 4\n",
      "Step: 70\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.256743899243505, 2: -4.57253569257393, 3: -4.496306466889799, 4: -4.174794774585676}, Best action: 4, Actual action: 4\n",
      "Step: 71\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.256743899243505, 2: -4.57253569257393, 3: -4.496306466889799, 4: -4.699063244872965}, Best action: 1, Actual action: 1\n",
      "Step: 72\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -3.9182394305899, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -4.062058995218086}, Best action: 2, Actual action: 2\n",
      "Step: 73\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -3.9182394305899, 2: -3.86383617911079, 3: -3.8977465390299004, 4: -4.062058995218086}, Best action: 2, Actual action: 2\n",
      "Step: 74\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -3.9182394305899, 2: -4.4160909229908185, 3: -3.8977465390299004, 4: -4.062058995218086}, Best action: 3, Actual action: 3\n",
      "Step: 75\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.121842545415845, 2: -3.8891319118886702, 3: -4.2466792884399, 4: -4.10166759617199}, Best action: 2, Actual action: 2\n",
      "Step: 76\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -3.9182394305899, 2: -4.4987837889133, 3: -4.439971502532813, 4: -4.062058995218086}, Best action: 1, Actual action: 1\n",
      "Step: 77\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853004033017774, 1: -4.817599192402291, 2: -4.92153390238356, 3: -4.9805177270141625, 4: -5.276291443101495}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.0678706046087 -5.036861115291161 -4.8222649513676705 -4.5899892182466 -4.834680196654723 \n",
      "-4.827452997533058 -4.9707526356241205 -4.5092113099668 -4.358472116373 -4.4917677143747134 \n",
      "-4.812888910563091 -4.847650022211381 -4.4921157109382 -4.3547699036404 -4.45538169500409 \n",
      "-4.611211802254981 -4.427110355607999 -4.345470877158001 -4.10166759617199 -4.062058995218086 \n",
      "-4.495805314668989 -4.420816426844237 -3.8560414239900003 -3.9444781267800004 -4.817599192402291 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.979784178100098, 2: -5.004266417138899, 3: -5.309254398269842, 4: -4.827452997533058}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.979784178100098, 2: -5.004266417138899, 3: -5.309254398269842, 4: -4.827452997533058}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -4.979784178100098, 2: -5.004266417138899, 3: -5.309254398269842, 4: -5.2929822277550835}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -4.82754107585358, 2: -4.812888910563091, 3: -4.866052016927161, 4: -5.008329707466611}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.847650022211381, 2: -4.95040218140565, 3: -4.8526653929084995, 4: -4.9233139565518}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.5103120331508, 2: -4.427110355607999, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.345470877158001, 2: -4.53265227999946, 3: -4.348996515288, 4: -4.376172926782891}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -3.8560414239900003, 2: -4.138260211275417, 3: -3.9264070455000004, 4: -4.31698957386238}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -3.8560414239900003, 2: -4.138260211275417, 3: -3.9264070455000004, 4: -4.31698957386238}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.4089976958309, 2: -4.138260211275417, 3: -3.9264070455000004, 4: -4.31698957386238}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -4.58833860313336, 2: -4.420816426844237, 3: -4.4423237224809, 4: -4.886026036115778}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.52128947643809, 2: -4.138260211275417, 3: -4.873502010293833, 4: -4.31698957386238}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -4.02672307972833, 3: -3.955862548719, 4: -4.364112033553219}, Best action: 0, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3.9444781267800004, 1: -4.0021106360646606, 2: -4.02672307972833, 3: -3.955862548719, 4: -4.364112033553219}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.121842545415845, 2: -4.462687129966686, 3: -4.2466792884399, 4: -4.10166759617199}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.121842545415845, 2: -4.462687129966686, 3: -4.2466792884399, 4: -4.10166759617199}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.121842545415845, 2: -4.462687129966686, 3: -4.2466792884399, 4: -4.632517512516511}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.0021106360646606, 2: -4.02672307972833, 3: -3.955862548719, 4: -4.531438486047123}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.52128947643809, 2: -4.84875676830565, 3: -4.873502010293833, 4: -4.31698957386238}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.52128947643809, 2: -4.84875676830565, 3: -4.873502010293833, 4: -4.31698957386238}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.52128947643809, 2: -4.84875676830565, 3: -4.873502010293833, 4: -4.828460512214766}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -4.52128947643809, 2: -4.84875676830565, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.77370204066451, 1: -5.014373423558662, 2: -4.84875676830565, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.4579406411477, 2: -4.53265227999946, 3: -4.348996515288, 4: -4.376172926782891}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.5103120331508, 2: -4.8625424460587805, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -4.58833860313336, 2: -4.694072413817512, 3: -4.4423237224809, 4: -4.886026036115778}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.82765792811066, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.495805314668989, 2: -4.82765792811066, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.5500263999416, 1: -4.991182836348781, 2: -4.82765792811066, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -4.611211802254981, 2: -4.861337070374288, 3: -4.83508402849926, 4: -4.9845455826983285}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -4.82765792811066, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -4.58833860313336, 2: -4.694072413817512, 3: -4.985834677129971, 4: -4.886026036115778}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -4.58833860313336, 2: -4.694072413817512, 3: -4.985834677129971, 4: -4.886026036115778}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -5.075388128851358, 2: -4.694072413817512, 3: -4.985834677129971, 4: -4.886026036115778}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.900057381449731, 1: -5.26813599529412, 2: -4.84875676830565, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.0021106360646606, 2: -4.02672307972833, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.0021106360646606, 2: -4.02672307972833, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.54192067881884, 2: -4.02672307972833, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -4.853004033017774, 1: -5.2919968472420065, 2: -4.92153390238356, 3: -4.9805177270141625, 4: -5.276291443101495}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.0678706046087 -5.036861115291161 -4.8222649513676705 -4.5899892182466 -4.834680196654723 \n",
      "-5.004266417138899 -4.9707526356241205 -4.5092113099668 -4.358472116373 -4.4917677143747134 \n",
      "-4.82754107585358 -4.8526653929084995 -4.4921157109382 -4.3547699036404 -4.45538169500409 \n",
      "-4.801658207822191 -4.8625424460587805 -4.376172926782891 -4.2466792884399 -4.062058995218086 \n",
      "-4.911326104395511 -4.886026036115778 -4.62658529204294 -4.33360557471723 -4.853004033017774 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -5.132210035567833, 2: -5.3413261582500455, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.0678706046087, 1: -5.132210035567833, 2: -5.3413261582500455, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.511762250193917, 1: -5.132210035567833, 2: -5.3413261582500455, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -5.296418435366114, 2: -5.004266417138899, 3: -5.309254398269842, 4: -5.4629234070365875}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -4.991397125769503, 3: -4.9707526356241205, 4: -5.460185460605046}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.071904033740531, 1: -5.296418435366114, 2: -5.426736276569428, 3: -5.309254398269842, 4: -5.4629234070365875}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.3413261582500455, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.3413261582500455, 3: -5.330370815294971, 4: -5.437887251163865}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.3413261582500455, 3: -5.750637441918424, 4: -5.437887251163865}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -5.4048008114952655, 2: -5.046629417365977, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.036861115291161, 1: -5.4048008114952655, 2: -5.046629417365977, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.483543614914956, 1: -5.4048008114952655, 2: -5.046629417365977, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -4.8222649513676705, 2: -4.835854802399238, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -4.833934090727689, 2: -4.5092113099668, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.358472116373, 2: -4.929337742497125, 3: -4.401953289027, 4: -4.896256465305999}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.3547699036404, 2: -4.418790280204072, 3: -4.7632929502428, 4: -4.379575516488}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.516432919003974, 2: -4.462687129966686, 3: -4.2466792884399, 4: -4.701944213038486}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.4579406411477, 2: -4.53265227999946, 3: -4.988252398380949, 4: -4.376172926782891}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.4579406411477, 2: -4.53265227999946, 3: -4.988252398380949, 4: -4.376172926782891}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -4.4579406411477, 2: -4.53265227999946, 3: -4.988252398380949, 4: -4.88231736337243}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.900057381449731, 1: -5.26813599529412, 2: -4.62658529204294, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.33360557471723, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.490275593034824, 1: -5.2919968472420065, 2: -4.92153390238356, 3: -4.9805177270141625, 4: -5.276291443101495}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.437887251163865 -5.085758813669752 -4.826788011553771 -4.5899892182466 -4.834680196654723 \n",
      "-5.296418435366114 -4.991397125769503 -4.833934090727689 -4.401953289027 -4.4917677143747134 \n",
      "-4.82754107585358 -4.8526653929084995 -4.4921157109382 -4.379575516488 -4.45538169500409 \n",
      "-4.801658207822191 -4.8625424460587805 -4.53265227999946 -4.3668211118769005 -4.062058995218086 \n",
      "-4.911326104395511 -4.886026036115778 -4.8728790447252495 -4.419803018402407 -4.92153390238356 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.310697552344411, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.310697552344411, 3: -5.440236725111343, 4: -5.085758813669752}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.310697552344411, 3: -5.440236725111343, 4: -5.5280405204394745}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -5.034687656209875, 2: -4.835854802399238, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.826788011553771, 1: -5.034687656209875, 2: -4.835854802399238, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.292377090513932, 1: -5.034687656209875, 2: -4.835854802399238, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -4.5899892182466, 2: -5.0202713867511815, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.863210833586024, 2: -4.929337742497125, 3: -4.401953289027, 4: -4.896256465305999}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -4.833934090727689, 2: -4.88128354525881, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8582782372601, 1: -4.4921157109382, 2: -4.681330158805496, 3: -4.89624632788599, 4: -4.95161824478257}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -5.093328150669551, 2: -4.53265227999946, 3: -4.988252398380949, 4: -4.99916365566688}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.3668211118769005, 1: -4.516432919003974, 2: -4.462687129966686, 3: -4.869367999538132, 4: -4.701944213038486}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.775287214000359, 2: -4.418790280204072, 3: -4.7632929502428, 4: -4.379575516488}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.775287214000359, 2: -4.418790280204072, 3: -4.7632929502428, 4: -4.379575516488}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.775287214000359, 2: -4.418790280204072, 3: -4.7632929502428, 4: -4.885413720004079}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.45538169500409, 2: -4.57253569257393, 3: -4.496306466889799, 4: -4.817868882874535}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.294079288904846, 2: -4.4987837889133, 3: -4.439971502532813, 4: -4.062058995218086}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.294079288904846, 2: -4.4987837889133, 3: -4.439971502532813, 4: -4.062058995218086}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.294079288904846, 2: -4.4987837889133, 3: -4.439971502532813, 4: -4.5964736856484585}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.490275593034824, 1: -5.2919968472420065, 2: -5.511618029310855, 3: -4.9805177270141625, 4: -5.276291443101495}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-5.437887251163865 -5.340768044592996 -4.873010423547258 -4.924581085936531 -4.834680196654723 \n",
      "-5.296418435366114 -4.991397125769503 -4.88128354525881 -4.863210833586024 -4.4917677143747134 \n",
      "-4.82754107585358 -4.8526653929084995 -4.681330158805496 -4.464052716043801 -4.496306466889799 \n",
      "-4.801658207822191 -4.8625424460587805 -4.710044884922722 -4.462687129966686 -4.439971502532813 \n",
      "-4.911326104395511 -4.886026036115778 -4.8728790447252495 -4.419803018402407 -4.9805177270141625 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.513990119210845, 3: -5.801537932374379, 4: -5.437887251163865}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.513990119210845, 3: -5.801537932374379, 4: -5.437887251163865}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.4666768014392915, 2: -5.513990119210845, 3: -5.801537932374379, 4: -5.848477398559117}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.296418435366114, 2: -5.426736276569428, 3: -5.309254398269842, 4: -5.4629234070365875}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -4.82754107585358, 2: -5.307885409047527, 3: -4.866052016927161, 4: -5.008329707466611}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.801658207822191, 1: -5.271524101995132, 2: -4.861337070374288, 3: -4.83508402849926, 4: -4.9845455826983285}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -4.866052016927161, 4: -5.008329707466611}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -4.866052016927161, 4: -5.008329707466611}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.962062246808672, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -5.3281073354037165, 4: -5.008329707466611}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.339950114978011, 2: -5.426736276569428, 3: -5.309254398269842, 4: -5.4629234070365875}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.339950114978011, 2: -5.426736276569428, 3: -5.309254398269842, 4: -5.4629234070365875}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.339950114978011, 2: -5.426736276569428, 3: -5.731421502425556, 4: -5.4629234070365875}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -5.452081153455396, 4: -5.008329707466611}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -5.452081153455396, 4: -5.008329707466611}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.2720972559213335, 2: -5.307885409047527, 3: -5.452081153455396, 4: -5.457580033794617}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -4.861337070374288, 3: -4.83508402849926, 4: -4.9845455826983285}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -4.861337070374288, 3: -4.83508402849926, 4: -4.9845455826983285}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -4.861337070374288, 3: -5.299926465934327, 4: -4.9845455826983285}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.94931341852461, 2: -4.8625424460587805, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.710044884922722, 1: -5.093328150669551, 2: -4.890390328620236, 3: -4.988252398380949, 4: -4.99916365566688}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8582782372601, 1: -5.020659917893382, 2: -4.681330158805496, 3: -4.89624632788599, 4: -4.95161824478257}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.464052716043801, 1: -4.775287214000359, 2: -4.95073820097372, 3: -4.7632929502428, 4: -4.967761498965706}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -4.863210833586024, 2: -4.929337742497125, 3: -5.255681942392128, 4: -4.896256465305999}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.775287214000359, 2: -4.95073820097372, 3: -4.7632929502428, 4: -4.967761498965706}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.8582782372601, 1: -5.020659917893382, 2: -4.984015715876028, 3: -4.89624632788599, 4: -4.95161824478257}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.022007134932711, 2: -4.88128354525881, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -5.2445883730552705, 2: -4.929337742497125, 3: -5.255681942392128, 4: -4.896256465305999}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -5.2445883730552705, 2: -4.929337742497125, 3: -5.255681942392128, 4: -4.896256465305999}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.9260394320256085, 1: -5.2445883730552705, 2: -4.929337742497125, 3: -5.255681942392128, 4: -5.3555933834284595}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -4.924581085936531, 2: -5.0202713867511815, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.2445883730552705, 2: -4.929337742497125, 3: -5.255681942392128, 4: -5.425651278283589}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.4917677143747134, 2: -4.598935981084081, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.63580595562706, 2: -4.57253569257393, 3: -4.496306466889799, 4: -4.817868882874535}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.775287214000359, 2: -4.95073820097372, 3: -5.3115346672049615, 4: -4.967761498965706}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.516432919003974, 2: -4.462687129966686, 3: -4.869367999538132, 4: -4.701944213038486}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.463627287771956, 2: -4.4987837889133, 3: -4.439971502532813, 4: -4.8378515925777705}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.516432919003974, 2: -4.942645630048247, 3: -4.869367999538132, 4: -4.701944213038486}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.419803018402407, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 2, Actual action: 2\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.490275593034824, 1: -5.2919968472420065, 2: -5.511618029310855, 3: -5.8027404461441465, 4: -5.276291443101495}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.513990119210845 -5.340768044592996 -4.873010423547258 -4.935725959380949 -4.834680196654723 \n",
      "-5.426736276569428 -4.991397125769503 -4.891919849535538 -5.031265622893231 -4.543121007008191 \n",
      "-5.307885409047527 -4.8526653929084995 -4.89624632788599 -4.95073820097372 -4.57253569257393 \n",
      "-4.9845455826983285 -4.863366185188158 -4.890390328620236 -4.701944213038486 -4.463627287771956 \n",
      "-4.911326104395511 -4.886026036115778 -4.8728790447252495 -4.531438486047123 -5.276291443101495 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.736766612790482, 2: -5.513990119210845, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.340768044592996, 3: -5.440236725111343, 4: -5.754469069442921}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.034687656209875, 2: -5.10147674701967, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.034687656209875, 2: -5.10147674701967, 3: -5.31810129454652, 4: -4.873010423547258}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.034687656209875, 2: -5.10147674701967, 3: -5.31810129454652, 4: -5.334439485428005}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.022007134932711, 2: -5.354096091423741, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.022007134932711, 2: -5.354096091423741, 3: -5.024174567404258, 4: -4.891919849535538}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.022007134932711, 2: -5.354096091423741, 3: -5.024174567404258, 4: -5.35164706307734}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.020659917893382, 2: -4.984015715876028, 3: -4.89624632788599, 4: -4.95161824478257}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.970724390263618, 2: -4.95040218140565, 3: -4.8526653929084995, 4: -4.9233139565518}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.343627788676534, 2: -5.307885409047527, 3: -5.452081153455396, 4: -5.7161567806757425}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.970724390263618, 2: -4.95040218140565, 3: -5.684653720619347, 4: -4.9233139565518}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.970724390263618, 2: -4.95040218140565, 3: -5.684653720619347, 4: -4.9233139565518}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.970724390263618, 2: -4.95040218140565, 3: -5.684653720619347, 4: -5.380215700462138}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.020659917893382, 2: -4.984015715876028, 3: -5.320283601044484, 4: -4.95161824478257}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.020659917893382, 2: -4.984015715876028, 3: -5.320283601044484, 4: -4.95161824478257}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.020659917893382, 2: -4.984015715876028, 3: -5.320283601044484, 4: -5.405972602752139}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.9923052966730515, 2: -4.95073820097372, 3: -5.3115346672049615, 4: -4.967761498965706}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.63580595562706, 2: -4.57253569257393, 3: -5.217613290029271, 4: -4.817868882874535}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.63580595562706, 2: -4.57253569257393, 3: -5.217613290029271, 4: -4.817868882874535}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.63580595562706, 2: -5.061007480242276, 3: -5.217613290029271, 4: -4.817868882874535}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.463627287771956, 2: -4.4987837889133, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.490275593034824, 1: -5.2919968472420065, 2: -5.511618029310855, 3: -5.8027404461441465, 4: -5.8939611408709345}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.608266353829337 -5.381215247532579 -5.10147674701967 -4.935725959380949 -4.834680196654723 \n",
      "-5.426736276569428 -4.991397125769503 -5.024174567404258 -5.031265622893231 -4.543121007008191 \n",
      "-5.343627788676534 -4.970724390263618 -5.020659917893382 -4.967761498965706 -4.817868882874535 \n",
      "-4.9845455826983285 -4.863366185188158 -4.890390328620236 -4.701944213038486 -4.4987837889133 \n",
      "-4.911326104395511 -4.886026036115778 -4.8728790447252495 -4.531438486047123 -5.2919968472420065 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.490742074545756, 2: -5.426736276569428, 3: -5.798501743374745, 4: -5.4629234070365875}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -4.991397125769503, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.3681602390809235, 2: -5.354096091423741, 3: -5.024174567404258, 4: -5.50299048560323}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.151479388814711, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -4.970724390263618, 2: -5.405850996414447, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.94931341852461, 2: -5.201390601393283, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.94931341852461, 2: -5.201390601393283, 3: -5.022951047446878, 4: -4.863366185188158}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -4.94931341852461, 2: -5.201390601393283, 3: -5.022951047446878, 4: -5.325663228521225}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -4.985834677129971, 4: -4.886026036115778}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -4.985834677129971, 4: -4.886026036115778}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.916833933042171, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -4.985834677129971, 4: -5.346283692865358}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -5.352612431106241, 2: -5.201390601393283, 3: -5.022951047446878, 4: -5.441510191857056}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -5.324793088345041, 3: -5.367675673596607, 4: -4.9845455826983285}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -5.324793088345041, 3: -5.367675673596607, 4: -4.9845455826983285}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.271524101995132, 2: -5.324793088345041, 3: -5.367675673596607, 4: -5.435936480255479}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -4.911326104395511, 4: -5.017844528030935}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -5.369306754999915, 4: -5.017844528030935}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -5.5013847432050484, 4: -5.017844528030935}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -5.5013847432050484, 4: -5.466238520508151}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.084639667587574, 2: -5.099320061349088, 3: -5.5013847432050484, 4: -5.56518198279675}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.090084199820694, 1: -5.527022097504692, 2: -5.099320061349088, 3: -5.5013847432050484, 4: -5.56518198279675}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.321667954493219, 1: -5.405326554759877, 2: -5.324793088345041, 3: -5.367675673596607, 4: -5.713528170641605}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.343627788676534, 2: -5.41867284571171, 3: -5.452081153455396, 4: -5.7161567806757425}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.405326554759877, 2: -5.324793088345041, 3: -5.367675673596607, 4: -5.713528170641605}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -5.352612431106241, 2: -5.201390601393283, 3: -5.439777026730334, 4: -5.441510191857056}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.093328150669551, 2: -4.890390328620236, 3: -4.988252398380949, 4: -4.99916365566688}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.931683736806347, 2: -4.942645630048247, 3: -4.869367999538132, 4: -4.701944213038486}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.931683736806347, 2: -4.942645630048247, 3: -4.869367999538132, 4: -4.701944213038486}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.931683736806347, 2: -4.942645630048247, 3: -4.869367999538132, 4: -5.178769233865022}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.093328150669551, 2: -5.197613845423198, 3: -4.988252398380949, 4: -4.99916365566688}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.248042178510963, 1: -5.352612431106241, 2: -5.38135522632172, 3: -5.439777026730334, 4: -5.441510191857056}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.249670003173907, 1: -5.3363990490287705, 2: -5.405850996414447, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 0, Actual action: 0\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.264776484830867, 1: -5.441434694995002, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.381215247532579, 3: -5.440236725111343, 4: -5.754469069442921}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.365923843744773, 2: -5.10147674701967, 3: -5.31810129454652, 4: -5.511540950072799}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.0202713867511815, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.0202713867511815, 3: -5.002113104953399, 4: -4.935725959380949}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.0202713867511815, 3: -5.002113104953399, 4: -5.391510623036663}, Best action: 3, Actual action: 3\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.365923843744773, 2: -5.408085701800536, 3: -5.31810129454652, 4: -5.511540950072799}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.4048008114952655, 2: -5.57031768983919, 3: -5.440236725111343, 4: -5.754469069442921}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.441434694995002, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.3363990490287705, 2: -5.405850996414447, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.352612431106241, 2: -5.38135522632172, 3: -5.439777026730334, 4: -5.441510191857056}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -4.985834677129971, 4: -5.417263855050694}, Best action: 3, Actual action: 3\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.099320061349088, 3: -5.5013847432050484, 4: -5.56518198279675}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 1, Actual action: 1\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.2097374680773205, 2: -5.296900223709328, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 1, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.900057381449731, 1: -5.26813599529412, 2: -4.8728790447252495, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.715776370752451, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 4, Actual action: 4\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.715776370752451, 3: -4.792347809700428, 4: -4.531438486047123}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.715776370752451, 3: -4.792347809700428, 4: -5.023609022302882}, Best action: 1, Actual action: 1\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -4.615837762461831, 2: -4.715776370752451, 3: -4.792347809700428, 4: -5.141189489824372}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.616798565577312, 1: -5.100412363840267, 2: -4.715776370752451, 3: -4.792347809700428, 4: -5.141189489824372}, Best action: 0, Actual action: 0\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.884138279542969, 1: -4.931683736806347, 2: -4.942645630048247, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 0, Actual action: 0\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.9923052966730515, 2: -5.098827731082255, 3: -5.3115346672049615, 4: -4.967761498965706}, Best action: 4, Actual action: 4\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.9923052966730515, 2: -5.098827731082255, 3: -5.3115346672049615, 4: -4.967761498965706}, Best action: 4, Actual action: 4\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -4.9923052966730515, 2: -5.098827731082255, 3: -5.3115346672049615, 4: -5.420662964058793}, Best action: 1, Actual action: 1\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -4.931683736806347, 2: -4.942645630048247, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 1, Actual action: 1\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -4.715776370752451, 3: -4.792347809700428, 4: -5.141189489824372}, Best action: 2, Actual action: 2\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.490275593034824, 1: -5.8248560687454365, 2: -5.511618029310855, 3: -5.8027404461441465, 4: -5.8939611408709345}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.608266353829337 -5.440236725111343 -5.346280098994776 -5.0202713867511815 -4.834680196654723 \n",
      "-5.4629234070365875 -5.460185460605046 -5.030419710544309 -5.031265622893231 -4.543121007008191 \n",
      "-5.41867284571171 -5.405850996414447 -5.020659917893382 -5.098827731082255 -4.817868882874535 \n",
      "-5.367675673596607 -5.38135522632172 -4.99916365566688 -4.942645630048247 -4.4987837889133 \n",
      "-5.5013847432050484 -5.376722048598385 -4.873502010293833 -4.792347809700428 -5.490275593034824 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.736766612790482, 2: -5.777421128041411, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.608266353829337, 1: -5.736766612790482, 2: -5.777421128041411, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.003522381984697, 1: -5.736766612790482, 2: -5.777421128041411, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.490742074545756, 2: -5.485705299530241, 3: -5.798501743374745, 4: -5.4629234070365875}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.490742074545756, 2: -5.485705299530241, 3: -5.798501743374745, 4: -5.4629234070365875}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.490742074545756, 2: -5.485705299530241, 3: -5.798501743374745, 4: -5.871260300403295}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.460185460605046}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.4687211121744, 3: -5.505317530892243, 4: -5.868768769150591}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.030419710544309, 1: -5.3681602390809235, 2: -5.354096091423741, 3: -5.575115761680342, 4: -5.50299048560323}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.365923843744773, 2: -5.408085701800536, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.346280098994776, 1: -5.365923843744773, 2: -5.408085701800536, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.765114890085247, 1: -5.365923843744773, 2: -5.408085701800536, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.3681602390809235, 2: -5.354096091423741, 3: -5.575115761680342, 4: -5.50299048560323}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.2445883730552705, 2: -5.031265622893231, 3: -5.255681942392128, 4: -5.425651278283589}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.543121007008191, 1: -4.991185009618209, 2: -4.598935981084081, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -4.834680196654723, 2: -4.884266636729379, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -4.598935981084081, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -4.598935981084081, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -5.085031742786513, 3: -4.8215414978748905, 4: -4.894659189119936}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.2445883730552705, 2: -5.0830545779659575, 3: -5.255681942392128, 4: -5.425651278283589}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -5.313951787557313, 3: -5.499428357939915, 4: -4.894659189119936}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -5.313951787557313, 3: -5.499428357939915, 4: -4.894659189119936}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -4.991185009618209, 2: -5.313951787557313, 3: -5.499428357939915, 4: -5.354139862099141}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.979118698657991, 2: -5.161103572082146, 3: -5.217613290029271, 4: -4.817868882874535}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.979118698657991, 2: -5.161103572082146, 3: -5.217613290029271, 4: -4.817868882874535}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.84010176588038, 1: -4.979118698657991, 2: -5.161103572082146, 3: -5.217613290029271, 4: -5.284260683415828}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.270403059991145, 1: -5.3015922960901944, 2: -5.313951787557313, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -5.108606164343578, 2: -4.884266636729379, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -5.108606164343578, 2: -4.884266636729379, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -5.108606164343578, 2: -5.344682639423735, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.895866185384443, 1: -5.108606164343578, 2: -5.400119874103772, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.355238228699843, 1: -5.108606164343578, 2: -5.400119874103772, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.108606164343578, 2: -5.400119874103772, 3: -4.996594484444261, 4: -4.970048945716027}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.108606164343578, 2: -5.400119874103772, 3: -4.996594484444261, 4: -5.422744540601585}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.0202713867511815, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.108606164343578, 2: -5.400119874103772, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.383296281749912, 1: -5.3015922960901944, 2: -5.313951787557313, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -4.979118698657991, 2: -5.161103572082146, 3: -5.217613290029271, 4: -5.348908498704691}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.7328801750432214, 2: -4.4987837889133, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.7328801750432214, 2: -4.4987837889133, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.646783311314398, 1: -4.7328801750432214, 2: -4.993893247911103, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 0, Actual action: 0\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.041926738885572, 2: -5.161103572082146, 3: -5.217613290029271, 4: -5.348908498704691}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -4.7328801750432214, 2: -5.163283806955773, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -5.8248560687454365, 2: -5.511618029310855, 3: -5.8027404461441465, 4: -5.8939611408709345}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.777421128041411 -5.440236725111343 -5.408085701800536 -5.074304364020974 -5.400119874103772 \n",
      "-5.490742074545756 -5.505317530892243 -5.3681602390809235 -5.2445883730552705 -5.313951787557313 \n",
      "-5.41867284571171 -5.405850996414447 -5.020659917893382 -5.098827731082255 -5.161103572082146 \n",
      "-5.367675673596607 -5.38135522632172 -4.99916365566688 -4.942645630048247 -4.8378515925777705 \n",
      "-5.5013847432050484 -5.376722048598385 -4.873502010293833 -4.792347809700428 -5.511618029310855 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.848042184095479, 2: -5.57031768983919, 3: -5.440236725111343, 4: -5.754469069442921}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.8986446209786845, 2: -5.777421128041411, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.848042184095479, 2: -5.57031768983919, 3: -6.123734786224677, 4: -5.754469069442921}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.5361241895579365, 1: -5.848042184095479, 2: -5.57031768983919, 3: -6.123734786224677, 4: -5.754469069442921}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.937873012497722, 1: -5.848042184095479, 2: -5.57031768983919, 3: -6.123734786224677, 4: -5.754469069442921}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.773410218427707, 2: -5.408085701800536, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.074304364020974, 1: -5.385221680016325, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.517616971259087, 1: -5.385221680016325, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.2445883730552705, 2: -5.372979400983743, 3: -5.255681942392128, 4: -5.425651278283589}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -5.3938943564804465, 2: -5.098827731082255, 3: -5.3115346672049615, 4: -5.485833586711051}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.237825615673567, 2: -5.161103572082146, 3: -5.217613290029271, 4: -5.348908498704691}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.237825615673567, 2: -5.161103572082146, 3: -5.217613290029271, 4: -5.348908498704691}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.237825615673567, 2: -5.596604250594753, 3: -5.217613290029271, 4: -5.348908498704691}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.285606046809059, 1: -5.3938943564804465, 2: -5.590376666494764, 3: -5.3115346672049615, 4: -5.485833586711051}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.554509299482154, 2: -5.372979400983743, 3: -5.255681942392128, 4: -5.425651278283589}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.3681602390809235, 2: -5.510734763685892, 3: -5.575115761680342, 4: -5.50299048560323}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.020659917893382, 2: -5.408499514376316, 3: -5.320283601044484, 4: -5.477649990134797}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.093328150669551, 2: -5.197613845423198, 3: -5.649739404431975, 4: -4.99916365566688}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.093328150669551, 2: -5.197613845423198, 3: -5.649739404431975, 4: -4.99916365566688}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.093328150669551, 2: -5.197613845423198, 3: -5.649739404431975, 4: -5.449238926656861}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.900057381449731, 1: -5.26813599529412, 2: -5.057753078170695, 3: -4.873502010293833, 4: -5.04509052713633}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.7114629280122875, 2: -5.376722048598385, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4.900057381449731, 1: -5.26813599529412, 2: -5.057753078170695, 3: -5.742495060394075, 4: -5.04509052713633}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.162881917124724, 1: -5.3568694434049595, 2: -5.197613845423198, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.451388552879512, 2: -5.408499514376316, 3: -5.320283601044484, 4: -5.477649990134797}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.769255974098932, 2: -5.405850996414447, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.339667495385646, 1: -5.451388552879512, 2: -5.408499514376316, 3: -5.8107676672001505, 4: -5.477649990134797}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.5035505574017325, 2: -5.510734763685892, 3: -5.575115761680342, 4: -5.50299048560323}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.5035505574017325, 2: -5.510734763685892, 3: -5.575115761680342, 4: -5.50299048560323}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.5035505574017325, 2: -5.510734763685892, 3: -5.575115761680342, 4: -5.90772134189894}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.451388552879512, 2: -5.408499514376316, 3: -5.8107676672001505, 4: -5.477649990134797}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.3938943564804465, 2: -5.590376666494764, 3: -5.3115346672049615, 4: -5.485833586711051}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.451388552879512, 2: -5.743193031873651, 3: -5.8107676672001505, 4: -5.477649990134797}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.3568694434049595, 2: -5.197613845423198, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.21294723399012, 2: -4.942645630048247, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -4.937698621246115, 2: -5.163283806955773, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -4.937698621246115, 2: -5.163283806955773, 3: -5.0023078146465005, 4: -4.8378515925777705}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -4.937698621246115, 2: -5.163283806955773, 3: -5.0023078146465005, 4: -5.302444949245771}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -5.8248560687454365, 2: -5.857753550271274, 3: -5.8027404461441465, 4: -5.8939611408709345}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-5.801537932374379 -5.754469069442921 -5.511540950072799 -5.49086267731592 -5.400119874103772 \n",
      "-5.490742074545756 -5.505317530892243 -5.510734763685892 -5.372979400983743 -5.313951787557313 \n",
      "-5.41867284571171 -5.447847336984791 -5.477649990134797 -5.3938943564804465 -5.237825615673567 \n",
      "-5.367675673596607 -5.38135522632172 -5.3568694434049595 -5.21294723399012 -5.0023078146465005 \n",
      "-5.5013847432050484 -5.406718683834121 -5.04509052713633 -4.792347809700428 -5.8027404461441465 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.8986446209786845, 2: -5.96200270634607, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.8986446209786845, 2: -5.96200270634607, 3: -5.801537932374379, 4: -5.912855949021738}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.8986446209786845, 2: -5.96200270634607, 3: -6.179399518460685, 4: -5.912855949021738}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.490742074545756, 2: -5.871320753043111, 3: -5.798501743374745, 4: -5.930547322659824}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.747445180427137, 2: -5.41867284571171, 3: -5.452081153455396, 4: -5.7161567806757425}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.769255974098932, 2: -5.765715770903818, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.769255974098932, 2: -5.765715770903818, 3: -5.684653720619347, 4: -5.447847336984791}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.769255974098932, 2: -5.765715770903818, 3: -5.684653720619347, 4: -5.85754107665616}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.747445180427137, 2: -5.854623627528852, 3: -5.452081153455396, 4: -5.7161567806757425}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.747445180427137, 2: -5.854623627528852, 3: -5.452081153455396, 4: -5.7161567806757425}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.6967022872794395, 1: -5.747445180427137, 2: -5.854623627528852, 3: -5.8613938496444105, 4: -5.7161567806757425}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.72479076376298, 1: -5.8381992124810616, 2: -5.871320753043111, 3: -5.798501743374745, 4: -5.930547322659824}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.937365542479931, 2: -5.96200270634607, 3: -6.295842094838804, 4: -5.912855949021738}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.937365542479931, 2: -5.96200270634607, 3: -6.295842094838804, 4: -5.912855949021738}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -5.937365542479931, 2: -5.96200270634607, 3: -6.295842094838804, 4: -6.280698913609782}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -5.8381992124810616, 2: -5.871320753043111, 3: -5.798501743374745, 4: -5.930547322659824}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -5.8381992124810616, 2: -5.871320753043111, 3: -5.798501743374745, 4: -5.930547322659824}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -5.8381992124810616, 2: -5.871320753043111, 3: -6.176636586471018, 4: -5.930547322659824}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -5.747445180427137, 2: -5.854623627528852, 3: -6.100468237660787, 4: -5.7161567806757425}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -5.747445180427137, 2: -5.854623627528852, 3: -6.100468237660787, 4: -5.7161567806757425}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -5.747445180427137, 2: -5.854623627528852, 3: -6.100468237660787, 4: -6.101702670414926}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.405326554759877, 2: -5.645605695963063, 3: -5.367675673596607, 4: -5.713528170641605}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.405326554759877, 2: -5.645605695963063, 3: -5.367675673596607, 4: -5.713528170641605}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.405326554759877, 2: -5.645605695963063, 3: -5.784584862972912, 4: -5.713528170641605}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.5013847432050484, 4: -5.56518198279675}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.5013847432050484, 4: -5.56518198279675}, Best action: 3, Actual action: 3\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.906260116316594, 4: -5.56518198279675}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.998423417697027, 4: -5.56518198279675}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.998423417697027, 4: -5.9643156043450425}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -5.575670411605231, 2: -5.629819355277538, 3: -5.998423417697027, 4: -6.012724593834742}, Best action: 1, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -6.327873962166664, 2: -5.629819355277538, 3: -5.998423417697027, 4: -6.012724593834742}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.7114629280122875, 2: -5.406718683834121, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.26813599529412, 2: -5.057753078170695, 3: -5.742495060394075, 4: -5.04509052713633}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.26813599529412, 2: -5.057753078170695, 3: -5.742495060394075, 4: -5.04509052713633}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.26813599529412, 2: -5.057753078170695, 3: -5.742495060394075, 4: -5.491032379694061}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -4.9187008674334525, 3: -4.792347809700428, 4: -5.141189489824372}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.26813599529412, 2: -5.287577033674417, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.26813599529412, 2: -5.287577033674417, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.69400375571765, 2: -5.287577033674417, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 2, Actual action: 2\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -4.9187008674334525, 3: -5.64642493715828, 4: -5.141189489824372}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -5.8248560687454365, 2: -5.857753550271274, 3: -6.179519769837662, 4: -5.8939611408709345}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-5.96200270634607 -5.754469069442921 -5.511540950072799 -5.49086267731592 -5.400119874103772 \n",
      "-5.871320753043111 -5.505317530892243 -5.510734763685892 -5.372979400983743 -5.313951787557313 \n",
      "-5.822561813655965 -5.689435953030394 -5.477649990134797 -5.3938943564804465 -5.237825615673567 \n",
      "-5.645605695963063 -5.38135522632172 -5.3568694434049595 -5.21294723399012 -5.0023078146465005 \n",
      "-5.719559463121577 -5.417263855050694 -5.412905405988538 -5.141189489824372 -5.8248560687454365 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -5.871320753043111, 3: -6.246605020756761, 4: -5.930547322659824}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.52151207675833, 3: -5.505317530892243, 4: -5.916540977776323}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -5.946439275327028, 3: -6.246605020756761, 4: -5.930547322659824}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -5.946439275327028, 3: -6.246605020756761, 4: -5.930547322659824}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -5.946439275327028, 3: -6.246605020756761, 4: -6.2967980636204395}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.52151207675833, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.831239662384989, 2: -5.510734763685892, 3: -5.575115761680342, 4: -5.9486480856852975}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.554509299482154, 2: -5.372979400983743, 3: -5.773777987894761, 4: -5.425651278283589}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.383296281749912, 1: -5.463245375521992, 2: -5.313951787557313, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.383296281749912, 1: -5.463245375521992, 2: -5.313951787557313, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.383296281749912, 1: -5.463245375521992, 2: -5.735696126677155, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.705150376267415, 2: -5.400119874103772, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.705150376267415, 2: -5.400119874103772, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.705150376267415, 2: -5.814109085434432, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.461263468899967, 1: -5.705150376267415, 2: -5.905034318352416, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.86974975669897, 1: -5.705150376267415, 2: -5.905034318352416, 3: -5.466079271712884, 4: -5.48951598646001}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.686638750176401, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.686638750176401, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.49086267731592}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.686638750176401, 2: -5.539998131793416, 3: -5.707873359078022, 4: -5.896685036357487}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -5.705150376267415, 2: -5.905034318352416, 3: -5.894206695797184, 4: -5.48951598646001}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -5.705150376267415, 2: -5.905034318352416, 3: -5.894206695797184, 4: -5.48951598646001}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -5.705150376267415, 2: -5.905034318352416, 3: -5.894206695797184, 4: -5.895459547678609}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -5.463245375521992, 2: -5.834039600885144, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.237825615673567, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.348908498704691}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.19398962350137, 2: -5.163283806955773, 3: -5.0023078146465005, 4: -5.42978037813393}, Best action: 3, Actual action: 3\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.21294723399012, 2: -5.312924352992819, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -5.210003502427149, 3: -5.64642493715828, 4: -5.141189489824372}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -5.210003502427149, 3: -5.64642493715828, 4: -5.141189489824372}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -5.210003502427149, 3: -5.64642493715828, 4: -5.578482435740178}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.14964807450165, 2: -5.210003502427149, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.5861797477965025, 2: -5.210003502427149, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -6.238255416839464, 2: -5.857753550271274, 3: -6.179519769837662, 4: -5.8939611408709345}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-5.96200270634607 -5.754469069442921 -5.511540950072799 -5.686638750176401 -5.894206695797184 \n",
      "-5.9670687097069495 -5.766626699212805 -5.575115761680342 -5.38151462281115 -5.478273844000664 \n",
      "-5.822561813655965 -5.689435953030394 -5.477649990134797 -5.3938943564804465 -5.348908498704691 \n",
      "-5.645605695963063 -5.38135522632172 -5.3568694434049595 -5.312924352992819 -5.163283806955773 \n",
      "-5.719559463121577 -5.417263855050694 -5.412905405988538 -5.265780725962446 -5.857753550271274 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -5.848042184095479, 2: -5.837581187442353, 3: -6.123734786224677, 4: -5.754469069442921}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -5.848042184095479, 2: -5.837581187442353, 3: -6.123734786224677, 4: -5.754469069442921}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -5.848042184095479, 2: -5.837581187442353, 3: -6.123734786224677, 4: -6.136566853193059}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.773410218427707, 2: -5.5509951050370425, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.773410218427707, 2: -5.5509951050370425, 3: -5.809698786765817, 4: -5.511540950072799}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.773410218427707, 2: -5.5509951050370425, 3: -5.809698786765817, 4: -5.915502264566247}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.686638750176401, 2: -5.90050776221195, 3: -5.707873359078022, 4: -5.9770669903884155}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.38151462281115, 1: -5.554509299482154, 2: -5.741598888019798, 3: -5.773777987894761, 4: -5.425651278283589}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.827690719494672, 2: -5.90050776221195, 3: -5.707873359078022, 4: -5.9770669903884155}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.773410218427707, 2: -6.061276898146589, 3: -5.809698786765817, 4: -5.987856261536629}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.831239662384989, 2: -5.803186791165421, 3: -5.575115761680342, 4: -5.9486480856852975}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -5.766626699212805, 2: -5.915846366261405, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.689435953030394, 1: -5.769255974098932, 2: -5.765715770903818, 3: -5.884651106360805, 4: -6.090323621367287}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.785261998984476, 1: -6.0851057918758995, 2: -5.915846366261405, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -5.848042184095479, 2: -5.948106288303203, 3: -6.123734786224677, 4: -6.2420974471476125}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.0851057918758995, 2: -5.915846366261405, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.7335288512402, 1: -5.831239662384989, 2: -5.803186791165421, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.993184788803848, 2: -6.061276898146589, 3: -5.809698786765817, 4: -5.987856261536629}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -6.276639775081287, 2: -5.948106288303203, 3: -6.123734786224677, 4: -6.2420974471476125}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.993184788803848, 2: -6.061276898146589, 3: -6.298935972202176, 4: -5.987856261536629}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.822909802441791, 1: -5.993184788803848, 2: -6.061276898146589, 3: -6.298935972202176, 4: -5.987856261536629}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.198847920222031, 1: -5.993184788803848, 2: -6.061276898146589, 3: -6.298935972202176, 4: -5.987856261536629}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -5.993184788803848, 2: -6.061276898146589, 3: -6.298935972202176, 4: -5.987856261536629}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -5.993184788803848, 2: -6.061276898146589, 3: -6.298935972202176, 4: -6.348949197998333}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -5.831239662384989, 2: -5.803186791165421, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.554509299482154, 2: -5.741598888019798, 3: -5.773777987894761, 4: -5.425651278283589}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.554509299482154, 2: -5.741598888019798, 3: -5.773777987894761, 4: -5.425651278283589}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.554509299482154, 2: -5.741598888019798, 3: -5.773777987894761, 4: -5.837342663238066}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.3938943564804465, 2: -5.590376666494764, 3: -5.8467781945529005, 4: -5.485833586711051}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.585658210156753, 2: -5.312924352992819, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.19398962350137, 2: -5.163283806955773, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.19398962350137, 2: -5.163283806955773, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.19398962350137, 2: -5.598588264329754, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -6.238255416839464, 2: -6.146895301275894, 3: -6.179519769837662, 4: -5.8939611408709345}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-5.96200270634607 -6.0057446300195165 -6.061276898146589 -5.8137912579391315 -5.894206695797184 \n",
      "-5.9670687097069495 -5.916540977776323 -5.831239662384989 -5.741598888019798 -5.478273844000664 \n",
      "-5.822561813655965 -5.765715770903818 -5.477649990134797 -5.485833586711051 -5.348908498704691 \n",
      "-5.645605695963063 -5.38135522632172 -5.3568694434049595 -5.362065003012389 -5.293507486455594 \n",
      "-5.719559463121577 -5.417263855050694 -5.412905405988538 -5.265780725962446 -5.8939611408709345 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -6.190522966381536, 2: -5.96200270634607, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -6.276639775081287, 2: -6.211367568808171, 3: -6.123734786224677, 4: -6.2420974471476125}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0057446300195165, 1: -6.276639775081287, 2: -6.211367568808171, 3: -6.123734786224677, 4: -6.2420974471476125}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.36522761331776, 1: -6.276639775081287, 2: -6.211367568808171, 3: -6.123734786224677, 4: -6.2420974471476125}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -6.190522966381536, 2: -6.3608534209504155, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1471331945587595, 1: -6.190522966381536, 2: -6.3608534209504155, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.493891207048471, 1: -6.190522966381536, 2: -6.3608534209504155, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -5.9670687097069495, 3: -6.246605020756761, 4: -6.346295619376937}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.0851057918758995, 2: -6.135743006130702, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.0851057918758995, 2: -6.135743006130702, 3: -6.254275084443682, 4: -5.916540977776323}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.0851057918758995, 2: -6.135743006130702, 3: -6.254275084443682, 4: -6.284052289776454}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -5.769255974098932, 2: -5.765715770903818, 3: -5.884651106360805, 4: -6.090323621367287}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.655206070080741, 2: -5.743193031873651, 3: -5.8107676672001505, 4: -5.477649990134797}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.655206070080741, 2: -5.743193031873651, 3: -5.8107676672001505, 4: -5.477649990134797}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.655206070080741, 2: -5.743193031873651, 3: -5.8107676672001505, 4: -5.884661491022665}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.3568694434049595, 2: -5.4233043448814, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.752337772848043, 2: -5.412905405988538, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.678720811745642, 2: -5.265780725962446, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -5.9917233059052455, 1: -6.238255416839464, 2: -6.146895301275894, 3: -6.179519769837662, 4: -6.31861830622741}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.295842094838804 -6.211367568808171 -6.061276898146589 -5.8137912579391315 -5.894206695797184 \n",
      "-6.113906913595458 -6.135743006130702 -5.831239662384989 -5.741598888019798 -5.478273844000664 \n",
      "-5.822561813655965 -5.769255974098932 -5.743193031873651 -5.485833586711051 -5.348908498704691 \n",
      "-5.645605695963063 -5.38135522632172 -5.4233043448814 -5.362065003012389 -5.293507486455594 \n",
      "-5.719559463121577 -5.417263855050694 -5.545883231287669 -5.3178318629875365 -5.9917233059052455 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.352377951500783, 2: -6.3608534209504155, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.352377951500783, 2: -6.3608534209504155, 3: -6.295842094838804, 4: -6.337335980769723}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.352377951500783, 2: -6.3608534209504155, 3: -6.629216306303311, 4: -6.337335980769723}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.352377951500783, 2: -6.3608534209504155, 3: -6.696163775053806, 4: -6.337335980769723}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.352377951500783, 2: -6.3608534209504155, 3: -6.696163775053806, 4: -6.666975742500448}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.113906913595458, 2: -6.289105062969517, 3: -6.246605020756761, 4: -6.346295619376937}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -5.822561813655965, 2: -5.854623627528852, 3: -6.100468237660787, 4: -6.165600863187474}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.896654297472077, 2: -5.645605695963063, 3: -5.856772995652792, 4: -5.713528170641605}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.473787331585901, 2: -5.38135522632172, 3: -5.439777026730334, 4: -5.441510191857056}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.820140323191212, 2: -5.4233043448814, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.585658210156753, 2: -5.613552318933459, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.585658210156753, 2: -5.613552318933459, 3: -5.4274212426423825, 4: -5.362065003012389}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.412300642116519, 1: -5.585658210156753, 2: -5.613552318933459, 3: -5.4274212426423825, 4: -5.779479152741274}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.742858161572228, 2: -5.590376666494764, 3: -5.8467781945529005, 4: -5.485833586711051}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.742858161572228, 2: -5.590376666494764, 3: -5.8467781945529005, 4: -5.485833586711051}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.742858161572228, 2: -5.590376666494764, 3: -5.8467781945529005, 4: -5.8921085639070565}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.475651891431022, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.348908498704691}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.475651891431022, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.348908498704691}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.475651891431022, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.767506733821269}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.293507486455594, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.238255416839464, 2: -6.146895301275894, 3: -6.179519769837662, 4: -6.31861830622741}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.3608534209504155 -6.211367568808171 -6.061276898146589 -5.8137912579391315 -5.894206695797184 \n",
      "-6.227665760420877 -6.135743006130702 -5.831239662384989 -5.741598888019798 -5.478273844000664 \n",
      "-5.854623627528852 -5.769255974098932 -5.743193031873651 -5.685662978018529 -5.653036655180866 \n",
      "-5.713528170641605 -5.439777026730334 -5.570519694708023 -5.4274212426423825 -5.42978037813393 \n",
      "-5.719559463121577 -5.417263855050694 -5.545883231287669 -5.3178318629875365 -6.146895301275894 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.276639775081287, 2: -6.211367568808171, 3: -6.491551366215063, 4: -6.2420974471476125}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.199899779724376, 2: -6.061276898146589, 3: -6.298935972202176, 4: -6.389374598730951}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.827690719494672, 2: -5.90050776221195, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.8137912579391315, 1: -5.827690719494672, 2: -5.90050776221195, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.19055004472461, 1: -5.827690719494672, 2: -5.90050776221195, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.824505358697377, 2: -5.741598888019798, 3: -5.773777987894761, 4: -5.982886798904352}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -5.688963286247788, 2: -5.834039600885144, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -5.688963286247788, 2: -5.834039600885144, 3: -5.499428357939915, 4: -5.478273844000664}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -5.688963286247788, 2: -5.834039600885144, 3: -5.499428357939915, 4: -5.885229198040604}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.824505358697377, 2: -5.911561702442517, 3: -5.773777987894761, 4: -5.982886798904352}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -5.831239662384989, 2: -5.875096214526249, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.804584856166091, 2: -5.743193031873651, 3: -5.8107676672001505, 4: -6.069183065867667}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.685662978018529, 1: -5.742858161572228, 2: -5.791653550600276, 3: -5.8467781945529005, 4: -6.017415956251465}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -5.824505358697377, 2: -5.911561702442517, 3: -6.200681925321317, 4: -5.982886798904352}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -5.742858161572228, 2: -5.791653550600276, 3: -5.8467781945529005, 4: -6.017415956251465}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -5.585658210156753, 2: -5.613552318933459, 3: -5.4274212426423825, 4: -5.8619114353885085}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.820140323191212, 2: -5.785603086928175, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.820140323191212, 2: -5.785603086928175, 3: -5.649739404431975, 4: -5.570519694708023}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.820140323191212, 2: -5.785603086928175, 3: -5.649739404431975, 4: -5.969172922184301}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.473787331585901, 2: -5.8310120419861065, 3: -5.439777026730334, 4: -5.441510191857056}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.896654297472077, 2: -5.823458302916899, 3: -5.856772995652792, 4: -5.713528170641605}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.896654297472077, 2: -5.823458302916899, 3: -5.856772995652792, 4: -5.713528170641605}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.760505304277315, 1: -5.896654297472077, 2: -5.823458302916899, 3: -5.856772995652792, 4: -6.09931063528386}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -6.055196795095678, 2: -5.854623627528852, 3: -6.100468237660787, 4: -6.165600863187474}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -5.769255974098932, 2: -5.913468069099567, 3: -5.884651106360805, 4: -6.090323621367287}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.473787331585901, 2: -5.8310120419861065, 3: -6.071935520892733, 4: -5.441510191857056}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.473787331585901, 2: -5.8310120419861065, 3: -6.071935520892733, 4: -5.441510191857056}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.473787331585901, 2: -5.8310120419861065, 3: -6.071935520892733, 4: -5.85177427458992}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.7114629280122875, 2: -5.52719519536384, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.7114629280122875, 2: -5.52719519536384, 3: -5.529032717405759, 4: -5.417263855050694}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.460273741736189, 1: -5.7114629280122875, 2: -5.52719519536384, 3: -5.529032717405759, 4: -5.8297101080961315}, Best action: 0, Actual action: 0\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.677036920421961, 1: -5.835362455749653, 2: -5.8310120419861065, 3: -6.071935520892733, 4: -5.918945166043572}, Best action: 0, Actual action: 0\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -5.884548852814108, 2: -5.913468069099567, 3: -5.884651106360805, 4: -6.090323621367287}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -5.835362455749653, 2: -5.8310120419861065, 3: -6.071935520892733, 4: -5.918945166043572}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.725717908558505, 1: -5.820140323191212, 2: -5.785603086928175, 3: -5.871193332094768, 4: -6.073206209808331}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -5.804584856166091, 2: -6.079706315382373, 3: -5.8107676672001505, 4: -6.069183065867667}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -5.820140323191212, 2: -5.785603086928175, 3: -5.871193332094768, 4: -6.073206209808331}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -5.585658210156753, 2: -5.613552318933459, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.3178318629875365, 1: -5.678720811745642, 2: -5.379873950379494, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -5.7660096300355805, 2: -5.613552318933459, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 2, Actual action: 2\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.508335942679033, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 4, Actual action: 4\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.508335942679033, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.42978037813393}, Best action: 4, Actual action: 4\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.448638989628754, 1: -5.508335942679033, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.841100144101877}, Best action: 0, Actual action: 0\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.653036655180866, 1: -5.7353062531721335, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.912028705441255}, Best action: 0, Actual action: 0\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -5.688963286247788, 2: -5.834039600885144, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.7353062531721335, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.912028705441255}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.7353062531721335, 2: -5.685927189983185, 3: -5.703102226918265, 4: -5.912028705441255}, Best action: 2, Actual action: 2\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.7353062531721335, 2: -6.074193742884699, 3: -5.703102226918265, 4: -5.912028705441255}, Best action: 3, Actual action: 3\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -5.870497022697553, 2: -5.791653550600276, 3: -5.8467781945529005, 4: -6.017415956251465}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.7353062531721335, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -5.912028705441255}, Best action: 1, Actual action: 1\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.508335942679033, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.897507596009478}, Best action: 1, Actual action: 1\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.238255416839464, 2: -6.545897260862208, 3: -6.179519769837662, 4: -6.31861830622741}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.3608534209504155 -6.2420974471476125 -6.199899779724376 -5.90050776221195 -5.894206695797184 \n",
      "-6.227665760420877 -6.135743006130702 -5.875096214526249 -5.911561702442517 -5.812426726199046 \n",
      "-6.055196795095678 -5.884651106360805 -5.8107676672001505 -5.8467781945529005 -5.912028705441255 \n",
      "-5.823458302916899 -5.835362455749653 -5.820140323191212 -5.7660096300355805 -5.556244607836409 \n",
      "-5.719559463121577 -5.52719519536384 -5.545883231287669 -5.379873950379494 -6.179519769837662 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.4875023951624, 2: -6.3608534209504155, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.276639775081287, 2: -6.430771044379555, 3: -6.491551366215063, 4: -6.2420974471476125}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.276639775081287, 2: -6.430771044379555, 3: -6.491551366215063, 4: -6.2420974471476125}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.276639775081287, 2: -6.430771044379555, 3: -6.491551366215063, 4: -6.580308676904327}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.178740353619682, 2: -6.135743006130702, 3: -6.254275084443682, 4: -6.457340920397124}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.135110322056156, 2: -5.875096214526249, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -6.134165646743242, 2: -5.911561702442517, 3: -6.200681925321317, 4: -5.982886798904352}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.812426726199046, 1: -6.074497352511159, 2: -5.834039600885144, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -5.895743791799554, 2: -5.905034318352416, 3: -5.894206695797184, 4: -6.1107177595444675}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.133464171245504, 2: -5.90050776221195, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -5.895743791799554, 2: -5.905034318352416, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.074497352511159, 2: -5.834039600885144, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.074497352511159, 2: -5.834039600885144, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.074497352511159, 2: -6.208976036805481, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.074497352511159, 2: -6.334776114366216, 3: -6.126703005988748, 4: -5.943059889735392}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.074497352511159, 2: -6.334776114366216, 3: -6.126703005988748, 4: -6.308184499659207}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.9352827388872305, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -5.912028705441255}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.9352827388872305, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -5.912028705441255}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.9352827388872305, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.279946121951542}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.556244607836409, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.897507596009478}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.238255416839464, 2: -6.545897260862208, 3: -6.670243247953603, 4: -6.31861830622741}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.4875023951624 -6.430771044379555 -6.199899779724376 -5.9770669903884155 -5.905034318352416 \n",
      "-6.227665760420877 -6.178740353619682 -5.9486480856852975 -5.982886798904352 -6.126703005988748 \n",
      "-6.055196795095678 -5.884651106360805 -5.8107676672001505 -5.8467781945529005 -5.994086406236215 \n",
      "-5.823458302916899 -5.835362455749653 -5.820140323191212 -5.7660096300355805 -5.608611348423606 \n",
      "-5.719559463121577 -5.52719519536384 -5.545883231287669 -5.379873950379494 -6.238255416839464 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.227665760420877, 2: -6.289105062969517, 3: -6.246605020756761, 4: -6.346295619376937}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -6.055196795095678, 2: -6.1585597017730205, 3: -6.100468237660787, 4: -6.165600863187474}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -5.896654297472077, 2: -5.823458302916899, 3: -5.856772995652792, 4: -6.175940359993011}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -5.835362455749653, 2: -6.120932710131, 3: -6.071935520892733, 4: -5.918945166043572}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -5.7114629280122875, 2: -5.52719519536384, 3: -5.529032717405759, 4: -5.905792741615926}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.752337772848043, 2: -5.706572928628435, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.752337772848043, 2: -5.706572928628435, 3: -5.742495060394075, 4: -5.545883231287669}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.571940091016, 1: -5.752337772848043, 2: -5.706572928628435, 3: -5.742495060394075, 4: -5.946753740471778}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -5.820140323191212, 2: -6.002943458919788, 3: -5.871193332094768, 4: -6.073206209808331}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -5.752337772848043, 2: -5.706572928628435, 3: -5.742495060394075, 4: -6.007946847770138}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.379873950379494, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.568234807624857, 2: -6.545897260862208, 3: -6.670243247953603, 4: -6.31861830622741}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.4875023951624 -6.430771044379555 -6.199899779724376 -5.9770669903884155 -5.905034318352416 \n",
      "-6.246605020756761 -6.178740353619682 -5.9486480856852975 -5.982886798904352 -6.126703005988748 \n",
      "-6.100468237660787 -5.884651106360805 -5.8107676672001505 -5.8467781945529005 -5.994086406236215 \n",
      "-5.856772995652792 -5.918945166043572 -5.871193332094768 -5.7660096300355805 -5.608611348423606 \n",
      "-5.719559463121577 -5.529032717405759 -5.742495060394075 -5.629063183920355 -6.31861830622741 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.4875023951624, 2: -6.592184274284607, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.427475980069587, 2: -6.289105062969517, 3: -6.246605020756761, 4: -6.346295619376937}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.427475980069587, 2: -6.289105062969517, 3: -6.246605020756761, 4: -6.346295619376937}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.261892395083906, 1: -6.427475980069587, 2: -6.289105062969517, 3: -6.584410568888654, 4: -6.346295619376937}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.608500306329217, 2: -6.592184274284607, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.563712723473892, 1: -6.608500306329217, 2: -6.592184274284607, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.872978578361242, 1: -6.608500306329217, 2: -6.592184274284607, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.497615812473997, 2: -6.430771044379555, 3: -6.491551366215063, 4: -6.6421090855062745}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.199899779724376, 2: -6.215298608745355, 3: -6.298935972202176, 4: -6.389374598730951}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.135110322056156, 2: -6.275874600431064, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.135110322056156, 2: -6.275874600431064, 3: -6.128479202530406, 4: -5.9486480856852975}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.135110322056156, 2: -6.275874600431064, 3: -6.128479202530406, 4: -6.313269757973621}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.178740353619682, 2: -6.2724022343793315, 3: -6.254275084443682, 4: -6.457340920397124}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -6.211574639290157, 2: -5.913468069099567, 3: -5.884651106360805, 4: -6.090323621367287}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -6.2225209048722565, 2: -6.1585597017730205, 3: -6.100468237660787, 4: -6.165600863187474}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -6.2225209048722565, 2: -6.1585597017730205, 3: -6.100468237660787, 4: -6.165600863187474}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.1067507473759575, 1: -6.2225209048722565, 2: -6.1585597017730205, 3: -6.451426096271316, 4: -6.165600863187474}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.427475980069587, 2: -6.289105062969517, 3: -6.63057389690683, 4: -6.346295619376937}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.215440369015786, 1: -6.284441431514221, 2: -6.2724022343793315, 3: -6.254275084443682, 4: -6.457340920397124}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.497615812473997, 2: -6.5649959260147, 3: -6.491551366215063, 4: -6.6421090855062745}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.608500306329217, 2: -6.768142973375901, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.427475980069587, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.346295619376937}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.427475980069587, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.346295619376937}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.427475980069587, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.675129013633013}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.2225209048722565, 2: -6.1585597017730205, 3: -6.4916107150016575, 4: -6.165600863187474}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -6.211574639290157, 2: -5.913468069099567, 3: -6.429844383141318, 4: -6.090323621367287}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -6.166796986028431, 2: -6.079706315382373, 3: -5.8107676672001505, 4: -6.069183065867667}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -6.211574639290157, 2: -6.198068617342079, 3: -6.429844383141318, 4: -6.090323621367287}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -6.211574639290157, 2: -6.198068617342079, 3: -6.429844383141318, 4: -6.090323621367287}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.155005814480465, 1: -6.211574639290157, 2: -6.198068617342079, 3: -6.429844383141318, 4: -6.442194495444231}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.284441431514221, 2: -6.2724022343793315, 3: -6.254275084443682, 4: -6.457340920397124}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.531180956443105, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.2225209048722565, 2: -6.305765106147952, 3: -6.4916107150016575, 4: -6.165600863187474}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.2225209048722565, 2: -6.305765106147952, 3: -6.4916107150016575, 4: -6.165600863187474}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.2225209048722565, 2: -6.305765106147952, 3: -6.4916107150016575, 4: -6.510696785500601}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -5.896654297472077, 2: -6.208989419448909, 3: -5.856772995652792, 4: -6.175940359993011}, Best action: 3, Actual action: 3\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -5.896654297472077, 2: -6.208989419448909, 3: -5.856772995652792, 4: -6.175940359993011}, Best action: 3, Actual action: 3\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -5.896654297472077, 2: -6.208989419448909, 3: -6.22966342604404, 4: -6.175940359993011}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.719559463121577, 1: -6.327873962166664, 2: -5.842424069433392, 3: -5.998423417697027, 4: -6.06142613715828}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -6.122508594875685, 2: -6.208989419448909, 3: -6.299256323556786, 4: -6.175940359993011}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -5.842424069433392, 3: -5.998423417697027, 4: -6.06142613715828}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -5.7114629280122875, 2: -5.9448849368793955, 3: -5.529032717405759, 4: -5.905792741615926}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -5.962758908042004, 3: -5.998423417697027, 4: -6.06142613715828}, Best action: 2, Actual action: 2\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -5.7114629280122875, 2: -5.9448849368793955, 3: -6.282737987254599, 4: -5.905792741615926}, Best action: 1, Actual action: 1\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -5.7114629280122875, 2: -5.9448849368793955, 3: -6.282737987254599, 4: -5.905792741615926}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -6.097431264491182, 2: -5.9448849368793955, 3: -6.282737987254599, 4: -5.905792741615926}, Best action: 4, Actual action: 4\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -6.293435247158019, 2: -5.9448849368793955, 3: -6.282737987254599, 4: -5.905792741615926}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -6.293435247158019, 2: -5.9448849368793955, 3: -6.282737987254599, 4: -6.274271394870493}, Best action: 2, Actual action: 2\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -5.752337772848043, 2: -5.828355192670234, 3: -5.742495060394075, 4: -6.007946847770138}, Best action: 3, Actual action: 3\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.044427279715408, 1: -6.293435247158019, 2: -6.1459094926071405, 3: -6.282737987254599, 4: -6.34278393835936}, Best action: 0, Actual action: 0\n",
      "Step: 50\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -5.9605643538196755, 2: -6.120932710131, 3: -6.071935520892733, 4: -5.918945166043572}, Best action: 4, Actual action: 4\n",
      "Step: 51\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -5.9605643538196755, 2: -6.120932710131, 3: -6.071935520892733, 4: -5.918945166043572}, Best action: 4, Actual action: 4\n",
      "Step: 52\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -5.9605643538196755, 2: -6.120932710131, 3: -6.071935520892733, 4: -6.28624010109965}, Best action: 1, Actual action: 1\n",
      "Step: 53\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.293435247158019, 2: -6.1459094926071405, 3: -6.282737987254599, 4: -6.34278393835936}, Best action: 2, Actual action: 2\n",
      "Step: 54\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -5.752337772848043, 2: -5.828355192670234, 3: -6.370235602608888, 4: -6.007946847770138}, Best action: 1, Actual action: 1\n",
      "Step: 55\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -5.752337772848043, 2: -5.828355192670234, 3: -6.370235602608888, 4: -6.007946847770138}, Best action: 1, Actual action: 1\n",
      "Step: 56\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.134627373291719, 2: -5.828355192670234, 3: -6.370235602608888, 4: -6.007946847770138}, Best action: 2, Actual action: 2\n",
      "Step: 57\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.656068223082152, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 4, Actual action: 4\n",
      "Step: 58\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.656068223082152, 3: -5.64642493715828, 4: -5.629063183920355}, Best action: 4, Actual action: 4\n",
      "Step: 59\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.656068223082152, 3: -5.64642493715828, 4: -6.022447497367523}, Best action: 3, Actual action: 3\n",
      "Step: 60\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.234430443392061, 2: -6.042376698242511, 3: -6.370235602608888, 4: -6.007946847770138}, Best action: 4, Actual action: 4\n",
      "Step: 61\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.234430443392061, 2: -6.042376698242511, 3: -6.370235602608888, 4: -6.007946847770138}, Best action: 4, Actual action: 4\n",
      "Step: 62\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.234430443392061, 2: -6.042376698242511, 3: -6.370235602608888, 4: -6.367231631470826}, Best action: 2, Actual action: 2\n",
      "Step: 63\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.656068223082152, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 2, Actual action: 2\n",
      "Step: 64\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.568234807624857, 2: -6.545897260862208, 3: -6.670243247953603, 4: -6.786738770704285}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.696163775053806 -6.4967479381737645 -6.215298608745355 -5.9770669903884155 -5.905034318352416 \n",
      "-6.547254794826165 -6.2724022343793315 -6.135110322056156 -5.982886798904352 -6.126703005988748 \n",
      "-6.266238216965987 -6.198068617342079 -5.891389042877181 -5.8467781945529005 -5.994086406236215 \n",
      "-6.175940359993011 -6.071935520892733 -5.871193332094768 -5.7660096300355805 -5.608611348423606 \n",
      "-5.998423417697027 -6.173984545267629 -6.085652930520794 -5.678720811745642 -6.545897260862208 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.497615812473997, 2: -6.5649959260147, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.4967479381737645, 1: -6.497615812473997, 2: -6.5649959260147, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.812040623738126, 1: -6.497615812473997, 2: -6.5649959260147, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.284441431514221, 2: -6.2724022343793315, 3: -6.8156840831632834, 4: -6.457340920397124}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.135110322056156, 2: -6.275874600431064, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.891389042877181, 1: -6.166796986028431, 2: -6.079706315382373, 3: -6.4142389000275175, 4: -6.069183065867667}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.179208902404332, 1: -6.285536156936133, 2: -6.275874600431064, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.338394927377529, 2: -6.215298608745355, 3: -6.298935972202176, 4: -6.389374598730951}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.133464171245504, 2: -6.2656032475788335, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.133464171245504, 2: -6.2656032475788335, 3: -6.147249612834245, 4: -5.9770669903884155}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.133464171245504, 2: -6.2656032475788335, 3: -6.147249612834245, 4: -6.339130961253458}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -6.134165646743242, 2: -6.199221818465479, 3: -6.200681925321317, 4: -5.982886798904352}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -6.134165646743242, 2: -6.199221818465479, 3: -6.200681925321317, 4: -5.982886798904352}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.061528883134312, 1: -6.134165646743242, 2: -6.199221818465479, 3: -6.200681925321317, 4: -6.344426987002961}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.359484724237076, 2: -6.2656032475788335, 3: -6.147249612834245, 4: -6.502019074834204}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.338394927377529, 2: -6.362954123089152, 3: -6.298935972202176, 4: -6.389374598730951}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.630407391094659, 2: -6.5649959260147, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.338394927377529, 2: -6.362954123089152, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.285536156936133, 2: -6.275874600431064, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.134165646743242, 2: -6.199221818465479, 3: -6.200681925321317, 4: -6.444281094039089}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -5.870497022697553, 2: -6.124763420129456, 3: -5.8467781945529005, 4: -6.017415956251465}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.166796986028431, 2: -6.079706315382373, 3: -6.4142389000275175, 4: -6.069183065867667}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.166796986028431, 2: -6.079706315382373, 3: -6.4142389000275175, 4: -6.069183065867667}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.166796986028431, 2: -6.079706315382373, 3: -6.4142389000275175, 4: -6.422956589939576}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -5.870497022697553, 2: -6.124763420129456, 3: -6.4007161028081, 4: -6.017415956251465}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -5.7660096300355805, 2: -5.859477338181829, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.867783603606604, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -5.678720811745642, 2: -5.867783603606604, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -6.067635938688534, 2: -5.867783603606604, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.568234807624857, 2: -6.81695555600697, 3: -6.670243247953603, 4: -6.786738770704285}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.696163775053806 -6.630407391094659 -6.362954123089152 -6.239484487263146 -5.905034318352416 \n",
      "-6.547254794826165 -6.284441431514221 -6.285536156936133 -6.199221818465479 -6.126703005988748 \n",
      "-6.266238216965987 -6.198068617342079 -6.166796986028431 -6.017415956251465 -5.994086406236215 \n",
      "-6.175940359993011 -6.071935520892733 -5.871193332094768 -5.859477338181829 -5.608611348423606 \n",
      "-5.998423417697027 -6.173984545267629 -6.085652930520794 -5.907048554536795 -6.568234807624857 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.547254794826165, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.266238216965987, 2: -6.305765106147952, 3: -6.4916107150016575, 4: -6.591311611496588}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -6.244614355728616, 2: -6.208989419448909, 3: -6.299256323556786, 4: -6.175940359993011}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -6.244614355728616, 2: -6.208989419448909, 3: -6.299256323556786, 4: -6.175940359993011}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -6.244614355728616, 2: -6.208989419448909, 3: -6.299256323556786, 4: -6.5201057275936405}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -6.474243124393751, 2: -6.120932710131, 3: -6.071935520892733, 4: -6.356681136703902}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.2182956687261015, 1: -6.244614355728616, 2: -6.439166713868005, 3: -6.299256323556786, 4: -6.581292002512981}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.529135513290938, 2: -6.305765106147952, 3: -6.4916107150016575, 4: -6.591311611496588}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.211574639290157, 2: -6.198068617342079, 3: -6.429844383141318, 4: -6.5297741592736}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.166796986028431, 2: -6.263073219923255, 3: -6.4142389000275175, 4: -6.46685777445368}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.1043381045081535, 2: -6.002943458919788, 3: -5.871193332094768, 4: -6.073206209808331}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -6.474243124393751, 2: -6.120932710131, 3: -6.544013043757415, 4: -6.356681136703902}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.1043381045081535, 2: -6.002943458919788, 3: -6.445074828415587, 4: -6.073206209808331}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -6.076364820517528, 2: -5.859477338181829, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.608611348423606, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.897507596009478}, Best action: 1, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.608611348423606, 2: -5.666990421469085, 3: -5.622718040996648, 4: -5.897507596009478}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.598804427409956, 1: -6.860099864571679, 2: -6.81695555600697, 3: -6.670243247953603, 4: -6.786738770704285}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.696163775053806 -6.630407391094659 -6.362954123089152 -6.239484487263146 -5.905034318352416 \n",
      "-6.563417205199738 -6.284441431514221 -6.285536156936133 -6.199221818465479 -6.126703005988748 \n",
      "-6.4916107150016575 -6.211574639290157 -6.263073219923255 -6.017415956251465 -5.994086406236215 \n",
      "-6.244614355728616 -6.234188262821624 -6.073206209808331 -5.8619114353885085 -5.622718040996648 \n",
      "-5.998423417697027 -6.173984545267629 -6.085652930520794 -5.907048554536795 -6.598804427409956 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.701349482328241, 2: -6.768142973375901, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.701349482328241, 2: -6.768142973375901, 3: -6.696163775053806, 4: -6.712123714965679}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.701349482328241, 2: -6.768142973375901, 3: -6.993509035298964, 4: -6.712123714965679}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.630378435225066, 2: -6.563417205199738, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.284441431514221, 2: -6.496679584303419, 3: -6.8156840831632834, 4: -6.457340920397124}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.211574639290157, 2: -6.514912420417238, 3: -6.429844383141318, 4: -6.5297741592736}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.234188262821624, 1: -6.474243124393751, 2: -6.3744774727381275, 3: -6.544013043757415, 4: -6.356681136703902}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.5708499568145315, 2: -6.514912420417238, 3: -6.429844383141318, 4: -6.5297741592736}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.529135513290938, 2: -6.551012090661879, 3: -6.4916107150016575, 4: -6.591311611496588}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.529135513290938, 2: -6.551012090661879, 3: -6.4916107150016575, 4: -6.591311611496588}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.529135513290938, 2: -6.551012090661879, 3: -6.807365750651509, 4: -6.591311611496588}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.244614355728616, 2: -6.439166713868005, 3: -6.299256323556786, 4: -6.581292002512981}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.122560862494153, 3: -5.998423417697027, 4: -6.06142613715828}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.122560862494153, 3: -5.998423417697027, 4: -6.06142613715828}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.122560862494153, 3: -6.358565310104295, 4: -6.06142613715828}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.122560862494153, 3: -6.4456117021086365, 4: -6.06142613715828}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.122560862494153, 3: -6.4456117021086365, 4: -6.415897784814035}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.293435247158019, 2: -6.173984545267629, 3: -6.282737987254599, 4: -6.34278393835936}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.234430443392061, 2: -6.085652930520794, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -6.259668312790203, 2: -5.907048554536795, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -6.860099864571679, 2: -6.81695555600697, 3: -6.670243247953603, 4: -6.786738770704285}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-6.712123714965679 -6.630407391094659 -6.362954123089152 -6.239484487263146 -5.905034318352416 \n",
      "-6.630378435225066 -6.457340920397124 -6.285536156936133 -6.199221818465479 -6.126703005988748 \n",
      "-6.551012090661879 -6.514912420417238 -6.263073219923255 -6.017415956251465 -5.994086406236215 \n",
      "-6.299256323556786 -6.356681136703902 -6.073206209808331 -5.8619114353885085 -5.622718040996648 \n",
      "-6.327873962166664 -6.282737987254599 -6.171507670886482 -5.978760564634855 -6.670243247953603 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.886502884444612, 2: -6.768142973375901, 3: -7.027443984215772, 4: -6.712123714965679}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.886502884444612, 2: -6.768142973375901, 3: -7.027443984215772, 4: -6.712123714965679}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.886502884444612, 2: -6.768142973375901, 3: -7.027443984215772, 4: -7.008032580618768}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.630407391094659, 2: -6.690599483777268, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.55981960097645, 2: -6.496679584303419, 3: -6.8156840831632834, 4: -6.457340920397124}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.55981960097645, 2: -6.496679584303419, 3: -6.8156840831632834, 4: -6.457340920397124}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.55981960097645, 2: -6.496679584303419, 3: -6.8156840831632834, 4: -6.776180237561383}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.285536156936133, 2: -6.4962616339051324, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.272346297599605, 2: -6.263073219923255, 3: -6.4142389000275175, 4: -6.46685777445368}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -6.1575175025985756, 2: -6.124763420129456, 3: -6.4007161028081, 4: -6.017415956251465}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -6.1575175025985756, 2: -6.124763420129456, 3: -6.4007161028081, 4: -6.017415956251465}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -6.1575175025985756, 2: -6.124763420129456, 3: -6.4007161028081, 4: -6.375848520188834}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -5.994086406236215, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.905892721044425, 2: -6.00967423437003, 3: -5.622718040996648, 4: -5.897507596009478}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -6.076364820517528, 2: -6.076209975208142, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -6.076364820517528, 2: -6.076209975208142, 3: -5.954863076977737, 4: -5.8619114353885085}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.884755269447603, 1: -6.076364820517528, 2: -6.076209975208142, 3: -5.954863076977737, 4: -6.234339406203543}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -6.1575175025985756, 2: -6.36768633106428, 3: -6.4007161028081, 4: -6.498643222323744}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.076364820517528, 2: -6.076209975208142, 3: -5.954863076977737, 4: -6.290085708872913}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.1043381045081535, 2: -6.24647098981926, 3: -6.445074828415587, 4: -6.073206209808331}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.1043381045081535, 2: -6.24647098981926, 3: -6.445074828415587, 4: -6.073206209808331}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.1043381045081535, 2: -6.24647098981926, 3: -6.445074828415587, 4: -6.426617650925581}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.171507670886482, 1: -6.234430443392061, 2: -6.293274622226884, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.174285524350384, 1: -6.509355023868866, 2: -6.24647098981926, 3: -6.445074828415587, 4: -6.487175629744162}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.272346297599605, 2: -6.4004142465560125, 3: -6.4142389000275175, 4: -6.46685777445368}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.24647098981926, 3: -6.445074828415587, 4: -6.487175629744162}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.076364820517528, 2: -6.076209975208142, 3: -6.414783337642522, 4: -6.290085708872913}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.905892721044425, 2: -6.00967423437003, 3: -6.210420066764357, 4: -5.897507596009478}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.905892721044425, 2: -6.00967423437003, 3: -6.210420066764357, 4: -5.897507596009478}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -5.905892721044425, 2: -6.00967423437003, 3: -6.210420066764357, 4: -6.266731912368625}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -6.860099864571679, 2: -6.81695555600697, 3: -7.003844533917561, 4: -6.786738770704285}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-6.886502884444612 -6.6421090855062745 -6.362954123089152 -6.239484487263146 -5.905034318352416 \n",
      "-6.630378435225066 -6.55981960097645 -6.495395129846991 -6.199221818465479 -6.126703005988748 \n",
      "-6.551012090661879 -6.514912420417238 -6.4004142465560125 -6.186415638346729 -6.053810253830906 \n",
      "-6.299256323556786 -6.356681136703902 -6.445074828415587 -6.076364820517528 -6.00967423437003 \n",
      "-6.327873962166664 -6.282737987254599 -6.234430443392061 -5.978760564634855 -6.786738770704285 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.886502884444612, 2: -6.947444284124264, 3: -7.027443984215772, 4: -7.082999066496356}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.630378435225066, 2: -6.646739280046493, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.611051179469273, 2: -6.551012090661879, 3: -6.869336340830811, 4: -6.591311611496588}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.5708499568145315, 2: -6.514912420417238, 3: -6.801189117465475, 4: -6.5297741592736}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.586876131513561, 2: -6.4004142465560125, 3: -6.4142389000275175, 4: -6.46685777445368}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.186415638346729, 1: -6.339190842611824, 2: -6.36768633106428, 3: -6.4007161028081, 4: -6.498643222323744}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.249306902262174, 2: -6.199221818465479, 3: -6.200681925321317, 4: -6.444281094039089}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.296192986658532, 2: -6.334776114366216, 3: -6.126703005988748, 4: -6.4511613054999595}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.249306902262174, 2: -6.482551616697434, 3: -6.200681925321317, 4: -6.444281094039089}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.4962616339051324, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.4962616339051324, 3: -6.517627606684983, 4: -6.495395129846991}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.4962616339051324, 3: -6.517627606684983, 4: -6.810809568160762}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.249306902262174, 2: -6.482551616697434, 3: -6.781338247708194, 4: -6.444281094039089}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.339190842611824, 2: -6.36768633106428, 3: -6.4007161028081, 4: -6.498643222323744}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.076364820517528, 2: -6.2846021502884915, 3: -6.414783337642522, 4: -6.290085708872913}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.978760564634855, 1: -6.259668312790203, 2: -5.993601886296098, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.350432539405984, 2: -6.2846021502884915, 3: -6.414783337642522, 4: -6.290085708872913}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -6.087847676374913, 2: -6.00967423437003, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -6.087847676374913, 2: -6.00967423437003, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.0238235896593775, 1: -6.087847676374913, 2: -6.368803553276727, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -6.053810253830906, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.087847676374913, 2: -6.416177462951769, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -6.860099864571679, 2: -6.81695555600697, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.926967120006656 -6.6421090855062745 -6.362954123089152 -6.239484487263146 -5.905034318352416 \n",
      "-6.63057389690683 -6.55981960097645 -6.517627606684983 -6.444281094039089 -6.255550096215623 \n",
      "-6.591311611496588 -6.5297741592736 -6.4142389000275175 -6.36768633106428 -6.073363927378796 \n",
      "-6.299256323556786 -6.356681136703902 -6.445074828415587 -6.290085708872913 -6.130518768003138 \n",
      "-6.327873962166664 -6.282737987254599 -6.234430443392061 -5.993601886296098 -6.81695555600697 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -6.690599483777268, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -6.690599483777268, 3: -6.902040384748172, 4: -6.6421090855062745}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -6.690599483777268, 3: -6.902040384748172, 4: -6.94431926781071}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.617297919086915, 2: -6.362954123089152, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.359484724237076, 2: -6.2656032475788335, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.239484487263146, 1: -6.359484724237076, 2: -6.2656032475788335, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.577930883409463, 1: -6.359484724237076, 2: -6.2656032475788335, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -6.215146455896923, 2: -5.905034318352416, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -6.215146455896923, 2: -5.905034318352416, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -6.215146455896923, 2: -6.2735812297006985, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5.914499185757333, 1: -6.215146455896923, 2: -6.31810246343351, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.282194259039173, 1: -6.215146455896923, 2: -6.31810246343351, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.215146455896923, 2: -6.31810246343351, 3: -6.268831956971398, 4: -6.1107177595444675}, Best action: 4, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.255550096215623, 1: -6.296192986658532, 2: -6.334776114366216, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.588510223524347, 2: -6.31810246343351, 3: -6.268831956971398, 4: -6.545340405230954}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.359484724237076, 2: -6.3096381226233405, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.588510223524347, 2: -6.31810246343351, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.588510223524347, 2: -6.31810246343351, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.588510223524347, 2: -6.649473241724494, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.477900811134936, 1: -6.588510223524347, 2: -6.812046981191748, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.794889738132792, 1: -6.588510223524347, 2: -6.812046981191748, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.588510223524347, 2: -6.812046981191748, 3: -6.6376900750220456, 4: -6.545340405230954}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.588510223524347, 2: -6.812046981191748, 3: -6.6376900750220456, 4: -6.856259768760168}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.296192986658532, 2: -6.334776114366216, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.073363927378796, 1: -6.436537643246771, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.449044079842677, 2: -6.334776114366216, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.449044079842677, 2: -6.334776114366216, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.449044079842677, 2: -6.664646264073257, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.1269321780922645, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.475508282063961, 3: -6.16154959867805, 4: -6.33557363069381}, Best action: 3, Actual action: 3\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.45577458888038, 2: -6.36768633106428, 3: -6.4007161028081, 4: -6.498643222323744}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.33557363069381}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.33557363069381}, Best action: 4, Actual action: 4\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.436537643246771, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.665372003931368}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.130518768003138, 2: -6.416177462951769, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -6.860099864571679, 2: -6.96180391486078, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.926967120006656 -6.72305278807994 -6.370048363866872 -6.359484724237076 -6.6376900750220456 \n",
      "-6.63057389690683 -6.55981960097645 -6.517627606684983 -6.444281094039089 -6.4511613054999595 \n",
      "-6.591311611496588 -6.5297741592736 -6.4142389000275175 -6.4007161028081 -6.509373966407219 \n",
      "-6.299256323556786 -6.356681136703902 -6.445074828415587 -6.290085708872913 -6.169732767103374 \n",
      "-6.327873962166664 -6.282737987254599 -6.234430443392061 -5.993601886296098 -6.860099864571679 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.646739280046493, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.646739280046493, 3: -6.63057389690683, 4: -6.773768445219667}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.646739280046493, 3: -6.9338222461852155, 4: -6.773768445219667}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.55981960097645, 2: -6.640952245548609, 3: -6.8156840831632834, 4: -6.839928487041908}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.5708499568145315, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.5297741592736}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.5708499568145315, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.5297741592736}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.5708499568145315, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.842094484938976}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.474243124393751, 2: -6.3744774727381275, 3: -6.544013043757415, 4: -6.356681136703902}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.474243124393751, 2: -6.3744774727381275, 3: -6.544013043757415, 4: -6.356681136703902}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.474243124393751, 2: -6.3744774727381275, 3: -6.544013043757415, 4: -6.68457983440055}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.446377178900521, 3: -6.445074828415587, 4: -6.487175629744162}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.474243124393751, 2: -6.757958358290438, 3: -6.544013043757415, 4: -6.731784736357938}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.293435247158019, 2: -6.446777328248607, 3: -6.282737987254599, 4: -6.34278393835936}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.513183567916196, 3: -6.4456117021086365, 4: -6.500864077101668}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.327873962166664, 2: -6.513183567916196, 3: -6.4456117021086365, 4: -6.500864077101668}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.431187908161463, 1: -6.658365305571665, 2: -6.513183567916196, 3: -6.4456117021086365, 4: -6.500864077101668}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.383184403907453, 2: -6.439166713868005, 3: -6.299256323556786, 4: -6.581292002512981}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.383184403907453, 2: -6.439166713868005, 3: -6.299256323556786, 4: -6.581292002512981}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.383184403907453, 2: -6.439166713868005, 3: -6.632323254436676, 4: -6.581292002512981}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.513183567916196, 3: -6.4456117021086365, 4: -6.500864077101668}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.513183567916196, 3: -6.4456117021086365, 4: -6.500864077101668}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.513183567916196, 3: -6.765506648918859, 4: -6.500864077101668}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.513183567916196, 3: -6.842250567344237, 4: -6.500864077101668}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.513183567916196, 3: -6.842250567344237, 4: -6.815786310162518}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.293435247158019, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.34278393835936}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.293435247158019, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.34278393835936}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.298788312466834, 1: -6.627026074913798, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.34278393835936}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.6364420821156, 2: -6.757958358290438, 3: -6.544013043757415, 4: -6.731784736357938}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.759263919098741, 2: -6.439166713868005, 3: -6.733611692608704, 4: -6.581292002512981}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.6364420821156, 2: -6.757958358290438, 3: -6.770126342608826, 4: -6.731784736357938}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.664721140589515, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.34278393835936}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.664721140589515, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.34278393835936}, Best action: 4, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.664721140589515, 2: -6.446777328248607, 3: -6.653851708080458, 4: -6.932702517713444}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.234430443392061, 2: -6.293274622226884, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.234430443392061, 2: -6.293274622226884, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.573331703486776, 2: -6.293274622226884, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -5.993601886296098, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 2, Actual action: 2\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -6.956774842951701, 2: -6.96180391486078, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-6.926967120006656 -6.72305278807994 -6.370048363866872 -6.359484724237076 -6.6376900750220456 \n",
      "-6.773768445219667 -6.640952245548609 -6.517627606684983 -6.444281094039089 -6.4511613054999595 \n",
      "-6.591311611496588 -6.581463399847429 -6.4142389000275175 -6.4007161028081 -6.509373966407219 \n",
      "-6.581292002512981 -6.7012991982826415 -6.446377178900521 -6.290085708872913 -6.169732767103374 \n",
      "-6.645516412897144 -6.594566391972431 -6.370235602608888 -6.07584894883496 -6.956774842951701 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.878127804795574, 3: -6.977241041456181, 4: -6.773768445219667}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.878127804795574, 3: -6.977241041456181, 4: -6.773768445219667}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.842796545522243, 1: -6.869357636958629, 2: -6.878127804795574, 3: -6.977241041456181, 4: -7.064129285149897}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.959256820976766, 2: -6.947444284124264, 3: -7.027443984215772, 4: -7.082999066496356}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.926967120006656, 1: -6.959256820976766, 2: -6.947444284124264, 3: -7.027443984215772, 4: -7.082999066496356}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203540079206057, 1: -6.959256820976766, 2: -6.947444284124264, 3: -7.027443984215772, 4: -7.082999066496356}, Best action: 2, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -6.959256820976766, 2: -6.947444284124264, 3: -7.027443984215772, 4: -7.082999066496356}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -6.72305278807994, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.617297919086915, 2: -6.590277846992064, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.370048363866872, 1: -6.617297919086915, 2: -6.590277846992064, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.696744011118854, 1: -6.617297919086915, 2: -6.590277846992064, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7450678260839565, 1: -6.617297919086915, 2: -6.590277846992064, 3: -6.847540297292125, 4: -6.389374598730951}, Best action: 4, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.611564754222874, 3: -6.517627606684983, 4: -6.843052880279234}, Best action: 3, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.611564754222874, 3: -6.517627606684983, 4: -6.843052880279234}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.845099029109261, 2: -6.640952245548609, 3: -6.8156840831632834, 4: -6.839928487041908}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.552312763324172, 1: -6.6016429238314505, 2: -6.611564754222874, 3: -6.930934079562872, 4: -6.863583649442759}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7450678260839565, 1: -7.104602624934871, 2: -6.590277846992064, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.359484724237076, 2: -6.648626807643478, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.6596752727417945, 2: -6.482551616697434, 3: -6.781338247708194, 4: -6.444281094039089}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.6596752727417945, 2: -6.482551616697434, 3: -6.781338247708194, 4: -6.444281094039089}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.6596752727417945, 2: -6.482551616697434, 3: -6.781338247708194, 4: -6.7642957955755705}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.507719472239002, 2: -6.790190331079895, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.507719472239002, 2: -6.790190331079895, 3: -6.535222660109142, 4: -6.4511613054999595}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.507719472239002, 2: -6.790190331079895, 3: -6.535222660109142, 4: -6.7705567880049635}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.509373966407219, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.169732767103374, 2: -6.416177462951769, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -7.0824299249231, 2: -6.96180391486078, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-6.959256820976766 -6.73204445354016 -6.710210411331238 -6.502019074834204 -6.6376900750220456 \n",
      "-6.869357636958629 -6.779700643535779 -6.6016429238314505 -6.48542507470917 -6.535222660109142 \n",
      "-6.591311611496588 -6.581463399847429 -6.4142389000275175 -6.4007161028081 -6.538406003135617 \n",
      "-6.581292002512981 -6.7012991982826415 -6.446377178900521 -6.290085708872913 -6.210420066764357 \n",
      "-6.645516412897144 -6.594566391972431 -6.370235602608888 -6.07584894883496 -6.96180391486078 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -6.73204445354016, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7450678260839565, 1: -7.104602624934871, 2: -6.710210411331238, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.75581615859537, 2: -6.648626807643478, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.75581615859537, 2: -6.648626807643478, 3: -6.616863098767187, 4: -6.502019074834204}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.75581615859537, 2: -6.648626807643478, 3: -6.616863098767187, 4: -6.816837358099127}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7450678260839565, 1: -7.104602624934871, 2: -6.83765649174883, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.7450678260839565, 1: -7.104602624934871, 2: -6.83765649174883, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.0380117217364, 1: -7.104602624934871, 2: -6.83765649174883, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.75581615859537, 2: -6.648626807643478, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.632931718879801, 1: -6.75581615859537, 2: -6.648626807643478, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.935967864180619, 1: -6.75581615859537, 2: -6.648626807643478, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.658767341545846, 2: -6.812046981191748, 3: -6.6376900750220456, 4: -6.922319257930738}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.75581615859537, 2: -6.941391641532205, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.48542507470917, 1: -6.6596752727417945, 2: -6.773695819124711, 3: -6.781338247708194, 4: -6.827296389082479}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.8287759263739645, 2: -6.941391641532205, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.6596752727417945, 2: -6.773695819124711, 3: -6.781338247708194, 4: -6.827296389082479}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.45577458888038, 2: -6.668583273968415, 3: -6.4007161028081, 4: -6.498643222323744}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.586876131513561, 2: -6.5510380917164515, 3: -6.4142389000275175, 4: -6.46685777445368}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.581463399847429, 1: -6.705996716411613, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.906597913513668}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.779700643535779, 1: -6.845099029109261, 2: -6.87146856284744, 3: -6.8156840831632834, 4: -6.839928487041908}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -6.793486884631137, 2: -7.0084748785323185, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -6.845099029109261, 2: -6.87146856284744, 3: -6.8156840831632834, 4: -6.839928487041908}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -6.869357636958629, 2: -6.878127804795574, 3: -6.977241041456181, 4: -7.149078130388007}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.611051179469273, 2: -6.832180269604151, 3: -6.869336340830811, 4: -6.591311611496588}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.611051179469273, 2: -6.832180269604151, 3: -6.869336340830811, 4: -6.591311611496588}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.604850175742905, 1: -6.611051179469273, 2: -6.832180269604151, 3: -6.869336340830811, 4: -6.898093566461895}, Best action: 0, Actual action: 0\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -6.925898169008099, 2: -6.878127804795574, 3: -6.977241041456181, 4: -7.149078130388007}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -6.845099029109261, 2: -6.87146856284744, 3: -7.145748094252817, 4: -6.839928487041908}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -6.845099029109261, 2: -6.87146856284744, 3: -7.145748094252817, 4: -6.839928487041908}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -6.845099029109261, 2: -6.87146856284744, 3: -7.145748094252817, 4: -7.124334923208137}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.705996716411613, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.906597913513668}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.7012991982826415, 2: -6.757958358290438, 3: -6.770126342608826, 4: -6.731784736357938}, Best action: 1, Actual action: 1\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.594566391972431, 3: -6.653851708080458, 4: -6.932702517713444}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.384144990122528, 3: -6.370235602608888, 4: -6.431048288723517}, Best action: 3, Actual action: 3\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.719347477310443, 3: -6.653851708080458, 4: -6.932702517713444}, Best action: 3, Actual action: 3\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.645516412897144, 1: -6.775098736167951, 2: -6.649000906989615, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.759263919098741, 2: -6.919434757900437, 3: -6.733611692608704, 4: -6.581292002512981}, Best action: 4, Actual action: 4\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.759263919098741, 2: -6.919434757900437, 3: -6.733611692608704, 4: -6.581292002512981}, Best action: 4, Actual action: 4\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.629499302852451, 1: -6.759263919098741, 2: -6.919434757900437, 3: -6.733611692608704, 4: -6.888975722286813}, Best action: 0, Actual action: 0\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -6.611051179469273, 2: -6.832180269604151, 3: -6.869336340830811, 4: -6.939737998997943}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917901385655356, 1: -6.759263919098741, 2: -6.919434757900437, 3: -6.733611692608704, 4: -6.9587920075391665}, Best action: 3, Actual action: 3\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917901385655356, 1: -6.759263919098741, 2: -6.919434757900437, 3: -6.733611692608704, 4: -6.9587920075391665}, Best action: 3, Actual action: 3\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917901385655356, 1: -6.759263919098741, 2: -6.919434757900437, 3: -7.027586640273921, 4: -6.9587920075391665}, Best action: 1, Actual action: 1\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -6.775098736167951, 2: -6.649000906989615, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 2, Actual action: 2\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.719347477310443, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 2, Actual action: 2\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.384144990122528, 3: -6.92664344380606, 4: -6.431048288723517}, Best action: 2, Actual action: 2\n",
      "Step: 46\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -6.234347811420488, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 4, Actual action: 4\n",
      "Step: 47\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -6.234347811420488, 3: -6.33107944040964, 4: -6.07584894883496}, Best action: 4, Actual action: 4\n",
      "Step: 48\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -6.234347811420488, 3: -6.33107944040964, 4: -6.429022543439814}, Best action: 2, Actual action: 2\n",
      "Step: 49\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -6.983773100534579, 1: -7.0824299249231, 2: -7.049136398853608, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.959256820976766 -6.8442728704777505 -6.847540297292125 -6.941342845811334 -6.658767341545846 \n",
      "-6.925898169008099 -6.87146856284744 -6.6016429238314505 -6.750547570548741 -6.535222660109142 \n",
      "-6.832180269604151 -6.735826781752094 -6.46685777445368 -6.45577458888038 -6.538406003135617 \n",
      "-6.917901385655356 -6.73159277662663 -6.446377178900521 -6.290085708872913 -6.210420066764357 \n",
      "-6.775098736167951 -6.743092189730292 -6.431048288723517 -6.259668312790203 -6.983773100534579 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -6.959256820976766, 2: -7.040417186757177, 3: -7.230174268562231, 4: -7.082999066496356}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -6.925898169008099, 2: -7.128154854983503, 3: -6.977241041456181, 4: -7.149078130388007}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -6.832180269604151, 3: -6.869336340830811, 4: -6.939737998997943}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -6.735826781752094, 3: -6.801189117465475, 4: -6.906597913513668}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.586876131513561, 2: -6.5510380917164515, 3: -6.8724092438791695, 4: -6.46685777445368}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.586876131513561, 2: -6.5510380917164515, 3: -6.8724092438791695, 4: -6.46685777445368}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.494298115235226, 1: -6.586876131513561, 2: -6.5510380917164515, 3: -6.8724092438791695, 4: -6.784840574752849}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.6016429238314505, 2: -6.611564754222874, 3: -6.930934079562872, 4: -6.863583649442759}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.586876131513561, 2: -6.5510380917164515, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.45577458888038, 2: -6.668583273968415, 3: -6.735605119303099, 4: -6.498643222323744}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.350432539405984, 2: -6.396296344868573, 3: -6.414783337642522, 4: -6.290085708872913}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.350432539405984, 2: -6.396296344868573, 3: -6.414783337642522, 4: -6.290085708872913}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.350432539405984, 2: -6.396296344868573, 3: -6.414783337642522, 4: -6.623977995074351}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -6.2802909925750585, 3: -6.33107944040964, 4: -6.592723981594577}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.259668312790203, 2: -6.2802909925750585, 3: -6.33107944040964, 4: -6.592723981594577}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.5962981646390855, 2: -6.2802909925750585, 3: -6.33107944040964, 4: -6.592723981594577}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.235375335044639, 1: -7.0824299249231, 2: -7.049136398853608, 3: -7.003844533917561, 4: -7.156741213470564}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.040417186757177 -6.8442728704777505 -6.847540297292125 -6.941342845811334 -6.658767341545846 \n",
      "-6.977241041456181 -6.87146856284744 -6.611564754222874 -6.750547570548741 -6.535222660109142 \n",
      "-6.869336340830811 -6.801189117465475 -6.586876131513561 -6.498643222323744 -6.538406003135617 \n",
      "-6.917901385655356 -6.73159277662663 -6.446377178900521 -6.396296344868573 -6.210420066764357 \n",
      "-6.775098736167951 -6.743092189730292 -6.431048288723517 -6.301143171730731 -7.003844533917561 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.205903198994237, 2: -7.040417186757177, 3: -7.230174268562231, 4: -7.082999066496356}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -7.100052795825373, 2: -7.0084748785323185, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8442728704777505, 1: -7.100052795825373, 2: -7.0084748785323185, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.128288312134753, 1: -7.100052795825373, 2: -7.0084748785323185, 3: -6.902040384748172, 4: -7.013817508640658}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.205903198994237, 2: -7.147902743762695, 3: -7.230174268562231, 4: -7.082999066496356}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.205903198994237, 2: -7.147902743762695, 3: -7.230174268562231, 4: -7.082999066496356}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.205903198994237, 2: -7.147902743762695, 3: -7.230174268562231, 4: -7.345529150511684}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.100052795825373, 2: -7.0084748785323185, 3: -7.327433282336866, 4: -7.013817508640658}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.104602624934871, 2: -6.956440341467522, 3: -6.847540297292125, 4: -6.898948774333496}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.100052795825373, 2: -7.147355128659853, 3: -7.327433282336866, 4: -7.013817508640658}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.100052795825373, 2: -7.147355128659853, 3: -7.327433282336866, 4: -7.013817508640658}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.100052795825373, 2: -7.147355128659853, 3: -7.327433282336866, 4: -7.282573932862999}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -7.016367243204333, 2: -6.87146856284744, 3: -7.145748094252817, 4: -7.156963705899315}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.866505146673471, 2: -6.611564754222874, 3: -6.930934079562872, 4: -6.863583649442759}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.750547570548741, 2: -6.773695819124711, 3: -6.781338247708194, 4: -6.827296389082479}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.640546883075098, 2: -6.668583273968415, 3: -6.735605119303099, 4: -6.498643222323744}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.540011236791711, 1: -6.640546883075098, 2: -6.668583273968415, 3: -6.735605119303099, 4: -6.498643222323744}, Best action: 4, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.838955767137107, 2: -6.773695819124711, 3: -6.781338247708194, 4: -6.827296389082479}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.823364860013748, 2: -6.790190331079895, 3: -6.535222660109142, 4: -6.848308451314089}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.838955767137107, 2: -6.870899936600876, 3: -6.781338247708194, 4: -6.827296389082479}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.866505146673471, 2: -7.029100007566767, 3: -6.930934079562872, 4: -6.863583649442759}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.866505146673471, 2: -7.029100007566767, 3: -6.930934079562872, 4: -6.863583649442759}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.866505146673471, 2: -7.029100007566767, 3: -6.930934079562872, 4: -7.145861120992911}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.586876131513561, 2: -6.784281226164753, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.446377178900521, 3: -6.7886444136004975, 4: -6.487175629744162}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.6053745873006635, 2: -6.396296344868573, 3: -6.414783337642522, 4: -6.706248156426283}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.2560344477475684, 2: -6.416177462951769, 3: -6.210420066764357, 4: -6.310446295282847}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.6053745873006635, 2: -6.570069888565986, 3: -6.414783337642522, 4: -6.706248156426283}, Best action: 3, Actual action: 3\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.725637757233597, 3: -6.7886444136004975, 4: -6.487175629744162}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.725637757233597, 3: -6.7886444136004975, 4: -6.487175629744162}, Best action: 4, Actual action: 4\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.509355023868866, 2: -6.725637757233597, 3: -6.7886444136004975, 4: -6.8033298230671875}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.45985214756857, 3: -6.92664344380606, 4: -6.431048288723517}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.45985214756857, 3: -6.92664344380606, 4: -6.431048288723517}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.45985214756857, 3: -6.92664344380606, 4: -6.752253942738401}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.301143171730731, 3: -6.33107944040964, 4: -6.592723981594577}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.235375335044639, 1: -7.0824299249231, 2: -7.049136398853608, 3: -7.303122374665071, 4: -7.156741213470564}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.205903198994237 -7.147355128659853 -6.898948774333496 -6.941342845811334 -6.658767341545846 \n",
      "-6.977241041456181 -6.942514307205272 -6.89335633239599 -6.827296389082479 -6.603308894768395 \n",
      "-6.869336340830811 -6.801189117465475 -6.780253128060778 -6.640546883075098 -6.538406003135617 \n",
      "-6.917901385655356 -6.73159277662663 -6.598029053490719 -6.476064704049607 -6.2560344477475684 \n",
      "-6.775098736167951 -6.743092189730292 -6.518322041812459 -6.33107944040964 -7.049136398853608 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.175894815488964, 2: -7.147355128659853, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.104602624934871, 2: -6.956440341467522, 3: -7.265946211728146, 4: -6.898948774333496}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.104602624934871, 2: -6.956440341467522, 3: -7.265946211728146, 4: -6.898948774333496}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.104602624934871, 2: -6.956440341467522, 3: -7.265946211728146, 4: -7.178043384643481}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.97721456355825, 2: -6.941391641532205, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.97721456355825, 2: -6.941391641532205, 3: -7.025191249004723, 4: -6.941342845811334}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.97721456355825, 2: -6.941391641532205, 3: -7.025191249004723, 4: -7.216621989688315}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.658767341545846, 2: -6.812046981191748, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.603308894768395, 1: -6.823364860013748, 2: -6.790190331079895, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.914556938916984, 2: -6.812046981191748, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.914556938916984, 2: -6.812046981191748, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.914556938916984, 2: -7.09896275288449, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.881214702050352, 1: -6.914556938916984, 2: -7.183680183949234, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.1619053788658205, 1: -6.914556938916984, 2: -7.183680183949234, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.823364860013748, 2: -6.790190331079895, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.823364860013748, 2: -6.790190331079895, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.823364860013748, 2: -7.0790732012827045, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.548420937994456, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.548420937994456, 2: -6.538406003135617, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.548420937994456, 2: -6.849949462853412, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.2560344477475684, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.310446295282847}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.235375335044639, 1: -7.0824299249231, 2: -7.394271294099841, 3: -7.303122374665071, 4: -7.156741213470564}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.205903198994237 -7.175894815488964 -7.104602624934871 -6.97721456355825 -6.922319257930738 \n",
      "-6.977241041456181 -6.942514307205272 -6.89335633239599 -6.827296389082479 -6.848308451314089 \n",
      "-6.869336340830811 -6.801189117465475 -6.780253128060778 -6.640546883075098 -6.622229996474976 \n",
      "-6.917901385655356 -6.73159277662663 -6.598029053490719 -6.476064704049607 -6.310446295282847 \n",
      "-6.775098736167951 -6.743092189730292 -6.518322041812459 -6.33107944040964 -7.0824299249231 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.126655835280172, 2: -7.128154854983503, 3: -6.977241041456181, 4: -7.149078130388007}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.126655835280172, 2: -7.128154854983503, 3: -6.977241041456181, 4: -7.149078130388007}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.126655835280172, 2: -7.128154854983503, 3: -7.249289347725124, 4: -7.149078130388007}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -7.039237720179611, 3: -6.869336340830811, 4: -6.939737998997943}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -7.039237720179611, 3: -6.869336340830811, 4: -6.939737998997943}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -7.039237720179611, 3: -7.151096070156038, 4: -6.939737998997943}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -7.039237720179611, 3: -7.236297386203938, 4: -6.939737998997943}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.015330588959978, 2: -7.039237720179611, 3: -7.236297386203938, 4: -7.215161579088129}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917901385655356, 1: -6.961617126571462, 2: -6.919434757900437, 3: -7.0777624384973725, 4: -6.9587920075391665}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.2050331812768365, 2: -7.039237720179611, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -6.81173747548269, 3: -6.801189117465475, 4: -6.906597913513668}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.2050331812768365, 2: -7.112886957164996, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -6.81173747548269, 3: -7.341557347050195, 4: -6.906597913513668}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.780253128060778, 2: -6.784281226164753, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.598029053490719, 1: -6.760084616252936, 2: -6.725637757233597, 3: -6.7886444136004975, 4: -6.852910551640501}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.92242884613356, 2: -6.784281226164753, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -6.640546883075098, 2: -6.668583273968415, 3: -6.735605119303099, 4: -6.847273424033661}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.476064704049607, 1: -6.6053745873006635, 2: -6.570069888565986, 3: -6.7960905938570235, 4: -6.706248156426283}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -6.809667098587691, 2: -6.668583273968415, 3: -6.735605119303099, 4: -6.847273424033661}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.622229996474976, 2: -6.88921590606085, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.362371683962468, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.310446295282847}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.362371683962468, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.310446295282847}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.362371683962468, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.6425061287073905}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.235375335044639, 1: -7.259808236071816, 2: -7.394271294099841, 3: -7.303122374665071, 4: -7.156741213470564}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.205903198994237 -7.175894815488964 -7.104602624934871 -6.97721456355825 -6.922319257930738 \n",
      "-7.128154854983503 -6.942514307205272 -6.89335633239599 -6.827296389082479 -6.848308451314089 \n",
      "-7.128796050857479 -6.906597913513668 -6.838865530815818 -6.735605119303099 -6.638505045374514 \n",
      "-6.919434757900437 -6.73159277662663 -6.725637757233597 -6.570069888565986 -6.405968664568972 \n",
      "-6.775098736167951 -6.743092189730292 -6.518322041812459 -6.33107944040964 -7.156741213470564 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.205903198994237, 2: -7.291654925987447, 3: -7.230174268562231, 4: -7.424354137498952}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.176828019600975, 2: -7.128154854983503, 3: -7.397520161349451, 4: -7.149078130388007}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -7.016367243204333, 2: -6.942514307205272, 3: -7.145748094252817, 4: -7.156963705899315}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.89335633239599, 1: -6.922020181193332, 2: -7.029100007566767, 3: -6.930934079562872, 4: -7.176455280904802}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.104602624934871, 2: -7.218131739253933, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -6.922020181193332, 2: -7.029100007566767, 3: -6.930934079562872, 4: -7.176455280904802}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.92242884613356, 2: -6.957271097907305, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.92242884613356, 2: -6.957271097907305, 3: -6.8724092438791695, 4: -6.838865530815818}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.92242884613356, 2: -6.957271097907305, 3: -6.8724092438791695, 4: -7.1233676330423945}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -7.073178781277499, 3: -7.341557347050195, 4: -6.906597913513668}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -7.073178781277499, 3: -7.341557347050195, 4: -6.906597913513668}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -6.9986520222501, 2: -7.073178781277499, 3: -7.341557347050195, 4: -7.185004101297438}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.73159277662663, 1: -6.911728697325933, 2: -6.757958358290438, 3: -6.770126342608826, 4: -6.731784736357938}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.049703861248725, 1: -7.05245535129258, 2: -7.073178781277499, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -7.016367243204333, 2: -7.177870059961279, 3: -7.145748094252817, 4: -7.156963705899315}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.05245535129258, 2: -7.073178781277499, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -6.911728697325933, 2: -6.757958358290438, 3: -6.770126342608826, 4: -6.731784736357938}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -6.911728697325933, 2: -6.757958358290438, 3: -6.770126342608826, 4: -6.731784736357938}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -6.911728697325933, 2: -6.757958358290438, 3: -6.770126342608826, 4: -7.025924110085724}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.760084616252936, 2: -6.725637757233597, 3: -6.7886444136004975, 4: -6.852910551640501}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.6053745873006635, 2: -6.570069888565986, 3: -6.7960905938570235, 4: -6.706248156426283}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.405968664568972, 1: -6.433197551307404, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.638505045374514, 1: -6.673684498826604, 2: -6.88921590606085, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.878445348541225, 2: -7.134832856739407, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 4, Actual action: 4\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.878445348541225, 2: -7.134832856739407, 3: -7.046406246654551, 4: -6.848308451314089}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.878445348541225, 2: -7.134832856739407, 3: -7.046406246654551, 4: -7.13196069069582}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.673684498826604, 2: -6.88921590606085, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.433197551307404, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.433197551307404, 2: -6.416177462951769, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 2, Actual action: 2\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.433197551307404, 2: -6.7387214912861095, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.235375335044639, 1: -7.259808236071816, 2: -7.394271294099841, 3: -7.303122374665071, 4: -7.452455712532388}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.230174268562231 -7.175894815488964 -7.142302930490192 -6.97721456355825 -6.922319257930738 \n",
      "-7.149078130388007 -7.080694440904799 -6.930934079562872 -6.827296389082479 -6.993528978903671 \n",
      "-7.128796050857479 -7.0579911715791885 -6.8967605798269975 -6.735605119303099 -6.673980888029872 \n",
      "-6.919434757900437 -6.770126342608826 -6.760084616252936 -6.6053745873006635 -6.503973776516897 \n",
      "-6.775098736167951 -6.743092189730292 -6.518322041812459 -6.33107944040964 -7.235375335044639 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.394395752436061, 2: -7.291654925987447, 3: -7.230174268562231, 4: -7.424354137498952}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.394395752436061, 2: -7.291654925987447, 3: -7.230174268562231, 4: -7.424354137498952}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.394395752436061, 2: -7.291654925987447, 3: -7.47945858439163, 4: -7.424354137498952}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.175894815488964, 2: -7.202884020076117, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.080694440904799, 1: -7.314125558867423, 2: -7.177870059961279, 3: -7.145748094252817, 4: -7.156963705899315}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.352951978681784, 2: -7.202884020076117, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.217296609260087, 2: -7.218131739253933, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.142302930490192, 1: -7.217296609260087, 2: -7.218131739253933, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.399495666746075, 1: -7.217296609260087, 2: -7.218131739253933, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.131683098080146, 2: -7.029100007566767, 3: -6.930934079562872, 4: -7.176455280904802}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.177870059961279, 3: -7.145748094252817, 4: -7.156963705899315}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.176828019600975, 2: -7.236252074334621, 3: -7.397520161349451, 4: -7.149078130388007}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.176828019600975, 2: -7.236252074334621, 3: -7.397520161349451, 4: -7.149078130388007}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.176828019600975, 2: -7.236252074334621, 3: -7.397520161349451, 4: -7.405661098653087}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.2050331812768365, 2: -7.128796050857479, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.0579911715791885, 2: -7.073178781277499, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -6.911728697325933, 2: -7.0235624191882575, 3: -6.770126342608826, 4: -7.076538681223828}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -6.961617126571462, 2: -6.919434757900437, 3: -7.0777624384973725, 4: -6.9587920075391665}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -6.911728697325933, 2: -7.0235624191882575, 3: -7.181754788160236, 4: -7.076538681223828}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.743092189730292, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.518322041812459, 1: -6.6548856143524535, 2: -6.649911183858749, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.760084616252936, 2: -6.894320385461809, 3: -6.7886444136004975, 4: -6.852910551640501}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -6.6548856143524535, 2: -6.649911183858749, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.339914800244495, 3: -6.33107944040964, 4: -6.592723981594577}, Best action: 3, Actual action: 3\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -6.6548856143524535, 2: -6.6931654651176835, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -6.6548856143524535, 2: -6.6931654651176835, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -6.955945909060733, 2: -6.6931654651176835, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.339914800244495, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.259808236071816, 2: -7.394271294099841, 3: -7.303122374665071, 4: -7.452455712532388}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.312583635135382 -7.203481542859495 -7.218131739253933 -6.97721456355825 -6.922319257930738 \n",
      "-7.195123021757616 -7.156963705899315 -7.029100007566767 -6.827296389082479 -6.993528978903671 \n",
      "-7.131768539458705 -7.073178781277499 -6.8967605798269975 -6.735605119303099 -6.673980888029872 \n",
      "-6.9587920075391665 -7.0235624191882575 -6.7886444136004975 -6.6053745873006635 -6.503973776516897 \n",
      "-6.775098736167951 -6.788361749940323 -6.704647534709809 -6.51443615124262 -7.259808236071816 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.195123021757616, 1: -7.3920076031546555, 2: -7.236252074334621, 3: -7.397520161349451, 4: -7.4537968057420985}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.394395752436061, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.424354137498952}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.312583635135382, 1: -7.394395752436061, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.424354137498952}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.554451107973198, 1: -7.394395752436061, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.424354137498952}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.3920076031546555, 2: -7.236252074334621, 3: -7.397520161349451, 4: -7.4537968057420985}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.177870059961279, 3: -7.405328095039567, 4: -7.156963705899315}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.177870059961279, 3: -7.405328095039567, 4: -7.156963705899315}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.177870059961279, 3: -7.405328095039567, 4: -7.4128369723683765}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.131683098080146, 2: -7.029100007566767, 3: -7.38114936430107, 4: -7.176455280904802}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.838955767137107, 2: -6.870899936600876, 3: -7.137636580819454, 4: -6.827296389082479}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.838955767137107, 2: -6.870899936600876, 3: -7.137636580819454, 4: -6.827296389082479}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -6.838955767137107, 2: -6.870899936600876, 3: -7.137636580819454, 4: -7.112839714065056}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -6.809667098587691, 2: -6.930864624541573, 3: -6.735605119303099, 4: -6.847273424033661}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.8967605798269975, 1: -6.92242884613356, 2: -6.957271097907305, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.131683098080146, 2: -7.133020075913485, 3: -7.38114936430107, 4: -7.176455280904802}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -6.92242884613356, 2: -6.957271097907305, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -6.894320385461809, 3: -6.7886444136004975, 4: -6.852910551640501}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.05307754341413, 2: -7.0235624191882575, 3: -7.181754788160236, 4: -7.076538681223828}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -6.894320385461809, 3: -7.267950000902538, 4: -6.852910551640501}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -6.894320385461809, 3: -7.267950000902538, 4: -6.852910551640501}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -6.894320385461809, 3: -7.267950000902538, 4: -7.136148601992856}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.6053745873006635, 2: -6.745841607157466, 3: -6.7960905938570235, 4: -6.706248156426283}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.51443615124262, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.45403047123085, 2: -7.394271294099841, 3: -7.303122374665071, 4: -7.452455712532388}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.424354137498952 -7.203481542859495 -7.218131739253933 -6.97721456355825 -6.922319257930738 \n",
      "-7.3920076031546555 -7.3113580121252095 -7.133020075913485 -6.870899936600876 -6.993528978903671 \n",
      "-7.131768539458705 -7.073178781277499 -6.957271097907305 -6.809667098587691 -6.673980888029872 \n",
      "-6.9587920075391665 -7.05307754341413 -6.939785454259718 -6.706248156426283 -6.503973776516897 \n",
      "-6.775098736167951 -6.788361749940323 -6.704647534709809 -6.56697273860297 -7.303122374665071 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.500803755454649, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.424354137498952}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.500803755454649, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.424354137498952}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.500803755454649, 2: -7.441640293144806, 3: -7.554186348488995, 4: -7.656162265124046}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.352951978681784, 2: -7.405553775704667, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.203481542859495, 1: -7.352951978681784, 2: -7.405553775704667, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.45516820400214, 1: -7.352951978681784, 2: -7.405553775704667, 3: -7.327433282336866, 4: -7.3793001579048525}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.500803755454649, 2: -7.478984079030671, 3: -7.554186348488995, 4: -7.693344863959697}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.352951978681784, 2: -7.405553775704667, 3: -7.690720432248531, 4: -7.3793001579048525}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.3113580121252095, 3: -7.405328095039567, 4: -7.455358445805474}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.220335675176198, 2: -7.133020075913485, 3: -7.38114936430107, 4: -7.176455280904802}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -7.039735723349221, 2: -6.870899936600876, 3: -7.137636580819454, 4: -7.1508381427875625}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -6.993528978903671, 2: -7.134832856739407, 3: -7.046406246654551, 4: -7.184736801387975}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.764472194873593, 2: -6.88921590606085, 3: -6.673980888029872, 4: -6.780132691423021}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -6.809667098587691, 2: -6.930864624541573, 3: -7.159936581590178, 4: -6.847273424033661}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.8372307412365885, 2: -6.745841607157466, 3: -6.7960905938570235, 4: -6.706248156426283}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.8372307412365885, 2: -6.745841607157466, 3: -6.7960905938570235, 4: -6.706248156426283}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.8372307412365885, 2: -6.745841607157466, 3: -6.7960905938570235, 4: -7.002685822347917}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.503973776516897, 2: -6.784762165687608, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.45403047123085, 2: -7.394271294099841, 3: -7.644039088840658, 4: -7.452455712532388}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.500803755454649 -7.3793001579048525 -7.218131739253933 -6.97721456355825 -6.922319257930738 \n",
      "-7.3920076031546555 -7.314125558867423 -7.176455280904802 -7.039735723349221 -7.005277417194564 \n",
      "-7.131768539458705 -7.073178781277499 -6.957271097907305 -6.847273424033661 -6.764472194873593 \n",
      "-6.9587920075391665 -7.05307754341413 -6.939785454259718 -6.7960905938570235 -6.639757125872561 \n",
      "-6.775098736167951 -6.788361749940323 -6.704647534709809 -6.56697273860297 -7.394271294099841 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.405553775704667, 3: -7.690720432248531, 4: -7.3793001579048525}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.405553775704667, 3: -7.690720432248531, 4: -7.3793001579048525}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.405553775704667, 3: -7.690720432248531, 4: -7.615163143693416}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.235786265371936, 2: -7.218131739253933, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -6.97721456355825, 2: -6.987740710805356, 3: -7.025191249004723, 4: -7.244189428609917}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -7.039735723349221, 2: -7.251848466572062, 3: -7.137636580819454, 4: -7.1508381427875625}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -7.013027716564059, 2: -6.930864624541573, 3: -7.159936581590178, 4: -6.847273424033661}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -7.013027716564059, 2: -6.930864624541573, 3: -7.159936581590178, 4: -6.847273424033661}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -7.013027716564059, 2: -6.930864624541573, 3: -7.159936581590178, 4: -7.131018815870632}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.764472194873593, 2: -6.88921590606085, 3: -7.083228438659017, 4: -6.780132691423021}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.639757125872561, 2: -6.784762165687608, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.45403047123085, 2: -7.616660257312915, 3: -7.644039088840658, 4: -7.452455712532388}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.500803755454649 -7.487242086366153 -7.235786265371936 -6.978984500609279 -6.922319257930738 \n",
      "-7.3920076031546555 -7.314125558867423 -7.176455280904802 -7.079851007833828 -7.005277417194564 \n",
      "-7.131768539458705 -7.073178781277499 -6.957271097907305 -7.013027716564059 -6.780132691423021 \n",
      "-6.9587920075391665 -7.05307754341413 -6.939785454259718 -6.7960905938570235 -6.7004648397384905 \n",
      "-6.775098736167951 -6.788361749940323 -6.704647534709809 -6.56697273860297 -7.452455712532388 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.500803755454649, 2: -7.603789510635312, 3: -7.554186348488995, 4: -7.693344863959697}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.3920076031546555, 2: -7.4207658092119075, 3: -7.397520161349451, 4: -7.4537968057420985}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.131768539458705, 1: -7.2050331812768365, 2: -7.32985245406489, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.415933277277017, 2: -7.4207658092119075, 3: -7.397520161349451, 4: -7.4537968057420985}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.415933277277017, 2: -7.4207658092119075, 3: -7.397520161349451, 4: -7.4537968057420985}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.415933277277017, 2: -7.4207658092119075, 3: -7.631743346828, 4: -7.4537968057420985}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.2050331812768365, 2: -7.32985245406489, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -6.961617126571462, 2: -7.1904437206240495, 3: -7.0777624384973725, 4: -6.9587920075391665}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -6.961617126571462, 2: -7.1904437206240495, 3: -7.0777624384973725, 4: -6.9587920075391665}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -6.961617126571462, 2: -7.1904437206240495, 3: -7.0777624384973725, 4: -7.232500726860642}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -6.775098736167951, 2: -7.00757154732042, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -6.775098736167951, 2: -7.00757154732042, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -7.065339849912836, 2: -7.00757154732042, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -7.148756944540116, 2: -7.00757154732042, 3: -6.842250567344237, 4: -6.857257321028371}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -7.148756944540116, 2: -7.00757154732042, 3: -7.1264480162832555, 4: -6.857257321028371}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -7.148756944540116, 2: -7.00757154732042, 3: -7.1670232316613065, 4: -6.857257321028371}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.895398163325229, 1: -7.148756944540116, 2: -7.00757154732042, 3: -7.1670232316613065, 4: -7.140104162135818}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.083991688953187, 2: -7.1904437206240495, 3: -7.0777624384973725, 4: -7.262159945208949}, Best action: 3, Actual action: 3\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.083991688953187, 2: -7.1904437206240495, 3: -7.0777624384973725, 4: -7.262159945208949}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.083991688953187, 2: -7.1904437206240495, 3: -7.34076381903261, 4: -7.262159945208949}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.148756944540116, 2: -7.00757154732042, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.85415007284112, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -6.788361749940323, 2: -6.85415007284112, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.830529396690189, 1: -7.077409192445694, 2: -6.85415007284112, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.05307754341413, 2: -7.153213788747632, 3: -7.181754788160236, 4: -7.076538681223828}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -6.85415007284112, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -6.704647534709809, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.56697273860297, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.45403047123085, 2: -7.616660257312915, 3: -7.644039088840658, 4: -7.720896613171505}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.554186348488995 -7.487242086366153 -7.235786265371936 -6.978984500609279 -6.922319257930738 \n",
      "-7.4207658092119075 -7.314125558867423 -7.176455280904802 -7.079851007833828 -7.005277417194564 \n",
      "-7.236297386203938 -7.073178781277499 -6.957271097907305 -7.013027716564059 -6.780132691423021 \n",
      "-7.1904437206240495 -7.076538681223828 -6.939785454259718 -6.7960905938570235 -6.7004648397384905 \n",
      "-7.099330172183704 -6.932702517713444 -6.807705633804382 -6.588403798197163 -7.45403047123085 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.47767020456194, 2: -7.4207658092119075, 3: -7.670080289277184, 4: -7.4537968057420985}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.314125558867423, 2: -7.408882062702444, 3: -7.405328095039567, 4: -7.455358445805474}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.089601454671068, 2: -7.073178781277499, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.091044859629759, 2: -6.957271097907305, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -7.013027716564059, 2: -7.072308940301768, 3: -7.159936581590178, 4: -7.227102227465737}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.8372307412365885, 2: -6.842802919694433, 3: -6.7960905938570235, 4: -7.064400284032339}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -6.939785454259718, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.8372307412365885, 2: -6.842802919694433, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.588403798197163, 1: -6.646665520449706, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.920330150663362, 2: -6.842802919694433, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.7004648397384905, 2: -6.784762165687608, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.479978691039872, 1: -7.656223352584731, 2: -7.616660257312915, 3: -7.644039088840658, 4: -7.720896613171505}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.554186348488995 -7.487242086366153 -7.235786265371936 -6.978984500609279 -6.922319257930738 \n",
      "-7.4537968057420985 -7.360687368721517 -7.176455280904802 -7.079851007833828 -7.005277417194564 \n",
      "-7.236297386203938 -7.089601454671068 -7.091044859629759 -7.040694737170187 -6.780132691423021 \n",
      "-7.1904437206240495 -7.076538681223828 -6.96243652055088 -6.920330150663362 -6.717016510166879 \n",
      "-7.099330172183704 -6.932702517713444 -6.807705633804382 -6.592723981594577 -7.479978691039872 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.637606534100736, 2: -7.603789510635312, 3: -7.554186348488995, 4: -7.693344863959697}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.637606534100736, 2: -7.603789510635312, 3: -7.554186348488995, 4: -7.693344863959697}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.637606534100736, 2: -7.603789510635312, 3: -7.774309577124985, 4: -7.693344863959697}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.487242086366153, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.235786265371936, 2: -7.273356970407576, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.220335675176198, 2: -7.1787309562380575, 3: -7.38114936430107, 4: -7.176455280904802}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.220335675176198, 2: -7.1787309562380575, 3: -7.38114936430107, 4: -7.176455280904802}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.220335675176198, 2: -7.1787309562380575, 3: -7.38114936430107, 4: -7.43057430562337}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.079851007833828, 1: -7.150265045802188, 2: -7.251848466572062, 3: -7.137636580819454, 4: -7.1508381427875625}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -7.299907392268694, 2: -6.987740710805356, 3: -7.025191249004723, 4: -7.244189428609917}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.978984500609279, 1: -7.299907392268694, 2: -6.987740710805356, 3: -7.025191249004723, 4: -7.244189428609917}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.250875895554445, 1: -7.299907392268694, 2: -6.987740710805356, 3: -7.025191249004723, 4: -7.244189428609917}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.091509862066413, 2: -7.183680183949234, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.091509862066413, 2: -7.183680183949234, 3: -7.0359800959644545, 4: -6.922319257930738}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.091509862066413, 2: -7.183680183949234, 3: -7.0359800959644545, 4: -7.199310524716972}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.205852670004433, 3: -7.025191249004723, 4: -7.244189428609917}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.436507404070084, 2: -7.273356970407576, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.436507404070084, 2: -7.273356970407576, 3: -7.265946211728146, 4: -7.252521015053041}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.436507404070084, 2: -7.273356970407576, 3: -7.265946211728146, 4: -7.499794123698267}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.5097110835878835, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.436507404070084, 2: -7.273356970407576, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.205852670004433, 3: -7.477061147093436, 4: -7.244189428609917}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.091509862066413, 2: -7.183680183949234, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -7.005277417194564, 2: -7.134832856739407, 3: -7.046406246654551, 4: -7.184736801387975}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.954650491444134, 2: -6.88921590606085, 3: -7.083228438659017, 4: -6.780132691423021}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.954650491444134, 2: -6.88921590606085, 3: -7.083228438659017, 4: -6.780132691423021}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.954650491444134, 2: -6.88921590606085, 3: -7.083228438659017, 4: -7.069920749194949}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.954650491444134, 2: -6.88921590606085, 3: -7.083228438659017, 4: -7.187256958828784}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -6.954650491444134, 2: -7.169186474515374, 3: -7.083228438659017, 4: -7.187256958828784}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.728829223716145, 2: -6.784762165687608, 3: -6.717016510166879, 4: -6.717771676880338}, Best action: 3, Actual action: 3\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.920330150663362, 2: -7.011656812157621, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 1, Actual action: 1\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -6.646665520449706, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -6.646665520449706, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.592723981594577}, Best action: 4, Actual action: 4\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -6.646665520449706, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.899378823251064}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -6.646665520449706, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -6.948465623609233, 2: -6.694461955557286, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 2, Actual action: 2\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.656223352584731, 2: -7.616660257312915, 3: -7.644039088840658, 4: -7.720896613171505}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.637606534100736 -7.542390254388925 -7.436507404070084 -7.244189428609917 -7.183680183949234 \n",
      "-7.4537968057420985 -7.360687368721517 -7.220335675176198 -7.137636580819454 -7.046406246654551 \n",
      "-7.236297386203938 -7.089601454671068 -7.091044859629759 -7.040694737170187 -7.036248422379586 \n",
      "-7.1904437206240495 -7.076538681223828 -6.96243652055088 -6.932139440157943 -6.717771676880338 \n",
      "-7.099330172183704 -6.932702517713444 -6.807705633804382 -6.83894100397919 -7.616660257312915 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.542390254388925, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.436507404070084, 2: -7.464076359744349, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.220335675176198, 2: -7.352552411969207, 3: -7.38114936430107, 4: -7.457829505115163}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.091044859629759, 2: -7.276279560207619, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -6.96243652055088, 2: -7.1321354458276085, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -6.889712671739387, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -6.889712671739387, 3: -6.92664344380606, 4: -6.807705633804382}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -6.889712671739387, 3: -6.92664344380606, 4: -7.095012126761987}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.83894100397919, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.656223352584731, 2: -7.771002131786322, 3: -7.644039088840658, 4: -7.720896613171505}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.637606534100736 -7.557495187689598 -7.464076359744349 -7.244189428609917 -7.183680183949234 \n",
      "-7.4537968057420985 -7.360687368721517 -7.344063759436844 -7.137636580819454 -7.046406246654551 \n",
      "-7.236297386203938 -7.089601454671068 -7.178988250846367 -7.040694737170187 -7.036248422379586 \n",
      "-7.1904437206240495 -7.076538681223828 -7.055070698542521 -6.932139440157943 -6.717771676880338 \n",
      "-7.099330172183704 -6.932702517713444 -6.92664344380606 -6.8755657623588515 -7.644039088840658 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.637606534100736, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.693344863959697}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.47767020456194, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.4537968057420985}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.47767020456194, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.4537968057420985}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.47767020456194, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.682955093225309}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.257124844234409, 2: -7.32985245406489, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.257124844234409, 2: -7.32985245406489, 3: -7.236297386203938, 4: -7.303933934966395}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.257124844234409, 2: -7.32985245406489, 3: -7.485030621445583, 4: -7.303933934966395}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.284532122224859, 2: -7.1904437206240495, 3: -7.372109649955343, 4: -7.262159945208949}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.15716931334272, 2: -7.153213788747632, 3: -7.181754788160236, 4: -7.076538681223828}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.15716931334272, 2: -7.153213788747632, 3: -7.181754788160236, 4: -7.076538681223828}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.15716931334272, 2: -7.153213788747632, 3: -7.181754788160236, 4: -7.339650199913684}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.055070698542521, 1: -7.110485215436637, 2: -7.1321354458276085, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.248678067609188, 2: -7.276279560207619, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.248678067609188, 2: -7.276279560207619, 3: -7.181585234333988, 4: -7.178988250846367}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.248678067609188, 2: -7.276279560207619, 3: -7.181585234333988, 4: -7.432879308270194}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.089601454671068, 2: -7.242707467432667, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.15716931334272, 2: -7.329928644694205, 3: -7.181754788160236, 4: -7.42806818887695}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.016179510399057, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.016179510399057, 3: -6.948253465254733, 4: -6.932702517713444}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.016179510399057, 3: -6.948253465254733, 4: -7.208759291119234}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.148756944540116, 2: -7.099330172183704, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.016179510399057, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -7.128513480397082, 3: -6.92664344380606, 4: -7.190168476785102}, Best action: 3, Actual action: 3\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.212199140522815, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.140469730563622, 2: -7.212199140522815, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.397827454812896, 2: -7.212199140522815, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -7.128513480397082, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 1, Actual action: 1\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.017058617651397, 2: -7.128513480397082, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.027500743346124, 1: -7.285523342062771, 2: -7.128513480397082, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.110485215436637, 2: -7.1321354458276085, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.128513480397082, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.8755657623588515, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.656223352584731, 2: -7.771002131786322, 3: -7.850865201505663, 4: -7.720896613171505}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.64490567027053 -7.557495187689598 -7.464076359744349 -7.244189428609917 -7.183680183949234 \n",
      "-7.509167903281384 -7.360687368721517 -7.344063759436844 -7.137636580819454 -7.046406246654551 \n",
      "-7.303933934966395 -7.242707467432667 -7.248678067609188 -7.040694737170187 -7.036248422379586 \n",
      "-7.262159945208949 -7.181754788160236 -7.1321354458276085 -6.932139440157943 -6.717771676880338 \n",
      "-7.148756944540116 -7.248961235968257 -7.182059615550378 -6.889097491829517 -7.656223352584731 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.509167903281384, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.449971898128921, 2: -7.32985245406489, 3: -7.526774185974429, 4: -7.303933934966395}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.449971898128921, 2: -7.32985245406489, 3: -7.526774185974429, 4: -7.303933934966395}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.449971898128921, 2: -7.32985245406489, 3: -7.526774185974429, 4: -7.5465798808194196}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.406267289274711, 2: -7.242707467432667, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.248678067609188, 2: -7.276279560207619, 3: -7.360735701716964, 4: -7.460371970637549}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.1321354458276085, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -6.932139440157943, 2: -7.011656812157621, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.889097491829517, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.748048336916394, 2: -7.771002131786322, 3: -7.850865201505663, 4: -7.720896613171505}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.64490567027053 -7.557495187689598 -7.464076359744349 -7.244189428609917 -7.183680183949234 \n",
      "-7.542705046635421 -7.360687368721517 -7.344063759436844 -7.137636580819454 -7.046406246654551 \n",
      "-7.449971898128921 -7.287408548152325 -7.276279560207619 -7.040694737170187 -7.036248422379586 \n",
      "-7.262159945208949 -7.181754788160236 -7.198014372423351 -6.949158922319377 -6.717771676880338 \n",
      "-7.148756944540116 -7.248961235968257 -7.182059615550378 -6.923565291666452 -7.720896613171505 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.701336066061173, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.693344863959697}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.64490567027053, 1: -7.701336066061173, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.693344863959697}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.856864159946182, 1: -7.701336066061173, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.693344863959697}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.701336066061173, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.693344863959697}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.701336066061173, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.900943826203325}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.542705046635421, 1: -7.567103277650919, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.779724694380808, 2: -7.725045041020115, 3: -7.836500461327101, 4: -7.928176596129883}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.557495187689598, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.360687368721517, 2: -7.408882062702444, 3: -7.405328095039567, 4: -7.455358445805474}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.406267289274711, 2: -7.495699981506709, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.288227853120382, 1: -7.406267289274711, 2: -7.495699981506709, 3: -7.341557347050195, 4: -7.287408548152325}, Best action: 4, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.538869660875536, 2: -7.408882062702444, 3: -7.405328095039567, 4: -7.455358445805474}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.567103277650919, 2: -7.566518283603803, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.538869660875536, 2: -7.408882062702444, 3: -7.769412619223037, 4: -7.455358445805474}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.344063759436844, 1: -7.3657799038177245, 2: -7.352552411969207, 3: -7.38114936430107, 4: -7.457829505115163}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.49212263729973, 2: -7.464076359744349, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.244189428609917}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.244189428609917}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.492212380035024}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.285157565307784, 1: -7.299907392268694, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 0, Actual action: 0\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.529493384430083, 1: -7.299907392268694, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.150265045802188, 2: -7.251848466572062, 3: -7.137636580819454, 4: -7.1508381427875625}, Best action: 3, Actual action: 3\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.3657799038177245, 2: -7.352552411969207, 3: -7.38114936430107, 4: -7.457829505115163}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.150265045802188, 2: -7.251848466572062, 3: -7.569331111777004, 4: -7.1508381427875625}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.040694737170187, 1: -7.1061361526805955, 2: -7.072308940301768, 3: -7.159936581590178, 4: -7.227102227465737}, Best action: 0, Actual action: 0\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.31798924168807, 2: -7.251848466572062, 3: -7.569331111777004, 4: -7.1508381427875625}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.31798924168807, 2: -7.251848466572062, 3: -7.569331111777004, 4: -7.1508381427875625}, Best action: 4, Actual action: 4\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.31798924168807, 2: -7.251848466572062, 3: -7.569331111777004, 4: -7.407262709936682}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -7.092435221772103, 2: -7.134832856739407, 3: -7.046406246654551, 4: -7.184736801387975}, Best action: 3, Actual action: 3\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.260962546276899, 1: -7.31798924168807, 2: -7.332773906447393, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.411476369690627, 2: -7.3647082552742384, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.2834256941342375, 2: -7.183680183949234, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.2834256941342375, 2: -7.183680183949234, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 2, Actual action: 2\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.2834256941342375, 2: -7.437148967393803, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 0, Actual action: 0\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.216981658409339, 1: -7.2834256941342375, 2: -7.489470040050945, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 0, Actual action: 0\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.467453309152499, 1: -7.2834256941342375, 2: -7.489470040050945, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 1, Actual action: 1\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.078088944242155, 1: -7.092435221772103, 2: -7.134832856739407, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 0, Actual action: 0\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.361594614249569, 2: -7.489470040050945, 3: -7.2940029212902715, 4: -7.3190749302029054}, Best action: 3, Actual action: 3\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.411476369690627, 2: -7.455251774526303, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.31798924168807, 2: -7.332773906447393, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 1, Actual action: 1\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.1061361526805955, 2: -7.072308940301768, 3: -7.159936581590178, 4: -7.227102227465737}, Best action: 2, Actual action: 2\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -7.036248422379586, 2: -7.250185545521286, 3: -7.083228438659017, 4: -7.187256958828784}, Best action: 1, Actual action: 1\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.728829223716145, 2: -6.784762165687608, 3: -7.177169073054011, 4: -6.717771676880338}, Best action: 4, Actual action: 4\n",
      "Step: 43\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.728829223716145, 2: -6.784762165687608, 3: -7.177169073054011, 4: -6.717771676880338}, Best action: 4, Actual action: 4\n",
      "Step: 44\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.728829223716145, 2: -6.784762165687608, 3: -7.177169073054011, 4: -7.0131722259611085}, Best action: 1, Actual action: 1\n",
      "Step: 45\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.748048336916394, 2: -7.771002131786322, 3: -7.850865201505663, 4: -7.86446325423628}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.779724694380808 -7.5807377790930754 -7.485959820175278 -7.455251774526303 -7.3190749302029054 \n",
      "-7.567103277650919 -7.442405500352135 -7.3657799038177245 -7.332773906447393 -7.092435221772103 \n",
      "-7.449971898128921 -7.341557347050195 -7.276279560207619 -7.1061361526805955 -7.045019900511033 \n",
      "-7.262159945208949 -7.181754788160236 -7.198014372423351 -6.949158922319377 -6.784762165687608 \n",
      "-7.148756944540116 -7.248961235968257 -7.182059615550378 -6.923565291666452 -7.748048336916394 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.567103277650919, 2: -7.6578462991493605, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.449971898128921, 2: -7.499578294026949, 3: -7.526774185974429, 4: -7.5918384758745034}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.284532122224859, 2: -7.351040703853705, 3: -7.372109649955343, 4: -7.262159945208949}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.284532122224859, 2: -7.351040703853705, 3: -7.372109649955343, 4: -7.262159945208949}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.284532122224859, 2: -7.351040703853705, 3: -7.372109649955343, 4: -7.508565550140144}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.148756944540116, 2: -7.293038420641607, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.148756944540116, 2: -7.293038420641607, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.405368819531505, 2: -7.293038420641607, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.445825699598808, 2: -7.293038420641607, 3: -7.1670232316613065, 4: -7.199282928507018}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.445825699598808, 2: -7.293038420641607, 3: -7.421991140811789, 4: -7.199282928507018}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.445825699598808, 2: -7.293038420641607, 3: -7.473618286171864, 4: -7.199282928507018}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.445825699598808, 2: -7.293038420641607, 3: -7.473618286171864, 4: -7.451347464941387}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.4816640493047695, 2: -7.305037394349913, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.4816640493047695, 2: -7.305037394349913, 3: -7.345282785994273, 4: -7.248961235968257}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.296045749834464, 1: -7.4816640493047695, 2: -7.305037394349913, 3: -7.345282785994273, 4: -7.496554724731114}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.231205970682161, 2: -7.329928644694205, 3: -7.181754788160236, 4: -7.42806818887695}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.29357269191102, 1: -7.41894633729998, 2: -7.351040703853705, 3: -7.372109649955343, 4: -7.551327574016151}, Best action: 0, Actual action: 0\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.5273467454321406, 2: -7.499578294026949, 3: -7.526774185974429, 4: -7.5918384758745034}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.406267289274711, 2: -7.495699981506709, 3: -7.341557347050195, 4: -7.532205415842743}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.5273467454321406, 2: -7.5966192805133534, 3: -7.526774185974429, 4: -7.5918384758745034}, Best action: 3, Actual action: 3\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.5273467454321406, 2: -7.5966192805133534, 3: -7.526774185974429, 4: -7.5918384758745034}, Best action: 3, Actual action: 3\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.5273467454321406, 2: -7.5966192805133534, 3: -7.74936450923673, 4: -7.5918384758745034}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.41894633729998, 2: -7.351040703853705, 3: -7.372109649955343, 4: -7.551327574016151}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.231205970682161, 2: -7.329928644694205, 3: -7.52596935926395, 4: -7.42806818887695}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446825953393238, 1: -7.4816640493047695, 2: -7.305037394349913, 3: -7.345282785994273, 4: -7.559452529839028}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.182059615550378, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.942836005851871, 3: -6.923565291666452, 4: -6.973736953889369}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.226293847804864, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.226293847804864, 3: -7.37644482613714, 4: -7.190168476785102}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.226293847804864, 3: -7.37644482613714, 4: -7.443053313874443}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.942836005851871, 3: -7.416392995362577, 4: -6.973736953889369}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.766888811380073, 1: -7.804158488588884, 2: -7.771002131786322, 3: -7.850865201505663, 4: -7.86446325423628}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.779724694380808 -7.5807377790930754 -7.485959820175278 -7.455251774526303 -7.3190749302029054 \n",
      "-7.6578462991493605 -7.442405500352135 -7.3657799038177245 -7.332773906447393 -7.092435221772103 \n",
      "-7.5918384758745034 -7.406267289274711 -7.276279560207619 -7.1061361526805955 -7.045019900511033 \n",
      "-7.372109649955343 -7.283419405274131 -7.198014372423351 -6.949158922319377 -6.784762165687608 \n",
      "-7.322527391515395 -7.345282785994273 -7.246326549520502 -6.973736953889369 -7.766888811380073 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.779724694380808, 2: -7.794075606130586, 3: -7.836500461327101, 4: -7.928176596129883}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.691187565249518, 2: -7.6578462991493605, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.442405500352135, 1: -7.538869660875536, 2: -7.589579851414088, 3: -7.769412619223037, 4: -7.455358445805474}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.617906287433389, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.5807377790930754, 1: -7.617906287433389, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.798471378974699, 1: -7.617906287433389, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.538869660875536, 2: -7.589579851414088, 3: -7.769412619223037, 4: -7.455358445805474}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.538869660875536, 2: -7.589579851414088, 3: -7.769412619223037, 4: -7.455358445805474}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.538869660875536, 2: -7.589579851414088, 3: -7.769412619223037, 4: -7.684376185682981}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.406267289274711, 2: -7.495699981506709, 3: -7.730842825344307, 4: -7.532205415842743}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.283419405274131, 1: -7.540200886491646, 2: -7.329928644694205, 3: -7.52596935926395, 4: -7.42806818887695}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.540196447199517, 2: -7.495699981506709, 3: -7.730842825344307, 4: -7.532205415842743}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.401897517881282, 2: -7.276279560207619, 3: -7.360735701716964, 4: -7.460371970637549}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.1061361526805955, 2: -7.306592116157642, 3: -7.159936581590178, 4: -7.227102227465737}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.949158922319377, 1: -7.173382912397703, 2: -7.011656812157621, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.239432342346755, 2: -7.306592116157642, 3: -7.159936581590178, 4: -7.227102227465737}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.401897517881282, 2: -7.383598239692045, 3: -7.360735701716964, 4: -7.460371970637549}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.540196447199517, 2: -7.543356441918842, 3: -7.730842825344307, 4: -7.532205415842743}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.540196447199517, 2: -7.543356441918842, 3: -7.730842825344307, 4: -7.532205415842743}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.540196447199517, 2: -7.543356441918842, 3: -7.730842825344307, 4: -7.754306928416896}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.329928644694205, 3: -7.52596935926395, 4: -7.42806818887695}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.228246491110695, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 4, Actual action: 4\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.228246491110695, 3: -7.267950000902538, 4: -7.198014372423351}, Best action: 4, Actual action: 4\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.228246491110695, 3: -7.267950000902538, 4: -7.45019307890525}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.173382912397703, 2: -7.011656812157621, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.948802075273894, 2: -6.784762165687608, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.948802075273894, 2: -6.784762165687608, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6.917785953210254, 1: -6.948802075273894, 2: -7.074133570775723, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 0, Actual action: 0\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -7.045019900511033, 2: -7.250185545521286, 3: -7.083228438659017, 4: -7.187256958828784}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -6.948802075273894, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 1, Actual action: 1\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.804158488588884, 2: -7.771002131786322, 3: -7.850865201505663, 4: -7.86446325423628}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.794075606130586 -7.660014872690121 -7.485959820175278 -7.455251774526303 -7.3190749302029054 \n",
      "-7.670080289277184 -7.589579851414088 -7.3657799038177245 -7.332773906447393 -7.092435221772103 \n",
      "-7.5918384758745034 -7.543356441918842 -7.366339367427619 -7.227102227465737 -7.083228438659017 \n",
      "-7.372109649955343 -7.42806818887695 -7.267950000902538 -7.064400284032339 -6.98939193427431 \n",
      "-7.322527391515395 -7.345282785994273 -7.246326549520502 -6.973736953889369 -7.771002131786322 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.700630969845773, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.700630969845773, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.660014872690121}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.700630969845773, 2: -7.6778100227356605, 3: -7.690720432248531, 4: -7.870613534148011}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.49212263729973, 2: -7.514201073148468, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.485959820175278, 1: -7.49212263729973, 2: -7.514201073148468, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.712223436359503, 1: -7.49212263729973, 2: -7.514201073148468, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.3657799038177245, 2: -7.4269699282966934, 3: -7.38114936430107, 4: -7.457829505115163}, Best action: 1, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.652963470400069, 2: -7.589579851414088, 3: -7.769412619223037, 4: -7.774922043877482}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.3657799038177245, 2: -7.4269699282966934, 3: -7.785674616075518, 4: -7.457829505115163}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.366339367427619, 1: -7.401897517881282, 2: -7.383598239692045, 3: -7.737159957004318, 4: -7.460371970637549}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.603312877998144, 2: -7.4269699282966934, 3: -7.785674616075518, 4: -7.457829505115163}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.360369165813238, 2: -7.332773906447393, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.092435221772103, 2: -7.134832856739407, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -7.233031671022958, 2: -7.250185545521286, 3: -7.083228438659017, 4: -7.187256958828784}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.239432342346755, 2: -7.306592116157642, 3: -7.578189576549759, 4: -7.227102227465737}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.239432342346755, 2: -7.306592116157642, 3: -7.578189576549759, 4: -7.227102227465737}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.239432342346755, 2: -7.306592116157642, 3: -7.578189576549759, 4: -7.476663026993821}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.173382912397703, 2: -7.096823035422725, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.173382912397703, 2: -7.096823035422725, 3: -7.200835277336075, 4: -7.064400284032339}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.173382912397703, 2: -7.096823035422725, 3: -7.200835277336075, 4: -7.328604258469428}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -6.98939193427431, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.804158488588884, 2: -7.881712260057631, 3: -7.850865201505663, 4: -7.86446325423628}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.794075606130586 -7.690720432248531 -7.514201073148468 -7.455251774526303 -7.3190749302029054 \n",
      "-7.670080289277184 -7.625239707233765 -7.457829505115163 -7.360369165813238 -7.134832856739407 \n",
      "-7.5918384758745034 -7.543356441918842 -7.383598239692045 -7.306592116157642 -7.110980350101863 \n",
      "-7.372109649955343 -7.42806818887695 -7.267950000902538 -7.173382912397703 -7.0203075691844266 \n",
      "-7.322527391515395 -7.345282785994273 -7.246326549520502 -6.973736953889369 -7.804158488588884 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.691187565249518, 2: -7.694133085200165, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.691187565249518, 2: -7.694133085200165, 3: -7.670080289277184, 4: -7.7252083750177025}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.691187565249518, 2: -7.694133085200165, 3: -7.879773063242237, 4: -7.7252083750177025}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.607077644664716, 2: -7.5966192805133534, 3: -7.7720873147237075, 4: -7.5918384758745034}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.607077644664716, 2: -7.5966192805133534, 3: -7.7720873147237075, 4: -7.5918384758745034}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.607077644664716, 2: -7.5966192805133534, 3: -7.7720873147237075, 4: -7.808573013045798}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.591261846922258, 2: -7.543356441918842, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.401897517881282, 2: -7.383598239692045, 3: -7.737159957004318, 4: -7.460371970637549}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.34610746430087, 2: -7.306592116157642, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.110980350101863, 1: -7.233031671022958, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.187256958828784}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.346658557491014, 2: -7.134832856739407, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.346658557491014, 2: -7.134832856739407, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.346658557491014, 2: -7.392697899632861, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.346658557491014, 2: -7.458906599087546, 3: -7.486020287149744, 4: -7.184736801387975}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.346658557491014, 2: -7.458906599087546, 3: -7.486020287149744, 4: -7.438110489263057}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.233031671022958, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.187256958828784}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.233031671022958, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.187256958828784}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.233031671022958, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.4404038325341935}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.0203075691844266, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.893180883173407, 2: -7.881712260057631, 3: -7.850865201505663, 4: -7.86446325423628}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.794075606130586 -7.690720432248531 -7.514201073148468 -7.455251774526303 -7.3190749302029054 \n",
      "-7.694133085200165 -7.625239707233765 -7.457829505115163 -7.360369165813238 -7.4563439924004165 \n",
      "-7.605168184638926 -7.591261846922258 -7.401897517881282 -7.34610746430087 -7.250185545521286 \n",
      "-7.372109649955343 -7.42806818887695 -7.267950000902538 -7.173382912397703 -7.051668893806189 \n",
      "-7.322527391515395 -7.345282785994273 -7.246326549520502 -6.973736953889369 -7.850865201505663 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.880827971749063, 2: -7.794075606130586, 3: -7.836500461327101, 4: -7.928176596129883}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.700630969845773, 2: -7.731408456615542, 3: -7.690720432248531, 4: -7.906087471830687}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.880827971749063, 2: -7.908891110734369, 3: -7.836500461327101, 4: -7.928176596129883}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.880827971749063, 2: -7.908891110734369, 3: -7.836500461327101, 4: -7.928176596129883}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.880827971749063, 2: -7.908891110734369, 3: -8.031215419807664, 4: -7.928176596129883}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.8185079219833, 2: -7.694133085200165, 3: -7.917839234176333, 4: -7.7252083750177025}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.652963470400069, 2: -7.625239707233765, 3: -7.769412619223037, 4: -7.774922043877482}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.603312877998144, 2: -7.582243857052058, 3: -7.785674616075518, 4: -7.457829505115163}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.603312877998144, 2: -7.582243857052058, 3: -7.785674616075518, 4: -7.457829505115163}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.603312877998144, 2: -7.582243857052058, 3: -7.785674616075518, 4: -7.686624849654799}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.360369165813238, 2: -7.378149920280143, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.34610746430087, 2: -7.390553295198273, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.173382912397703, 2: -7.271089770304464, 3: -7.200835277336075, 4: -7.38128708453935}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.985463537803047, 3: -7.416392995362577, 4: -6.973736953889369}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.985463537803047, 3: -7.416392995362577, 4: -6.973736953889369}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -6.985463537803047, 3: -7.416392995362577, 4: -7.2461006280393265}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.893180883173407, 2: -7.881712260057631, 3: -7.998287761116341, 4: -7.86446325423628}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-7.908891110734369 -7.700630969845773 -7.514201073148468 -7.455251774526303 -7.3190749302029054 \n",
      "-7.7252083750177025 -7.652963470400069 -7.603312877998144 -7.378149920280143 -7.4563439924004165 \n",
      "-7.605168184638926 -7.591261846922258 -7.401897517881282 -7.390553295198273 -7.250185545521286 \n",
      "-7.372109649955343 -7.42806818887695 -7.267950000902538 -7.200835277336075 -7.051668893806189 \n",
      "-7.322527391515395 -7.345282785994273 -7.246326549520502 -7.017360746362325 -7.86446325423628 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.92033059618704, 2: -7.908891110734369, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.700630969845773, 2: -7.731408456615542, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.652963470400069, 2: -7.703365869866659, 3: -7.769412619223037, 4: -7.774922043877482}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.591261846922258, 2: -7.635050218342441, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.463384506132336, 3: -7.52596935926395, 4: -7.42806818887695}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.463384506132336, 3: -7.52596935926395, 4: -7.42806818887695}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.463384506132336, 3: -7.52596935926395, 4: -7.659542051878025}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.302266666958743, 3: -7.267950000902538, 4: -7.499898965690188}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.533377951344289, 3: -7.52596935926395, 4: -7.711295655154994}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.41894633729998, 2: -7.492380906637921, 3: -7.372109649955343, 4: -7.551327574016151}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.41894633729998, 2: -7.492380906637921, 3: -7.372109649955343, 4: -7.551327574016151}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.41894633729998, 2: -7.492380906637921, 3: -7.608619781459362, 4: -7.551327574016151}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.322527391515395, 1: -7.445825699598808, 2: -7.500962443198449, 3: -7.473618286171864, 4: -7.552495867213841}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.573141820857469, 2: -7.492380906637921, 3: -7.67020851135892, 4: -7.551327574016151}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.533377951344289, 3: -7.6240057523902225, 4: -7.711295655154994}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.302266666958743, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.26606522389016, 2: -7.271089770304464, 3: -7.200835277336075, 4: -7.38128708453935}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.3851444406653, 2: -7.462903241338094, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.246326549520502, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -7.068761589711691, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.017360746362325, 2: -7.068761589711691, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.285798279189716, 2: -7.068761589711691, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.893180883173407, 2: -7.881712260057631, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.917295755801973 -7.731408456615542 -7.514201073148468 -7.455251774526303 -7.3190749302029054 \n",
      "-7.7252083750177025 -7.703365869866659 -7.603312877998144 -7.378149920280143 -7.4563439924004165 \n",
      "-7.605168184638926 -7.627138542294088 -7.401897517881282 -7.390553295198273 -7.250185545521286 \n",
      "-7.551327574016151 -7.540200886491646 -7.420487553039809 -7.26606522389016 -7.051668893806189 \n",
      "-7.445825699598808 -7.345282785994273 -7.308694859505533 -7.09106308961785 -7.881712260057631 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.868963508008633, 2: -7.731408456615542, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.627943248813839, 2: -7.514201073148468, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.455251774526303, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.361594614249569, 2: -7.489470040050945, 3: -7.632696151578435, 4: -7.3190749302029054}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.361594614249569, 2: -7.489470040050945, 3: -7.632696151578435, 4: -7.3190749302029054}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.361594614249569, 2: -7.489470040050945, 3: -7.632696151578435, 4: -7.5603581864846445}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.4563439924004165, 2: -7.458906599087546, 3: -7.486020287149744, 4: -7.594604480494027}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.309752298141682, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.309752298141682, 2: -7.250185545521286, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.309752298141682, 2: -7.497668846424371, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.0612315701380295, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.0612315701380295, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.051668893806189}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.0612315701380295, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.317018693363632}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.893180883173407, 2: -7.950612075864353, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.917295755801973 -7.759643714911814 -7.535395843869625 -7.477061147093436 -7.489470040050945 \n",
      "-7.7252083750177025 -7.703365869866659 -7.603312877998144 -7.378149920280143 -7.458906599087546 \n",
      "-7.605168184638926 -7.627138542294088 -7.401897517881282 -7.390553295198273 -7.342827033797182 \n",
      "-7.551327574016151 -7.540200886491646 -7.420487553039809 -7.26606522389016 -7.099599672384263 \n",
      "-7.445825699598808 -7.345282785994273 -7.308694859505533 -7.09106308961785 -7.893180883173407 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.8185079219833, 2: -7.845857471379367, 3: -7.917839234176333, 4: -7.7252083750177025}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.8185079219833, 2: -7.845857471379367, 3: -7.917839234176333, 4: -7.7252083750177025}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.8185079219833, 2: -7.845857471379367, 3: -7.917839234176333, 4: -7.92993962126611}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.605168184638926, 1: -7.607077644664716, 2: -7.769780646005597, 3: -7.7720873147237075, 4: -7.834118918520397}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.842037021755861, 2: -7.845857471379367, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.607077644664716, 2: -7.769780646005597, 3: -7.7720873147237075, 4: -7.834118918520397}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.573141820857469, 2: -7.751274231252666, 3: -7.67020851135892, 4: -7.551327574016151}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.573141820857469, 2: -7.751274231252666, 3: -7.67020851135892, 4: -7.551327574016151}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.573141820857469, 2: -7.751274231252666, 3: -7.67020851135892, 4: -7.7717080923546975}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.445825699598808, 2: -7.500962443198449, 3: -7.473618286171864, 4: -7.552495867213841}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.445825699598808, 2: -7.500962443198449, 3: -7.473618286171864, 4: -7.552495867213841}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.675701386634916, 2: -7.500962443198449, 3: -7.473618286171864, 4: -7.552495867213841}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.500962443198449, 3: -7.473618286171864, 4: -7.552495867213841}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.500962443198449, 3: -7.700992640416397, 4: -7.552495867213841}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446825953393238, 1: -7.4816640493047695, 2: -7.447972028030798, 3: -7.345282785994273, 4: -7.559452529839028}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.599775300975207, 3: -7.745878843032384, 4: -7.552495867213841}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.599775300975207, 3: -7.745878843032384, 4: -7.552495867213841}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.599775300975207, 3: -7.745878843032384, 4: -7.772771239164595}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.446825953393238, 1: -7.4816640493047695, 2: -7.447972028030798, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.540200886491646, 2: -7.568173795371011, 3: -7.6240057523902225, 4: -7.711295655154994}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.4816640493047695, 2: -7.447972028030798, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.308694859505533, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.354276715585442, 2: -7.09106308961785, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -7.946736872081679, 2: -7.950612075864353, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-7.917295755801973 -7.759643714911814 -7.535395843869625 -7.477061147093436 -7.489470040050945 \n",
      "-7.845857471379367 -7.703365869866659 -7.603312877998144 -7.378149920280143 -7.458906599087546 \n",
      "-7.769780646005597 -7.627138542294088 -7.401897517881282 -7.390553295198273 -7.342827033797182 \n",
      "-7.67020851135892 -7.568173795371011 -7.420487553039809 -7.26606522389016 -7.099599672384263 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.101510744772207 -7.946736872081679 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.845936594354006, 2: -7.845857471379367, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.814218443047036, 2: -7.703365869866659, 3: -7.769412619223037, 4: -7.774922043877482}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.603312877998144, 2: -7.620123410013928, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.401897517881282, 2: -7.556699438056895, 3: -7.737159957004318, 4: -7.460371970637549}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.420487553039809, 1: -7.508038949178137, 2: -7.462903241338094, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.650784669750374, 2: -7.556699438056895, 3: -7.737159957004318, 4: -7.460371970637549}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.650784669750374, 2: -7.556699438056895, 3: -7.737159957004318, 4: -7.460371970637549}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.650784669750374, 2: -7.556699438056895, 3: -7.737159957004318, 4: -7.68893849328017}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.445050905472227, 2: -7.390553295198273, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.342827033797182, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.099599672384263, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -8.049818239025456, 2: -7.950612075864353, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.917295755801973 -7.759643714911814 -7.535395843869625 -7.477061147093436 -7.489470040050945 \n",
      "-7.845936594354006 -7.769412619223037 -7.620123410013928 -7.378149920280143 -7.458906599087546 \n",
      "-7.769780646005597 -7.627138542294088 -7.642018112916291 -7.396248369374944 -7.384958438010972 \n",
      "-7.67020851135892 -7.568173795371011 -7.462903241338094 -7.26606522389016 -7.149955748688552 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.101510744772207 -7.950612075864353 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.868963508008633, 2: -7.759643714911814, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.627943248813839, 2: -7.690174044681153, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.627943248813839, 2: -7.690174044681153, 3: -7.709460598879, 4: -7.535395843869625}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.627943248813839, 2: -7.690174044681153, 3: -7.709460598879, 4: -7.757210217921359}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.655868277283653, 2: -7.620123410013928, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.586383962665028, 2: -7.378149920280143, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.518284691112283, 2: -7.458906599087546, 3: -7.486020287149744, 4: -7.594604480494027}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.518284691112283, 2: -7.458906599087546, 3: -7.486020287149744, 4: -7.594604480494027}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.518284691112283, 2: -7.687605005169667, 3: -7.486020287149744, 4: -7.594604480494027}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.586383962665028, 2: -7.679529337288926, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.586383962665028, 2: -7.679529337288926, 3: -7.569331111777004, 4: -7.514723528917038}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.586383962665028, 2: -7.679529337288926, 3: -7.569331111777004, 4: -7.738398411314504}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.655868277283653, 2: -7.638313776428308, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.586383962665028, 2: -7.679529337288926, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.396248369374944, 1: -7.445050905472227, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.591509941399823, 1: -7.649599575460208, 2: -7.679529337288926, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.477061147093436, 4: -7.550198865902807}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.835094286992666, 2: -7.690174044681153, 3: -7.709460598879, 4: -7.8543550533313455}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.550198865902807}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.550198865902807}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.770680967971555}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.565874326180651, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 0, Actual action: 0\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784945636824393, 1: -7.5687189227364, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.715570523285666, 1: -7.649599575460208, 2: -7.679529337288926, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.445050905472227, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 1, Actual action: 1\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.26606522389016, 2: -7.271089770304464, 3: -7.602050524672501, 4: -7.38128708453935}, Best action: 1, Actual action: 1\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.101510744772207, 1: -7.354276715585442, 2: -7.145963175347945, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 0, Actual action: 0\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.378830225654504, 2: -7.271089770304464, 3: -7.602050524672501, 4: -7.38128708453935}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.149955748688552, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -7.978265883586462, 1: -8.049818239025456, 2: -7.980372616665004, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.917295755801973 -7.779635005025577 -7.709460598879 -7.573975870916984 -7.489470040050945 \n",
      "-7.845936594354006 -7.769412619223037 -7.655868277283653 -7.679529337288926 -7.515951260669336 \n",
      "-7.769780646005597 -7.627138542294088 -7.642018112916291 -7.511606500000254 -7.384958438010972 \n",
      "-7.67020851135892 -7.568173795371011 -7.462903241338094 -7.378830225654504 -7.177169073054011 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.145963175347945 -7.978265883586462 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.92033059618704, 2: -7.928400196648513, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.917295755801973, 1: -7.92033059618704, 2: -7.928400196648513, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.104739137779795, 1: -7.92033059618704, 2: -7.928400196648513, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.845936594354006, 2: -7.924312101729931, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.777283099419554, 2: -7.769780646005597, 3: -7.7720873147237075, 4: -7.834118918520397}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.627138542294088, 1: -7.6758614176825555, 2: -7.635050218342441, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.814218443047036, 2: -7.8290200181651635, 3: -7.769412619223037, 4: -7.774922043877482}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.911556987889836, 1: -7.978115982699935, 2: -7.924312101729931, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 0, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.047241701045449, 2: -7.928400196648513, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.047241701045449, 2: -7.928400196648513, 3: -8.086592199097508, 4: -7.928176596129883}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.047241701045449, 2: -7.928400196648513, 3: -8.086592199097508, 4: -8.114640702478193}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.868963508008633, 2: -7.779635005025577, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.835094286992666, 2: -7.78467848584939, 3: -7.709460598879, 4: -7.8543550533313455}, Best action: 3, Actual action: 3\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.868963508008633, 2: -7.922626585594548, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.850351230718515, 1: -7.868963508008633, 2: -7.922626585594548, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 0, Actual action: 0\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.04381961995385, 1: -7.868963508008633, 2: -7.922626585594548, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.814218443047036, 2: -7.8290200181651635, 3: -8.08530242211307, 4: -7.774922043877482}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.814218443047036, 2: -7.8290200181651635, 3: -8.08530242211307, 4: -7.774922043877482}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.784638151100605, 1: -7.814218443047036, 2: -7.8290200181651635, 3: -8.08530242211307, 4: -7.975179059928509}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -7.9845832063416236, 2: -7.922626585594548, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -7.9845832063416236, 2: -7.922626585594548, 3: -8.016637416899806, 4: -7.906087471830687}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -7.9845832063416236, 2: -7.922626585594548, 3: -8.016637416899806, 4: -8.094539599365925}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.835094286992666, 2: -7.78467848584939, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 0, Actual action: 0\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.739841679848731, 1: -7.835094286992666, 2: -7.78467848584939, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 0, Actual action: 0\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.943255928662346, 1: -7.835094286992666, 2: -7.78467848584939, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 2, Actual action: 2\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.573975870916984, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 2, Actual action: 2\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.675798095269294, 2: -7.489470040050945, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.675798095269294, 2: -7.489470040050945, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 2, Actual action: 2\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.675798095269294, 2: -7.715417736446359, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 0, Actual action: 0\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.546320143163983, 1: -7.675798095269294, 2: -7.784061089607462, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 0, Actual action: 0\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7671513302792246, 1: -7.675798095269294, 2: -7.784061089607462, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 4, Actual action: 4\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.675798095269294, 2: -7.784061089607462, 3: -7.632696151578435, 4: -7.618927456190615}, Best action: 4, Actual action: 4\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.675798095269294, 2: -7.784061089607462, 3: -7.632696151578435, 4: -7.83322398513346}, Best action: 3, Actual action: 3\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.723868319532964, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 2, Actual action: 2\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.675798095269294, 2: -7.784061089607462, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 1, Actual action: 1\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.515951260669336, 1: -7.518284691112283, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.594604480494027}, Best action: 0, Actual action: 0\n",
      "Step: 36\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.755500330669092, 2: -7.784061089607462, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 1, Actual action: 1\n",
      "Step: 37\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.518284691112283, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.594604480494027}, Best action: 1, Actual action: 1\n",
      "Step: 38\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.384958438010972, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 39\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.17739094057389, 2: -7.210819979177878, 3: -7.177169073054011, 4: -7.351299441148168}, Best action: 3, Actual action: 3\n",
      "Step: 40\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.378830225654504, 2: -7.418573133468174, 3: -7.602050524672501, 4: -7.38128708453935}, Best action: 1, Actual action: 1\n",
      "Step: 41\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.145963175347945, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 2, Actual action: 2\n",
      "Step: 42\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.110836150558244, 1: -8.049818239025456, 2: -7.980372616665004, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-7.99434437373557 -7.961534419236927 -7.813388304027696 -7.805426301003483 -7.765360632867859 \n",
      "-7.917839234176333 -7.814218443047036 -7.655868277283653 -7.679529337288926 -7.594604480494027 \n",
      "-7.7720873147237075 -7.635050218342441 -7.642018112916291 -7.511606500000254 -7.390312648969106 \n",
      "-7.67020851135892 -7.568173795371011 -7.462903241338094 -7.38128708453935 -7.17739094057389 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.178698137033448 -7.980372616665004 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -7.9845832063416236, 2: -7.961534419236927, 3: -8.016637416899806, 4: -8.126781494268176}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.99991516640424, 1: -7.835094286992666, 2: -7.813388304027696, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.889783289121425, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.889783289121425, 3: -7.876747090901078, 4: -7.805426301003483}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.889783289121425, 3: -7.876747090901078, 4: -8.00293793391317}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.809156891098923, 1: -7.853047548396408, 2: -7.889783289121425, 3: -7.876747090901078, 4: -8.025710875181446}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.00633277090002, 1: -7.853047548396408, 2: -7.889783289121425, 3: -7.876747090901078, 4: -8.025710875181446}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.715570523285666, 1: -7.695451190978525, 2: -7.679529337288926, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.633644803900116, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.594604480494027}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.633644803900116, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.594604480494027}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.633644803900116, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.811090077249565}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.390312648969106, 1: -7.452002792974846, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.649517726054987, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.452002792974846, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.17739094057389, 2: -7.210819979177878, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.110836150558244, 1: -8.049818239025456, 2: -8.146880141248412, 3: -7.998287761116341, 4: -8.092648125118467}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-7.99434437373557 -7.9845832063416236 -7.835094286992666 -7.876747090901078 -7.765360632867859 \n",
      "-7.917839234176333 -7.814218443047036 -7.655868277283653 -7.695451190978525 -7.701074034915124 \n",
      "-7.7720873147237075 -7.635050218342441 -7.642018112916291 -7.511606500000254 -7.458886941162336 \n",
      "-7.67020851135892 -7.568173795371011 -7.462903241338094 -7.38128708453935 -7.196352180561625 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.178698137033448 -7.998287761116341 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.047241701045449, 2: -7.99434437373557, 3: -8.086592199097508, 4: -8.133468229533117}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -7.9845832063416236, 2: -8.024997968186126, 3: -8.016637416899806, 4: -8.126781494268176}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -7.814218443047036, 2: -7.8290200181651635, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.6758614176825555, 2: -7.635050218342441, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.650784669750374, 2: -7.642018112916291, 3: -7.737159957004318, 4: -7.789820394154102}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.530017921898253, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.530017921898253, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.511606500000254}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.530017921898253, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.735561915000232}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.426113194597286, 2: -7.418573133468174, 3: -7.602050524672501, 4: -7.38128708453935}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.426113194597286, 2: -7.418573133468174, 3: -7.602050524672501, 4: -7.38128708453935}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.394464523319981, 1: -7.426113194597286, 2: -7.418573133468174, 3: -7.602050524672501, 4: -7.616971246930809}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.6318443306666985, 2: -7.586745226895545, 3: -7.578189576549759, 4: -7.772870708237608}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.650784669750374, 2: -7.748603076291835, 3: -7.737159957004318, 4: -7.789820394154102}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.508038949178137, 2: -7.462903241338094, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.426113194597286, 2: -7.418573133468174, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.196352180561625, 2: -7.210819979177878, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.110836150558244, 1: -8.049818239025456, 2: -8.146880141248412, 3: -8.175247718837445, 4: -8.092648125118467}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.047241701045449 -8.016637416899806 -7.835094286992666 -7.876747090901078 -7.765360632867859 \n",
      "-7.917839234176333 -7.8290200181651635 -7.655868277283653 -7.695451190978525 -7.701074034915124 \n",
      "-7.7720873147237075 -7.6758614176825555 -7.652479578663083 -7.586745226895545 -7.458886941162336 \n",
      "-7.67020851135892 -7.568173795371011 -7.499898965690188 -7.426113194597286 -7.210819979177878 \n",
      "-7.691906552346043 -7.4816640493047695 -7.320827936316638 -7.178698137033448 -8.049818239025456 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -7.978115982699935, 2: -7.924312101729931, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -7.978115982699935, 2: -7.924312101729931, 3: -7.917839234176333, 4: -8.025985378933084}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -7.978115982699935, 2: -7.924312101729931, 3: -8.105233703100463, 4: -8.025985378933084}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -7.865812521162081, 2: -7.8290200181651635, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.655868277283653, 2: -7.808802387401504, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.652479578663083, 1: -7.710030092458894, 2: -7.748603076291835, 3: -7.737159957004318, 4: -7.789820394154102}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.6803082273366075, 1: -7.864095286445463, 2: -7.808802387401504, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 0, Actual action: 0\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.99991516640424, 1: -7.835094286992666, 2: -8.003734134215591, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 1, Actual action: 0\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.99991516640424, 1: -7.835094286992666, 2: -8.003734134215591, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.864095286445463, 2: -7.808802387401504, 3: -7.785674616075518, 4: -7.810280009177647}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -7.865812521162081, 2: -7.884155306416275, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.6758614176825555, 2: -7.853539693296439, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.6868774313541115, 2: -7.568173795371011, 3: -7.6240057523902225, 4: -7.711295655154994}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.508038949178137, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.508038949178137, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.499898965690188}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.508038949178137, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.724908058778071}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.374630588541011, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.320827936316638, 2: -7.374630588541011, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.362243098838289, 1: -7.56195342204814, 2: -7.374630588541011, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.580674523334291, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.374630588541011, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 2, Actual action: 2\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.178698137033448, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.110836150558244, 1: -8.118431603585375, 2: -8.146880141248412, 3: -8.175247718837445, 4: -8.092648125118467}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.047241701045449 -8.016637416899806 -7.8543550533313455 -7.876747090901078 -7.765360632867859 \n",
      "-7.978115982699935 -7.884155306416275 -7.808802387401504 -7.695451190978525 -7.701074034915124 \n",
      "-7.7720873147237075 -7.730842825344307 -7.710030092458894 -7.586745226895545 -7.458886941162336 \n",
      "-7.67020851135892 -7.6240057523902225 -7.631518229051649 -7.426113194597286 -7.210819979177878 \n",
      "-7.691906552346043 -7.4816640493047695 -7.37644482613714 -7.272914795049303 -8.092648125118467 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.047241701045449, 2: -8.166946834510272, 3: -8.086592199097508, 4: -8.133468229533117}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -7.978115982699935, 2: -8.033937424886775, 3: -8.12921617271129, 4: -8.025985378933084}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.777283099419554, 2: -7.854960283858771, 3: -7.7720873147237075, 4: -7.834118918520397}, Best action: 3, Actual action: 3\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.777283099419554, 2: -7.854960283858771, 3: -7.7720873147237075, 4: -7.834118918520397}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.777283099419554, 2: -7.854960283858771, 3: -7.972599456398574, 4: -7.834118918520397}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.688432998760782, 2: -7.751274231252666, 3: -7.67020851135892, 4: -7.8114156841300195}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.688432998760782, 2: -7.751274231252666, 3: -7.67020851135892, 4: -7.8114156841300195}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.688432998760782, 2: -7.751274231252666, 3: -7.879889745336618, 4: -7.8114156841300195}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.691906552346043, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.4816640493047695, 2: -7.564840039002562, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.4816640493047695, 2: -7.564840039002562, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.70831428486734, 2: -7.564840039002562, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -7.564840039002562, 3: -7.752049931042639, 4: -7.559452529839028}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -7.564840039002562, 3: -7.752049931042639, 4: -7.779101802153516}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.4522085498511945, 3: -7.37644482613714, 4: -7.497603348109384}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -7.63140431307134, 3: -7.752049931042639, 4: -7.805430611807427}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.4522085498511945, 3: -7.8190819762015, 4: -7.497603348109384}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.272914795049303, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.110836150558244, 1: -8.118431603585375, 2: -8.146880141248412, 3: -8.175247718837445, 4: -8.227530590358661}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.086592199097508 -8.016637416899806 -7.8543550533313455 -7.876747090901078 -7.765360632867859 \n",
      "-7.993202323196197 -7.884155306416275 -7.808802387401504 -7.695451190978525 -7.701074034915124 \n",
      "-7.834118918520397 -7.730842825344307 -7.710030092458894 -7.586745226895545 -7.458886941162336 \n",
      "-7.70401568735293 -7.6240057523902225 -7.631518229051649 -7.426113194597286 -7.210819979177878 \n",
      "-7.7010812735282554 -7.699429356686602 -7.497603348109384 -7.282835528424401 -8.110836150558244 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.086592199097508, 4: -8.133468229533117}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.086592199097508, 4: -8.133468229533117}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.258798901178732, 4: -8.133468229533117}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.125941696689482, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.307892664436354, 4: -8.133468229533117}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.294606943987429, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.307892664436354, 4: -8.133468229533117}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.307892664436354, 4: -8.133468229533117}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.166998116091492, 2: -8.166946834510272, 3: -8.307892664436354, 4: -8.301456088875137}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.027975259502263, 2: -8.024997968186126, 3: -8.016637416899806, 4: -8.126781494268176}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.166998116091492, 2: -8.21017099113987, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -7.993202323196197, 2: -8.033937424886775, 3: -8.12921617271129, 4: -8.025985378933084}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.890597204142681, 2: -7.854960283858771, 3: -7.996859256169696, 4: -7.834118918520397}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.890597204142681, 2: -7.854960283858771, 3: -7.996859256169696, 4: -7.834118918520397}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.890597204142681, 2: -7.854960283858771, 3: -7.996859256169696, 4: -8.029048215853562}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.797806916018774, 2: -7.853539693296439, 3: -7.730842825344307, 4: -7.782989815073298}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.890597204142681, 2: -7.947478716914766, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.70401568735293, 1: -7.899287607276373, 2: -7.751274231252666, 3: -7.915619703529895, 4: -7.8114156841300195}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.929312427170141, 2: -7.947478716914766, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.899287607276373, 2: -7.751274231252666, 3: -7.915619703529895, 4: -7.8114156841300195}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.6868774313541115, 2: -7.731735541746154, 3: -7.6240057523902225, 4: -7.711295655154994}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.899287607276373, 2: -7.850572082561347, 3: -7.915619703529895, 4: -7.8114156841300195}, Best action: 4, Actual action: 4\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.899287607276373, 2: -7.850572082561347, 3: -7.915619703529895, 4: -7.8114156841300195}, Best action: 4, Actual action: 4\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.899287607276373, 2: -7.850572082561347, 3: -7.915619703529895, 4: -8.008388272558317}, Best action: 2, Actual action: 2\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.6868774313541115, 2: -7.731735541746154, 3: -7.989647279384338, 4: -7.711295655154994}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -7.699429356686602, 3: -7.752049931042639, 4: -7.805430611807427}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.536281838975055, 3: -7.8190819762015, 4: -7.497603348109384}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.536281838975055, 3: -7.8190819762015, 4: -7.497603348109384}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.536281838975055, 3: -7.8190819762015, 4: -7.72281904677954}, Best action: 2, Actual action: 2\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.297068761457108, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 4, Actual action: 4\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.297068761457108, 3: -7.416392995362577, 4: -7.282835528424401}, Best action: 4, Actual action: 4\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.297068761457108, 3: -7.416392995362577, 4: -7.527380330866205}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.118431603585375, 2: -8.146880141248412, 3: -8.175247718837445, 4: -8.227530590358661}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.19119369339807 -8.024997968186126 -7.8543550533313455 -7.876747090901078 -7.765360632867859 \n",
      "-8.025985378933084 -7.884155306416275 -7.808802387401504 -7.695451190978525 -7.701074034915124 \n",
      "-7.947478716914766 -7.782989815073298 -7.710030092458894 -7.586745226895545 -7.458886941162336 \n",
      "-7.899287607276373 -7.699858925547847 -7.631518229051649 -7.426113194597286 -7.210819979177878 \n",
      "-7.7010812735282554 -7.743001647637261 -7.55272496192127 -7.305636475049864 -8.118431603585375 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.044956556321141, 2: -8.033937424886775, 3: -8.12921617271129, 4: -8.025985378933084}, Best action: 4, Actual action: 4\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.044956556321141, 2: -8.033937424886775, 3: -8.12921617271129, 4: -8.025985378933084}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.044956556321141, 2: -8.033937424886775, 3: -8.12921617271129, 4: -8.203646694829107}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -7.904029000439078, 2: -7.884155306416275, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.864095286445463, 2: -7.808802387401504, 3: -8.049875603748838, 4: -7.810280009177647}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.715570523285666, 1: -7.695451190978525, 2: -7.819582562929055, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.6318443306666985, 2: -7.586745226895545, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.458886941162336, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.239987991666782, 2: -7.210819979177878, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.239987991666782, 2: -7.210819979177878, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.239987991666782, 2: -7.46184618105187, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.212891317294336, 2: -8.146880141248412, 3: -8.175247718837445, 4: -8.227530590358661}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.19119369339807 -8.024997968186126 -7.8543550533313455 -7.876747090901078 -7.765360632867859 \n",
      "-8.044956556321141 -7.904029000439078 -7.810280009177647 -7.715570523285666 -7.701074034915124 \n",
      "-7.947478716914766 -7.782989815073298 -7.710030092458894 -7.6318443306666985 -7.462275648113149 \n",
      "-7.899287607276373 -7.699858925547847 -7.631518229051649 -7.426113194597286 -7.298244714734962 \n",
      "-7.7010812735282554 -7.743001647637261 -7.55272496192127 -7.305636475049864 -8.146880141248412 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.027975259502263, 2: -8.024997968186126, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -7.989905867720437, 2: -8.003734134215591, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -7.989905867720437, 2: -8.003734134215591, 3: -8.029730556769898, 4: -7.8543550533313455}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -7.989905867720437, 2: -8.003734134215591, 3: -8.029730556769898, 4: -8.047463098531525}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.864095286445463, 2: -7.914195703432756, 3: -8.049875603748838, 4: -7.810280009177647}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.864095286445463, 2: -7.914195703432756, 3: -8.049875603748838, 4: -7.810280009177647}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.864095286445463, 2: -7.914195703432756, 3: -8.049875603748838, 4: -8.007354808351657}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.710030092458894, 2: -7.748603076291835, 3: -7.737159957004318, 4: -7.789820394154102}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.631518229051649, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.55272496192127, 3: -7.8190819762015, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.305636475049864, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.212891317294336, 2: -8.214936368355604, 3: -8.175247718837445, 4: -8.227530590358661}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.19119369339807 -8.027975259502263 -8.003734134215591 -7.876747090901078 -7.765360632867859 \n",
      "-8.044956556321141 -7.904029000439078 -7.914195703432756 -7.715570523285666 -7.701074034915124 \n",
      "-7.947478716914766 -7.782989815073298 -7.737159957004318 -7.6318443306666985 -7.462275648113149 \n",
      "-7.899287607276373 -7.699858925547847 -7.65533456224303 -7.426113194597286 -7.298244714734962 \n",
      "-7.7010812735282554 -7.743001647637261 -7.572838040982517 -7.3525142997633175 -8.175247718837445 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.19119369339807, 2: -8.21017099113987, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.044956556321141, 2: -8.08955954068586, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.971463370031674, 2: -7.947478716914766, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.797806916018774, 2: -7.853539693296439, 3: -8.064468017890004, 4: -7.782989815073298}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.797806916018774, 2: -7.853539693296439, 3: -8.064468017890004, 4: -7.782989815073298}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.797806916018774, 2: -7.853539693296439, 3: -8.064468017890004, 4: -7.9825207317167015}, Best action: 1, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -7.971463370031674, 2: -7.998969621900848, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.899287607276373, 2: -7.911427927652965, 3: -7.915619703529895, 4: -8.059802214130523}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7010812735282554, 1: -7.721200950462702, 2: -7.729338535171467, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.927804592285524, 2: -7.911427927652965, 3: -7.915619703529895, 4: -8.059802214130523}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.699858925547847, 1: -7.905225522051559, 2: -7.731735541746154, 3: -7.989647279384338, 4: -7.711295655154994}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.797806916018774, 2: -7.853539693296439, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -7.905225522051559, 2: -7.731735541746154, 3: -7.989647279384338, 4: -7.711295655154994}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -7.905225522051559, 2: -7.731735541746154, 3: -7.989647279384338, 4: -7.711295655154994}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -7.905225522051559, 2: -7.731735541746154, 3: -7.989647279384338, 4: -7.9172790461910445}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.780859042061394, 2: -7.65533456224303, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.426113194597286, 2: -7.470902579601733, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.3525142997633175, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.212891317294336, 2: -8.214936368355604, 3: -8.352391663536181, 4: -8.227530590358661}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.21017099113987 -8.027975259502263 -8.003734134215591 -7.876747090901078 -7.765360632867859 \n",
      "-8.08955954068586 -7.904029000439078 -7.914195703432756 -7.715570523285666 -7.701074034915124 \n",
      "-7.996859256169696 -7.853539693296439 -7.737159957004318 -7.6318443306666985 -7.462275648113149 \n",
      "-7.915619703529895 -7.873994549591469 -7.6806851438481045 -7.470902579601733 -7.298244714734962 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.212891317294336 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.141953416333074, 2: -8.08955954068586, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -7.904029000439078, 2: -8.013545464436845, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.925930172277423, 2: -7.853539693296439, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.852532774777725, 2: -7.748603076291835, 3: -7.737159957004318, 4: -7.789820394154102}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -7.925930172277423, 2: -7.9524535345031415, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -7.905225522051559, 2: -7.873994549591469, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.780859042061394, 2: -7.6806851438481045, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.598147902268016, 2: -7.470902579601733, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.298244714734962, 1: -7.322971713577892, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.486652877250315, 2: -7.5706662461372, 3: -7.462275648113149, 4: -7.502796036782015}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.6318443306666985, 2: -7.700372945031047, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.598147902268016, 2: -7.558668476895493, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.322971713577892, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.273832359684981, 2: -8.214936368355604, 3: -8.352391663536181, 4: -8.227530590358661}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.21017099113987 -8.027975259502263 -8.003734134215591 -7.876747090901078 -7.765360632867859 \n",
      "-8.111219444424238 -8.00307480838434 -7.914195703432756 -7.715570523285666 -7.701074034915124 \n",
      "-7.996859256169696 -7.9524535345031415 -7.748603076291835 -7.700372945031047 -7.486652877250315 \n",
      "-7.915619703529895 -7.905225522051559 -7.684950051520396 -7.587473935687641 -7.351299441148168 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.214936368355604 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.027975259502263, 2: -8.064527390017004, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -8.051770051614024, 2: -8.013545464436845, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -8.051770051614024, 2: -8.013545464436845, 3: -8.08530242211307, 4: -8.00307480838434}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -8.051770051614024, 2: -8.013545464436845, 3: -8.08530242211307, 4: -8.18279807562975}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.93153390353625, 2: -7.914195703432756, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.715570523285666, 1: -7.814808752883244, 2: -7.819582562929055, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 0, Actual action: 0\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -7.905723518043671, 2: -7.889783289121425, 3: -7.876747090901078, 4: -8.025710875181446}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -8.025317394205937, 2: -8.003734134215591, 3: -8.029730556769898, 4: -8.176570062706707}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -7.905723518043671, 2: -7.889783289121425, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.765360632867859, 2: -7.784061089607462, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.701074034915124, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.486652877250315, 2: -7.5706662461372, 3: -7.828021472651341, 4: -7.502796036782015}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.386395629725828, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 4, Actual action: 4\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.386395629725828, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.351299441148168}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.386395629725828, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.589682491444833}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.273832359684981, 2: -8.224153597032394, 3: -8.352391663536181, 4: -8.227530590358661}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.21017099113987 -8.064527390017004 -8.025317394205937 -7.905723518043671 -7.784061089607462 \n",
      "-8.111219444424238 -8.051770051614024 -7.93153390353625 -7.804998041670824 -7.732436933108259 \n",
      "-7.996859256169696 -7.9524535345031415 -7.748603076291835 -7.700372945031047 -7.502796036782015 \n",
      "-7.915619703529895 -7.905225522051559 -7.684950051520396 -7.587473935687641 -7.400203976568823 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.224153597032394 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.185288120741543, 2: -8.064527390017004, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -8.025317394205937, 2: -8.091097877609913, 3: -8.029730556769898, 4: -8.176570062706707}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.93153390353625, 2: -7.941031694204665, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.852532774777725, 2: -7.748603076291835, 3: -8.093719435245145, 4: -7.789820394154102}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.78570589935202, 2: -7.700372945031047, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.603217835055048, 2: -7.5706662461372, 3: -7.828021472651341, 4: -7.502796036782015}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.603217835055048, 2: -7.5706662461372, 3: -7.828021472651341, 4: -7.502796036782015}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.603217835055048, 2: -7.5706662461372, 3: -7.828021472651341, 4: -7.727544393471633}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.603217835055048, 2: -7.5706662461372, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.603217835055048, 2: -7.7893062839848515, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.400203976568823, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.273832359684981, 2: -8.254682545617012, 3: -8.352391663536181, 4: -8.227530590358661}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.21017099113987 -8.078242403482378 -8.029730556769898 -7.905723518043671 -7.784061089607462 \n",
      "-8.111219444424238 -8.051770051614024 -7.941031694204665 -7.804998041670824 -7.732436933108259 \n",
      "-7.996859256169696 -7.9524535345031415 -7.789820394154102 -7.747302084296536 -7.654487004526251 \n",
      "-7.915619703529895 -7.905225522051559 -7.684950051520396 -7.587473935687641 -7.404320175847398 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.227530590358661 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.23553417995993, 2: -8.21017099113987, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.185288120741543, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078242403482378, 1: -8.185288120741543, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.251200587168963, 1: -8.185288120741543, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.185288120741543, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.126781494268176}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.185288120741543, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.29537115978404}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -8.051770051614024, 2: -8.111853066224217, 3: -8.08530242211307, 4: -8.209251633756821}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -8.070528602396832, 2: -7.9524535345031415, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.852532774777725, 2: -7.912162393104332, 3: -8.093719435245145, 4: -7.789820394154102}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.852532774777725, 2: -7.912162393104332, 3: -8.093719435245145, 4: -7.789820394154102}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.852532774777725, 2: -7.912162393104332, 3: -8.093719435245145, 4: -7.988736558680232}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.684950051520396, 1: -7.780859042061394, 2: -7.719499603862214, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.886297622008961, 1: -7.910062819209293, 2: -7.912162393104332, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.969521882150011, 2: -7.941031694204665, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.814808752883244, 2: -7.819582562929055, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.814808752883244, 2: -7.819582562929055, 3: -7.84396727008463, 4: -7.804998041670824}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.814808752883244, 2: -7.819582562929055, 3: -7.84396727008463, 4: -8.00254821792045}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.78570589935202, 2: -7.747302084296536, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.654487004526251, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.404320175847398, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.273832359684981, 2: -8.254682545617012, 3: -8.352391663536181, 4: -8.372991561859163}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.23553417995993 -8.20695982830851 -8.029730556769898 -7.905723518043671 -7.784061089607462 \n",
      "-8.111219444424238 -8.082394667292917 -7.969521882150011 -7.819582562929055 -7.732436933108259 \n",
      "-7.996859256169696 -7.955938075800069 -7.910062819209293 -7.772870708237608 -7.662948042889018 \n",
      "-7.915619703529895 -7.905225522051559 -7.719499603862214 -7.587473935687641 -7.426724879534519 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.254682545617012 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.240462553881514, 2: -8.20695982830851, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -8.127074201284955, 2: -8.091097877609913, 3: -8.029730556769898, 4: -8.176570062706707}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.240462553881514, 2: -8.224777733814468, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -8.127074201284955, 2: -8.091097877609913, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.046417889104482, 1: -8.127074201284955, 2: -8.091097877609913, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.22224027908508, 1: -8.127074201284955, 2: -8.091097877609913, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -7.905723518043671, 2: -7.9789204415351085, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.956795563568519, 2: -7.819582562929055, 3: -7.84396727008463, 4: -8.030249911627472}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.734296234064268, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.734296234064268, 2: -7.732436933108259, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.734296234064268, 2: -7.936517609128516, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.662948042889018, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.426724879534519, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.261223296324806, 1: -8.273832359684981, 2: -8.373105715491592, 3: -8.352391663536181, 4: -8.372991561859163}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.23553417995993 -8.240076263556077 -8.112745837376366 -7.9789204415351085 -7.784061089607462 \n",
      "-8.111219444424238 -8.082394667292917 -7.969521882150011 -7.84396727008463 -7.735528087137775 \n",
      "-7.996859256169696 -7.955938075800069 -7.910062819209293 -7.772870708237608 -7.681941956711863 \n",
      "-7.915619703529895 -7.905225522051559 -7.719499603862214 -7.587473935687641 -7.434263357976545 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.261223296324806 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.23553417995993, 2: -8.264393445934713, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.141953416333074, 2: -8.111219444424238, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.082394667292917, 1: -8.146664368108947, 2: -8.111853066224217, 3: -8.08530242211307, 4: -8.209251633756821}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.240462553881514, 2: -8.240076263556077, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.127074201284955, 2: -8.112745837376366, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.024434227776903, 2: -7.9789204415351085, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.914406031568037, 2: -7.784061089607462, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.914406031568037, 2: -7.784061089607462, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.914406031568037, 2: -7.983495591542792, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.8480463725423215, 1: -7.914406031568037, 2: -8.05526712091356, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.041722199013513, 1: -7.914406031568037, 2: -8.05526712091356, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -7.914406031568037, 2: -8.05526712091356, 3: -7.9196029539795445, 4: -7.865806281291879}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -7.914406031568037, 2: -8.05526712091356, 3: -7.9196029539795445, 4: -8.05788371597561}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.880417538146531, 2: -7.958431710504908, 3: -7.735528087137775, 4: -7.8643612988840506}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.956795563568519, 2: -7.945232172110596, 3: -7.84396727008463, 4: -8.030249911627472}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -7.969521882150011, 2: -8.016151583173835, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -7.910062819209293, 2: -7.912162393104332, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.780859042061394, 2: -7.719499603862214, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 2, Actual action: 2\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.598147902268016, 2: -7.587473935687641, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 2, Actual action: 2\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.434263357976545, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.273832359684981, 2: -8.373105715491592, 3: -8.352391663536181, 4: -8.372991561859163}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.264393445934713 -8.240462553881514 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.112978741654189 -8.08530242211307 -8.016151583173835 -7.945232172110596 -7.8643612988840506 \n",
      "-7.996859256169696 -7.955938075800069 -7.912162393104332 -7.772870708237608 -7.681941956711863 \n",
      "-7.915619703529895 -7.905225522051559 -7.722830181094054 -7.598147902268016 -7.445230547142489 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.273832359684981 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.112978741654189, 1: -8.141953416333074, 2: -8.257861624949687, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.293641167979626, 2: -8.264393445934713, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.240462553881514, 2: -8.295331754630466, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.146664368108947, 2: -8.111853066224217, 3: -8.08530242211307, 4: -8.209251633756821}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.141953416333074, 2: -8.257861624949687, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.141953416333074, 2: -8.257861624949687, 3: -8.12921617271129, 4: -8.227853983641197}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.141953416333074, 2: -8.257861624949687, 3: -8.297586717167276, 4: -8.227853983641197}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -8.095569298897031, 2: -7.998969621900848, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -8.095569298897031, 2: -7.998969621900848, 3: -7.996859256169696, 4: -8.06542265151096}, Best action: 3, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -8.095569298897031, 2: -7.998969621900848, 3: -8.177141923114423, 4: -8.06542265151096}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.955938075800069, 1: -8.070528602396832, 2: -8.004999872715137, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 0, Actual action: 0\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.146664368108947, 2: -8.111853066224217, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.104103071774528, 2: -8.016151583173835, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.956795563568519, 2: -7.945232172110596, 3: -8.139709451549972, 4: -8.030249911627472}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.880417538146531, 2: -7.958431710504908, 3: -8.027166297482328, 4: -7.8643612988840506}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.880417538146531, 2: -7.958431710504908, 3: -8.027166297482328, 4: -7.8643612988840506}, Best action: 4, Actual action: 4\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.880417538146531, 2: -7.958431710504908, 3: -8.027166297482328, 4: -8.056568781984485}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.681941956711863, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.445230547142489, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.29889601670839, 2: -8.373105715491592, 3: -8.352391663536181, 4: -8.372991561859163}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.293641167979626 -8.273141217299738 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.191651339130761 -8.146664368108947 -8.049875603748838 -7.956795563568519 -7.910414738751262 \n",
      "-8.012566806086141 -8.004999872715137 -7.912162393104332 -7.772870708237608 -7.698830938856602 \n",
      "-7.915619703529895 -7.905225522051559 -7.722830181094054 -7.598147902268016 -7.466628828248045 \n",
      "-7.721200950462702 -7.743001647637261 -7.572838040982517 -7.354276715585442 -8.29889601670839 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.191651339130761, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.227853983641197}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.012566806086141, 1: -8.095569298897031, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.06542265151096}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.209344246842852, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.227853983641197}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.095569298897031, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.06542265151096}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.095569298897031, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.06542265151096}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.095569298897031, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.239534612874975}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.927804592285524, 2: -7.928028522459052, 3: -7.915619703529895, 4: -8.059802214130523}, Best action: 3, Actual action: 3\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.927804592285524, 2: -7.928028522459052, 3: -7.915619703529895, 4: -8.059802214130523}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.927804592285524, 2: -7.928028522459052, 3: -8.103213930212204, 4: -8.059802214130523}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.721200950462702, 2: -7.729338535171467, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.721200950462702, 2: -7.729338535171467, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.926292864921059, 2: -7.729338535171467, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -7.743001647637261, 3: -7.752049931042639, 4: -7.805430611807427}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.572838040982517, 3: -7.8190819762015, 4: -7.77667019424775}, Best action: 2, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -8.007756565486941, 3: -7.752049931042639, 4: -7.805430611807427}, Best action: 3, Actual action: 3\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.944765188103329, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 3, Actual action: 3\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.944765188103329, 3: -7.745878843032384, 4: -7.833095117706377}, Best action: 3, Actual action: 3\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.944765188103329, 3: -7.94874974715947, 4: -7.833095117706377}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.944765188103329, 3: -8.039682020058112, 4: -7.833095117706377}, Best action: 4, Actual action: 4\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.944765188103329, 3: -8.039682020058112, 4: -8.028116557112803}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.752245313397557, 1: -7.7939879776563465, 2: -8.007756565486941, 3: -7.949366855960495, 4: -7.805430611807427}, Best action: 0, Actual action: 0\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -7.905225522051559, 2: -7.908754421476111, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -7.7939879776563465, 2: -8.007756565486941, 3: -7.949366855960495, 4: -7.805430611807427}, Best action: 1, Actual action: 1\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -7.7939879776563465, 2: -8.007756565486941, 3: -7.949366855960495, 4: -7.805430611807427}, Best action: 1, Actual action: 1\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -7.992529059667277, 2: -8.007756565486941, 3: -7.949366855960495, 4: -7.805430611807427}, Best action: 4, Actual action: 4\n",
      "Step: 25\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -8.021651701530743, 2: -8.007756565486941, 3: -7.949366855960495, 4: -7.805430611807427}, Best action: 4, Actual action: 4\n",
      "Step: 26\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -8.021651701530743, 2: -8.007756565486941, 3: -7.949366855960495, 4: -8.002941856744759}, Best action: 3, Actual action: 3\n",
      "Step: 27\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.973795222662354, 3: -8.039682020058112, 4: -8.138071458074977}, Best action: 1, Actual action: 1\n",
      "Step: 28\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -7.9533934999809945, 2: -7.973795222662354, 3: -8.039682020058112, 4: -8.138071458074977}, Best action: 1, Actual action: 1\n",
      "Step: 29\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -8.137588084982704, 2: -7.973795222662354, 3: -8.039682020058112, 4: -8.138071458074977}, Best action: 2, Actual action: 2\n",
      "Step: 30\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -8.021651701530743, 2: -8.007756565486941, 3: -8.137185420580655, 4: -8.139281339002476}, Best action: 2, Actual action: 2\n",
      "Step: 31\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.572838040982517, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 32\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.387693396984743, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 1, Actual action: 1\n",
      "Step: 33\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.354276715585442, 2: -7.387693396984743, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 1, Actual action: 1\n",
      "Step: 34\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.592391811182752, 2: -7.387693396984743, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 35\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.365127186366756, 2: -8.373105715491592, 3: -8.352391663536181, 4: -8.372991561859163}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.293641167979626 -8.273141217299738 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.227853983641197 -8.146664368108947 -8.049875603748838 -7.956795563568519 -7.910414738751262 \n",
      "-8.121208889748917 -8.004999872715137 -7.912162393104332 -7.772870708237608 -7.698830938856602 \n",
      "-7.928028522459052 -7.908754421476111 -7.722830181094054 -7.598147902268016 -7.466628828248045 \n",
      "-8.039682020058112 -7.834774469744533 -7.61424794372246 -7.416392995362577 -8.352391663536181 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.293641167979626, 2: -8.401214013237498, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.253926772408164, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.227853983641197}, Best action: 4, Actual action: 4\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.253926772408164, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.227853983641197}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.253926772408164, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.38734712511349}, Best action: 1, Actual action: 1\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.121208889748917, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.281364593394091}, Best action: 1, Actual action: 1\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.946953229103341, 2: -7.928028522459052, 3: -8.131843112772495, 4: -8.059802214130523}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -7.908754421476111, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.780859042061394, 2: -7.817803848293211, 3: -7.722830181094054, 4: -7.754002354712098}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -7.9463678888337945, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.780859042061394, 2: -7.817803848293211, 3: -8.108841008064777, 4: -7.754002354712098}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.780859042061394, 2: -7.817803848293211, 3: -8.108841008064777, 4: -7.754002354712098}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.780859042061394, 2: -7.817803848293211, 3: -8.108841008064777, 4: -7.956142142788009}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.61424794372246, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.643270832675918, 2: -7.504206587162781, 3: -7.416392995362577, 4: -7.563363729866878}, Best action: 3, Actual action: 3\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.668703120615934, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 1, Actual action: 1\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.6196122522638285, 2: -7.668703120615934, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.833847149560084, 2: -7.668703120615934, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.499733788423836, 1: -7.643270832675918, 2: -7.504206587162781, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 0, Actual action: 0\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.598147902268016, 2: -7.680500713529766, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 1, Actual action: 1\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.504206587162781, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.365127186366756, 2: -8.373105715491592, 3: -8.453088512417116, 4: -8.372991561859163}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.307892664436354 -8.273141217299738 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.257861624949687 -8.146664368108947 -8.049875603748838 -7.956795563568519 -7.910414738751262 \n",
      "-8.133823992166725 -8.004999872715137 -7.912162393104332 -7.772870708237608 -7.698830938856602 \n",
      "-7.946953229103341 -7.954433693433489 -7.817803848293211 -7.602050524672501 -7.466628828248045 \n",
      "-8.039682020058112 -7.834774469744533 -7.741654680684901 -7.5261736796733505 -8.365127186366756 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.30357187793744, 2: -8.257861624949687, 3: -8.324740938946517, 4: -8.424415398161962}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.146664368108947, 2: -8.204268088993228, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.266194791221622, 1: -8.070528602396832, 2: -8.004999872715137, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -7.943800961049323, 2: -7.912162393104332, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.78570589935202, 2: -7.874864682095917, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.78570589935202, 2: -7.874864682095917, 3: -7.854954540152779, 4: -7.772870708237608}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.78570589935202, 2: -7.874864682095917, 3: -7.854954540152779, 4: -7.9733123444962235}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.680500713529766, 3: -7.602050524672501, 4: -7.651213388582266}, Best action: 3, Actual action: 3\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.845626738621332, 2: -7.817803848293211, 3: -8.108841008064777, 4: -7.998110038348529}, Best action: 2, Actual action: 3\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -7.9753786962001785, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 4, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -7.9753786962001785, 3: -7.989647279384338, 4: -7.954433693433489}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -7.9753786962001785, 3: -7.989647279384338, 4: -8.138534661024476}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.845626738621332, 2: -7.817803848293211, 3: -8.153975392487604, 4: -7.998110038348529}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.680500713529766, 3: -8.22836626899972, 4: -7.651213388582266}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.680500713529766, 3: -8.22836626899972, 4: -7.651213388582266}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.680500713529766, 3: -8.22836626899972, 4: -7.862604183609863}, Best action: 2, Actual action: 2\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.466628828248045, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.425380634845922, 2: -8.373105715491592, 3: -8.453088512417116, 4: -8.372991561859163}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.307892664436354 -8.273141217299738 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.30357187793744 -8.198716333710157 -8.049875603748838 -7.956795563568519 -7.910414738751262 \n",
      "-8.133823992166725 -8.070528602396832 -7.943800961049323 -7.7887478894713515 -7.698830938856602 \n",
      "-7.946953229103341 -7.986209494529992 -7.845626738621332 -7.716019422233893 -7.51057489135528 \n",
      "-8.039682020058112 -7.834774469744533 -7.741654680684901 -7.5261736796733505 -8.372991561859163 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 3, Actual action: 3\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.307892664436354, 4: -8.345372544840833}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.460182324637081, 4: -8.345372544840833}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.317569960320567, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.483249900323367, 4: -8.345372544840833}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.468988663891714, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.483249900323367, 4: -8.345372544840833}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.483249900323367, 4: -8.345372544840833}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.393925843547333, 2: -8.401214013237498, 3: -8.483249900323367, 4: -8.494289015805158}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.30357187793744, 2: -8.324584300663215, 3: -8.324740938946517, 4: -8.424415398161962}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.133823992166725, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.281364593394091}, Best action: 1, Actual action: 1\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -7.946953229103341, 2: -8.098893933641556, 3: -8.131843112772495, 4: -8.059802214130523}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -8.17253293885478, 2: -8.183662340310658, 3: -8.039682020058112, 4: -8.138071458074977}, Best action: 3, Actual action: 3\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -8.17253293885478, 2: -8.183662340310658, 3: -8.039682020058112, 4: -8.138071458074977}, Best action: 3, Actual action: 3\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078364748751726, 1: -8.17253293885478, 2: -8.183662340310658, 3: -8.216110638252882, 4: -8.138071458074977}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -8.206837759157404, 2: -8.098893933641556, 3: -8.131843112772495, 4: -8.059802214130523}, Best action: 4, Actual action: 4\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -8.206837759157404, 2: -8.098893933641556, 3: -8.131843112772495, 4: -8.059802214130523}, Best action: 4, Actual action: 4\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.093144634743108, 1: -8.206837759157404, 2: -8.098893933641556, 3: -8.131843112772495, 4: -8.234420014858774}, Best action: 0, Actual action: 0\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.150414514790379, 2: -8.14420680358814, 3: -8.196879586051129, 4: -8.281364593394091}, Best action: 2, Actual action: 2\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.266194791221622, 1: -8.070528602396832, 2: -8.109351525686023, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.986209494529992, 1: -8.003652814106797, 2: -8.02995898673752, 3: -7.989647279384338, 4: -8.173910210024593}, Best action: 0, Actual action: 0\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.266194791221622, 1: -8.175882550808975, 2: -8.109351525686023, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -7.943800961049323, 2: -7.987241512982896, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.845626738621332, 2: -7.879263229580957, 3: -8.153975392487604, 4: -7.998110038348529}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.895034242654915, 2: -7.741654680684901, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 23\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.5261736796733505, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 24\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.425380634845922, 2: -8.373105715491592, 3: -8.453088512417116, 4: -8.466692214379362}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.401214013237498 -8.273141217299738 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.318754621448793 -8.198716333710157 -8.049875603748838 -7.956795563568519 -7.910414738751262 \n",
      "-8.150414514790379 -8.145413931018554 -7.987241512982896 -7.7887478894713515 -7.698830938856602 \n",
      "-8.098893933641556 -7.989647279384338 -7.879263229580957 -7.716019422233893 -7.51057489135528 \n",
      "-8.138071458074977 -7.834774469744533 -7.770366148603904 -7.534832997515525 -8.373105715491592 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.273141217299738, 2: -8.295331754630466, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.198716333710157, 2: -8.204268088993228, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.266194791221622, 1: -8.175882550808975, 2: -8.145413931018554, 3: -8.163332131514656, 4: -8.230471167662573}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.049337754388212, 2: -7.987241512982896, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7887478894713515, 1: -7.836231514919928, 2: -7.874864682095917, 3: -7.854954540152779, 4: -8.003753012924758}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -7.956795563568519, 2: -8.06465586930714, 3: -8.139709451549972, 4: -8.030249911627472}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.123879195437636, 1: -7.836231514919928, 2: -7.874864682095917, 3: -7.854954540152779, 4: -8.003753012924758}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.716019422233893, 3: -8.22836626899972, 4: -7.907465996320097}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.528786047930726, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.528786047930726, 2: -7.51057489135528, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.528786047930726, 2: -7.734623151133305, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.396905015400026, 1: -8.425380634845922, 2: -8.438554957561948, 3: -8.453088512417116, 4: -8.466692214379362}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.401214013237498 -8.295331754630466 -8.127074201284955 -8.002981526735557 -7.9196029539795445 \n",
      "-8.318754621448793 -8.204268088993228 -8.049875603748838 -8.030249911627472 -7.910414738751262 \n",
      "-8.150414514790379 -8.163332131514656 -8.007609941770085 -7.854954540152779 -7.698830938856602 \n",
      "-8.098893933641556 -7.989647279384338 -7.879263229580957 -7.7382221258286545 -7.554371667267095 \n",
      "-8.138071458074977 -7.834774469744533 -7.770366148603904 -7.534832997515525 -8.396905015400026 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.46528580548406, 2: -8.401214013237498, 3: -8.483249900323367, 4: -8.548508834853855}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.368274352035202, 2: -8.295331754630466, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.127074201284955, 2: -8.174200141381075, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.104103071774528, 2: -8.137253217726965, 3: -8.049875603748838, 4: -8.070652662855991}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.317656917496045, 2: -8.204268088993228, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.104103071774528, 2: -8.137253217726965, 3: -8.350444712459398, 4: -8.070652662855991}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.104103071774528, 2: -8.137253217726965, 3: -8.350444712459398, 4: -8.070652662855991}, Best action: 4, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.104103071774528, 2: -8.137253217726965, 3: -8.350444712459398, 4: -8.244293923198953}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.049337754388212, 2: -8.007609941770085, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.123879195437636, 1: -7.933598883501446, 2: -7.874864682095917, 3: -7.854954540152779, 4: -8.003753012924758}, Best action: 3, Actual action: 3\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.049337754388212, 2: -8.063274171700758, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.056396078979299, 1: -7.955302965216903, 2: -7.879263229580957, 3: -8.153975392487604, 4: -7.998110038348529}, Best action: 2, Actual action: 2\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.7382221258286545, 2: -7.755167604221167, 3: -8.22836626899972, 4: -7.907465996320097}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.534832997515525, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.425380634845922, 2: -8.438554957561948, 3: -8.453088512417116, 4: -8.466692214379362}, Best action: 1, Actual action: 1\n",
      "V:\n",
      "-8.459340122574428 -8.307813069074118 -8.174200141381075 -8.002981526735557 -7.9196029539795445 \n",
      "-8.318754621448793 -8.209251633756821 -8.137253217726965 -8.030249911627472 -7.910414738751262 \n",
      "-8.150414514790379 -8.163332131514656 -8.059425203437982 -7.874864682095917 -7.698830938856602 \n",
      "-8.098893933641556 -7.989647279384338 -7.955302965216903 -7.755167604221167 -7.554371667267095 \n",
      "-8.138071458074977 -7.834774469744533 -7.770366148603904 -7.563363729866878 -8.425380634845922 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.318754621448793, 2: -8.324584300663215, 3: -8.324740938946517, 4: -8.424415398161962}, Best action: 1, Actual action: 1\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.350825520551323, 1: -8.150414514790379, 2: -8.25154884830025, 3: -8.196879586051129, 4: -8.281364593394091}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.306121974380703, 1: -8.206837759157404, 2: -8.098893933641556, 3: -8.131843112772495, 4: -8.278889155627795}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.267195685258677, 1: -8.003652814106797, 2: -8.02995898673752, 3: -7.989647279384338, 4: -8.173910210024593}, Best action: 3, Actual action: 3\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.306121974380703, 1: -8.206837759157404, 2: -8.181503689665469, 3: -8.131843112772495, 4: -8.278889155627795}, Best action: 3, Actual action: 3\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.306121974380703, 1: -8.206837759157404, 2: -8.181503689665469, 3: -8.131843112772495, 4: -8.278889155627795}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.306121974380703, 1: -8.206837759157404, 2: -8.181503689665469, 3: -8.299977232622972, 4: -8.278889155627795}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.267195685258677, 1: -8.003652814106797, 2: -8.02995898673752, 3: -8.285757649284156, 4: -8.173910210024593}, Best action: 1, Actual action: 1\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.078457204201518, 1: -8.021651701530743, 2: -7.834774469744533, 3: -8.137185420580655, 4: -8.139281339002476}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.7765706737846045, 1: -7.895034242654915, 2: -7.770366148603904, 3: -7.961068641764688, 4: -7.77667019424775}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.578041613976749, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.578041613976749, 3: -7.813525223869959, 4: -7.563363729866878}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.578041613976749, 3: -7.813525223869959, 4: -7.782660994178859}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.480729306858114, 2: -8.438554957561948, 3: -8.453088512417116, 4: -8.466692214379362}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.459340122574428 -8.307813069074118 -8.174200141381075 -8.002981526735557 -7.9196029539795445 \n",
      "-8.324584300663215 -8.209251633756821 -8.137253217726965 -8.030249911627472 -7.910414738751262 \n",
      "-8.196879586051129 -8.163332131514656 -8.059425203437982 -7.874864682095917 -7.698830938856602 \n",
      "-8.201109148393051 -8.02995898673752 -7.955302965216903 -7.755167604221167 -7.554371667267095 \n",
      "-8.138071458074977 -7.977474027343616 -7.7765706737846045 -7.593033677022853 -8.438554957561948 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.368274352035202, 2: -8.312463278503861, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 0, Actual action: 0\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.307813069074118, 1: -8.368274352035202, 2: -8.312463278503861, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 0, Actual action: 0\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.460109892857448, 1: -8.368274352035202, 2: -8.312463278503861, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.233106659165054, 2: -8.174200141381075, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.024434227776903, 2: -8.002981526735557, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -7.957218353738401, 2: -8.05526712091356, 3: -7.9196029539795445, 4: -8.116457257167673}, Best action: 3, Actual action: 3\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.024434227776903, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -8.043027083441995, 2: -8.06465586930714, 3: -8.139709451549972, 4: -8.030249911627472}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -8.043027083441995, 2: -8.06465586930714, 3: -8.139709451549972, 4: -8.030249911627472}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -8.043027083441995, 2: -8.06465586930714, 3: -8.139709451549972, 4: -8.207527419581}, Best action: 1, Actual action: 1\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.123879195437636, 1: -7.933598883501446, 2: -7.874864682095917, 3: -8.20545903506973, 4: -8.003753012924758}, Best action: 2, Actual action: 2\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.698830938856602, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.554371667267095, 2: -7.771779013937219, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.480729306858114, 2: -8.473184081706231, 3: -8.453088512417116, 4: -8.466692214379362}, Best action: 3, Actual action: 3\n",
      "V:\n",
      "-8.459340122574428 -8.31693221572409 -8.176570062706707 -8.025710875181446 -7.957218353738401 \n",
      "-8.324584300663215 -8.209251633756821 -8.137253217726965 -8.05172219595844 -7.910414738751262 \n",
      "-8.196879586051129 -8.163332131514656 -8.059425203437982 -7.92353952868344 -7.7889241443720065 \n",
      "-8.201109148393051 -8.02995898673752 -7.955302965216903 -7.755167604221167 -7.5945693900855495 \n",
      "-8.138071458074977 -7.977474027343616 -7.7765706737846045 -7.593033677022853 -8.453088512417116 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.46528580548406, 2: -8.459340122574428, 3: -8.483249900323367, 4: -8.548508834853855}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.479106244873872, 1: -8.368274352035202, 2: -8.352348442369056, 3: -8.31693221572409, 4: -8.359620493779055}, Best action: 3, Actual action: 3\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.46528580548406, 2: -8.482649106993957, 3: -8.483249900323367, 4: -8.548508834853855}, Best action: 1, Actual action: 1\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.405456565372537, 1: -8.333711219125085, 2: -8.324584300663215, 3: -8.324740938946517, 4: -8.424415398161962}, Best action: 2, Actual action: 2\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.317656917496045, 2: -8.257655465812677, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 4, Actual action: 4\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.317656917496045, 2: -8.257655465812677, 3: -8.293195342107452, 4: -8.209251633756821}, Best action: 4, Actual action: 4\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.317656917496045, 2: -8.257655465812677, 3: -8.293195342107452, 4: -8.370418986718708}, Best action: 2, Actual action: 4\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.382701240209714, 1: -8.317656917496045, 2: -8.257655465812677, 3: -8.293195342107452, 4: -8.517081277914023}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.196574360011223, 2: -8.137253217726965, 3: -8.350444712459398, 4: -8.288752880457263}, Best action: 2, Actual action: 2\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.05172219595844, 1: -8.082943100841891, 2: -8.06465586930714, 3: -8.139709451549972, 4: -8.235604679546116}, Best action: 0, Actual action: 0\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.206945851195943, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 4, Actual action: 4\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.206945851195943, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.025710875181446}, Best action: 4, Actual action: 4\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.206945851195943, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.203396896415116}, Best action: 0, Actual action: 0\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.061601791291093, 1: -8.206945851195943, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.250237140587299}, Best action: 0, Actual action: 0\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.236057630074896, 1: -8.206945851195943, 2: -8.115176545396986, 3: -8.170699357804738, 4: -8.250237140587299}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -7.957218353738401, 2: -8.05526712091356, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -7.910414738751262, 2: -7.958431710504908, 3: -8.027166297482328, 4: -8.08879508409714}, Best action: 1, Actual action: 1\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.7889241443720065, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 1, Actual action: 1\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.602438861784574, 2: -7.771779013937219, 3: -7.5945693900855495, 4: -7.6419487092224045}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.777036940570441, 2: -7.755167604221167, 3: -8.22836626899972, 4: -7.907465996320097}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.602438861784574, 2: -7.771779013937219, 3: -7.9411426984277, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.480729306858114, 2: -8.473184081706231, 3: -8.597374350526998, 4: -8.466692214379362}, Best action: 4, Actual action: 4\n",
      "V:\n",
      "-8.482649106993957 -8.352348442369056 -8.176570062706707 -8.156864521067805 -8.05526712091356 \n",
      "-8.324740938946517 -8.293195342107452 -8.147962107521096 -8.06465586930714 -7.933550393908898 \n",
      "-8.196879586051129 -8.163332131514656 -8.059425203437982 -7.92353952868344 -7.804994098718295 \n",
      "-8.201109148393051 -8.02995898673752 -7.955302965216903 -7.777036940570441 -7.618264579825741 \n",
      "-8.138071458074977 -7.977474027343616 -7.7765706737846045 -7.593033677022853 -8.466692214379362 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.506650627710247, 1: -8.48944186408561, 2: -8.482649106993957, 3: -8.483249900323367, 4: -8.548508834853855}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.479106244873872, 1: -8.368274352035202, 2: -8.352348442369056, 3: -8.588574724014496, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.233106659165054, 2: -8.199835050793908, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 4, Actual action: 4\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.233106659165054, 2: -8.199835050793908, 3: -8.36504302006671, 4: -8.176570062706707}, Best action: 4, Actual action: 4\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.233106659165054, 2: -8.199835050793908, 3: -8.36504302006671, 4: -8.340678757063104}, Best action: 2, Actual action: 2\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.29689876477905, 1: -8.206945851195943, 2: -8.156864521067805, 3: -8.170699357804738, 4: -8.250237140587299}, Best action: 2, Actual action: 2\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -8.103157773762362, 2: -8.05526712091356, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 2, Actual action: 2\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -8.103157773762362, 2: -8.05526712091356, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 2, Actual action: 2\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -8.103157773762362, 2: -8.230293080031341, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 0, Actual action: 0\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.075475307747773, 1: -8.103157773762362, 2: -8.264164307278831, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 0, Actual action: 4\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.281877909080592, 1: -8.103157773762362, 2: -8.264164307278831, 3: -8.191752019897246, 4: -8.116457257167673}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.933550393908898, 1: -8.00007003081645, 2: -7.958431710504908, 3: -8.027166297482328, 4: -8.08879508409714}, Best action: 0, Actual action: 0\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.281877909080592, 1: -8.136491596442443, 2: -8.264164307278831, 3: -8.191752019897246, 4: -8.275203522464281}, Best action: 1, Actual action: 1\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.283913232509269, 1: -8.00007003081645, 2: -7.958431710504908, 3: -8.027166297482328, 4: -8.08879508409714}, Best action: 2, Actual action: 2\n",
      "Step: 14\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.283913232509269, 1: -8.00007003081645, 2: -7.958431710504908, 3: -8.027166297482328, 4: -8.08879508409714}, Best action: 2, Actual action: 2\n",
      "Step: 15\n",
      "---------------------------------\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.283913232509269, 1: -8.00007003081645, 2: -8.142172856559467, 3: -8.027166297482328, 4: -8.08879508409714}, Best action: 1, Actual action: 1\n",
      "Step: 16\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.8304936204064965, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 4, Actual action: 4\n",
      "Step: 17\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.8304936204064965, 2: -7.837537074793074, 3: -7.828021472651341, 4: -7.804994098718295}, Best action: 4, Actual action: 4\n",
      "Step: 18\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.8304936204064965, 2: -7.837537074793074, 3: -7.828021472651341, 4: -8.002544629833649}, Best action: 3, Actual action: 3\n",
      "Step: 19\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.123879195437636, 1: -7.933598883501446, 2: -7.92353952868344, 3: -8.20545903506973, 4: -8.003753012924758}, Best action: 2, Actual action: 2\n",
      "Step: 20\n",
      "---------------------------------\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.83514062300145, 1: -7.8304936204064965, 2: -7.837537074793074, 3: -8.10086916549872, 4: -8.04095185583095}, Best action: 1, Actual action: 1\n",
      "Step: 21\n",
      "---------------------------------\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.674267746445147, 1: -7.618264579825741, 2: -7.771779013937219, 3: -7.9411426984277, 4: -7.6419487092224045}, Best action: 1, Actual action: 1\n",
      "Step: 22\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.480729306858114, 2: -8.473184081706231, 3: -8.597374350526998, 4: -8.617614998103042}, Best action: 2, Actual action: 2\n",
      "V:\n",
      "-8.483249900323367 -8.358256595029339 -8.233106659165054 -8.170699357804738 -8.159978845153221 \n",
      "-8.324740938946517 -8.293195342107452 -8.147962107521096 -8.06465586930714 -8.022052223043463 \n",
      "-8.196879586051129 -8.163332131514656 -8.059425203437982 -7.933598883501446 -7.83514062300145 \n",
      "-8.201109148393051 -8.02995898673752 -7.955302965216903 -7.777036940570441 -7.625105564164621 \n",
      "-8.138071458074977 -7.977474027343616 -7.7765706737846045 -7.593033677022853 -8.473184081706231 \n",
      "\n",
      "Observable state: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Step: 0\n",
      "---------------------------------\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.479106244873872, 1: -8.368274352035202, 2: -8.358256595029339, 3: -8.588574724014496, 4: -8.359620493779055}, Best action: 2, Actual action: 2\n",
      "Step: 1\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.233106659165054, 2: -8.327043767144312, 3: -8.36504302006671, 4: -8.375934266849375}, Best action: 1, Actual action: 1\n",
      "Step: 2\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.147962107521096, 1: -8.196574360011223, 2: -8.235620300499034, 3: -8.350444712459398, 4: -8.288752880457263}, Best action: 0, Actual action: 0\n",
      "Step: 3\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.323159973008593, 2: -8.327043767144312, 3: -8.36504302006671, 4: -8.375934266849375}, Best action: 0, Actual action: 0\n",
      "Step: 4\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.276013308772539, 1: -8.323159973008593, 2: -8.327043767144312, 3: -8.36504302006671, 4: -8.375934266849375}, Best action: 0, Actual action: 0\n",
      "Step: 5\n",
      "---------------------------------\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.43117211098301, 1: -8.323159973008593, 2: -8.327043767144312, 3: -8.36504302006671, 4: -8.375934266849375}, Best action: 1, Actual action: 1\n",
      "Step: 6\n",
      "---------------------------------\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.418366990857866, 1: -8.196574360011223, 2: -8.235620300499034, 3: -8.350444712459398, 4: -8.288752880457263}, Best action: 1, Actual action: 1\n",
      "Step: 7\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.087136991399396, 2: -8.063274171700758, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 4, Actual action: 4\n",
      "Step: 8\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.087136991399396, 2: -8.063274171700758, 3: -8.093719435245145, 4: -8.059425203437982}, Best action: 4, Actual action: 4\n",
      "Step: 9\n",
      "---------------------------------\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.120865434506674, 1: -8.087136991399396, 2: -8.063274171700758, 3: -8.093719435245145, 4: -8.234076935128563}, Best action: 2, Actual action: 2\n",
      "Step: 10\n",
      "---------------------------------\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8.123879195437636, 1: -7.933598883501446, 2: -8.035053785397606, 3: -8.20545903506973, 4: -8.003753012924758}, Best action: 1, Actual action: 1\n",
      "Step: 11\n",
      "---------------------------------\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.777780009337302, 1: -7.777036940570441, 2: -7.833492238467622, 3: -8.22836626899972, 4: -7.907465996320097}, Best action: 1, Actual action: 1\n",
      "Step: 12\n",
      "---------------------------------\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7.804473179679476, 1: -7.643270832675918, 2: -7.593033677022853, 3: -7.813525223869959, 4: -7.816479806739053}, Best action: 2, Actual action: 2\n",
      "Step: 13\n",
      "---------------------------------\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: -8.544673852262376, 1: -8.480729306858114, 2: -8.517506250144388, 3: -8.597374350526998, 4: -8.617614998103042}, Best action: 1, Actual action: 1\n",
      "[159, 36, 49, 46, 54, 10, 40, 27, 34, 48, 60, 44, 59, 71, 42, 62, 25, 34, 13, 54, 77, 38, 22, 19, 38, 22, 60, 44, 39, 40, 31, 33, 18, 20, 51, 20, 11, 64, 29, 16, 20, 30, 22, 36, 37, 26, 49, 16, 35, 21, 23, 30, 28, 23, 18, 11, 28, 11, 36, 9, 32, 9, 45, 31, 30, 21, 19, 16, 22, 13, 23, 11, 29, 42, 15, 16, 22, 18, 30, 11, 11, 18, 13, 15, 11, 20, 13, 20, 19, 35, 20, 17, 24, 11, 14, 13, 13, 21, 22, 13]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(0.9, 0.01, 0.9, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(100, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 159)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 36)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 49)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 46)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 10)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 27)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 48)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 60)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 44)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 59)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 71)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 62)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 25)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 34)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 54)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 77)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 38)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 60)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 44)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 39)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 40)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 51)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 64)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 36)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 37)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 26)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 49)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 35)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 28)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 36)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 32)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 45)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 31)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 23)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 42)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 16)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 18)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 4, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 35)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 3, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 20)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 14)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 4, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 3, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 22)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
