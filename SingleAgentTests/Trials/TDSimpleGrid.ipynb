{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD0 in a simple grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/edwardgunn/Documents/4YP/DistributedReinforcementLearningOnTheEdge\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 4\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.00 0.00 0.00 0.00 0.00 \n",
      "-1.00 0.00 0.00 0.00 0.00 \n",
      "-1.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: -1}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: -1}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -1}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.00 -1.00 0.00 0.00 0.00 \n",
      "-1.00 -1.00 0.00 0.00 0.00 \n",
      "-1.00 -1.00 0.00 0.00 0.00 \n",
      "-1.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -1}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: 0, 4: 0}, Best action: 3, Actual action: 3\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: 0}, Best action: 4, Actual action: 4\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -1}, Best action: 0, Actual action: 0\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-1.00 -1.00 -1.00 -1.00 -1.00 \n",
      "-1.00 -1.00 -1.00 -1.00 -1.00 \n",
      "-1.00 -1.00 -1.00 -1.00 -1.00 \n",
      "-1.00 -1.00 -1.00 -1.00 0.00 \n",
      "-1.00 -1.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -3, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.00 -1.00 -1.00 -1.00 -1.00 \n",
      "-2.00 -2.00 -2.00 -2.00 -2.00 \n",
      "-1.00 -1.00 -1.00 -1.00 -1.00 \n",
      "-1.00 -1.00 -1.00 -1.00 0.00 \n",
      "-1.00 -1.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -3, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -3, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-2.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-2.00 -2.00 -2.00 -2.00 -2.00 \n",
      "-2.00 -2.00 -1.00 -1.00 -1.00 \n",
      "-1.00 -1.00 -1.00 -1.00 0.00 \n",
      "-1.00 -1.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -3, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -1}, Best action: 4, Actual action: 4\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -1}, Best action: 4, Actual action: 4\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -1, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-2.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-2.00 -2.00 -1.00 -1.00 -1.00 \n",
      "-2.00 -2.00 -1.00 -1.00 0.00 \n",
      "-1.00 -1.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -3, 1: -3, 2: -4, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -4, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -4, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -4, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-3.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-2.00 -2.00 -2.00 -1.00 -1.00 \n",
      "-2.00 -2.00 -2.00 -1.00 0.00 \n",
      "-2.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -2.00 -2.00 -1.00 -1.00 \n",
      "-2.00 -2.00 -2.00 -1.00 0.00 \n",
      "-2.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -3}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -3}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -2.00 -2.00 -1.00 -1.00 \n",
      "-3.00 -2.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -2.00 -1.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -1, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 0, Actual action: 0\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -2.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -2.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -3.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-4.00 -4.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-3.00 -3.00 -3.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-3.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -3.00 -3.00 -2.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -2}, Best action: 3, Actual action: 3\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -3.00 -3.00 -3.00 \n",
      "-4.00 -4.00 -3.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-3.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -3}, Best action: 4, Actual action: 4\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -3}, Best action: 4, Actual action: 4\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -3.00 -3.00 -3.00 \n",
      "-5.00 -4.00 -3.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -3.00 -3.00 -3.00 \n",
      "-5.00 -4.00 -3.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -6, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -6, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -6, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -6, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -4.00 -4.00 -3.00 -3.00 \n",
      "-5.00 -4.00 -4.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -5.00 -4.00 -3.00 -3.00 \n",
      "-5.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -6, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -6, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -6, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-5.00 -5.00 -4.00 -4.00 -3.00 \n",
      "-5.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -5.00 -4.00 -4.00 -3.00 \n",
      "-5.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-4.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -5.00 -4.00 -4.00 -3.00 \n",
      "-5.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -5.00 -4.00 -4.00 -3.00 \n",
      "-5.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -5.00 -4.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -5.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-6.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -7, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 0\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 0\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -2, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 3\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -2, 4: -3}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 1\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 0\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 0\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 0\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -3.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -7, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -7, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -7, 3: -7, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 0\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -4, 4: -5}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -5, 4: -6}, Best action: 3, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -3, 4: -4}, Best action: 3, Actual action: 3\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -7, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-7.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -7, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -2, 4: -2}, Best action: 2, Actual action: 3\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 3\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -6}, Best action: 2, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 4\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -6, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -6, 4: -7}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 0\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -4.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -4.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -4.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 2\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -4.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -4.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 4\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: 0, 4: 0}, Best action: 2, Actual action: 3\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -2, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 0\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 0\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -3, 2: -3, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 4\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: 0}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 0\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -5}, Best action: 4, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -5}, Best action: 4, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -4, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 3\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -3}, Best action: 4, Actual action: 4\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -3}, Best action: 4, Actual action: 4\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -4}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -3, 2: -4, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -7, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 3\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -6, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -8, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 3\n",
      "State: (2, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 1, Actual action: 3\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -7, 3: -8, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -8, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -8, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -9, 4: -8}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -9, 4: -8}, Best action: 4, Actual action: 4\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -9, 4: -9}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -9, 3: -9, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -9, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -5, 3: -7, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 3\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -8, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -8, 3: -7, 4: -6}, Best action: 4, Actual action: 4\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -8, 3: -7, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -7, 3: -8, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -7, 2: -8, 3: -7, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -8, 2: -7, 3: -8, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -8, 2: -7, 3: -8, 4: -7}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -7, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -1, 4: -2}, Best action: 1, Actual action: 3\n",
      "State: (2, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -5, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 3\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (0, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (0, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -5, 4: -4}, Best action: 2, Actual action: 3\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 0, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -6, 3: -8, 4: -7}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 0\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -7}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -7}, Best action: 4, Actual action: 4\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -9}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -7, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -8.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -8, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -9, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 1\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -2.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -4, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -4, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -2, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -8, 4: -9}, Best action: 1, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -9, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -8, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -5.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -6.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -6, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -7.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -7, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -8, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 4\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -5.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -5, 2: -8, 3: -7, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 4\n",
      "State: (2, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -6, 3: -6, 4: -7}, Best action: 1, Actual action: 1\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -7.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -7, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -6, 3: -7, 4: -8}, Best action: 2, Actual action: 2\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -7, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -7, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -7, 4: -8}, Best action: 3, Actual action: 3\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -8.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -8, 2: -8, 3: -10, 4: -9}, Best action: 1, Actual action: 1\n",
      "State: (1, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -8, 2: -8, 3: -8, 4: -8}, Best action: 0, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -8, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-9.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -9, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 4\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -7, 3: -9, 4: -10}, Best action: 2, Actual action: 2\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 0\n",
      "State: (0, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -9, 2: -6, 3: -10, 4: -9}, Best action: 2, Actual action: 2\n",
      "State: (0, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (1, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -7, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (1, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (1, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -2, 3: -2, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (2, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: -1, 3: -3, 4: -2}, Best action: 1, Actual action: 1\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-8.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -10, 2: -10, 3: -9, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -8, 1: -10, 2: -10, 3: -9, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -10, 2: -10, 3: -9, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -10, 3: -9, 4: -10}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -10, 3: -9, 4: -10}, Best action: 3, Actual action: 3\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -10, 3: -10, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -10, 1: -10, 2: -10, 3: -11, 4: -10}, Best action: 0, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11, 1: -10, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -1, 3: -4, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 0\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -2.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -2, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -2}, Best action: 4, Actual action: 4\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -3, 2: -3, 3: -4, 4: -3}, Best action: 0, Actual action: 0\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -3, 4: -3}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -3, 2: -3, 3: -4, 4: -4}, Best action: 1, Actual action: 1\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -3.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 0\n",
      "State: (0, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -11, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -3, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -4.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -4, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -4.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -4, 4: -5}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -4, 4: -5}, Best action: 3, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -3, 3: -5, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -4, 2: -4, 3: -4, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -4, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -1, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-4.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -4, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -4}, Best action: 4, Actual action: 4\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -5, 3: -5, 4: -5}, Best action: 0, Actual action: 0\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 3\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -5, 3: -6, 4: -5}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -5, 3: -5, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (4, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -5, 3: -5, 4: -6}, Best action: 2, Actual action: 2\n",
      "State: (4, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -5, 1: -5, 2: -2, 3: -4, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (4, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -1, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (4, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -2, 1: -1, 2: 0, 3: -2, 4: -1}, Best action: 2, Actual action: 2\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-5.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-5.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -5, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -5, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "V:\n",
      "-7.00 -6.00 -5.00 -4.00 -3.00 \n",
      "-6.00 -8.00 -4.00 -3.00 -2.00 \n",
      "-6.00 -4.00 -3.00 -2.00 -1.00 \n",
      "-4.00 -3.00 -2.00 -1.00 0.00 \n",
      "-3.00 -2.00 -1.00 0.00 0.00 \n",
      "\n",
      "Action values: {0: -8, 1: -7, 2: -10, 3: -11, 4: -10}, Best action: 1, Actual action: 1\n",
      "State: (1, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -9, 1: -6, 2: -8, 3: -9, 4: -8}, Best action: 1, Actual action: 1\n",
      "State: (2, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -7, 1: -6, 2: -6, 3: -6, 4: -6}, Best action: 1, Actual action: 1\n",
      "State: (3, 0)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -6, 2: -4, 3: -6, 4: -5}, Best action: 2, Actual action: 2\n",
      "State: (3, 1)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -6, 1: -5, 2: -3, 3: -4, 4: -4}, Best action: 2, Actual action: 2\n",
      "State: (3, 2)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -4, 1: -4, 2: -2, 3: -3, 4: -3}, Best action: 2, Actual action: 2\n",
      "State: (3, 3)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -3, 1: -2, 2: -1, 3: -3, 4: -2}, Best action: 2, Actual action: 2\n",
      "State: (3, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: -1\n",
      "Action values: {0: -1, 1: 0, 2: 0, 3: -2, 4: 0}, Best action: 1, Actual action: 1\n",
      "State: (4, 4)\n",
      "Possible actions: [0, 1, 2, 3, 4]\n",
      "Reward: 0\n",
      "Action values: {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}, Best action: 0, Actual action: 0\n",
      "[104, 33, 85, 30, 51, 24, 33, 17, 19, 21, 15, 17, 11, 11, 11, 29, 15, 7, 13, 17, 13, 11, 11, 7, 11, 11, 7, 9, 11, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 15, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 11, 9, 15, 7, 8, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 8, 7, 7, 7, 7, 7, 8, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 9, 7, 8, 11, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 9, 8, 7, 7, 7, 7, 7, 15, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 10, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 23, 7, 7, 7, 7, 7, 7, 7, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 11, 7, 8, 11, 7, 8, 9, 7, 7, 9, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 13, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 14, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 9, 13, 8, 7, 11, 14, 7, 7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SingleAgentTests.Agents.TD0 import TD0\n",
    "from SingleAgentTests.Environments.SimpleGrid import SimpleGrid\n",
    "from SingleAgentTests.Universe import Universe\n",
    "import matplotlib.pyplot as plt\n",
    "gridSize = 5\n",
    "terminal = (4,4)\n",
    "environment = SimpleGrid(gridSize,gridSize,terminal)\n",
    "initailState = environment.getObservableState()\n",
    "possibleAction = environment.getPossibleActions()\n",
    "allStateActions = environment.getAllPossibleStateActions()\n",
    "agent = TD0(1, 0.01, 1, initailState, possibleAction, allStateActions)\n",
    "universe = Universe(environment, agent)\n",
    "universe.trainMany(1000, SimpleGrid, gridSize,gridSize,terminal)\n",
    "stepCounts = [entry[4] for entry in universe.getHistory() if entry[4] is not None]\n",
    "print(stepCounts)\n",
    "plt.plot(stepCounts)\n",
    "plt.xlabel(\"Episode number\")\n",
    "plt.ylabel(\"Number of steps\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 0, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 2, (2, 4), -1, None)\n",
      "((2, 4), 3, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 0, (3, 3), -1, None)\n",
      "((3, 3), 2, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 104)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 4, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 3, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 4, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 4, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 0, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 3, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 4, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 4, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 4, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 4, (2, 4), -1, None)\n",
      "((2, 4), 0, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 85)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 2, (1, 4), -1, None)\n",
      "((1, 4), 3, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 0, (2, 3), -1, None)\n",
      "((2, 3), 2, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 30)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 2, (0, 4), -1, None)\n",
      "((0, 4), 3, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 2, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 51)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 24)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 3, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 3, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 3, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 0, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 33)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 2, (3, 2), -1, None)\n",
      "((3, 2), 0, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 3, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 3, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 4, (4, 0), -1, None)\n",
      "((4, 0), 0, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 19)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 4, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 3, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 4, (3, 1), -1, None)\n",
      "((3, 1), 0, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 21)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 3, (2, 2), -1, None)\n",
      "((2, 2), 2, (2, 3), -1, None)\n",
      "((2, 3), 0, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 4, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 4, (2, 2), -1, None)\n",
      "((2, 2), 0, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 2, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 2, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 3, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 2, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 3, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 0, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 3, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 4, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 4, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 4, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 0, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 29)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 4, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 4, (3, 0), -1, None)\n",
      "((3, 0), 0, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 15)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 2, (0, 4), -1, None)\n",
      "((0, 4), 1, (1, 4), -1, None)\n",
      "((1, 4), 1, (2, 4), -1, None)\n",
      "((2, 4), 1, (3, 4), -1, None)\n",
      "((3, 4), 1, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 3, (0, 1), -1, None)\n",
      "((0, 1), 3, (0, 0), -1, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 2, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 4, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 2, (1, 2), -1, None)\n",
      "((1, 2), 3, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 4, (1, 1), -1, None)\n",
      "((1, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 17)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 3, (0, 2), -1, None)\n",
      "((0, 2), 2, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 0, (0, 3), -1, None)\n",
      "((0, 3), 1, (1, 3), -1, None)\n",
      "((1, 3), 1, (2, 3), -1, None)\n",
      "((2, 3), 1, (3, 3), -1, None)\n",
      "((3, 3), 1, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 13)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 3, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 2, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 4, (2, 0), -1, None)\n",
      "((2, 0), 0, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 2, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 3, (1, 0), -1, None)\n",
      "((1, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 4, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 0, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 2, (0, 2), -1, None)\n",
      "((0, 2), 1, (1, 2), -1, None)\n",
      "((1, 2), 1, (2, 2), -1, None)\n",
      "((2, 2), 1, (3, 2), -1, None)\n",
      "((3, 2), 1, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 2, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 0, (0, 1), -1, None)\n",
      "((0, 1), 1, (1, 1), -1, None)\n",
      "((1, 1), 1, (2, 1), -1, None)\n",
      "((2, 1), 1, (3, 1), -1, None)\n",
      "((3, 1), 1, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 9)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 4, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 0, (0, 0), -1, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 11)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n",
      "((4, 2), 2, (4, 3), -1, None)\n",
      "((4, 3), 2, (4, 4), 0, 7)\n",
      "(None, None, (0, 0), None, None)\n",
      "((0, 0), 1, (1, 0), -1, None)\n",
      "((1, 0), 1, (2, 0), -1, None)\n",
      "((2, 0), 1, (3, 0), -1, None)\n",
      "((3, 0), 1, (4, 0), -1, None)\n",
      "((4, 0), 2, (4, 1), -1, None)\n",
      "((4, 1), 2, (4, 2), -1, None)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m         pygame\u001b[39m.\u001b[39mquit()\n\u001b[1;32m     38\u001b[0m \u001b[39mprint\u001b[39m(step)\n\u001b[0;32m---> 39\u001b[0m gameDisplay\u001b[39m.\u001b[39;49mfill(white)\n\u001b[1;32m     40\u001b[0m drawGrid(gridSize,gridSize,terminal)\n\u001b[1;32m     41\u001b[0m text \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mrender(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpisode: \u001b[39m\u001b[39m{\u001b[39;00mepisode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, black)\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import time\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "displayWidth = 400\n",
    "topMargin = displayWidth/10\n",
    "displayHeight = displayWidth + topMargin\n",
    "squareSize = displayWidth/gridSize\n",
    "black = (0,0,0)\n",
    "white = (255,255,255)\n",
    "red = (255,0,0)\n",
    "blue = (0,0,255)\n",
    "episode = 1\n",
    "gameDisplay = pygame.display.set_mode((displayWidth,displayHeight))\n",
    "gameDisplay.fill(white)\n",
    "pygame.display.set_caption('SimpleGridVisualisation')\n",
    "\n",
    "font = pygame.font.Font('freesansbold.ttf', 32)\n",
    "\n",
    "#######\n",
    "def drawGrid(width, height, terminal):\n",
    "    pygame.draw.rect(gameDisplay, red, [squareSize*terminal[0], squareSize*terminal[1] + topMargin, squareSize, squareSize])\n",
    "    for w in range(width):\n",
    "        for h in range(height):\n",
    "            pygame.draw.rect(gameDisplay, black, [squareSize*w, squareSize*h + topMargin, squareSize, squareSize], 1)\n",
    "\n",
    "#######\n",
    "\n",
    "def drawAgent(x,y):\n",
    "    pygame.draw.circle(gameDisplay, blue, [squareSize*(x+0.5), squareSize*(y+0.5) + topMargin], squareSize/2)\n",
    "\n",
    "for step in universe.getHistory():\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            pygame.quit()\n",
    "    print(step)\n",
    "    gameDisplay.fill(white)\n",
    "    drawGrid(gridSize,gridSize,terminal)\n",
    "    text = font.render(f\"Episode: {episode}\", True, black)\n",
    " \n",
    "    textRect = text.get_rect()\n",
    "    \n",
    "    textRect.center = (displayWidth // 2, topMargin // 2)\n",
    "    gameDisplay.blit(text, textRect)\n",
    "    drawAgent(step[2][0],step[2][1])\n",
    "    pygame.time.wait(50)\n",
    "    pygame.display.flip()\n",
    "\n",
    "    if step[4] is not None:\n",
    "        episode += 1\n",
    "pygame.quit()\n",
    "quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
